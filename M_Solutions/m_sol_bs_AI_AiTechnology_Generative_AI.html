<!DOCTYPE html>
<html lang="en">

<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>AI Technology : Generative AI</title>
    <link rel="stylesheet" href="/css/monika.css">

    <!-- Font awesome cdn -->
    <link rel="stylesheet" href="/css/all.min.css">
    <!-- Bootstrap -->
    <link href="https://cdn.jsdelivr.net/npm/bootstrap@5.0.2/dist/css/bootstrap.min.css" rel="stylesheet"
        integrity="sha384-EVSTQN3/azprG1Anm3QDgpJLIm9Nao0Yz1ztcQTwFspd3yD65VohhpuuCOmLASjC" crossorigin="anonymous">

    <!-- Font family -->
    <link href="https://fonts.cdnfonts.com/css/intel-clear" rel="stylesheet">
    <style>
        * {
            font-family: 'Intel Clear', sans-serif;
        }
    </style>
</head>

<body>
    <!-- Top Dropdown Start -->
    <section class="m_ai_tdrop">
        <div class="dropdown">
            <button class="btn  dropdown-toggle" type="button" data-bs-toggle="dropdown" aria-expanded="false">
                Artificial Intelligence
            </button>
            <ul class="dropdown-menu">
                <li><a class="dropdown-item" href="m_sol_bs_AI_AiHome.html">AI Home</a></li>
                <li><a class="dropdown-item" href="m_sol_bs_AI_AdvancedAnalyticSolutions.html">Advanced Analytics
                        Solutions</a></li>
                <li><a class="dropdown-item m_dropActive" href="m_sol_bs_AI_AiTechnology.html">AI Technology</a>
                </li>
                <li><a class="dropdown-item" href="m_sol_bs_AI_DeployOnIntelArchitecture.html">Deploy on Intel
                        Architecture</a></li>
                <li><a class="dropdown-item" href="m_sol_bs_AI_hardware.html">Hardware</a></li>
                <li><a class="dropdown-item" href="m_sol_bs_AI_software.html">Software</a></li>
                <li><a class="dropdown-item" href="m_sol_bs_AI_useCases.html">Use Cases</a></li>
            </ul>
        </div>
        <div class="m_ai_shlash">/</div>
        <div class="dropdown">
            <button class="btn dropdown-toggle" type="button" data-bs-toggle="dropdown" aria-expanded="false">
                AI Technology
            </button>
            <ul class="dropdown-menu" style="overflow: auto; height: auto;">
                <li><a class="dropdown-item" href="m_sol_bs_AI_AiTechnology_Classical_Machine_Learning.html">Classical Machine Learning</a></li>
                <li><a class="dropdown-item" href="m_sol_bs_AI_AiTechnology_Computer_Vision.html">Computer Vision</a></li>
                <li><a class="dropdown-item m_dropActive" href="m_sol_bs_AI_AiTechnology_Generative_AI.html">Generative AI</a></li>
                <li><a class="dropdown-item" href="m_sol_bs_AI_AiTechnology_Recommendation_Systems.html">Recommendation Systems</a></li>
            </ul>
        </div>
        <div class="m_ai_shlash">/</div>
        <div class="m_ai_httl">Generative AI</div>
    </section>

    <!-- Top Dropdown End -->


    <!-- hero section -->
    <div class="m_ai_q" style="background-color: #004a86;">
        <div class="m_container">
            <div>
                <a href="" class="text-white m_ai_r"> Learn the Latest in Generative AI</a>
                <p class="m_para text-white m_dNone">Join our new GenAI webinar series to learn about the latest trends
                    and best practices in generative AI from industry leaders and practitioners.</p>
            </div>
        </div>
    </div>
    <div class="m_ai_af">
        <div class="m_container m_marg">
            <div>
                <h2 class="text-white m_ag mb-4">Capture the Power of Generative AI</h2>
                <p class="m_ah text-white">Optimize training and deployment to realize transformative benefits for your business with the purpose-built Intel® AI hardware and software portfolio.</p>
            </div>
            <img src="/img/Monika_img/ai_t11.jpg" alt="">
        </div>
    </div>

    <!-- main body -->
    <div class="m_container mt-3">
        <div class="m_marg">
            <div class="row">
                <div class="col-md-4">
                    <div class=" justify-content-end gap-3 my-3 m_prMailRes">
                        <i class="fa-solid fa-print m_color fs-4"></i>
                        <i class="fa-regular fa-envelope m_color fs-4"></i>
                    </div>
                    <div>
                        <!-- Tracing navbar Start -->
                        <nav class="m_navigation m_sideNav" id="mainNav">
                            <a class="m_navigation__link m_sideNav__link" href="#1">Generative AI Overview</a>
                            <a class="m_navigation__link m_sideNav__link" href="#2">How It Works</a>
                            <a class="m_navigation__link m_sideNav__link" href="#3">Use Cases</a>
                            <a class="m_navigation__link m_sideNav__link" href="#4">Training and Deployment Recommendations</a>
                        </nav>
                        <!-- Tracing navbar End -->
                    </div>
                    <div class="m_lightBg p-3 mt-4">
                        <p class="fw-bold">Key Takeaways</p>
                        <ul>
                            <li>Generative AI can combine different modalities to create images, text, video, or audio in response to a user query.</li>
                            <li>Language AI allows solutions to understand and process human language.</li>
                            <li>Intel® hardware helps accelerate performance for use cases including content creation, translation, and summarization.</li>
                            <li>Intel also provides a range of software and development resources that can help you train and deploy generative AI.</li>
                        </ul>
                    </div>
                </div>
                <div class="col-md-8">

                    <!-- 1 -->
                    <div class="m_page-section m_sideNav_section" id="1">
                        <div class=" justify-content-end gap-3 my-3 m_prMail">
                            <i class="fa-solid fa-print m_color fs-4"></i>
                            <i class="fa-regular fa-envelope m_color fs-4"></i>
                        </div>
                        <div class="m_subHeading mb-5 pb-5">
                            Generative AI solutions give you the ability to create, respond, synthesize, and iterate at an unprecedented pace. Whether you’re creating content, summarizing text, or building AI chatbots that generate dynamic, intelligent responses, these solutions can help your business become faster, more agile, and more responsive. But making the most of them requires a finely tuned balance of performance, cost, and scalability from both your hardware and software technology selections.
                        </div>
                        <h3 class="m_subHeading">What Is Generative AI?</h3>
                        <p class="m_para2">
                            Generative AI has delivered a sizable impact on the world in a relatively short period of time. Through this technology, engaging and informative text can be generated out of simple user inputs. Intelligent, responsive, and human-like digital chatbots can help customers—without any involvement from an employee. Beautiful images, video, or audio can be created almost instantly in response to any query you can imagine.
                        </p>
                        <p class="m_para2">
                            Generative AI is made possible by massive sets of data and intricately trained AI algorithms, requiring significant efforts from data scientists and developers to ensure the output or experience that their business needs. Ideally, they’re deployed on powerful, carefully selected hardware that delivers the low latency and fast response times required for these workloads within budget constraints.
                        </p>
                        <p class="m_para2">
                            In general, generative AI refers to AI solutions that generate content—whether it’s a demand generation email, a fantastic landscape, or a dynamic chatbot reply—in response to a user prompt. Solutions built using these technologies, such as ChatGPT, Stable Diffusion, and Dall-E, are making headlines every day, and organizations everywhere are seeking ways to operationalize them and capture their game-changing value.
                        </p>
                        <p class="m_para2">
                            Generative AI is trained on sets of unstructured data using transformer models that require data scientists and developers to fine-tune the output or experience that their business needs.
                        </p>
                        <p class="m_para2">
                            Organizations looking to apply generative AI to their business challenges have the option to train models from scratch or select a pretrained model that can be fine-tuned to the needs of their business.
                        </p>
                        <p class="m_para2">
                            Generative AI is built on and deployed in conjunction with language AI and natural language processing (NLP), which allow AI to process and understand human language. Together, generative AI and NLP can understand a user prompt to generate an appropriate response, whether it’s text, video, imagery, or audio.
                        </p>
                    </div>

                    <!-- 2 -->
                    <div class="m_page-section m_sideNav_section mt-5 pt-5" id="2">
                        <h3 class="m_subHeading">How Does Generative AI Work?</h3>
                        <p class="m_para2">
                            Generative AI is enabled by extensive data sets that “teach” AI models how to respond to user prompts. Generative AI models find commonalities between similar types of data and information to create new content. Model training is also informed by the input of data scientists and subject matter experts who help guide the algorithm’s learning and shepherd it toward more-accurate outputs.
                        </p>
                        <p class="m_para2">
                            To enable generative AI solutions, open source models can be customized to fit an organization’s unique needs. For example, a generalized AI chatbot algorithm can be trained to the specific attributes of an organization’s customer base and business model. Or, as another example, a model intended to generate text to be used in content marketing can be further specialized or fine-tuned to focus on a specific industry and target audience. More domain-specific models are also emerging at a rapid pace. These are trained on smaller, more targeted data sets than larger models. Emerging results indicate these smaller models can replicate the accuracy of larger ones if trained on carefully sourced data.
                        </p>
                        <p class="m_para2">
                            Generative AI solutions make use of a branch of AI called large language models (LLMs). These are language AI models that employ deep neural networks to process and generate text. They’re trained on massive amounts of text data and are designed to deliver coherent, meaningful outputs. LLMs rely on transformer architectures to process input sequences in a parallel fashion, which improves performance and speed compared to traditional neural networks.
                        </p>
                    </div>

                    <!-- 3 -->
                    <div class="m_page-section m_sideNav_section mt-5 pt-5" id="3">
                        <div>
                            <h3 class="m_subHeading">Generative AI and Language AI Use Cases</h3>
                            <p class="m_para2 mb-0">
                                Together, generative AI and language AI can be combined to create new tools, services, and applications, including:
                            </p>
                            <ul>
                                <li class="m_para2"><span class="fw-bold">Content generation:</span> Automatically create articles, blog posts, product descriptions, and other written materials.</li>
                                <li class="m_para2"><span class="fw-bold">Chatbots:</span> Power dynamic and intelligent conversational AI models that your customers can interact with through text or speech.</li>
                                <li class="m_para2"><span class="fw-bold">Image, video, and audio generation:</span> Create new visuals and sounds by examining preexisting materials and working against a user prompt.</li>
                                <li class="m_para2"><span class="fw-bold">Language translation:</span> Translate text from one language to another.</li>
                                <li class="m_para2"><span class="fw-bold">Data augmentation:</span> Create synthetic data for other machine learning models to help improve their accuracy and performance.</li>
                                <li class="m_para2"><span class="fw-bold">Text summarization:</span> Summarize large pieces of text into a concise format so readers can quickly understand the main points and ideas.</li>
                            </ul>
                            <div class="m_para2">
                                To learn about more AI use cases, including those outside of language and generative AI, <a href="" class="m_ai_link">visit the Intel® AI use cases overview.</a> 
                            </div>
                        </div>
                    </div>

                    <!-- 3 -->
                    <div class="m_page-section m_sideNav_section mt-5 pt-5" id="4">
                        <h3 class="m_subHeading">Training and Deploying Generative AI with Intel® Technologies</h3>
                        <p class="m_para2">
                            Putting the power of generative AI to work for your business is a matter of balancing speed, cost, and scale. To help you deploy generative AI capabilities confidently, Intel offers a purpose-built portfolio of both hardware and software technologies that combine to help streamline your initiative and accelerate ROI. Our mission is to enable AI innovators to deploy AI anywhere it is needed—from the edge to the cloud and data center—with optimal performance, scalability, and cost.
                        </p>

                        <h3 class="m_subHeading mt-4 pt-3">Software Resources to Simplify Generative AI Training and Deployment</h3>
                        <p class="m_para2">
                            Intel offers developers and data scientists <a href="" class="m_ai_link"> a wide range of software tools and optimizations</a> that can help maximize performance and dramatically boost productivity both during training and deployment.
                        </p>
                        <p class="m_para2">
                            For popular data science frameworks such as <a href="" class="m_ai_link">PyTorch</a>  and <a href="" class="m_ai_link">TensorFlow</a>, we offer optimizations that provide significant performance boosts on Intel® architecture. As part of our oneAPI unified programming language, we offer the <a href="" class="m_ai_link">Intel® oneAPI Deep Neural Network Library</a> with highly optimized implementations of deep learning building blocks. The <a href="" class="m_ai_link">oneAPI® unified programming model</a> can also be used to support heterogeneous hardware platforms with less effort from development teams.
                        </p>
                        <p class="m_para2">
                            The <a href="" class="m_ai_link">Intel® Extension for Transformers</a> is another critical tool that can help you accelerate transformer-based models on Intel® platforms. This toolkit features a seamless user experience for model compression, advanced software optimizations, a unique compression-aware runtime, and optimized model packages, including Stable Diffusion, GPT-J-6BM, and BLOOM-176B.
                        </p>
                        <p class="m_para2">
                            Additionally, through our partnership with Accenture, we offer a range of <a href="" class="m_ai_link">reference kits</a> that can help kick-start your generative or language AI project.
                        </p>

                        <h3 class="m_para2 mt-4 pt-3 fw-bold">Intel® Distribution of OpenVINO™ Toolkit</h3>
                        <p class="m_para2">
                            The <a href="" class="m_ai_link">Intel® Distribution of OpenVINO™ toolkit</a> helps developers save time and accelerate results as they develop and deploy generative AI. This open source toolkit empowers developers to write code once and deploy it anywhere. You can easily convert and optimize models for popular frameworks—including TensorFlow, PyTorch, and Caffe—and deploy them with accelerated performance across the various types of hardware architectures required by your AI strategy.
                        </p>
                        <p class="m_para2">
                            To get started, check out the <a href="" class="m_ai_link">Image Generation with Stable Diffusion</a> and <a href="" class="m_ai_link">Text-to-Image Generation with ControlNet</a> Conditioning notebooks on GitHub.
                        </p>
                        <p class="m_para2">
                            You can also consult <a href="" class="m_ai_link">this article for more details about using Stable Diffusion on Intel® GPUs and CPUs</a> with the Intel® Distribution of OpenVINO™ toolkit.
                        </p>

                        <h3 class="m_para2 mt-4 pt-3 fw-bold">Hugging Face Partnership for Generative AI</h3>
                        <p class="m_para2">
                            To facilitate generative AI and language AI training and innovation,<a href="" class="m_ai_link"> Intel has teamed up with Hugging Face</a>, a popular platform for sharing AI models and data sets. Most notably, Hugging Face is known for its <a href="" class="m_ai_link">transformers library built for NLP</a>.
                        </p>
                        <p class="m_para2">
                            We’ve worked with Hugging Face to build state-of-the-art hardware and software acceleration to train, fine-tune, and predict with transformer models. The hardware acceleration is driven by <a href="" class="m_ai_link">Intel® Xeon® Scalable processors</a>, while the software acceleration is enabled by our portfolio of optimized AI software tools, frameworks, and libraries.
                        </p>
                        <p class="m_para2">
                            <a href="" class="m_ai_link">Optimum Intel</a> provides an interface between the Hugging Face transformers library and our different tools and libraries that accelerate end-to-end pipelines on Intel® architectures, including <a href="" class="m_ai_link">Intel® Neural Compressor</a>. <a href="" class="m_ai_link">Intel Labs</a>, <a href="" class="m_ai_link">UKP Lab</a>, and Hugging Face have also collaborated to build <a href="" class="m_ai_link">SetFit</a>, an efficient framework for few-shot fine-tuning of <a href="" class="m_ai_link">sentence transformers</a>.
                        </p>
                        <p class="m_para2">
                            Intel’s Habana® Gaudi® <a href="" class="m_ai_link">deep learning accelerators</a> are also paired with Hugging Face open source software through the <a href="" class="m_ai_link">Habana® Optimum Library</a> to enable developer ease of use on thousands of models optimized by the Hugging Face community.
                        </p>
                        <p class="m_para2">
                            Hugging Face has also published several evaluations of Habana® Gaudi®2 performance on generative AI models: <a href="" class="m_ai_link">Stable Diffusion, T5-3B</a>, <a href="" class="m_ai_link">BLOOMZ 176B and 7B</a>, and the new <a href="" class="m_ai_link">BridgeTower model</a>.
                        </p>
                        <p class="m_para2">
                            <a href="" class="m_ai_link">Additional resources for running Stable Diffusion via the Intel® Distribution of OpenVINO™ toolkit are also available via Hugging Face.</a>
                        </p>
                        <p class="m_para2 mb-0">
                            To learn more about how Intel and Hugging Face can help you plan and optimize your generative and AI efforts, visit:
                        </p>
                        <ul>
                            <li class="m_para2">
                                <a href="" class="m_ai_link">Blog: Fine-tuning Stable Diffusion Models on Intel® CPUs</a>
                            </li>
                            <li class="m_para2">
                                <a href="" class="m_ai_link">Blog: Accelerating Stable Diffusion Inference on Intel® CPUs</a>
                            </li>
                            <li class="m_para2">
                                <a href="" class="m_ai_link">Blog: Optimizing Stable Diffusion for Intel® CPUs with NNCF and Hugging Face Optimum</a>
                            </li>
                            <li class="m_para2">
                                <a href="" class="m_ai_link">Blog: Accelerating PyTorch Transformers with Intel® Xeon® Scalable processors, part 1</a>
                            </li>
                            <li class="m_para2">
                                <a href="" class="m_ai_link">Blog: Accelerating PyTorch Transformers with 4th Gen Intel® Xeon® Scalable processors, part 2</a>
                            </li>
                            <li class="m_para2">
                                <a href="" class="m_ai_link">SetFit Webinar: Few-Shot Learning in Production</a>
                            </li>
                            <li class="m_para2">
                                <a href="" class="m_ai_link">Optimize Transformer Models with Tools from Intel and Hugging Face</a>
                            </li>
                        </ul>

                        <h3 class="m_subHeading mt-4 pt-3">Hardware Recommendations for Generative AI Training and Deployment</h3>
                        <p class="m_para2">
                            While the right software tool set is essential to successful generative and language AI deployment, hardware also plays an integral role. As AI has progressed from the lab to everyday use, scalability and sustainability have become chief concerns for both training and inferencing.
                        </p>
                        <p class="m_para2">
                            The computational requirements for deploying your generative or language AI models vary greatly based on the number of parameters involved. The same is true for training the model. No matter the scale of your initiative, Intel offers a hardware solution that’s right for you.
                        </p>
                        
                        <h3 class="m_para2 mt-4 pt-3 fw-bold">Large-Scale Training and Inference: Habana® Gaudi®2</h3>
                        <p class="m_para2">
                            Large-scale training, fine-tuning, and inference of generative AI workloads require specialized AI hardware, which is where our <a href="" class="m_ai_link">Habana® solutions</a> come into play.
                        </p>
                        <p class="m_para2">
                            Depending on your training and deployment needs, Habana® Gaudi®2 deployments can scale from a single accelerator to a multi thousand Habana® Gaudi®2 cluster composed of eight accelerator-enabled AI servers. <a href="" class="m_ai_link">On Intel® Developer Cloud, you can explore the advantages of running training and inference workloads on the Habana® Gaudi®2 platform.</a>
                        </p>
                        <p class="m_para2">
                            To learn more about the advanced performance capabilities of Habana® Gaudi®2 solutions, see <a href="" class="m_ai_link">https://habana.ai/blog/.</a>
                        </p>

                        <h3 class="m_para2 mt-4 pt-3 fw-bold">Medium-Scale Training and Inference: Intel® Xeon® Scalable Processors with Integrated Accelerator Engines or Discrete Graphics</h3>
                        <p class="m_para2">
                            Generally, we recommend <a href="" class="m_ai_link">Intel® Xeon® Scalable processors</a> for generative AI inference model fine-tuning and less-demanding training workloads. These solutions can be augmented with a discrete GPU for more-advanced workloads.
                        </p>
                        <p class="m_para2 mb-0">
                            To maximize the cost-effectiveness of your deployment, the latest Intel® Xeon® Scalable processors feature two powerful, integrated AI acceleration engines:
                        </p>
                        <ul>
                            <li class="m_para2">
                                <a href="" class="m_ai_link">Intel® Advanced Matrix Extensions (Intel® AMX)</a> for optimizing deep learning training and inference workloads through a specialized architecture.
                            </li>
                            <li class="m_para2">
                                <a href="" class="m_ai_link">Intel® Auto Mixed Precision (Intel® AMP) </a> to accelerate training and boost memory efficiency by leveraging both single-precision (32-bit) and half-precision (16-bit) representations.
                            </li>
                        </ul>
                        <p class="m_para2">
                            By taking advantage of these integrated features, you can use Intel® Xeon® Scalable processors to support more-demanding inferencing and training workloads without investing in specialized hardware. This helps boost the cost efficiency and scalability of your AI solution.
                        </p>

                        <h3 class="m_para2 mt-4 pt-3 fw-bold">Small-Scale Inference: Intel® Core® Processors with Integrated or Discrete Graphics</h3>
                        <p class="m_para2">
                            For basic inferencing tasks, including edge deployments, <a href="" class="m_ai_link">Intel® Core™ Ultra processors</a> can be deployed to maximize cost efficiency while still meeting performance needs. These processors feature integrated graphics that can handle many low-complexity inferencing tasks. They can also be augmented with <a href="" class="m_ai_link">Intel® Arc™ graphics</a> to improve performance and support more complexity.
                        </p>
                        <p class="m_para2 mb-0">
                            Additionally, Intel® Core™ Ultra processors also deliver high-performance inferencing capabilities for complex workloads via powerful integrated graphics capabilities or through augmentation with discrete graphics accelerators. By relying on general-purpose CPUs for inferencing, you can enhance overall flexibility with support for a wider array of workloads as your needs change.
                        </p>
                        
                        <h3 class="m_subHeading mt-4 pt-3">Start Building on the Intel® AI Platform Today</h3>
                        <p class="m_para2">
                            The breadth and depth of the Intel® AI hardware and software portfolios provide myriad ways to pursue AI innovation with confidence, minimized risk, and maximum flexibility. We’re ready to help your generative and language AI initiative succeed—whether you’re training a model from scratch, fine-tuning an existing algorithm, or seeking a way to run advanced inferencing at scale.
                        </p>
                        <p class="m_para2 mb-0">
                            To learn more about our comprehensive AI portfolio and further explore how you can benefit from Intel® technologies, visit:
                        </p>
                        <ul>
                            <li class="m_para2">
                                <a href="" class="m_ai_link">Intel® AI processors</a>
                            </li>
                            <li class="m_para2">
                                <a href="" class="m_ai_link">Intel® AI software</a> 
                            </li>
                        </ul>
                    </div>
                </div>
            </div>


        </div>
    </div>

    <div class="m_container py-5">
        <div class="m_ai_hh">
            <h1 class="m_mainHeading text-start mb-0">Related Content</h1>

            <div class="row">
                <div class="col-md-4 col-sm-6 mt-3">
                    <div>
                        <h4 class="m_subHeading m_color m_underline mt-3">Classical Machine Learning</h4>
                        <p class="m_para">
                            Get deployment and training insights for supporting classical machine learning workloads. 
                        </p>
                        <a href="" class="m_para m_ai_link">Read the article</a>
                    </div>
                </div>
                <div class="col-md-4 col-sm-6 mt-3">
                    <div>
                        <h4 class="m_subHeading m_color m_underline mt-3">Computer Vision</h4>
                        <p class="m_para">
                            Find out how to train and deploy computer vision models using Intel® hardware and software.
                        </p>
                        <a href="" class="m_para m_ai_link">Read the article</a>
                    </div>
                </div>

                <div class="m_separator1">
                    <div class="m_line"></div>
                    <h2 class="m_showMore"><i class="fa-solid fa-angle-down"></i>Show more</h2>
                    <div class="m_line"></div>
                </div>

                <div class="col-md-4 col-sm-6 mt-3 m_hidden">
                    <div>
                        <h4 class="m_subHeading m_color m_underline mt-3">Recommendation Systems</h4>
                        <p class="m_para">
                            Learn how you can drive revenue and enhance the customer experience by cost-effectively deploying AI-driven recommendation engines.
                        </p>
                        <a href="" class="m_para m_ai_link">Read the article</a>
                    </div>
                </div>

                <div class="m_separator2">
                    <div class="m_line"></div>
                    <h2 class="m_showLess"><i class="fa-solid fa-angle-up"></i>Show less</h2>
                    <div class="m_line"></div>
                </div>
            </div>
        </div>
    </div>

</body>
<!-- jQuery -->
<script src="/js/jquery-3.7.1.js"></script>
<!-- Font awesome -->
<script src="/js/all.min.js"></script>

<!-- Bootstrap -->
<script src="https://cdn.jsdelivr.net/npm/bootstrap@5.0.2/dist/js/bootstrap.bundle.min.js"
    integrity="sha384-MrcW6ZMFYlzcLA8Nl+NtUVF0sA7MsXsP1UyJoMp4YLEuNSfAP+JcXn/tWtIaxVXM"
    crossorigin="anonymous"></script>
<!-- Script -->
<script src="/js/monika.js"></script>


</html>