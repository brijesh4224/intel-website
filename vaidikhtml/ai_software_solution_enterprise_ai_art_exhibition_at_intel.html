<!DOCTYPE html>
<html lang="en">

<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>Enterprise AI Art Exhibition at Intel Vision 2024</title>

    <link rel="stylesheet" href="../css/mv_ai_software_solution_enterprise_ai_art_exhibition_at_intel.css">

    <!-- header footer -->
    <link rel="stylesheet" href='/css/yatri.css'>

    <link href="https://cdn.jsdelivr.net/npm/bootstrap@5.0.2/dist/css/bootstrap.min.css" rel="stylesheet"
        integrity="sha384-EVSTQN3/azprG1Anm3QDgpJLIm9Nao0Yz1ztcQTwFspd3yD65VohhpuuCOmLASjC" crossorigin="anonymous">
    <script src="https://cdn.jsdelivr.net/npm/bootstrap@5.0.2/dist/js/bootstrap.bundle.min.js"
        integrity="sha384-MrcW6ZMFYlzcLA8Nl+NtUVF0sA7MsXsP1UyJoMp4YLEuNSfAP+JcXn/tWtIaxVXM"
        crossorigin="anonymous"></script>
    <link href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/6.6.0/css/all.min.css" rel="stylesheet">

</head>

<body>

    <!-- header -->
    <div id="navbar"></div>

    <!-- Intel AMX ? -->
    <section>
        <div class="mv_intel_amx_bg_color">
            <div class="container">
                <div class="row mv_intel_amx_content">
                    <div class="col-md-8 col-sm-12 mv_intel_amx_item">
                        <div class="mv_intel_amx">
                            <h2>Enterprise AI Art Exhibition at Intel Vision 2024</h2>
                            <p class="mv_intel_amx_heading_text">Real-Time Fine-Tuning on Stable Diffusion with the
                                Intel<sup>®</sup> Gaudi<sup>®</sup> AI Accelerator</p>
                        </div>
                    </div>
                    <div class="col-md-4 col-sm-6 col-8 mv_intel_amx_item">
                        <div class="mv_intel_amx_image">
                            <img src="/img/mv_image/parallel-universe-issue-57-2024-rwd_480-270.webp" alt="">
                        </div>
                    </div>
                </div>
            </div>
        </div>
    </section>

    <section class="container py-5">
        <div class="row">
            <div class="d-flex justify-content-end col-xl-10 py-3 d-md-none">
                <i class="fa-solid fa-print fs-4 px-2 " style="color:#0068B5"></i>
                <i class="fa-regular fa-envelope fs-4 px-2" style="color:#0068B5"></i>
            </div>
            <div class="col-lg-3 col-md-4">
                <!-- nav -->
                <div class="VK_sticky_side_bar VK_side_bar_postion_stickey">
                    <div>
                        <div class="VK_sidebar_dropdown">
                            <p class="m-0">
                                <a href="#MV_demo" class="text-decoration-none VK_a">
                                    Demo Overview
                                </a>
                            </p>
                            <details>
                                <summary>
                                    <a href="#MV_tutorial" class="text-decoration-none VK_a">
                                        Tutorial: Create Your Own Stable Diffusion Art
                                    </a>
                                </summary>
                                <ul class="list-unstyled ps-3 mb-0">
                                    <li>
                                        <a href="#MV_dreamBooth"
                                            class="text-decoration-none VK_a my-1">
                                            DreamBooth Fine-Tuning
                                        </a>
                                    </li>
                                    <li>
                                        <a href="#MV_fine"
                                            class="text-decoration-none VK_a my-1">
                                            Fine-Tuning on Intel Gaudi
                                        </a>
                                    </li>
                                </ul>
                            </details>
                            <p class="m-0">
                                <a href="#MV_use_text" class="text-decoration-none VK_a">
                                    Use Text Prompts to Generate Fine-Tuned Images
                                </a>
                            </p>
                        </div>
                    </div>
                </div>
                <!-- thinkcode -->
                <div class="">
                    <div class="dk_things_code mt-4">
                        <h6 style="font-weight: 700; margin-bottom: 11px;">Get the Latest on All Things CODE</h6>
                        <!-- sign up button -->
                        <div class="dk_get_code">
                            <button class="dk_button">Sign Up</button>
                        </div>
                    </div>
                    <p class="mb-0"><b>Srinarayan Srikanthan and Preethi Venkatesh</b></p>
                    <p class="mt-2 mv_think_text">Intel Corporation</p>
                </div>
            </div>
            <div class="col-lg-9 col-md-8">
                <div class="d-md-flex justify-content-end col-xl-10 py-3 d-none">
                    <i class="fa-solid fa-print fs-4 px-2 " style="color:#0068B5"></i>
                    <i class="fa-regular fa-envelope fs-4 px-2" style="color:#0068B5"></i>
                </div>
                <div class="col-xl-10 VK_all_sections">
                    <div style="padding-bottom: 16px;">
                        <p>The Enterprise AI Art Exhibition at Intel Vision 2024 gave attendees a chance to run the
                            opensource Stable Diffusion model on Intel<sup>®</sup> Gaudi<sup>®</sup> AI accelerator to
                            create their own unique pieces of art. A standout feature of the demo was the practical
                            application of few-shot training, which allowed participants to create artwork in real time,
                            offering a tangible example of how AI can be harnessed in an enterprise setting to foster
                            creativity and innovation.</p>
                        <p>This demo is described below, along with a tutorial to show you how to run it yourself.</p>
                    </div>
                    <section id="MV_demo">
                        <h3 style="font-weight: 350; margin: 0.5rem 0 11px;">Demo Overview</h3>
                        <p>
                            We highlighted the capabilities of an Intel Gaudi hardware and software stack to create a
                            custom artwork based on Stable Diffusion. The demo involved fine-tuning a variant of the
                            Stable Diffusion 1.5 model called <a class="b_special_a1" href="">Dreamlike Diffusioniik</a>
                            with a limited set of images utilizing the <a class="b_special_a1" href="">Dreambooth</a>
                            fine-tuning technique, showcasing the potential for personalized art generation with minimal
                            data. The Intel Gaudi processors along with <a class="b_special_a1"
                                href="">optimum-habana</a> provided the necessary computational power, enabling fast
                            model training.
                        </p>
                        <p>The base model is Stable Diffusion 1.5-based Dreamlike Diffusion 1.0. DreamBooth fine-tuning
                            is a method to personalize text-to-image models like Stable Diffusion given just a few (3-5)
                            images of a subject.</p>
                        <div class="text-center dk_f1_vision">
                            <img src="/img/mv_image/f1-vision-2024-ai-art.png" alt="">
                        </div>
                        <p style="padding-top: 1.5rem;">The resulting fine-tuned model can generate unique artwork based
                            on user prompts, e.g.:</p>
                        <div class="text-center dk_f2_vision">
                            <img src="/img/mv_image/f2-vision-2024-ai-art.png" alt="">
                        </div>
                        <p style="text-align: center; padding-top: 2rem;">
                            <em>
                                Prompt: a dreamlike vision of the universe swirling within close-up side portrait of
                                solo gaudigeekatintel, fluid, constellations and nebulae, dreamlike art, fantasy, star
                                trek aesthetic, vibrant pastel color aesthetic, concept art, sharp focus, flawless skin,
                                pastel colors, digital painting, hd, dramatic lighting, trending in art station
                            </em>
                        </p>
                        <p>You can watch the <a class="b_special_a3" href="">recorded version</a> of the demo from Intel
                            Vision 2024.</p>
                    </section>
                    <section id="MV_tutorial">
                        <h2 style="font-weight: 350; margin: 2.5rem 0 11px; font-size: 1.8rem;">Tutorial: Create Your Own Stable Diffusion Art</h2>
                    </section>
                    <section id="MV_dreamBooth">
                        <h3 style="font-weight: 400;">DreamBooth Fine-Tuning</h3>
                        <p class="mb-0">
                            The demo uses dreambooth fine-tuning on Stable Diffusion 1.5 to create custom art for your
                            own images (resized to 512 x 512 resolution). Four environment variables must be set:
                        </p>
                        <ol>
                            <li><strong>MODEL_NAME:</strong> Set this to the Dreamlike Diffusion 1.0 model
                                “dreamlike-art/dreamlike-diffusion-1.0,” which is Stable Diffusion 1.5 fine-tuned on
                                high quality art, made by <a class="b_special_a3" href="">dreamlike.art.</a></li>
                            <li><strong>INSTANCE_DIR:</strong> Set this to the directory (e.g.,
                                /home/art_studio/gaudigeekatintel/) with 3-5 input images: front, right side, and left
                                side pictures of the subject resized to 512 x 512 at shoulder level with good lighting
                                and a plain background (see example images below). Note that the subject’s reference or
                                the name must be as unique as possible (e.g., “gaudigeekatintel”). For ease of use, this
                                reference name will be used throughout the tutorial to create the model artifacts.</li>
                            <li><strong>OUTPUT_DIR</strong>Set this to output directory to store the fine-tuned model
                                (e.g., /home/art_studio/dd_model_gaudigeekatintel).</li>
                            <li><strong>CLASS_DATA_DIR:</strong> Set this to the directory with images of the class
                                being trained on. In this case, download sample images of men and women that will be
                                used by dreambooth fine-tuning to generate human-like images. Refer to this <a
                                    class="b_special_a3" href="">Kaggle dataset</a> to choose about 50 images each of
                                “men” and “women,” preferably JPEG, and save in a directory named
                                /home/art_studio/person.</li>
                            <div class="text-center mt-3 dk_f3_vision">
                                <img src="../img/mv_image/f3-vision-2024-ai-art.png" alt="">
                            </div>
                        </ol>
                    </section>
                    <section id="MV_fine">
                        <h3 style="font-weight: 400;">Fine-Tuning on Intel Gaudi</h3>
                        <p>Launch the Gaudi docker image and mount the volume of all the directories created above:</p>
                        <!-- code toolbar -->
                        <div class="mv_code_toolbar">
                            <div class="mv_toolbar_item mv_copy_icon">
                                <i class="fa-regular fa-copy"></i>
                            </div>
                            <div class="mv_copy_message text-end hidden">Copied</div>
                            <div class="d-flex mv_pre">
                                <div class="">
                                    <div class="mv_code text-break code-content">
                                        <span>cd /home/art_studio
                                            <br>
                                            <br>
                                            docker run -it --runtime=habana \
                                            <br>
                                            -e HABANA_VISIBLE_DEVICES=all \
                                            <br>
                                            -e OMPI_MCA_btl_vader_single_copy_mechanism=none \
                                            <br>
                                            --cap-add=sys_nice \
                                            <br>
                                            --net=host \
                                            <br>
                                            --ipc=host \
                                            <br>
                                            -v $(pwd):/home \
                                            <br>
                                            vault.habana.ai/gaudi-docker/1.15.1/ubuntu22.04/
                                            habanalabs/pytorch-installer-2.2.0:latest</span>
                                    </div>
                                </div>
                            </div>
                        </div>
                        <p>Additionally, install optimum-habana:</p>
                        <!-- code toolbar -->
                        <div class="mv_code_toolbar">
                            <div class="mv_toolbar_item mv_copy_icon">
                                <i class="fa-regular fa-copy"></i>
                            </div>
                            <div class="mv_copy_message text-end hidden">Copied</div>
                            <div class="d-flex mv_pre">
                                <div class="">
                                    <div class="mv_code text-break code-content">
                                        <p>pip install optimum-habana==v1.11.0
                                            <br>
                                            pip install peft
                                        </p>
                                    </div>
                                </div>
                            </div>
                        </div>
                        <p>Setup all the environment variables in the container:</p>
                        <!-- code toolbar -->
                        <div class="mv_code_toolbar">
                            <div class="mv_toolbar_item mv_copy_icon">
                                <i class="fa-regular fa-copy"></i>
                            </div>
                            <div class="mv_copy_message text-end hidden">Copied</div>
                            <div class="d-flex mv_pre">
                                <div class="">
                                    <div class="mv_code text-break code-content">
                                        <p>export MODEL_NAME="dreamlike-art/dreamlike-diffusion-1.0" <br>
                                            export INSTANCE_DIR="/home/gaudigeekatintel/"<br>
                                            export OUTPUT_DIR="/home/dd_model_gaudigeekatintel"<br>
                                            export CLASS_DATA_DIR="/home/person"</p>
                                    </div>
                                </div>
                            </div>
                        </div>
                        <p>Clone the optimum-habana git repo:Clone the optimum-habana git repo:</p>
                        <!-- code toolbar -->
                        <div class="mv_code_toolbar">
                            <div class="mv_toolbar_item mv_copy_icon">
                                <i class="fa-regular fa-copy"></i>
                            </div>
                            <div class="mv_copy_message text-end hidden">Copied</div>
                            <div class="d-flex mv_pre">
                                <div class="">
                                    <div class="mv_code text-break code-content">
                                        <p>git clone -b v1.11.0 https://github.com/huggingface/optimum-habana.git</p>
                                    </div>
                                </div>
                            </div>
                        </div>
                        <p>Support for optimum-habana with dreambooth fine-tuning is being added via the <a
                                class="b_special_a3" href="">PR</a>, which gives users the ability to run fine-tuning on
                            Gaudi-based architectures. If the PR is still under review, use the dream_booth branch:</p>
                        <!-- code toolbar -->
                        <div class="mv_code_toolbar">
                            <div class="mv_toolbar_item mv_copy_icon">
                                <i class="fa-regular fa-copy"></i>
                            </div>
                            <div class="mv_copy_message text-end hidden">Copied</div>
                            <div class="d-flex mv_pre">
                                <div class="">
                                    <div class="mv_code text-break code-content">
                                        <p>cd optimum-habana <br>
                                            git checkout dream_booth <br>
                                            cd examples/stable-diffusion/training/</p>
                                    </div>
                                </div>
                            </div>
                        </div>
                        <p class="mb-0">When you’re training AI models on Intel Gaudi processors, the first time you run
                            your training script, optimum-habana takes extra time to build a complex map of
                            computations, known as a graph. This graph is tailored to the hardware to ensure efficient
                            processing. The is a one-time warmup cost for the specific use-case. You’ll need to run just
                            once for the first subject’s three images, after which the graph can be used to fine-tune
                            for subsequent subjects. To build the graph, you control the recipe cache with the
                            environment variable,<span
                                style="background-color: #E6E6E6;">PT_HPU_RECIPE_CACHE_CONFIG</span>, which needs three
                            pieces of information, separated by commas:</p>
                        <ol>
                            <li>Where to save the graph (a path on your computer, like /tmp/recipe_cache).</li>
                            <li>Whether to delete the graph after use (False means keep it, True means delete it).</li>
                            <li>How big the cache can be (in megabytes, like 1024 for 1 GB).</li>
                        </ol>
                        <p>For example:</p>
                        <!-- code toolbar -->
                        <div class="mv_code_toolbar">
                            <div class="mv_toolbar_item mv_copy_icon">
                                <i class="fa-regular fa-copy"></i>
                            </div>
                            <div class="mv_copy_message text-end hidden">Copied</div>
                            <div class="d-flex mv_pre">
                                <div class="">
                                    <div class="mv_code text-break code-content">
                                        <p>PT_HPU_RECIPE_CACHE_CONFIG=/tmp/recipe_cache,False,1024 python</p>
                                    </div>
                                </div>
                            </div>
                        </div>
                        <p>This will create the graph and store it in the given location for subsequent reuse.</p>
                        <p>Run the train_dreambooth.py script with the following parameters and five steps to create the
                            graph. Please note that this step only needs to be run once on the specified bare-metal
                            system or container. It is not required to repeat this process for subsequent runs, whether
                            using the same or a different subject’s image once the graph is saved in the cache.</p>
                        <!-- code toolbar -->
                        <div class="mv_code_toolbar">
                            <div class="mv_toolbar_item mv_copy_icon">
                                <i class="fa-regular fa-copy"></i>
                            </div>
                            <div class="mv_copy_message text-end hidden">Copied</div>
                            <div class="d-flex mv_pre">
                                <div class="">
                                    <div class="mv_code text-break code-content">
                                        <p>PT_HPU_RECIPE_CACHE_CONFIG=/tmp/dld_recipe_cache,False,1024 \ <br>
                                            python train_dreambooth.py \ <br>
                                            --pretrained_model_name_or_path=$MODEL_NAME \ <br>
                                            --instance_data_dir $INSTANCE_DIR \ <br>
                                            --output_dir=$OUTPUT_DIR \ <br>
                                            --class_data_dir=$CLASS_DATA_DIR \ <br>
                                            --with_prior_preservation \ <br>
                                            --prior_loss_weight=1.0 \ <br>
                                            --instance_prompt="gaudigeekatintel" \ <br>
                                            --class_prompt="person" \ <br>
                                            --train_batch_size=1 \ <br>
                                            --gradient_accumulation_steps=1 \ <br>
                                            --learning_rate=2e-6 \ <br>
                                            --lr_scheduler="constant" \ <br>
                                            --lr_warmup_steps=0 \ <br>
                                            --max_train_steps=5 \ <br>
                                            --gaudi_config_name Habana/stable-diffusion \ <br>
                                            --train_text_encoder \ <br>
                                            --center_crop \ <br>
                                            --num_class_images=12 \ <br>
                                            --seed=0 \ <br>
                                            --prior_generation_precision bf16 full</p>
                                    </div>
                                </div>
                            </div>
                        </div>
                        <p>Now run the train_dreambooth.py script for 350 steps to fully fine-tune on the subject’s
                            image. This step will reuse the graph saved in /tmp/dld_recipe_cache.</p>
                        <!-- code toolbar -->
                        <div class="mv_code_toolbar">
                            <div class="mv_toolbar_item mv_copy_icon">
                                <i class="fa-regular fa-copy"></i>
                            </div>
                            <div class="mv_copy_message text-end hidden">Copied</div>
                            <div class="d-flex mv_pre">
                                <div class="">
                                    <div class="mv_code text-break code-content">
                                        <p>PT_HPU_RECIPE_CACHE_CONFIG=/tmp/dld_recipe_cache,False,1024 \ <br>
                                            python train_dreambooth.py \ <br>
                                            --pretrained_model_name_or_path=$MODEL_NAME \ <br>
                                            --instance_data_dir $INSTANCE_DIR \<br>
                                            --output_dir=$OUTPUT_DIR \<br>
                                            --class_data_dir=$CLASS_DATA_DIR \<br>
                                            --with_prior_preservation \<br>
                                            --prior_loss_weight=1.0 \<br>
                                            --instance_prompt="gaudigeekatintel" \<br>
                                            --class_prompt="person" \<br>
                                            --train_batch_size=1 \<br>
                                            --gradient_accumulation_steps=1 \<br>
                                            --learning_rate=2e-6 \<br>
                                            --lr_scheduler="constant" \<br>
                                            --lr_warmup_steps=0 \<br>
                                            --max_train_steps=350 \<br>
                                            --gaudi_config_name Habana/stable-diffusion \<br>
                                            --train_text_encoder \<br>
                                            --center_crop \<br>
                                            --num_class_images=12 \<br>
                                            --seed=0 \<br>
                                            --prior_generation_precision bf16 full</p>
                                    </div>
                                </div>
                            </div>
                        </div>
                        <p>This will use the saved graph with the best parameters to fine-tune the model for your images
                            saved in the INSTANCE_DIR. The fine-tuned model will be saved in OUTPUT_DIR. Fine-tuning
                            with the saved graph will take about 3-4 minutes to run on a single Gaudi card. This version
                            of the demo setup is targeted for a single card, but we are currently optimizing the
                            workloads to run on eight cards.</p>
                    </section>
                    <section id="MV_use_text">
                        <h3 style="font-weight: 350; margin: 2.5rem 0 11px;">Use Text Prompts to Generate Fine-Tuned
                            Images</h3>
                        <p>Example output from this demo is shown below. The following example script uses
                            optimum-habana’s diffusers classes to run the Stable Diffusion pipeline and scheduler. It
                            loads the fine-tuned model and generates a portrait based on the input prompt. The prompt we
                            are trying here is “portrait of solo gaudigeekatintel in a multiverse universe with planets,
                            moons and solar flares, star trek, pastel colors, blue and purple tone background, dramatic
                            lighting, trending in art station.” Be sure to enter the instance prompt used in the
                            dreambooth fine-tuning to create your own portrait.</p>
                        <p>
                        <!-- code toolbar -->
                        <div class="mv_code_toolbar">
                            <div class="mv_toolbar_item mv_copy_icon">
                                <i class="fa-regular fa-copy"></i>
                            </div>
                            <div class="mv_copy_message text-end hidden">Copied</div>
                            <div class="d-flex mv_pre">
                                <div class="">
                                    <div class="mv_code text-break code-content">
                                        <p>import torch <br>
                                            import os <br>
                                            from optimum.habana.diffusers import GaudiStableDiffusionPipeline,
                                            GaudiDDIMScheduler <br><br>

                                            # Setting the Scheduler <br>
                                            scheduler = GaudiDDIMScheduler.from_pretrained( <br>
                                            "dreamlike-art/dreamlike-diffusion-1.0", <br>
                                            subfolder="scheduler"<br>
                                            ) <br><br>

                                            # Using the Intel Gaudi stable diffusion pipeline <br>
                                            pipeline = GaudiStableDiffusionPipeline.from_pretrained(
                                            “/home/dd_model_gaudigeekatintel”, <br>
                                            subfolder="scheduler"<br>
                                            use_habana=True,<br>
                                            use_hpu_graphs=True,<br>
                                            gaudi_config="Habana/stable-diffusion"<br>
                                            )<br><br>

                                            negative_prompt="easynegative, head covered, face covered, helmet, not
                                            indoors, no flashy jewelry, not indian bride, two men, two women, two
                                            persons, two heads, two bodies, duplicate person, multiple person, mirror
                                            reflection, eye color change, low quality, worst quality:1.4, bad anatomy,
                                            bad composition, out of frame, ugly, old person with wrinkles, morbid,
                                            mutilated, out of frame, extra fingers, mutated hands, poorly drawn hands,
                                            poorly drawn face, mutation, deformed, ugly, blurry, bad anatomy, bad
                                            proportions, extra limbs, cloned face, disfigured, out of frame, ugly, extra
                                            limbs, bad anatomy, gross proportions, malformed limbs, missing arms,
                                            missing legs, extra arms, extra legs, mutated hands, fused fingers, too many
                                            fingers, long neck, watermark, signature, text, deformed nose, deformed
                                            lips" <br><br>

                                            #Use the instance label used in the –-instance_prompt flag of dreambooth
                                            fine-tuning instead of “gaudigeekatintel”
                                            prompt=" portrait of solo gaudigeekatintel in a multiverse universe with
                                            planets, moons and solar flares, star trek, pastel colors, blue and purple
                                            tone background, dramatic lighting, trending in art station" <br><br>

                                            image = pipeline(prompt, height=536, width=960, negative_prompt=
                                            negative_prompt, num_inference_steps=150, guidance_scale=7).images[0]
                                            <br><br>

                                            output_path= '/home/output/' <br>
                                            os.makedirs(output_path)<br>
                                            filename='gaudigeekatintel.png'<br>
                                            os.path.join(output_path, filename)</p>
                                    </div>
                                </div>
                            </div>
                        </div>
                        <div class="text-center dk_f4_vision">
                            <img src="../img/mv_image/f4-vision-2024-ai-art.png" alt="">
                        </div>
                        <p class="text-center mt-3"> <i>Prompt: portrait of solo gaudigeekatintel in a multiverse
                                universe with planets, moons and solar flares, star trek, pastel colors, blue and purple
                                tone background, dramatic lighting, trending in art station</i></p>
                        <div class="text-center dk_f5_vision">
                            <img src="../img/mv_image/f5-vision-2024-ai-art.png" alt="">
                        </div>
                        <p class="text-center mt-3"> <i>Prompt: create a captivating book cover of Patatintel as an
                                astronaut in space, face not covered, bring illuminating large planet , dramatic
                                lighting, 4k, trending in art station, sharp focus, flawless skin, photorealistic,
                                dreamart, hd</i></p>
                        <div class="text-center dk_f6_vision">
                            <img src="../img/mv_image/f6-vision-2024-ai-art.png" alt="">
                        </div>
                        <p class="text-center mt-3"> <i>Prompt: photorealistic close-up portrait of solo
                                Christophatintel with suit, futuristic cityscape dominated with skyscraper with
                                electronic gadgets, dramatic lighting, trending in art station</i></p>
                        <div class="text-center dk_f7_vision">
                            <img src="../img/mv_image/f7-vision-2024-ai-art.png" alt="">
                        </div>
                        <p class="text-center mt-3"> <i>Prompt: portrait of solo Sriatintel in the interstellar space,
                                dressed in the space suit from the movie interstellar, black hole, moons, universe, make
                                it look like a movie poster, dramatic lighting, trending in art station</i></p>
                        <p>You can try this tutorial on Gaudi instances available in the <a class="b_special_a3"
                                href="">Intel <sup>®</sup> Tiber<sup>™</sup> Developer Cloud<sup>1</sup></a> or on <a
                                class="b_special_a3" href="">AWS.</a> For more information, please reach out to <a
                                class="b_special_a3" href="">Intel AI Framework</a> support.</p>
                    </section>
                </div>
            </div>
        </div>
    </section>

    <!-- Discover More -->
    <section>
        <div class="mv_discover_more_padd">
            <div class="container">
                <div class="mv_explore_resources">
                    <div class="mv_explore_resources_content">
                        <h2 class="mb-2">The Parallel Universe Magazine - Issue #57</h2>
                        <p>Intel’s quarterly magazine for software innovation helps you take your software development
                            into the future with the latest tools, tips, and training to expand your expertise.
                        </p>
                    </div>
                    <div class="mv_intel_tiber_content row">
                        <div class="mv_intel_tiber col-xxl-4 col-md-6">
                            <div class="mv_intel_card">
                                <div class="mv_intel_tiber_img">
                                    <i class="fa-regular fa-newspaper"></i>
                                </div>
                                <div style="align-content: center;">
                                    <a href="" class="dk_issue">
                                        AI PC Brings Larger LLM Development to Your Desk</a>
                                </div>
                            </div>
                        </div>
                        <div class="mv_intel_tiber col-xxl-4 col-md-6">
                            <div class="mv_intel_card">
                                <div class="mv_intel_tiber_img">
                                    <i class="fa-regular fa-newspaper"></i>
                                </div>
                                <div style="align-content: center;">
                                    <a href="" class="dk_issue">Low-Bit Quantized Open LLM Leaderboard</a>
                                </div>
                            </div>
                        </div>
                        <div class="mv_intel_tiber col-xxl-4 col-md-6">
                            <div class="mv_intel_card">
                                <div class="mv_intel_tiber_img">
                                    <i class="fa-regular fa-newspaper"></i>
                                </div>
                                <div style="align-content: center;">
                                    <a href="" class="dk_issue">Enterprise AI Art Exhibition at Intel Vision 2024</a>
                                </div>
                            </div>
                        </div>
                        <div class="mv_intel_tiber col-xxl-4 col-md-6">
                            <div class="mv_intel_card">
                                <div class="mv_intel_tiber_img">
                                    <i class="fa-regular fa-newspaper"></i>
                                </div>
                                <div style="align-content: center;">
                                    <a href="" class="dk_issue">

                                        Accelerating GGUF Models with Transformers</a>
                                </div>
                            </div>
                        </div>
                        <div class="mv_intel_tiber col-xxl-4 col-md-6">
                            <div class="mv_intel_card">
                                <div class="mv_intel_tiber_img">
                                    <i class="fa-regular fa-newspaper"></i>
                                </div>
                                <div style="align-content: center;">
                                    <a href="" class="dk_issue">
                                        Run LLMs on Intel® GPUs Using llama.cpp</a>
                                </div>
                            </div>
                        </div>
                        <div class="mv_intel_tiber col-xxl-4 col-md-6">
                            <div class="mv_intel_card">
                                <div class="mv_intel_tiber_img">
                                    <i class="fa-regular fa-newspaper"></i>
                                </div>
                                <div style="align-content: center;">
                                    <a href="" class="dk_issue">
                                        Accelerate Simulations and Backpropagation with Python* and C++ Analytics</a>
                                </div>
                            </div>
                        </div>
                        <div class="mv_intel_tiber col-xxl-4 col-md-6">
                            <div class="mv_intel_card">
                                <div class="mv_intel_tiber_img">
                                    <i class="fa-regular fa-newspaper"></i>
                                </div>
                                <div style="align-content: center;">
                                    <a href="" class="dk_issue">
                                        Accelerate Memory-Bandwidth-Bound Kernels Using the Intel® Data Streaming Accelerator (Intel® DSA)</a>
                                </div>
                            </div>
                        </div>
                        <div class="mv_intel_tiber col-xxl-4 col-md-6">
                            <div class="mv_intel_card">
                                <div class="mv_intel_tiber_img">
                                    <i class="fa-solid fa-bell"></i>
                                </div>
                                <div style="align-content: center;">
                                    <a href="" class="dk_issue">
                                        Check out the Latest Issue</a>
                                </div>
                            </div>
                        </div>
                    </div>
                </div>
            </div>
        </div>
    </section>

    <section style="border-top: 1px solid #d7d7d7;" class="container py-5">
        <h4 class="h6">Product and Performance Information</h4>
        <div class="disclaimer" style="font-size: 12px;"><sup>1</sup> Formerly Intel® Developer Cloud</div>
        <div class="disclaimer" style="font-size: 12px;"><sup>2</sup> Performance varies by use, configuration and other factors. Learn more at <a class="b_special_a1" href="">www.Intel.com/PerformanceIndex.</a></div>
        </div>
    </section>

    <!-- footer -->
    <div id="footer"></div>

    <!-- script header and footer -->
    <script>
        // navbar include  
        fetch('/y_index/y_navbar.html')
            .then(response => response.text())
            .then(data => {
                document.getElementById('navbar').innerHTML = data;
            });
        // footer include 
        fetch('/y_index/y_footer.html')
            .then(response => response.text())
            .then(data => {
                document.getElementById('footer').innerHTML = data;
            });
    </script>

    <!-- nav script -->
    <script>
        document.addEventListener('DOMContentLoaded', function () {
        if (document.getElementsByClassName('VK_all_sections section') && document.getElementsByClassName('VK_sidebar_dropdown')) {
            const sections = document.querySelectorAll('.VK_all_sections section');
            const navLinks = document.querySelectorAll('.VK_sidebar_dropdown a');
            const detailsElements = document.querySelectorAll('.VK_sidebar_dropdown details');

            function removeActiveClass() {
                navLinks.forEach(link => link.classList.remove('VK_sidebar_active_link'));
                detailsElements.forEach(details => {
                    details.removeAttribute('open');
                    details.setAttribute('close', ''); // Optional: to visually indicate it's closed
                });
            }

            function activateLinkAndDetails(targetId) {
                navLinks.forEach(link => {
                    if (link.getAttribute('href') === `#${targetId}`) {
                        link.classList.add('VK_sidebar_active_link');
                        let parentDetails = link.closest('details');

                        // Open all ancestor details elements
                        while (parentDetails) {
                            parentDetails.setAttribute('open', '');
                            parentDetails.removeAttribute('close'); // Optional: remove the closed indicator
                            parentDetails = parentDetails.parentElement.closest('details');
                        }
                    }
                });
            }

            function onScroll() {
                let currentSection = '';
                sections.forEach(section => {
                    const sectionTop = section.getBoundingClientRect().top;
                    const sectionBottom = section.getBoundingClientRect().bottom;

                    // Check if the section is in view
                    if (sectionTop <= 100 && sectionBottom >= 0) {
                        currentSection = section.getAttribute('id');
                    }
                });

                if (currentSection) {
                    removeActiveClass();
                    activateLinkAndDetails(currentSection);
                } else {
                    removeActiveClass();
                }
            }

            window.addEventListener('scroll', onScroll);
        } else {
            return
        }
    });
    </script>

    <!-- copy script -->
    <script>
        document.addEventListener("DOMContentLoaded", () => {
            document.querySelectorAll(".mv_copy_icon").forEach((icon) => {
                icon.addEventListener("click", async function () {
                    try {
                        const toolbar = this.closest(".mv_code_toolbar");
                        const codeBlock = toolbar.querySelector(".code-content");
                        const codeContent = codeBlock.innerText;
    
                        // Use Clipboard API to copy text
                        await navigator.clipboard.writeText(codeContent);
    
                        // Hide the copy icon and show the "Copied!" message
                        const message = toolbar.querySelector(".mv_copy_message");
                        this.classList.add("hidden"); // Hide the copy icon
                        message.classList.remove("hidden"); // Show the "Copied!" message
    
                        // Hide the message and show the icon again after 2 seconds
                        setTimeout(() => {
                            message.classList.add("hidden");
                            this.classList.remove("hidden");
                        }, 2000); // Adjust delay as needed
    
                    } catch (err) {
                        console.error('Failed to copy text: ', err);
                    }
                });
            });
        });
    </script>
    

</body>
</html>