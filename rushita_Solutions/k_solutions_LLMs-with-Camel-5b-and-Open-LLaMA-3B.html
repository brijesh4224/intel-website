<!DOCTYPE html>
<html lang="en">

<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>LLMs with Camel-5b and Open LLaMA 3B</title>
    <link href="https://cdn.jsdelivr.net/npm/bootstrap@5.0.2/dist/css/bootstrap.min.css" rel="stylesheet"
        integrity="sha384-EVSTQN3/azprG1Anm3QDgpJLIm9Nao0Yz1ztcQTwFspd3yD65VohhpuuCOmLASjC" crossorigin="anonymous">

    <link href=" https://fonts.cdnfonts.com/css/intel-clear " rel="stylesheet">
    <link rel="stylesheet" href="../css/owl.carousel.min.css">
    <link rel="stylesheet" href="../css/yatri.css">
    <link rel="stylesheet" href="../css/rushita.css">
    <link rel="stylesheet" href="../css/rushita_automotive.css">

    <link rel="stylesheet" href="../css/owl.theme.default.min.css">
    <style>
        * {
            font-family: 'Intel Clear', sans-serif;
        }

        .dk_new_options_table {
            border: none !important;
            justify-content: center !important;
            text-align: center !important;
        }

        .dk_new_options_table thead tr td {
            margin-left: 0;
            max-width: fit-content;
            white-space: normal;
            overflow: auto;
            background: #fff;
            padding: 1rem;
            text-align: left;
            border-left: .125rem solid #e2e2e2;
            font-weight: 700 !important;
        }

        .dk_new_options_table thead tr:nth-child(even) td {
            background-color: #f7f7f7;
        }

        .mv_intel_amx h2 {
            font-weight: 300;
        }

        .mv_intel_amx {
            font-size: 1.25rem;
        }

        .mv_intel_amx_bg_color {
            background-color: #0068B5;
        }

        .mv_intel_amx_content {
            padding-right: 200px;
        }

        .mv_intel_amx_item {
            align-content: center;
        }

        .mv_intel_amx {
            color: #fff;
            padding: 1rem;
        }

        .mv_intel_amx h3 {
            font-weight: 300;
        }

        .mv_intel_amx p {
            margin-top: 1.5rem;
            margin-bottom: 0rem;
        }

        .mv_intel_amx_image {
            padding: 1rem;
        }

        .mv_intel_amx_image img {
            width: 100%;
            /* height: 199px; */
        }

        .mv_intel_amx_heading_text {
            font-size: 1.2rem;
            line-height: 1.15;
        }

        .VK_sidebar_active_link {
            color: #262626;
            font-weight: 700;
        }

        .VK_sidebar_active_link:hover {
            color: #262626;
        }

        .VK_print_email_font span {
            font-size: 1.375rem;
        }

        .VK_side_bar_postion_stickey {
            position: sticky;
            top: 0px;
            z-index: 3;
            background-color: #fff;
        }

        .VK_side_heading {
            font-size: 26px;
            font-weight: 400;
        }

        .VK_sidebar_dropdown P {
            margin-left: .313rem !important;
            margin-bottom: .313rem !important;
        }

        .VK_sidebar_dropdown details {
            margin-left: .313rem !important;
            margin-bottom: .313rem !important;
        }
    </style>
</head>

<body>
    <div id="navbar"></div>

    <section class="m_ai_tdrop">
        <div>
            <button class="btn dropdown-toggle" type="button" data-bs-toggle="dropdown" aria-expanded="false">
                Developers
            </button>
            <ul class="dropdown-menu">
                <li><a class="dropdown-item m_dropActive"
                        href="../dhruvin_developer-tools/ds_Developer-Zone.html">Overview</a></li>
                <li><a class="dropdown-item m_dropActive"
                        href="../rushita_Solutions/k_solutions_in_Viewall_SDF_Industrial-Automation_Control-flow-Enforcement_Technology.html">Topics
                        & Technologies</a></li>
                <li><a class="dropdown-item m_dropActive"
                        href="../dhruvin_developer-tools/ds_Development-Tools.html">Tools</a></li>
                <li><a class="dropdown-item m_dropActive"
                        href="../rushita_Solutions/k_solutions_in_Viewall_SDF_Industrial-Automation_Hardware-Platforms.html">Hardware
                        Platforms</a></li>
                <li><a class="dropdown-item m_dropActive"
                        href="../dhruvin_developer-tools/ds_Resource-Documentation-Center.html">Resources &
                        Documentation</a></li>
                <li><a class="dropdown-item m_dropActive" href="../dhruvin_developer-tools/ds_Learn.html">Learn</a>
                </li>
                <li><a class="dropdown-item m_dropActive"
                        href="../dhruvin_developer-tools/ds_Communities-and-Events.html">Community & Events</a></li>
                <li><a class="dropdown-item m_dropActive"
                        href="../dhruvin_developer-tools/ds_Developer-Programs.html">Developer Programs</a></li>
                <li><a class="dropdown-item m_dropActive" href="../dhruvin_developer-tools/ds_Get-Help.html">Get
                        Help</a></li>
            </ul>
        </div>


        <div class="m_ai_shlash">/</div>
        <div>
            <button class="btn dropdown-toggle" type="button" data-bs-toggle="dropdown" aria-expanded="false">
                Tools
            </button>
            <ul class="dropdown-menu">
                <li><a class="dropdown-item m_dropActive" href="../Product/B20_developer_catelog.html">Software
                        Catalog</a></li>
                <li><a class="dropdown-item m_dropActive" href="../Product/B17_oneapi.html">oneAPI</a></li>
                <li><a class="dropdown-item m_dropActive"
                        href="../rushita_Solutions/k_solutions_Intel-Tiber™Edge-Platform.html">Intel® Tiber™ Edge
                        Platform</a></li>
                <li><a class="dropdown-item m_dropActive" href="../Product/B10_intel_Quarts.html">FPGA</a></li>
                <li><a class="dropdown-item m_dropActive" href="../VK_developers/VK_technology_sdk.html">Intel®
                        Active Management Technology SDK</a></li>
                <li><a class="dropdown-item m_dropActive" href="../VK_developers/VK_intel_adviser.html">Intel®
                        Advisor</a></li>
                <li><a class="dropdown-item m_dropActive" href="#">Intel® AI Reference Models</a></li>
                <li><a class="dropdown-item m_dropActive"
                        href="../rushita_Solutions/k_solutions_Intel-Collaboration-Suite-for-WebRTC.html">Intel®
                        Collaboration Suite for WebRTC SDK</a>
                </li>
                <li><a class="dropdown-item m_dropActive" href="../Product/B1_19_Intel_AICloud.html">Intel® Tiber™
                        AI Cloud</a></li>
                <li><a class="dropdown-item m_dropActive"
                        href="../rushita_Solutions/k_solutions_Intel-Distribution-for-Python.html">Intel® Distribution
                        for Python*</a></li>
                <li><a class="dropdown-item m_dropActive"
                        href="../rushita_Solutions/k_solutions_Intel-Distribution-for-GDB.html">Intel® Distribution for
                        GDB*</a></li>
                <li><a class="dropdown-item m_dropActive" href="#">Intel® DPC++ Compatibility Tool</a></li>
                <li><a class="dropdown-item m_dropActive" href="#">Intel® Dynamic Application Loader</a></li>
                <li><a class="dropdown-item m_dropActive"
                        href="../rushita_Solutions/k_solutions_Topics_viewall_Cloud-Insider-Program_AI-Frameworks-and-Tools.html">Frameworks</a>
                </li>
                <li><a class="dropdown-item m_dropActive" href="#">Intel® Embree</a></li>
                <li><a class="dropdown-item m_dropActive" href="../VK_developers/VK_ai_scikit.html">Intel® Extension
                        for Scikit-learn*</a></li>
                <li><a class="dropdown-item m_dropActive"
                        href="../rushita_Solutions/k_solutions_Intel-Fortran-Compiler.html">Intel® Fortran Compiler</a>
                </li>
                <li><a class="dropdown-item m_dropActive" href="#">Intel® Graphics Performance Analyzers</a></li>
                <li><a class="dropdown-item m_dropActive"
                        href="../rushita_Solutions/k_solutions_Intel-HE-Toolkit.html">Intel® Homomorphic Encryption
                        Toolkit</a></li>
                <li><a class="dropdown-item m_dropActive"
                        href="../rushita_Solutions/k_solutions_Intel-In-Band-Manageability.html">Intel® In-Band
                        Manageability</a></li>
                <li><a class="dropdown-item m_dropActive"
                        href="../rushita_Solutions/k_solutions_Intel-Cryptography-Primitives-Library.html">Intel®
                        Integrated Performance Primitives</a></li>
                <li><a class="dropdown-item m_dropActive" href="../rushita_Solutions/">Intel® Integrated Simulation
                        Infrastructure with
                        Modeling</a></li>
                <li><a class="dropdown-item m_dropActive"
                        href="../rushita_Solutions/k_solutions_Instruction-Set-Architecture(ISA)Extensions.html">Instruction
                        Set Architecture (ISA) Extensions</a>
                </li>
                <li><a class="dropdown-item m_dropActive"
                        href="../rushita_Solutions/k_solutions_Intel-Intelligent-Storage-Acceleration-Library.html">Intel®
                        Intelligent Storage Acceleration Library
                        (Intel® ISA-L)</a></li>
                <li><a class="dropdown-item m_dropActive" href="#">Modin*</a></li>
                <li><a class="dropdown-item m_dropActive" href="#">Intel® MPI Library</a></li>
                <li><a class="dropdown-item m_dropActive" href="#">Intel® Neural Compressor</a></li>
                <li><a class="dropdown-item m_dropActive" href="#">OpenCL™ Runtime</a></li>
                <li><a class="dropdown-item m_dropActive" href="#">Intel® Open Image Denoise</a></li>
                <li><a class="dropdown-item m_dropActive" href="#">Intel® Open Path Guiding Library (Intel® Open
                        PGL)</a></li>
                <li><a class="dropdown-item m_dropActive" href="#">Pin</a></li>
                <li><a class="dropdown-item m_dropActive" href="#">Intel® Platform Analysis Library</a></li>
                <li><a class="dropdown-item m_dropActive" href="#">Intel Tools for OpenCL™ Software</a></li>
                <li><a class="dropdown-item m_dropActive" href="#">Intel Tools for OpenCL™ Applications</a></li>
                <li><a class="dropdown-item m_dropActive" href="#">Intel® OpenSWR</a></li>
                <li><a class="dropdown-item m_dropActive" href="#">OpenVINO™ Toolkit</a></li>
                <li><a class="dropdown-item m_dropActive" href="#">Intel® Open Volume Kernel Library</a></li>
                <li><a class="dropdown-item m_dropActive" href="#">Intel® Optimization for XGBoost*</a></li>
                <li><a class="dropdown-item m_dropActive" href="#">Intel® OSPRay</a></li>
                <li><a class="dropdown-item m_dropActive" href="#">Intel® OSPRay for Hydra*</a></li>
                <li><a class="dropdown-item m_dropActive" href="#">Intel® OSPRay Studio</a></li>
                <li><a class="dropdown-item m_dropActive" href="#">PyTorch* Optimizations from Intel</a></li>
                <li><a class="dropdown-item m_dropActive" href="#">TensorFlow* Optimizations from Intel</a></li>
                <li><a class="dropdown-item m_dropActive" href="#">Intel® Rendering Toolkit</a></li>
                <li><a class="dropdown-item m_dropActive" href="#">Intel® Smart Edge Open</a></li>
                <li><a class="dropdown-item m_dropActive" href="#">Intel® Software Guard Extensions</a></li>
                <li><a class="dropdown-item m_dropActive" href="#">Intel® Secure Device Onboard</a></li>
                <li><a class="dropdown-item m_dropActive" href="#">Intel® Software Development Emulator</a></li>
                <li><a class="dropdown-item m_dropActive" href="#">Intel® Trust Domain Extensions (Intel® TDX)</a>
                </li>
                <li><a class="dropdown-item m_dropActive" href="#">Intel® Quantum SDK</a></li>
                <li><a class="dropdown-item m_dropActive" href="#">Intel® Query Processing Library (Intel® QPL)</a>
                </li>
                <li><a class="dropdown-item m_dropActive" href="#">Intel® Video Processing Library</a></li>
                <li><a class="dropdown-item m_dropActive" href="#">Intel® VTune™ Profiler</a></li>
                <li><a class="dropdown-item m_dropActive" href="#">Resellers</a></li>
            </ul>
        </div>
        <div class="m_ai_shlash">/</div>
        <div>
            <button class="btn dropdown-toggle" type="button" data-bs-toggle="dropdown" aria-expanded="false">
                oneAPI
            </button>
            <ul class="dropdown-menu">
                <li><a class="dropdown-item m_dropActive" href="#">Overview</a></li>
                <li><a class="dropdown-item m_dropActive" href="#">Data Parallel C++/SYCL*</a></li>
                <li><a class="dropdown-item m_dropActive" href="#">Toolkits</a></li>
                <li><a class="dropdown-item m_dropActive" href="#">Tech Articles & How-Tos</a></li>
                <li><a class="dropdown-item m_dropActive" href="#">Components</a></li>
                <li><a class="dropdown-item m_dropActive" href="#">Code Samples</a></li>
                <li><a class="dropdown-item m_dropActive" href="#">Training</a></li>
                <li><a class="dropdown-item m_dropActive" href="#">Documentation</a></li>
                <li><a class="dropdown-item m_dropActive" href="#">Support</a></li>
            </ul>
        </div>
        <div class="m_ai_shlash">/</div>
        <div>
            <button class="btn dropdown-toggle" type="button" data-bs-toggle="dropdown" aria-expanded="false">
                Tech Articles & How-Tos
            </button>
            <ul class="dropdown-menu">
                <li><a class="dropdown-item m_dropActive" href="#">Library</a></li>
                <li><a class="dropdown-item m_dropActive" href="#">News Updates</a></li>
                <li><a class="dropdown-item m_dropActive" href="#">Webinars</a></li>
            </ul>
        </div>
        <div class="m_ai_shlash">/</div>
        <div class="m_ai_httl">LLMs with Camel-5b and Open LLaMA 3B
        </div>
    </section>
    <section class="k_bgblue">
        <div class="k_container11">
            <div class="row text-white py-4">
                <h3 class="fw-light">Generative AI Playground: LLMs with Camel-5b and Open LLaMA 3B on the Latest Intel® GPU</h3>
                <p>How Hugging Face and Intel® Technologies Enhanced Performance of Falcon LLM 7-Billion Parameter Model </p>
            </div>
        </div>
    </section>
    <section class="k_space k_spacenone">
        <div class="k_container11">
            <div class="row  g-3">
                <div class="float-end k_bignone" style="padding-left:70%;">
                    <div>
                        <a href="#" class="fs-4"><i class="fa-solid fa-print mx-3 k_icon0"></i></a>
                        <a href="#" class="fs-4"> <i class="fa-regular fa-envelope k_icon0"></i></a>
                    </div>
                </div>
                <div class="col-lg-3 col-md-4 col-sm-12">
                    <div class="VK_sticky_side_bar VK_side_bar_postion_stickey">
                        <div>
                            <div class="VK_sidebar_dropdown">
                                <ul class="k_listnone k_menu ">
                                    <li class="k_text"><a href="#section1">Intel GPU Hardware</a></li>
                                    <li class="k_text"><a href="#section2">Run the LLM Examples</a></li>
                                    <li class="k_text"><a href="#section2">Disclaimer for Using Large Language Models</a></li>
                                   
                                </ul>
                            </div>
                        </div>
                    </div>
                    <div>
                      <p><b>
                        Benjamin Consolvo</b></p>
                    </div>
                </div>
                <div class="col-lg-8 col-md-7 col-sm-12  k_16smpx k_width75">
                    <div class="float-end mx-3 k_smnone">
                        <div>
                            <a href="#" class="fs-4"><i class="fa-solid fa-print mx-3 k_icon0"></i></a>
                            <a href="#" class="fs-4"> <i class="fa-regular fa-envelope k_icon0"></i></a>
                        </div>
                    </div>
                    <div class=" k_smpaddnone k_smpaddnone1 pt-5">
                        <p class="k_plink1 k_intext1blue1">This article was originally published on <a href="#">Medium*</a>.</p>
                        <p class="k_plink1 k_intext1blue1"><img alt="" src="../img/rushita_img/llam5.jpg" width="100%"><br>
                            Figure 1. Photo by <a href="#">Brett Jordan on Unsplash</a></p>
                            <p class="k_plink1 k_intext1blue1"><strong>Oct. 15, 2023—</strong>Large Language Models (LLMs) have taken the world by storm this past year with chatbots, code generation, debugging, retrieval augmented generation (RAG), instruction-following, and many more applications. In this article, I demonstrate LLM inference on the latest <a href="#">Intel® Data Center GPU Max Series 1100</a>.</p>
                            <p>The two LLM models that I worked with are:<br>
                                &nbsp;</p>
                                <ol>
                                    <li class="k_plink1 k_intext1blue1"><a href="#">Camel-5b</a>: Derived from the base architecture of Palmyra-Base, Camel-5b is a 5-billion parameter LLM model, trained on 70 K instruction-response records. The Camel-5b model differentiates itself from other LLMs in being able to take in complex instructions and generate contextually accurate responses.</li>
                                    <li class="k_plink1 k_intext1blue1"><a href="#">Open LLaMA 3B v2</a>: An open source, 3-billion parameter reproduction of the Meta* LLaMA model, trained on a variety of data. The biggest clear advantage to this model is that it builds upon the success of the Meta LLaMA 2 and is permissively licensed for much broader consumption.</li>
                                </ol>
                                <p>Just a note on these particular models—they were not fine-tuned for chat, so your mileage may vary in terms of the responses from these models.</p>

                        <h2 class="fw-light mt-5" id="section1">Intel GPU Hardware </h2>
                        <p class="k_plink1 k_intext1blue1">The particular GPU that I used for my inference test is the <a href="#">Intel Data Center GPU Max Series 1100</a>, which has 48 GB of memory, 56 X<sup>e</sup>-cores, and 300 W of thermal design power. On the command line, I can first verify that I indeed do have the GPUs that I expect by running:</p>
                        <div class="p-3" style="border: 1px solid #CCCCCC;">
                            <div class="float-end px-3">
                                <i class="fa-solid fa-copy fs-4" style="color: #0068B5;"></i>
                            </div>
                            <p>clinfo -l <br>
                               </pre>
                        </div>
                        <p class="pt-4">And I get an output showing that I have access to four Intel GPUs on the current node:</p>
                        <div class="p-3" style="border: 1px solid #CCCCCC;">
                            <div class="float-end p-3">
                                <i class="fa-solid fa-copy fs-4" style="color: #0068B5;"></i>
                            </div>
                            <p><div class="toolbar"><div class="toolbar-item"><i class="fa fa-docs"></i></div></div>Platform #0: Intel(R) OpenCL Graphics <br>
                                +-- Device #0: Intel(R) Data Center GPU Max 1100 <br>
                                
                                +-- Device #1: Intel(R) Data Center GPU Max 1100<br>
                                +-- Device #2: Intel(R) Data Center GPU Max 1100<br>
                                `-- Device #3: Intel(R) Data Center GPU Max 1100<br>
                               </p>
                        </div>
                        <p>Similar to the nvidia-smi function, you can run the xpu-smi in the command line with a few options selected to get the statistics you want on GPU use.</p>
                        <div class="p-3" style="border: 1px solid #CCCCCC;">
                            <div class="float-end px-3">
                                <i class="fa-solid fa-copy fs-4" style="color: #0068B5;"></i>
                            </div>
                            <p>xpu-smi dump -d 0 -m 0,5,18<br>
                               </pre>
                        </div>
                        <p>The result is a printout every 1 s of important GPU use for the device 0:</p>
                        <div class="p-3" style="border: 1px solid #CCCCCC;">
                            <div class="float-end p-3">
                                <i class="fa-solid fa-copy fs-4" style="color: #0068B5;"></i>
                            </div>
                            <p><div class="toolbar"><div class="toolbar-item"><i class="fa fa-docs"></i></div></div>getpwuid error: Success<br>
                                Timestamp, DeviceId, GPU Utilization (%), GPU Memory Utilization (%), GPU Memory Used (MiB) <br>
                                
                                13:34:51.000,    0, 0.02, 0.05, 28.75<br>
                                13:34:52.000,    0, 0.00, 0.05, 28.75<br>
                                13:34:53.000,    0, 0.00, 0.05, 28.75<br>
                                13:34:54.000,    0, 0.00, 0.05, 28.75<br>
                               </p>
                        </div>
                        <h2 class="fw-light mt-5" id="section2">Run the LLM Examples </h2>
                        <p class="k_plink1 k_intext1blue1">My colleague, <a href="#">Rahul Nair</a>, wrote an LLM inference Jupyter* Notebook that is hosted directly on the Intel® Developer Cloud. It gives you the option of using either model that I outlined earlier. Here are the steps you can take to get started:</p>
                        <ol>
                            <li class="k_plink1 k_intext1blue1">Go to <a href="#">Intel Developer Cloud</a>.</li>
                            <li>Register as a standard user.</li>
                            <li class="k_plink1 k_intext1blue1">Once you are logged in, go to the <a href="#">Training and Workshops section</a>.</li>
                            <li>Select <strong>GenAI Launch Jupyter Notebook</strong>. You can find the LLM inference notebook and run it there.</li>
                        </ol>
                        <p>Figure 2 shows the user interface within the LLM notebook. You have the option of selecting a model, interacting with or without context, and then selecting the parameters of <strong>Temperature</strong>, <strong>Top P</strong>, <strong>Top K</strong>, <strong>Num Beams</strong>, and <strong>Rep Penalty</strong>. Their definitions are:<br>
                            &nbsp;</p>
                            <ul>
                                <li><strong>Temperature</strong>: The temperature for controlling randomness in Boltzmann distribution. Higher values increase randomness, lower values make the generation more deterministic.</li>
                                <li><strong>Top P</strong>: The cumulative distribution function (CDF) threshold for nucleus sampling. It helps in controlling the trade-off between randomness and diversity.</li>
                                <li><strong>Top K</strong>: The number of highest probability vocabulary tokens to keep for top-k-filtering.</li>
                                <li><strong>Num Beams</strong>: The number of beams for a beam search. It controls the breadth of the search.</li>
                                <li><strong>Repetition Penalty</strong>: The penalty applied for repeating tokens.</li>
                            </ul>
                            <div class="my-5">
                                <img src="../img/rushita_img/llam6.png" alt="" width="100%">
                            </div>
                            <p>Figure 2. A mini user interface within the Jupyter Notebook environment allows for a text prompt and response in line.</p>
                            <p class="k_plink1 k_intext1blue1">To speed up inference on the Intel GPU, the <a href="#">Intel® Extension for PyTorch*</a> was used. Two of the key functions are:</p>
                            <div class="p-3" style="border: 1px solid #CCCCCC;">
                                <div class="float-end px-3">
                                    <i class="fa-solid fa-copy fs-4" style="color: #0068B5;"></i>
                                </div>
                                <p>ipex.optimize_transformers(self.model, dtype=self.torch_dtype)<br>
                                   </pre>
                            </div>
                            <p>and</p>
                            <div class="p-3" style="border: 1px solid #CCCCCC;">
                                <div class="float-end px-3">
                                    <i class="fa-solid fa-copy fs-4" style="color: #0068B5;"></i>
                                </div>
                                <p>ipex.optimize(self.model, dtype=self.torch_dtype)<br>
                                   </pre>
                            </div>
                            <p class="k_plink1 k_intext1blue1">where <span class="code-simple">self.model</span> is the loaded LLM model, and <span class="code-simple">self.torch_dtype</span> is the data type, which to speed up performance on the Intel GPU should be <span class="code-simple">torch.bfloat16</span>. You can learn more about the Intel Extension for PyTorch in the <a href="#">GitHub* repository</a>.</p>
                            <p>I was able to generate responses with these models within seconds after the model was loaded into memory. As I mentioned, because these models are not fine-tuned for chat, your mileage may vary in terms of the response of the model.</p>
                            <p>You can reach me on:</p>
                            <ul>
                                <li class="k_plink1 k_intext1blue1"><a href="#">DevHub Discord* server</a> (user name <strong>bconsolvo</strong>)</li>
                                <li class="k_plink1 k_intext1blue1"><a href="#">LinkedIn*</a></li>
                                <li class="k_plink1 k_intext1blue1"><a href="#">X (formerly known as Twitter*)</a></li>
                            </ul>
                        <h2 class="fw-light mt-5" id="section3">Disclaimer for Using Large Language Models</h2>
                        <p>Be aware that while LLMs like Camel-5b and OpenLLaMA 3b v2 are powerful tools for text generation, they may sometimes produce results that are unexpected, biased, or inconsistent with the given prompt. It’s advisable to carefully review the generated text and consider the context and application in which you are using these models.</p>
                        <p>Use of these models must also adhere to the licensing agreements and be in accordance with ethical guidelines and best practices for AI. If you have any concerns or encounter issues with the models, refer to the respective model cards and documentation provided in the previous links.</p>
                    </div>
                </div>
            </div>
    </section>
    <section class="my-4" style="font-size: 13px;">
        <div class="k_container11">
            <div class="row">
                <div>
                    <hr class="mb-5">
                    <p>Product and Performance Information </p>
                
                    <div class="k_plink1 k_intext1blue1"><sup>1</sup>Performance varies by use, configuration and other
                        factors. Learn more at &nbsp;<a href="#">www.Intel.com/PerformanceIndex.</a>.
                    </div>
                </div>
            </div>
        </div>
    </section>
    <div id="footer"></div>
    <script>
        // navbar include  
        fetch('../y_index/y_navbar.html')
            .then(response => response.text())
            .then(data => {
                document.getElementById('navbar').innerHTML = data;
            });
        // footer include 
        fetch('../y_index/y_footer.html')
            .then(response => response.text())
            .then(data => {
                document.getElementById('footer').innerHTML = data;
            });
    </script>
    <script src="https://cdn.jsdelivr.net/npm/@splidejs/splide@4.1.4/dist/js/splide.min.js"></script>
    <script src="../js/jquery-3.7.1.js"></script>

    <script src="../js/owl.carousel.min.js"></script>
    <script src="../js/rushita.js"></script>
</body>

</html>