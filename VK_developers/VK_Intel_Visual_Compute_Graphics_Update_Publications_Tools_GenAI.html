<!DOCTYPE html>
<html lang="en">

<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>Document</title>

    <!-- font family -->
    <link href="https://fonts.cdnfonts.com/css/intel-clear" rel="stylesheet">
    <!-- boootstap file -->
    <link href="https://cdn.jsdelivr.net/npm/bootstrap@5.0.2/dist/css/bootstrap.min.css" rel="stylesheet"
        integrity="sha384-EVSTQN3/azprG1Anm3QDgpJLIm9Nao0Yz1ztcQTwFspd3yD65VohhpuuCOmLASjC" crossorigin="anonymous">
    <!-- costom css file -->
    <link rel="stylesheet" href="/css/vivek.css">
    <link rel="stylesheet" href="/css/yatri.css">

    <!-- all.min file -->
    <link rel="stylesheet" href="/css/all.min.css">

</head>

<body>


    <main>

        <!-- header -->
        <header>
            <div id="navbar"></div>
        </header>


        <!-- poster -->
        <section class=" VK_light_blue">
            <div class="VK_cont">
                <div class="row m-0">
                    <div class="col text-white">
                        <h1 class="VK_py_pre_heading fw-light m-0 pt-3 pb-5">
                            Intel Visual Compute & Graphics Lab 2024 Update: New Publications and Tools for GenAI
                        </h1>
                    </div>
                </div>
            </div>
        </section>

        <section>
            <div class="VK_cont py-5 VK_border_bottom">
                <div class="row m-0">
                    <div class="col-md-4 col-lg-3 d-md-block d-none">
                        <div class="VK_sticky_side_bar VK_side_bar_postion_stickey bg-white">
                            <div>
                                <div class="VK_sidebar_dropdown">
                                    <p class="m-0">
                                        <a href="#VK_Highlights" class="text-decoration-none VK_a">
                                            Highlights
                                        </a>
                                    </p>
                                    <p class="m-0">
                                        <a href="#VK_SIGGRAPH_HPG_Highlights" class="text-decoration-none VK_a">
                                            SIGGRAPH and HPG Highlights
                                        </a>
                                    </p>
                                    <details>
                                        <summary>
                                            <a href="#VK_Graphics_Building_Blocks_Creators_GenAI"
                                                class="text-decoration-none VK_a">
                                                Graphics Building Blocks for Creators and GenAI
                                            </a>
                                        </summary>
                                        <ul class="list-unstyled ps-4">
                                            <li>
                                                <a href="#VK_More_Accessible_Differentiable_Rendering"
                                                    class="text-decoration-none VK_a my-1">
                                                    More Accessible Differentiable Rendering
                                                </a>
                                            </li>
                                            <li>
                                                <a href="#VK_Fast_Accessible_Tracing_Python_Intel_Embree_Coming_Soon"
                                                    class="text-decoration-none VK_a my-1">
                                                    Fast and Accessible Ray Tracing in Python* with Intel® Embree Coming
                                                    Soon
                                                </a>
                                            </li>
                                            <li>
                                                <a href="#VK_Recent_Papers_Visual_Compute_Graphics_Lab"
                                                    class="text-decoration-none VK_a my-1">
                                                    Recent Papers from Visual Compute & Graphics Lab
                                                </a>
                                            </li>
                                        </ul>
                                    </details>
                                    <details>
                                        <summary>
                                            <a href="#VK_Rich_Open_Ecosystem_Rendering_Libraries"
                                                class="text-decoration-none VK_a">
                                                A Rich and Open Ecosystem of Rendering Libraries
                                            </a>
                                        </summary>
                                        <ul class="list-unstyled ps-4">
                                            <li>
                                                <a href="#VK_Opening_Development_Intel_Toolkit_Ecosystem_Contributions"
                                                    class="text-decoration-none VK_a my-1">
                                                    Opening the Development of Intel® Rendering Toolkit to Broader
                                                    Ecosystem Contributions
                                                </a>
                                            </li>
                                        </ul>
                                    </details>
                                    <p class="m-0">
                                        <a href="#VK_Enabling_Creator_Rendering_Becoming_Choice_Blender"
                                            class="text-decoration-none VK_a">
                                            Enabling the 3D Creator and Rendering Markets with Intel® Open Image Denoise
                                            Becoming the Default Choice in Blender*
                                        </a>
                                    </p>
                                    <p class="m-0">
                                        <a href="#VK_Path_guiding_Research_Physically_Rendering_ResearchFramework"
                                            class="text-decoration-none VK_a">
                                            Path Guiding Research with Intel® Open PGL in the Physically Based Rendering
                                            (PBRT) Research Framework
                                        </a>
                                    </p>
                                    <p class="m-0">
                                        <a href="#VK_Conclusion" class="text-decoration-none VK_a">
                                            Conclusion
                                        </a>
                                    </p>
                                </div>
                            </div>
                        </div>
                        <div class="mt-4">
                            <div class="d-flex">
                                <div class="VK_profile_img me-3">
                                    <img src="/img/vivek/VK_104.webp" class="w-100 h-100 rounded-circle" alt="">
                                </div>
                                <p>
                                    Anton Kaplanyan is vice president of Graphics Research at
                                    <a href="" class="VK_a VK_testing_gmail_link">
                                        Intel Labs
                                    </a>,
                                    where he focuses on real-time rendering, neural rendering, graphics systems, shading
                                    and appearance, as well as differentiable rendering.
                                </p>
                            </div>
                        </div>
                    </div>
                    <div class="col-12 col-md-8 col-lg-7">
                        <div class="VK_all_sections">
                            <div class="VK_section_descriptions">
                                <div class="text-end">
                                    <p class="m-0 VK_print_email_font">
                                        <span class="VK_a mx-2 d-inline-block">
                                            <i class="fa-solid fa-print"></i>
                                        </span>
                                        <span class="VK_a mx-2 d-inline-block">
                                            <i class="fa-regular fa-envelope"></i>
                                        </span>
                                    </p>
                                </div>
                            </div>
                            <section class="mt-5" id="VK_Highlights">
                                <h3 class="VK_side_heading">
                                    Highlights
                                </h3>
                                <p>
                                    Researchers from the Intel Visual Compute & Graphics (VCG) Lab will present papers
                                    at
                                    <a href="" class="Vk_text_underline_dots VK_a">
                                        SIGGRAPH and High-Performance Graphics (HPG) 2024
                                    </a>
                                    from July 26 through August 1 in Denver, Colorado, US. Researchers from Intel will
                                    explain how N-dimensional Gaussian mixtures can fit high-dimensional functions,
                                    making scene dynamics, variable lighting, and more possible within the same
                                    efficient framework. In a course talk, researchers will introduce a component
                                    implementation for extremely large-scale tiled triangular scenes, enabling bigger
                                    worlds for gamers to explore.
                                </p>
                                <p>
                                    The VCG Lab’s mission is to drive Intel’s graphics and GPU ecosystem, guiding GPU
                                    hardware design, as well as providing new technologies and building blocks for the
                                    broader ecosystem. During the last year, the researchers have investigated
                                    challenging problems in graphics, such as optimizations for content creation and
                                    more efficient geometric and material representations, as well as opening Intel®
                                    technologies and libraries to the broader ecosystem of graphics and AI
                                    practitioners.
                                </p>
                                <ul>
                                    <li>
                                        Researchers from the VCG Lab will present papers and talks at SIGGRAPH and HPG.
                                    </li>
                                    <li>
                                        The VCG Lab shares progress and contributions to the graphics community,
                                        including better representations and rendering techniques, as well as tools for
                                        graphics and 3D generative AI (GenAI).
                                    </li>
                                    <li>
                                        The lab also provides updates on Intel's open ecosystem of libraries to help
                                        graphics and machine learning communities achieve higher-fidelity visuals in the
                                        field of 3D experiences.
                                    </li>
                                </ul>
                            </section>
                            <section class="mt-4" id="VK_SIGGRAPH_HPG_Highlights">
                                <h3 class="VK_side_heading fw-light">
                                    SIGGRAPH and HPG Highlights
                                </h3>
                                <p>
                                    Novel rich scene and material representations are driving the next wave of asset
                                    generation and scanning methods. Neural radiance field (NeRF) and, recently,
                                    Gaussian splats, have been demonstrated as powerful and efficient representations
                                    that can close the loops, such as sensing-to-pixels and generation-to-pixels.
                                    Gaussian splats, a representation for efficient 3D reconstruction, have been
                                    demonstrated as a convenient representation amenable to more localized optimizations
                                    yet still too static for production use due to some fundamental variables baked into
                                    it that limit variability in lighting, materials, scene dynamics, and animations.
                                    The team’s work on
                                    <a href="" class="Vk_text_underline_dots VK_a">
                                        N-Dimensional Gaussians for Fitting of High Dimensional Functions
                                    </a>
                                    expands Gaussian splats to overcome these limitations and will be presented with an
                                    interactive demo at SIGGRAPH 2024 by Stavros Diolatzis (Intel) co-authored with
                                    Tobias Zirr, Alexandr Kuznetsov (Intel), Georgios Kopanas (Inria and Universite Cote
                                    d'Azur) and Anton Kaplanyan (Intel).
                                </p>
                                <div>
                                    <img src="/img/vivek/VK_105.png" class="w-100" alt="">
                                    <p class="text-center">
                                        Figure 1. N-dimensional Gaussians for fitting high-dimensional functions.
                                    </p>
                                </div>
                                <p class="mt-4">
                                    In this work, N-dimensional Gaussian mixtures are employed to fit high-dimensional
                                    functions, making scene dynamics, variable lighting, global illumination, and
                                    complex anisotropic effects possible within the same efficient framework. The method
                                    results in orders of magnitude faster training without sacrificing the quality
                                    achieved by implicit methods. The
                                    <a href="" class="Vk_text_underline_dots VK_a">
                                        presentation and the demo
                                    </a>
                                    will be part of the
                                    <a href="" class="Vk_text_underline_dots VK_a">
                                        SIGGRAPH Radiance Field Processing session.
                                    </a>
                                </p>
                                <p>
                                    Another paper presented at HPG 2024,
                                    <a href="" class="Vk_text_underline_dots VK_a">
                                        Concurrent Binary Trees for Large-Scale Game Components
                                    </a>
                                    introduces a large-scale component implementation suitable for extremely large-scale
                                    tessellated scenes, such as planetary scales, enabling bigger and better worlds for
                                    gaming players to explore. Intel’s Anis Benyoub and Jonathan Dupuy will also give a
                                    talk at the SIGGRAPH course
                                    <a href="" class="Vk_text_underline_dots VK_a">
                                        Advances in Real-Time Rendering in Games, Part II
                                    </a>,
                                    which will expand on this topic of state-of-the-art proven rendering techniques for
                                    fast, real-time, and interactive rendering of complex worlds.
                                </p>
                                <div>
                                    <img src="/img/vivek/VK_106.png" class="w-100" alt="">
                                    <p class="mt-4 text-center">
                                        Figure 2. Concurrent binary trees for large-scale game components.
                                    </p>
                                </div>
                            </section>
                            <section class="mt-4" id="VK_Graphics_Building_Blocks_Creators_GenAI">
                                <h3 class="VK_side_heading fw-light">
                                    Graphics Building Blocks for Creators and GenAI
                                </h3>
                                <p>
                                    As production costs keep shifting toward creating high-quality assets, it becomes
                                    increasingly important for the ecosystem to have efficient tools for the creation
                                    and generation of assets. To this end, we are working on both moving the needle in
                                    the state-of-the-art methods, as well as providing existing high-quality tools to
                                    the community.
                                </p>
                            </section>
                            <section class="mt-4" id="VK_More_Accessible_Differentiable_Rendering">
                                <h3 class="VK_side_heading">
                                    More Accessible Differentiable Rendering
                                </h3>
                                <p>
                                    One content creation building block is called differentiable rendering. It reverses
                                    the process of image rendering and answers the question: What do we need to change
                                    in the scene to match the reference image? This method is widely used in asset
                                    scanning, optimization, and generation. The challenging part of differentiable
                                    rendering is making the existing renderers differentiable. The work,
                                    <a href="" class="Vk_text_underline_dots VK_a">
                                        Transform a Nondifferentiable Rasterizer into a Differentiable Rasterizer with
                                        Stochastic Gradient Estimation,
                                    </a>
                                    shows how to drastically simplify the computations in the differentiable rendering
                                    machinery to make it applicable even to large black box renderers and game engines
                                    that
                                    were not engineered with differentiable rendering in mind. Winning both the Best
                                    Presentation award and Best Paper second place award at the Interactive 3D Graphics
                                    and
                                    Games (I3D) 2024, Intel’s Thomas Deliot, Erich Heitz, and Laurent Belcour show how
                                    to
                                    transform any existing rendering engine into a differentiable one with only a few
                                    compute shaders, amounting to minimal engineering efforts and no external
                                    dependencies.
                                </p>
                                <div>
                                    <img src="/img/vivek/VK_107.png" class="w-100" alt="">
                                    <p class="mt-4 text-center">
                                        Figure 3. Transform a nondifferentiable rasterizer into a differentiable
                                        rasterizer with stochastic gradient estimation.
                                    </p>
                                </div>
                            </section>
                            <section class="mt-4" id="VK_Fast_Accessible_Tracing_Python_Intel_Embree_Coming_Soon">
                                <h3 class="VK_side_heading">
                                    Fast and Accessible Ray Tracing in Python* with Intel® Embree Coming Soon
                                </h3>
                                <p>
                                    Another challenge for content creation lies deeper down in the rendering process
                                    within accelerating the more fundamental ray tracing operation. For example,
                                    multiple recent works on accelerating 3D representations use various accelerating
                                    structures and complex PyTorch* code. Within the ray tracing context, we have Intel
                                    Embree, an Oscar*-winning and thoroughly tested library highly optimized for ray
                                    tracing, which we are happy to expose as a building block to the community of
                                    machine learning practitioners.
                                </p>
                                <div class="d-flex justify-content-center">
                                    <div class="col-md-5 col-lg-4">
                                        <img src="/img/vivek/VK_108.jpg" class="w-100" alt="">
                                    </div>
                                </div>
                                <p>
                                    A new Python* API for
                                    <a href="" class="Vk_text_underline_dots VK_a">
                                        Intel® Embree
                                    </a>
                                    is under development allowing the Python ecosystem and AI practitioners to employ
                                    high-performant ray tracing capabilities of Intel Embree directly in their
                                    Python-based AI research and development. Key abstractions were also added to
                                    low-level API in Intel Embree to ensure good performance by limiting transitions
                                    between Python and C/C++. For more details, see the
                                    <a href="" class="Vk_text_underline_dots VK_a">
                                        development branch on GitHub*.
                                    </a>
                                </p>
                                <p>
                                    The Python API in Intel Embree will be released in the second half of 2024. This
                                    enables efficient ray tracing in the Python and PyTorch ecosystem for efficient
                                    geometric optimizations, differentiable rendering, and 3D GenAI training.
                                </p>
                            </section>
                            <section class="mt-4" id="VK_Recent_Papers_Visual_Compute_Graphics_Lab">
                                <h3 class="VK_side_heading">
                                    Recent Papers from Visual Compute & Graphics Lab
                                </h3>
                                <p>
                                    While good building blocks for new asset generation methods are important, the group
                                    looks at more graphics problems, such as frame extrapolation, perception, and
                                    large-scale visualization.
                                </p>
                                <p>
                                    In addition to geometric representations, advanced materials are as important. A
                                    recent Eurographics Symposium on Rendering (EGSR) 2024 paper on
                                    <a href="" class="Vk_text_underline_dots VK_a">
                                        Nonorthogonal Reduction for Rendering Fluorescent Materials in Nonspectral
                                        Engines,
                                    </a>
                                    by Alban Fichet and Laurent Belcour (Intel) in collaboration with Pascal Barla
                                    (Inria*), is a method to accurately handle fluorescence in a nonspectral (for
                                    example, tristimulus) rendering engine, showcasing color-shifting and increased
                                    luminance effects. Core to the method is a principled reduction technique that
                                    encodes the re-radiation into a low-dimensional matrix working in the space of the
                                    renderer's color-matching functions (CMFs). The reduction technique enables support
                                    for fluorescence in an RGB renderer, including real-time applications.
                                </p>
                                <div>
                                    <img src="/img/vivek/VK_109.png" class="w-100" alt="">
                                    <p class="text-center mt-4">
                                        Figure 4. Nonorthogonal reduction for rendering fluorescent materials in
                                        nonspectral engines.
                                    </p>
                                </div>
                                <p>
                                    This contribution to the state-of-the-art in graphics, as well as new building
                                    blocks for the graphics and machine learning community, will help achieve
                                    higher-quality visuals
                                </p>
                                <p>
                                    A recent SIGGRAPH Asia 2023 work,
                                    <a href="" class="Vk_text_underline_dots VK_a">
                                        ExtraSS: A Framework for Joint Spatial Super Sampling and Frame Extrapolation
                                    </a>,
                                    is a collaboration between Intel and the University of California Santa Barbara. It
                                    introduces a framework that integrates spatial supersampling and frame extrapolation
                                    techniques to enhance real-time rendering performance while achieving a balance
                                    between performance and quality. With its ability to generate temporally stable
                                    high-quality results, the framework creates new possibilities for real-time
                                    rendering applications, advancing the boundaries of performance and photo-realistic
                                    rendering in various domains.
                                </p>
                                <div class="d-flex justify-content-center">
                                    <div class="col-md-7">
                                        <img src="/img/vivek/VK_110.png" class="w-100" alt="">
                                    </div>
                                </div>
                                <p class="mt-4 text-center">
                                    Figure 5. ExtraSS—A framework for joint spatial super-sampling and frame
                                    extrapolation.
                                </p>
                                <p>
                                    Another SIGGRAPH Asia 2023 paper on
                                    <a href="" class="Vk_text_underline_dots VK_a">
                                        The Effect of Display Capabilities on the Gloss Consistency Between Real and
                                        Virtual Objects
                                    </a>
                                    is a collaboration between Intel and scientists across the research community. The
                                    work investigates how display capabilities affect gloss appearance with respect to a
                                    real-world reference object. A series of gloss-matching experiments were conducted
                                    to study how gloss perception degrades based on individual factors: object albedo,
                                    display luminance, dynamic range, stereopsis, and tone mapping.
                                </p>
                                <div>
                                    <img src="/img/vivek/VK_111.png" class="w-100" alt="">
                                    <p class="text-center">
                                        Figure 6. The effect of display capabilities on the gloss consistency between
                                        real and virtual objects.
                                    </p>
                                </div>
                                <p>
                                    <a href="" class="Vk_text_underline_dots VK_a">
                                        Speculative Progressive Raycasting for Memory Constrained Isosurface
                                        Visualization of Massive Volumes
                                    </a>,
                                    published at IEEE Large Data Analysis and Visualization, presents Intel’s
                                    collaborative research with the University of Illinois at Chicago and demonstrates a
                                    novel implicit isosurface rendering algorithm for interactive visualization of
                                    massive volumes within a small memory footprint. This addresses the memory
                                    constraints of lightweight end-user devices encountered when attempting to visualize
                                    the massive data sets produced by today's simulations and data acquisition systems.
                                </p>
                                <div>
                                    <img src="/img/vivek/VK_112.png" class="w-100" alt="">
                                    <p class="text-center mt-4">
                                        Figure 7: Speculative progressive raycasting for memory-constrained isosurface
                                        visualization of massive volumes.
                                    </p>
                                </div>
                            </section>
                            <section class="mt-4" id="VK_Rich_Open_Ecosystem_Rendering_Libraries">
                                <h3 class="VK_side_heading fw-light">
                                    A Rich and Open Ecosystem of Rendering Libraries
                                </h3>
                                <p>
                                    Beyond research papers, the lab has made improvements to our ecosystem of rendering
                                    libraries.
                                </p>
                            </section>
                            <section class="mt-4" id="VK_Opening_Development_Intel_Toolkit_Ecosystem_Contributions">
                                <h3 class="VK_n22">
                                    Opening the Development of Intel® Rendering Toolkit to Broader Ecosystem
                                    Contributions
                                </h3>
                                <div class="d-flex justify-content-center">
                                    <div class="col-md-4">
                                        <img src="/img/vivek/VK_113.png" class="w-100" alt="">
                                    </div>
                                </div>
                                <p class="mt-3">
                                    Based on community feedback, we are making libraries in the
                                    <a href="" class="Vk_text_underline_dots VK_a">
                                        Intel® Rendering Toolkit
                                    </a>
                                    truly open for the community to contribute. Particularly, we opened the internal
                                    development and feature branches, which are now hosted directly on
                                    <a href="" class="Vk_text_underline_dots VK_a">
                                        GitHub
                                    </a>.
                                    We hope this will allow the community to contribute features and functionality
                                    directly and effectively. This new chapter brings more community-funded features and
                                    functionality, development transparency, early development feedback channels, and
                                    cross-platform CI for validation of contributions. The component list includes.
                                </p>
                                <ul>
                                    <li>
                                        <a href="" class="Vk_text_underline_dots VK_a">
                                            Intel® Embree
                                        </a>
                                    </li>
                                    <li>
                                        <a href="" class="Vk_text_underline_dots VK_a">
                                            Intel® Open Image Denoise
                                        </a>
                                    </li>
                                    <li>
                                        <a href="" class="Vk_text_underline_dots VK_a">
                                            Intel® Open Volume Kernel Library (Intel® Open VKL)
                                        </a>
                                    </li>
                                    <li>
                                        <a href="" class="Vk_text_underline_dots VK_a">
                                            Intel® Open Path Guiding Library (Intel® Open PGL)
                                        </a>
                                    </li>
                                    <li>
                                        <a href="" class="Vk_text_underline_dots VK_a">
                                            Intel® OSPRay
                                        </a>
                                    </li>
                                    <li>
                                        <a href="" class="Vk_text_underline_dots VK_a">
                                            Intel® OSPRay Studio
                                        </a>
                                    </li>
                                </ul>
                                <p>
                                    We invite the rendering community to contribute to making Intel Rendering Toolkit
                                    the industry's leading open source, cross-platform, cross-architecture graphics
                                    stack.
                                </p>
                            </section>
                            <section class="mt-5" id="VK_Enabling_Creator_Rendering_Becoming_Choice_Blender">
                                <h3 class="VK_side_heading">
                                    Enabling the 3D Creator and Rendering Markets with Intel® Open Image Denoise
                                    Becoming the Default Choice in Blender*
                                </h3>
                                <p>
                                    <a href="" class="Vk_text_underline_dots VK_a">
                                        Intel Open Image Denoise
                                    </a>
                                    provides full cross-vendor GPU support, running inclusively on Intel, NVIDIA*, AMD*,
                                    and Apple* GPUs. The compelling quality and performance of Intel Open Image Denoise
                                    has led to it being selected as the default denoiser in Blender* on all these
                                    platforms.
                                    <a href="" class="Vk_text_underline_dots VK_a">
                                        Benchmarks
                                    </a>
                                    show Intel® Arc™ A770 GPU outperforming the NVIDIA GeForce RTX 3090, and matching
                                    the performance and price of the higher-end NVIDIA GeForce RTX 4070 in denoising.
                                    The integration into Blender solidifies Intel GPUs as a viable platform in Blender
                                    and allows Intel to continue to improve the Blender experience on current and future
                                    Intel platforms, as well as cross-vendor platforms.
                                </p>
                            </section>
                            <section class="mt-5" id="VK_Path_guiding_Research_Physically_Rendering_ResearchFramework">
                                <h3 class="VK_side_heading fw-light">
                                    Path Guiding Research with Intel® Open PGL in the Physically Based Rendering (PBRT)
                                    Research Framework
                                </h3>
                                <p>
                                    We released an official example integration of
                                    <a href="" class="Vk_text_underline_dots VK_a">
                                        Intel Open PGL
                                    </a>
                                    into a fork of the commonly used
                                    <a href="" class="Vk_text_underline_dots VK_a">
                                        PBRT
                                    </a>
                                    research framework. This integration not only shows some gritty details about how to
                                    robustly integrate a production-ready, path-guiding framework into a rendering
                                    system, but it also enables researchers to build upon and compare against current
                                    state-of-the-art, path-guiding algorithms used in production. Through constant
                                    updates, new Intel Open PGL features will be directly accessible to the rendering
                                    and research community, allowing them to work on open challenges more effectively.
                                    The integration of Intel Open PGL into PBRT is accessible
                                    <a href="" class="Vk_text_underline_dots">
                                        on GitHub.
                                    </a>
                                </p>
                            </section>
                            <section class="mt-5" id="VK_Conclusion">
                                <h3 class="VK_side_heading">
                                    Conclusion
                                </h3>
                                <p>
                                    We are excited to share the progress and contributions of Intel Visual Compute &
                                    Graphics Research (VCG) Lab to the graphics technologies and ecosystem. We hope that
                                    the presented tools for optimizations, new representations and materials, and other
                                    high-profile technologies, as well as the progress in our open ecosystem of graphics
                                    libraries, will inspire the researchers and help the practitioners in graphics and
                                    machine learning communities to achieve higher-fidelity visuals.
                                </p>
                                <div class="VK_bg_e6 p-3 mt-4">
                                    <a href="" class="Vk_text_underline_dots VK_a">
                                        Intel Graphics Research
                                    </a>
                                </div>
                            </section>
                        </div>
                    </div>
                </div>
            </div>
        </section>


        <section class="py-5">
            <div class="VK_cont">
                <div class="row m-0">
                    <div class="col">
                        <p>
                            Product and Performance Information
                        </p>
                        <p class="VK_font14">
                            Performance varies by use, configuration and other factors. Learn more at
                            <a href="" class="Vk_text_underline_dots VK_a">
                                www.Intel.com/PerformanceIndex.
                            </a>
                        </p>
                    </div>
                </div>
            </div>
        </section>


        <!-- footer -->
        <footer>
            <div id="footer"></div>
        </footer>

    </main>



    <!---------------- Javascript Files ---------------->

    <script>
        // navbar include
        fetch('/y_index/y_navbar.html')
            .then(response => response.text())
            .then(data => {
                document.getElementById('navbar').innerHTML = data;
            });
        // footer include 
        fetch('/y_index/y_footer.html')
            .then(response => response.text())
            .then(data => {
                document.getElementById('footer').innerHTML = data;
            });
    </script>

    <!-- jquery -->
    <script src="/js/jquery-3.7.1.js"></script>


    <!-- bootstrap js file -->
    <script src="https://cdn.jsdelivr.net/npm/bootstrap@5.0.2/dist/js/bootstrap.bundle.min.js"
        integrity="sha384-MrcW6ZMFYlzcLA8Nl+NtUVF0sA7MsXsP1UyJoMp4YLEuNSfAP+JcXn/tWtIaxVXM"
        crossorigin="anonymous"></script>

    <!-- costom js file -->
    <script src="/js/vivek.js"></script>

    <!-- all min -->
    <!-- <script src="/js/all.min.js"></script> -->

</body>

</html>