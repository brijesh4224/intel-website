<!DOCTYPE html>
<html lang="en">

<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>OpenMP* Vectorization Support</title>
    <link href="https://cdn.jsdelivr.net/npm/bootstrap@5.0.2/dist/css/bootstrap.min.css" rel="stylesheet"
        integrity="sha384-EVSTQN3/azprG1Anm3QDgpJLIm9Nao0Yz1ztcQTwFspd3yD65VohhpuuCOmLASjC" crossorigin="anonymous">

    <link href=" https://fonts.cdnfonts.com/css/intel-clear " rel="stylesheet">
    <link rel="stylesheet" href="../css/owl.carousel.min.css">
    <link rel="stylesheet" href="../css/yatri.css">
    <link rel="stylesheet" href="../css/rushita.css">
    <link rel="stylesheet" href="../css/rushita_automotive.css">

    <link rel="stylesheet" href="../css/owl.theme.default.min.css">
    <style>
        * {
            font-family: 'Intel Clear', sans-serif;
        }

        .footnote {
            color: #bbb !important;
        }
        .k_tab-container ul li a.active {
            border-bottom: none !important;
            background-color: #FFFFFF !important;
            border: 2px solid #CCCCCC;
        }
    </style>
</head>

<body>
    <div id="navbar"></div>
    <section class="m_ai_tdrop">
        <div>
            <button class="btn dropdown-toggle" type="button" data-bs-toggle="dropdown" aria-expanded="false">
                Developers
            </button>
            <ul class="dropdown-menu">
                <li><a class="dropdown-item m_dropActive"
                        href="../dhruvin_developer-tools/ds_Developer-Zone.html">Overview</a></li>
                <li><a class="dropdown-item m_dropActive"
                        href="../rushita_Solutions/k_solutions_in_Viewall_SDF_Industrial-Automation_Control-flow-Enforcement_Technology.html">Topics
                        & Technologies</a></li>
                <li><a class="dropdown-item m_dropActive"
                        href="../dhruvin_developer-tools/ds_Development-Tools.html">Tools</a></li>
                <li><a class="dropdown-item m_dropActive"
                        href="../rushita_Solutions/k_solutions_in_Viewall_SDF_Industrial-Automation_Hardware-Platforms.html">Hardware
                        Platforms</a></li>
                <li><a class="dropdown-item m_dropActive"
                        href="../dhruvin_developer-tools/ds_Resource-Documentation-Center.html">Resources &
                        Documentation</a></li>
                <li><a class="dropdown-item m_dropActive" href="../dhruvin_developer-tools/ds_Learn.html">Learn</a>
                </li>
                <li><a class="dropdown-item m_dropActive"
                        href="../dhruvin_developer-tools/ds_Communities-and-Events.html">Community & Events</a></li>
                <li><a class="dropdown-item m_dropActive"
                        href="../dhruvin_developer-tools/ds_Developer-Programs.html">Developer Programs</a></li>
                <li><a class="dropdown-item m_dropActive" href="../dhruvin_developer-tools/ds_Get-Help.html">Get
                        Help</a></li>
            </ul>
        </div>
        <div class="m_ai_shlash">/</div>
        <div>
            <button class="btn dropdown-toggle" type="button" data-bs-toggle="dropdown" aria-expanded="false">
                Tools
            </button>
            <ul class="dropdown-menu">
                <li><a class="dropdown-item m_dropActive" href="../Product/B20_developer_catelog.html">Software
                        Catalog</a></li>
                <li><a class="dropdown-item m_dropActive" href="../Product/B17_oneapi.html">oneAPI</a></li>
                <li><a class="dropdown-item m_dropActive"
                        href="../rushita_Solutions/k_solutions_Intel-Tiber™Edge-Platform.html">Intel® Tiber™ Edge
                        Platform</a></li>
                <li><a class="dropdown-item m_dropActive" href="../Product/B10_intel_Quarts.html">FPGA</a></li>
                <li><a class="dropdown-item m_dropActive" href="../VK_developers/VK_technology_sdk.html">Intel®
                        Active Management Technology SDK</a></li>
                <li><a class="dropdown-item m_dropActive" href="../VK_developers/VK_intel_adviser.html">Intel®
                        Advisor</a></li>
                <li><a class="dropdown-item m_dropActive" href="#">Intel® AI Reference Models</a></li>
                <li><a class="dropdown-item m_dropActive" href="../rushita_Solutions/k_solutions_Intel-Collaboration-Suite-for-WebRTC.html">Intel® Collaboration Suite for WebRTC SDK</a>
                </li>
                <li><a class="dropdown-item m_dropActive" href="../Product/B1_19_Intel_AICloud.html">Intel® Tiber™
                        AI Cloud</a></li>
                <li><a class="dropdown-item m_dropActive" href="../rushita_Solutions/k_solutions_Intel-Distribution-for-Python.html">Intel® Distribution for Python*</a></li>
                <li><a class="dropdown-item m_dropActive" href="../rushita_Solutions/k_solutions_Intel-Distribution-for-GDB.html">Intel® Distribution for GDB*</a></li>
                <li><a class="dropdown-item m_dropActive" href="../rushita_Solutions/k_solutions_Intel-DPC++Compatibility-Tool.html">Intel® DPC++ Compatibility Tool</a></li>
                <li><a class="dropdown-item m_dropActive" href="../rushita_Solutions/k_solutions_Intel-Dynamic-Application-Loader.html">Intel® Dynamic Application Loader</a></li>
                <li><a class="dropdown-item m_dropActive"
                        href="../rushita_Solutions/k_solutions_Topics_viewall_Cloud-Insider-Program_AI-Frameworks-and-Tools.html">Frameworks</a>
                </li>
                <li><a class="dropdown-item m_dropActive" href="#">Intel® Embree</a></li>
                <li><a class="dropdown-item m_dropActive" href="../VK_developers/VK_ai_scikit.html">Intel® Extension
                        for Scikit-learn*</a></li>
                <li><a class="dropdown-item m_dropActive" href="../rushita_Solutions/k_solutions_Intel-Fortran-Compiler.html">Intel® Fortran Compiler</a></li>
                <li><a class="dropdown-item m_dropActive" href="../rushita_Solutions/Anal">Intel® Graphics Performance Analyzers</a></li>
                <li><a class="dropdown-item m_dropActive" href="#">Intel® Homomorphic Encryption Toolkit</a></li>
                <li><a class="dropdown-item m_dropActive" href="#">Intel® In-Band Manageability</a></li>
                <li><a class="dropdown-item m_dropActive" href="#">Intel® Integrated Performance Primitives</a></li>
                <li><a class="dropdown-item m_dropActive" href="#">Intel® Integrated Simulation Infrastructure with
                        Modeling</a></li>
                <li><a class="dropdown-item m_dropActive" href="#">Instruction Set Architecture (ISA) Extensions</a>
                </li>
                <li><a class="dropdown-item m_dropActive" href="#">Intel® Intelligent Storage Acceleration Library
                        (Intel® ISA-L)</a></li>
                <li><a class="dropdown-item m_dropActive" href="#">Modin*</a></li>
                <li><a class="dropdown-item m_dropActive" href="#">Intel® MPI Library</a></li>
                <li><a class="dropdown-item m_dropActive" href="#">Intel® Neural Compressor</a></li>
                <li><a class="dropdown-item m_dropActive" href="#">OpenCL™ Runtime</a></li>
                <li><a class="dropdown-item m_dropActive" href="#">Intel® Open Image Denoise</a></li>
                <li><a class="dropdown-item m_dropActive" href="#">Intel® Open Path Guiding Library (Intel® Open
                        PGL)</a></li>
                <li><a class="dropdown-item m_dropActive" href="#">Pin</a></li>
                <li><a class="dropdown-item m_dropActive" href="#">Intel® Platform Analysis Library</a></li>
                <li><a class="dropdown-item m_dropActive" href="#">Intel Tools for OpenCL™ Software</a></li>
                <li><a class="dropdown-item m_dropActive" href="#">Intel Tools for OpenCL™ Applications</a></li>
                <li><a class="dropdown-item m_dropActive" href="#">Intel® OpenSWR</a></li>
                <li><a class="dropdown-item m_dropActive" href="#">OpenVINO™ Toolkit</a></li>
                <li><a class="dropdown-item m_dropActive" href="#">Intel® Open Volume Kernel Library</a></li>
                <li><a class="dropdown-item m_dropActive" href="#">Intel® Optimization for XGBoost*</a></li>
                <li><a class="dropdown-item m_dropActive" href="#">Intel® OSPRay</a></li>
                <li><a class="dropdown-item m_dropActive" href="#">Intel® OSPRay for Hydra*</a></li>
                <li><a class="dropdown-item m_dropActive" href="#">Intel® OSPRay Studio</a></li>
                <li><a class="dropdown-item m_dropActive" href="#">PyTorch* Optimizations from Intel</a></li>
                <li><a class="dropdown-item m_dropActive" href="#">TensorFlow* Optimizations from Intel</a></li>
                <li><a class="dropdown-item m_dropActive" href="#">Intel® Rendering Toolkit</a></li>
                <li><a class="dropdown-item m_dropActive" href="#">Intel® Smart Edge Open</a></li>
                <li><a class="dropdown-item m_dropActive" href="#">Intel® Software Guard Extensions</a></li>
                <li><a class="dropdown-item m_dropActive" href="#">Intel® Secure Device Onboard</a></li>
                <li><a class="dropdown-item m_dropActive" href="#">Intel® Software Development Emulator</a></li>
                <li><a class="dropdown-item m_dropActive" href="#">Intel® Trust Domain Extensions (Intel® TDX)</a>
                </li>
                <li><a class="dropdown-item m_dropActive" href="#">Intel® Quantum SDK</a></li>
                <li><a class="dropdown-item m_dropActive" href="#">Intel® Query Processing Library (Intel® QPL)</a>
                </li>
                <li><a class="dropdown-item m_dropActive" href="#">Intel® Video Processing Library</a></li>
                <li><a class="dropdown-item m_dropActive" href="#">Intel® VTune™ Profiler</a></li>
                <li><a class="dropdown-item m_dropActive" href="#">Resellers</a></li>
            </ul>
        </div>
        <div class="m_ai_shlash">/</div>
        <div>
            <button class="btn dropdown-toggle" type="button" data-bs-toggle="dropdown" aria-expanded="false">
                oneAPI
            </button>
            <ul class="dropdown-menu">
                <li><a class="dropdown-item m_dropActive" href="#">Overview</a></li>
                <li><a class="dropdown-item m_dropActive" href="#">Data Parallel C++/SYCL*</a></li>
                <li><a class="dropdown-item m_dropActive" href="#">Toolkits</a></li>
                <li><a class="dropdown-item m_dropActive" href="#">Tech Articles & How-Tos</a></li>
                <li><a class="dropdown-item m_dropActive" href="#">Components</a></li>
                <li><a class="dropdown-item m_dropActive" href="#">Code Samples</a></li>
                <li><a class="dropdown-item m_dropActive" href="#">Training</a></li>
                <li><a class="dropdown-item m_dropActive" href="#">Documentation</a></li>
            </ul>
        </div>
        <div class="m_ai_shlash">/</div>
        <div>
            <button class="btn dropdown-toggle" type="button" data-bs-toggle="dropdown" aria-expanded="false">
                Tech Articles & How-Tos
            </button>
            <ul class="dropdown-menu">
                <li><a class="dropdown-item m_dropActive" href="#">Library</a></li>
                <li><a class="dropdown-item m_dropActive" href="#">News Updates</a></li>
                <li><a class="dropdown-item m_dropActive" href="#">Webinars</a></li>

            </ul>
        </div>
        <div class="m_ai_shlash">/</div>
        <div class="m_ai_httl">OpenMP* Vectorization Support</div>
    </section>
    <section class="k_bgblue py-4">
        <div class="k_container11">

            <div class="row  g-4">
                <div class="col-md-10 col-sm-12 mx-0 text-white align-content-center k_tstartauto k_text2 px-0 mx-0">
                    <h3 class="fw-lighter   mb-2 k_marketsmall">
                        Delve into the Mysteries of OpenMP* Vectorization Support
                    </h3>
                    <div id="hiddenContent">

                        <div class="d-lg-flex gap-5 mt-4 k_dwrap">
                            <div class="k_mdflex ">
                                <p>ID</p>
                                <p>690515</p>

                            </div>

                            <div class="k_mdflex ">
                                <p>Updated</p>
                                <p style="justify-content: end;">7/28/2020</p>
                            </div>
                            <div class="k_mdflex ">
                                <p>Version</p>
                                <p style="justify-content: end;">Latest</p>
                            </div>
                            <div class="k_mdflex ">
                                <p>&nbsp;</p>
                                <p style="justify-content: end;">Public</p>
                            </div>
                        </div>
                    </div>

                </div>
            </div>
    </section>
    <section class="k_space k_spacenone">
        <div class="k_container11">
            <div class="row  g-3">
                <div class="float-end k_bignone" style="padding-left:70%;">
                    <div>
                        <a href="#" class="fs-4"><i class="fa-solid fa-print mx-3 k_icon0"></i></a>
                        <a href="#" class="fs-4"> <i class="fa-regular fa-envelope k_icon0"></i></a>

                    </div>
                </div>
                <div class="col-lg-3 col-md-4 col-sm-12">
                    <div class="VK_sticky_side_bar VK_side_bar_postion_stickey">
                        <div>
                            <div class="VK_sidebar_dropdown">
                                <ul class="k_listnone k_menu ">
                                    <li class="k_text"><a href="#section1">Simple Vectorization Example</a></li>
                                    <li class="k_text"><a href="#section2">Simple Use of OpenMP SIMD Directives</a></li>
                                    <li class="k_text"><a href="#section3">Advantages of the Intel® Compiler</a></li>
                                    <li class="k_text"><a href="#section4">The safelen Clause</a></li>
                                    <li class="k_text"><a href="#section5">Return of the Simple Example</a>
                                    </li>
                                    <li class="k_text"><a href="#section6">Reduce the Runtime</a></li>
                                    <li class="k_text"><a href="#section7">References</a></li>
                                    <li class="k_text"><a href="#section8">______</a></li>
                                    <li class="k_text"><a href="#section9">You May Also Like</a></li>
                                </ul>
                            </div>
                        </div>
                    </div>
                </div>
                <div class="col-lg-8 col-md-7 col-sm-12  k_16smpx k_width75">
                    <div class="float-end mx-3 k_smnone">
                        <div>
                            <a href="#" class="fs-4"><i class="fa-solid fa-print mx-3 k_icon0"></i></a>
                            <a href="#" class="fs-4"> <i class="fa-regular fa-envelope k_icon0"></i></a>
                        </div>
                    </div>
                    <div class=" k_smpaddnone k_smpaddnone1 pt-5">
                        <h3>How to Use the OpenMP Single Instruction Multiple Data (SIMD) Directive to Tell the Compiler What Code to Vectorize</h3>
                        <div class="row">
                            <div class="col-sm-12 col-md-6">
                                <p>Clay P. Breshears, PhD, principal engineer, Omics Data Automation, Inc.</p>
                                <p class="k_plink1 k_intext1blue1"><a href="#">@IntelDevTools</a></p>
                            </div>
                            <div class="col-sm-12 col-md-6">
                                <p><b>Get the Latest on All Things CODE</b></p>
                                <p class="text-center k_btnlearn py-1 k_text m-auto k_under k_btn100"
                                    style="float: inline-start; width: 120px; background-color: #0068B5;">
                                    <a href="#" class="text-white">Sign Up</a>
                                </p>
                            </div>
                        </div>
                        <p>OpenMP* was created over 20 years ago to provide a standard for compiler-directed threading that's easier to use and understand than an explicit threading library like pthreads. Many of the details about creating and destroying, managing, and assigning computations to threads was abstracted away into compiler directives. Modern CPUs have vector registers that allow the same instruction to be run&nbsp;on multiple pieces of data. Such instruction-level parallelism greatly improves performance and power efficiency. But with thread-level parallelism, the compiler sometimes needs help with getting it right. The SIMD directive and clauses were added to OpenMP to give programmers a way to tell the compiler what computations can be vectorized.</p>


                        <h2 class="fw-light mt-5">Simple Vectorization Example</h2>
                        <p>The code in Figure 1 is used to compute the value of π. This is done by calculating the area under the curve of the function 4.0 / (1.0 + x2) for x between 0 and 1. The general process used in the code is known as numerical integration or Riemann sums.</p>
                        <div class="my-5">
                            <img src="../img/rushita_img/openmp1.jpg" alt="" width="100%">
                        </div>
                        <p style="text-align:center">Figure 1. Riemann sums serial code</p>
                        <p style="text-align:center">&nbsp;</p>
                        <p>If you think back to your linear algebra course, you should recall the midpoint rule of estimating the area under the curve between fixed values on the x-axis. The interval is divided into some number of equal-sized partitions. At the midpoint of each partition, the value of the function is computed. The width of each partition is multiplied by the functional value of the midpoint (or height) to yield the area of a rectangle mostly under the curve. The sum of the areas of all the rectangles across the interval yields a value that's close to the actual numerical answer.</p>
                        <p>Depending on the chosen width, some parts of the rectangle are outside the curve, and some area under the curve that's not within a rectangle. However, the estimate is more precise as the width decreases or as the number of rectangles increase.</p>
                        <p>Notice that the loop in Figure 1 generates a set of values, one at a time, through the loop iterator, <strong>i</strong>. The x variable holds the midpoint value, which is used to compute the functional value (the height of the rectangle at the midpoint). This is to the running total sum. Once the loop is complete, the width of all the rectangles, which is fixed at width, is multiplied by the sum of heights to compute the area. (The actual area multiplication could be done within the loop before adding the value to sum, but as an optimization, it was pulled out of the loop and performed once rather than hundreds of thousands or millions of times.)</p>
                        <p>Each iteration of the loop computing a rectangle’s area is independent. Thus, the loop could be threaded with OpenMP and the partial answers generated within each thread summed together to arrive at an answer. But that's a topic for another article. The aim of this article is to show how this loop can be vectorized.</p>
                        <p>The loop body is performing the same computations over and over again on a range of values generated by each loop iteration. These are an addition and multiplication to compute <strong>x</strong> and a multiplication, addition, and division added to sum. If sets of those values could be loaded into a vector register, those computations could be run&nbsp;in fewer instruction cycles. For the sake of oversimplification, a back-of-the-envelope calculation shows each loop iteration performing six arithmetic operations 10 million times. By packing four or eight values into one register and performing the arithmetic operation on all of those values in a single instruction, the number of running instructions goes from 60 million scalar instructions to 15 million or 7.5 million vector instructions.</p>

                        <h2 class="fw-light mt-5">Simple Use of OpenMP SIMD Directives</h2>
                        <p>Since vector registers need to be populated with multiple values, the basic OpenMP SIMD directive <strong>omp simd</strong> is used to vectorize loops that are generating multiple values and performing the same computations on each. Figure 2 shows the loop from Figure 1 with the added OpenMP directive. This informs the compiler that the computations within the loop can be converted from scalar to vectorize operations.</p>
                        <div class="my-5">
                            <img src="../img/rushita_img/openmp2.jpg" alt="" width="100%">
                        </div>
                        <p style="text-align:center">Figure 2. Example of OpenMP omp simd directive to vectorize a loop</p>
                        <p style="text-align:center">&nbsp;</p>
                        <p>Each <strong>num_rects </strong>iteration can be bundled (each with the corresponding values of the loop iterator, <strong>i</strong>) into a logical iteration where the loop body operations are carried out on each of the bundled iterations through supported SIMD hardware. The OpenMP standard calls these bundles of iterations a <em>SIMD chunk</em>. The number of serial iterations that are placed into a SIMD chunk depend on:</p>
                        <ul> 
                            <li>The hardware and instruction set support for vector operations at execution</li> 
                            <li>The size of the values being operated on</li> 
                            <li>Other implementation-specific factors</li> 
                           </ul>
                           <p>Table 1 shows some timing results for the two versions of the Riemann sums code. There's an obvious performance advantage to vectorizing this code.</p>
                           <p style="text-align:center">Table 1. Timing results of serial and vectorized Riemann sums code</p>
                           <div class="my-5">
                            <img src="../img/rushita_img/openmp3.jpg" alt="" width="100%">
                        </div>
                           <p>We can add several clauses to the SIMD directive. If you're familiar with OpenMP (and as seen in the previous example), you can use the private and reduction clauses as needed. Other, more specific, clauses are used with the SIMD directive. The clauses give better hints to the compiler about memory layout and access patterns that would produce better code or overcome some of the compiler’s conservative tendencies (for example, the <strong>safelen </strong>clause discussed next). This article doesn’t go into all of the available clauses. Consult the OpenMP specification for complete details.</p>

                        <h2 class="fw-light mt-5">Advantages of the Intel® Compiler</h2>
                        <p>Before going into more details about OpenMP SIMD support, a confession about the results presented in Table 1 is in order. The Intel® compiler has been improved over the years and benefits from intimate knowledge of the vector hardware changes and currently supported vector instructions in Intel® processors. As a result, the loop in Figure 2 doesn’t need hints from the OpenMP SIMD directive to recognize the vector possibilities and to vectorize the code. The confession is that the serial code was compiled with optimization disabled (via the <strong>-O0</strong> flag) to prevent the compiler from automatically vectorizing or parallelizing the loop.</p>
                        <p>The compiler optimization report provides insights into what the compiler finds on its own for vector and parallel optimizations. Plus, for those loops we assume can be vectorized, we can also use the generated optimization reports to determine why the compiler decided not to vectorize. Then, we can reexamine the code and consider transformations to allow vectorization. This could be refactoring the code to better order the operations or adding OpenMP SIMD directives and clauses to assure the compiler that vectorization is safe.</p>
                        <p>As a quick example, Figure 3 shows the compilation command on the original serial code (Figure 1) to determine what the compiler sees regarding vectorization.</p>
                        <div class="my-5">
                            <img src="../img/rushita_img/openmp4.jpg" alt="" width="100%">
                        </div>
                        <p style="text-align:center">Figure 3. Compile with vectorization optimization report flags</p>
                        <p style="text-align:center">&nbsp;</p>
                        <p>This generates a <strong>pi.optrpt</strong> output file containing the information shown in Figure 4.</p>
                        <div class="my-5">
                            <img src="../img/rushita_img/openmp5.jpg" alt="" width="100%">
                        </div>
                        <p style="text-align:center">Figure 4. Output vectorization report</p>
                        <p>In the actual code that was compiled, line 16 is the <strong>for-loop </strong>and line 17 is the assignment of <strong>x</strong>. (The emulation comment remained after casting the iteration variable, <strong>i</strong>, to <strong>double</strong>.) Thus, the Intel compiler can identify code that can be safely vectorized without any programmer intervention.</p>
                        <p>If you suspect that a loop should be vectorizable, try adding OpenMP SIMD directives, recompiling with the <strong>-fopenmp</strong> flag, and looking at the console output from the compiler. Even with SIMD directives, if the compiler is unable to safely vectorize the loop, it gives a warning message shown in Figure 5.</p>
                        <div class="my-5">
                            <img src="../img/rushita_img/openmp6.jpg" alt="" width="100%">
                        </div>
                        <p style="text-align:center">Figure 5. Compiler output for nonvectorizable code</p>
                        <p style="text-align:center">&nbsp;</p>
                        <p>At this point, use the <strong>-qopt-report</strong> option to request an optimization report from the compiler to determine why it was unable to vectorize the code. With this information, you can reevaluate the code with an eye toward:</p>
                        <ul> 
                            <li>Refactoring it to remove the impediment</li> 
                            <li>Adding some clauses to the directive that assure the compiler that vectorization is <strong>saf</strong></li> 
                            <li>Examining the loop for other possible optimizations</li> 
                           </ul>
                           <p>&nbsp;</p>

                        <h2 class="fw-light mt-5">The safelen Clause</h2>
                        <p>Now let's consider the function shown in Figure 6.</p>
                        <div class="my-5">
                            <img src="../img/rushita_img/openmp7.jpg" alt="" width="100%">
                        </div>
                        <p style="text-align:center">Figure 6. Another loop for possible vectorization</p>
                        <p>This code takes two floating-point arrays (<strong>A</strong>, <strong>B</strong>), a scaling factor (<strong>scale</strong>), and start and end (<strong>s</strong>, <strong>e</strong>) positions of the first array to be updated by adding a scaled value from a corresponding element of the second array. This is a floating-point, multiply-add operation that's typically vectorizable if there's no overlap between the <strong>A </strong>and <strong>B</strong> arrays.</p>
                        <p>If <strong>B</strong> is part of <strong>A</strong>, but a part that has higher index values (in other words, further down in the <strong>A</strong> array than the current element being computed), the code has an antidependency, or a write-after-read dependency. For example, if <strong>B</strong> is <strong>A</strong> offset by two elements, consider this (size 4) SIMD chunk of the inner loop:</p>
                        <div class="my-5">
                            <img src="../img/rushita_img/openmp8.jpg" alt="" width="100%">
                        </div>
                        <p style="text-align:center">Figure 7</p>
                        <p style="text-align:center">&nbsp;</p>
                        <p>There's no problem with vectorization because the current values of <strong>A[k+2]</strong> to <strong>A[k+5]</strong> are copied into a vector register, multiplied by scale, then added to the current values of <strong>A[k]</strong> to <strong>A[k+3]</strong> (also loaded into a vector register).</p>
                        <p>The third case, where <strong>B</strong> is <strong>A</strong> offset by a negative value, the code has a true dependency, or read-after-write dependency, that can cause problems if vectorized. Consider the case of a <strong>-2</strong> offset. The SIMD chunk in Figure 7 unwinds to:</p>
                        <div class="my-5">
                            <img src="../img/rushita_img/openmp9.jpg" alt="" width="100%">
                        </div>
                        <p style="text-align:center">Figure 8: Separate file holding the computation from the original example</p>
                        <p style="text-align:center">&nbsp;</p>
                        <p>There's a problem with reading the original values of <strong>A[k]</strong> and <strong>A[k+1]</strong> before the updated (correct) values have been written into them. If the minimum value of the offset is known, this is where the safe minimum length of SIMD chunks is given to the compiler through the <strong>safelen </strong>clause. If the gap between elements is never less than, for example, 12 between <strong>A</strong> and <strong>B</strong> (whenever those two arrays are actually part of the same array), the original function in Figure 6 can be vectorized with OpenMP, as shown in Figure 9. The compiler can now construct vector code that is safe for vector lengths of 12 elements or less.</p>
                        <div class="my-5">
                            <img src="../img/rushita_img/openmp11.jpg" alt="" width="100%">
                        </div>
                        <p style="text-align:center">Figure 9. Use the safelen clause to communicate to the compiler the safe length of vectors</p>
                        <div class="p-3" style="background-color: #E6E6E6; border-left: 3px solid #FDB813;">
                            <p class="note"><strong>Note </strong>Using the Intel compiler on the original <strong>scale()</strong> function (Figure 6) generates a vectorized version of the code. This is because a loop is contained in the code and it appears to be safe. However, since there's a chance of a true dependency, the compiler also generates the serial version of the loop. At runtime, the addresses of the A and B parameters are compared, and the correct choice of compiled code runs.</p>
                        </div>

                        <h2 class="fw-light mt-5">Return of the Simple Example</h2>
                        <p>As mentioned at the end of the previous section, the Intel compiler generates vectorized code when it’s safe to do so. Otherwise, it generates a serial code. But, what about a loop that contains a call to a user-defined function? If that function isn’t inlined, the compiler cannot determine if the loop can be vectorized safely.</p>
                        <p>Figures 10 and 11 show a restructured version of the Riemann sums code that's been split into two files. Figure 10, <strong>pi_func.cc</strong>, is the computation of the functional value at the i<sup>th</sup> midpoint within the bounds of the curve for which we're computing the area. Figure 11, <strong>pi_driver.cc</strong>, is the main body of the Riemann sums driver code.</p>
                        <div class="my-5">
                            <img src="../img/rushita_img/openmp10.jpg" alt="" width="100%">
                        </div>
                        <p style="text-align:center">Figure 10. Separate file holding the computation from the original example</p>
                        <p style="text-align:center">&nbsp;</p>
                        <div class="my-5">
                            <img src="../img/rushita_img/openmp12.jpg" alt="" width="100%">
                        </div>
                        <p style="text-align:center">Figure 11. Driver code to call a user-defined function from within the loop</p>
                        <p style="text-align:center">&nbsp;</p>
                        <p>One advantage of constructing the code this way is the ability to substitute almost any computational function that makes the driver code a more general Riemann sums algorithm. The print statement needs to be changed and the function name updated to something more generic. Then your desired computational function for processing is simply linked to the driver.</p>
                        <p>Without a loop in the <strong>pi_func.cc </strong>file (Figure 10), the compiler is unable to vectorize that computation. With the user-defined <strong>pi_func()</strong> call in the loop (Figure 11), the compiler cannot determine whether the code can be vectorized. In fact, compiling the <strong>pi_func.cc</strong> file with the report-generating options for vectorization gives an empty report.</p>
                        <p>The declare <strong>simd </strong>directive can be used to tell the compiler to vectorize code that the programmer knows is safe. The first step is to add the pragma shown in Figure 12 to the function <strong>pi_func()</strong>.</p>
                        <div class="my-5">
                            <img src="../img/rushita_img/openmp13.jpg" alt="" width="100%">
                        </div>
                        <p>This is also done at the extern declaration in the driver code file (Figure 13). To complete the process, the loop containing the call to <strong>pi_func() </strong>needs to be denoted as vectorizable in much the way it was in the original example.</p>
                        <div class="my-5">
                            <img src="../img/rushita_img/openmp14.jpg" alt="" width="100%">
                        </div>
                        <p style="text-align:center">Figure 13. Relevant code lines from Figure 11 with added OpenMP SIMD directives</p>
                        <p>The compilation process of the <strong>pi_func()</strong> code creates a vectorized version of the function, say <strong>vec_pi_func()</strong>. Within the driver function, the loop body is altered to call a vectorized version of the function <strong>vec_pi_func()</strong>. Essentially, if the vector length supported by the hardware and the data style was four, the four calls of <strong>pi_func() </strong>with parameter values <strong>i</strong>, <strong>i+1</strong>, <strong>i+2</strong>, and <strong>i+3</strong> are substituted for a single call to the vectorized version, <strong>vec_pi_func()</strong>, with the four values copied into a vector register for running the vector.</p>
                        <p>Table 2 shows some timing results from running the two versions of the separated Riemann sums code with the function value calculation set off in a separate file. The vectorized version uses the <strong>declare simd</strong> clause for vectorization. The vectorized version in this example is demonstrably faster than the serial code, though not as much as the original version shown at the outset.</p>
                        <p>&nbsp;</p>
                        <p style="text-align:center">Table 2. Runtimes for serial and vectorized compilations of Riemann Sums code with the userdefined function</p>
                        <div class="my-5">
                            <img src="../img/rushita_img/openmp15.jpg" alt="" width="100%">
                        </div>

                        <h2 class="fw-light mt-5">Reduce the Runtime</h2>
                        <p>For computations that can be run simultaneously, a vectorized solution on hardware that supports the running reduces the runtime by actually making multiple computations within the same machine cycles. This even applies to parallelized code. Try this exercise: Take the original Riemann sums code in Figure 1 and make the <strong>for-loop</strong> both threaded and vectorized.</p>
                        <p>In straightforward cases, the Intel compiler automatically vectorizes loops of computations at the appropriate compiler optimization levels. The optimization reports from the Intel compiler give you information about what was vectorized and what wasn’t (and why it wasn’t vectorized). In the latter case, if you believe the compiler was too conservative, you can restructure the code or add OpenMP SIMD directives and clauses to give the compiler hints about what is safe to vectorize. For the full range of SIMD pragmas and clauses, consult the OpenMP documentation for the version supported by your compiler.</p>

                        <h2 class="fw-light mt-5">References</h2>
                        <ul> 
                            <li class="k_plink1 k_intext1blue1">All compilation and running was done on the <a href="#">Intel® DevCloud</a>.</li> 
                            <li>The Intel compiler version used was 19.1 20200306.</li> 
                            <li class="k_plink1 k_intext1blue1">Running happened in an interactive session on <a href="#">Intel® Xeon® Platinum processors</a> with 384 GB memory. The session launched with the following command: <strong>qsub -I -l nodes=1:plat8153:ppn=2 -d</strong>.</li> 
                           </ul>
                           <p>&nbsp;</p>
                           <h3 class="fw-light">______</h3>
                           <div class="row">
                               <div class="mt-5">
                                   <h1 class="fw-light">You May Also Like</h1>
                               </div>
                               <div>
                                   <div class="k_tab-container">
                                       <ul class="d-flex k_text k_listnone gap-4 px-3 k_tab1 k_scrollable-menu">
                                           <li><a href="#" data-tab="gaming">Related Articles</a></li>
                                           <li><a href="#" data-tab="entertainment">Related Webinars</a></li>
                                           <li><a href="#" data-tab="entertainment1">Get the Software</a></li>
                                       </ul>
                                       <hr class="mb-2 k_hr">
                                       <div class="">
                                           <div class="k_custom-tab-content" id="gaming">
                                               <div class="row ">
                                                    <div class="col-sm-12 col-md-6">
                                                        <p>Use OpenMP* Accelerator Offload for Programming Heterogeneous Architectures</p>
                                                        <p><a href="#">Read</a></p>
                                                    </div>
                                                    <div class="col-sm-12 col-md-6">
                                                        <p>Use OpenMP* Accelerator Offload for Programming Heterogeneous Architectures</p>
                                                        <p><a href="#">Read</a></p>
                                                    </div>
                                               </div>
                                           </div>
                                           <div class="k_custom-tab-content" id="entertainment">
                                               <div class="row g-3">
                                                  <div class="col-sm-12 col-md-6">
                                                        <p>Run HPC Applications on CPUs and GPUs with Xe Architecture</p>
                                                        <p><a href="#">Read</a></p>
                                                  </div>
                                               </div>
                                           </div>
                                           <div class="k_custom-tab-content" id="entertainment1">
                                            <div class="row g-3">
                                                <div class="col-lg-12 col-md-12 col-sm-12 align-content-center">
                                                    <div class="k_table-container mb-3">
                                                        <table class="k_tebal   col-md-12 col-sm-12  k_tspace">
                                                            <tbody class="k_tebal k_14px">
                                                                <tr class="  k_rightborder1 k_tpadding1 ">
                                                                    <td><p class="k_plink1 k_intext1blue1"><b><a href="#">Intel® oneAPI DPC++/C++ Compiler</a></b></p>
                                                                        <p>Compile ISO C++, Khronos SYCL*, and DPC++ source code across CPUs, GPUs, and FPGAs.
                                                                            Part of the Intel® oneAPI Base Toolkit.</p>
                                                                        <p class="text-center k_btnlearn py-1 k_text m-auto k_under k_btn100"
                                                                        style="float: inline-start; width: 130px; background-color: #0068B5;">
                                                                        <a href="#" class="text-white">Get It Now</a>
                                                                        </p>
                                                                    <p class="k_plink1 k_intext1blue1 mt-5"><a href="#">See All Tools</a></p></td>
                                                                </tr>
                                                            </tbody>
                                                        </table>
                                                    </div>
                                                </div>
                                            </div>
                                        </div>
                                       </div>
                                   </div>
                                
                               </div>
                           </div>
                        
                    </div>
                </div>
            </div>
    </section>
    <section class="my-4">
        <div class="k_container11">
            <div class="row">
                <div>
                    <hr class="mb-5">
                    <p>Product and Performance Information
                    <p>
                        <div class="disclaimer k_plink1 k_intext1blue1"><sup>1</sup>Platinum 8380: 1-node, 2x Intel Xeon Platinum 8380 processor with 256GB (16 slots/ 16GB/3200) total DDR4 memory, uCode 0xd000389, HT on, Turbo on, Ubuntu 20.04.5 LTS,&nbsp; 5.4.0-146-generic, INTEL SSDPE2KE016T8 1.5T; <a href="#">GCN + Reddit FP32 inference</a>, <a href="#">GCN+Reddit FP32 training</a>, <a href="#">GraphSAGE + ogbn-products FP32 inference</a>, <a href="#">GCN-PROTAIN, GCN-REDDIT-BINARY FP32 training</a>; Software: PyTorch 2.1.0.dev20230302+cpu, pytorch_geometric 2.3.0, torch-scatter 2.1.0, torch-sparse 0.6.16, test by Intel on 3/02/2023.</div>
                        <div class="disclaimer k_plink1 k_intext1blue1"><sup>2</sup>Platinum 8380: 1-node, 2x Intel Xeon Platinum 8380 processor with 256GB (16 slots/ 16GB/3200) total DDR4 memory, uCode 0xd000389, HT on, Turbo on, Ubuntu 20.04.5 LTS,&nbsp; 5.4.0-146-generic, INTEL SSDPE2KE016T8 1.5T; <a href="#">GCN, GraphSAGE, GIN and EdgeCNN, FP32</a>; Software: PyTorch 2.1.0.dev20230411+cpu, pytorch_geometric 2.4.0, torch-scatter 2.1.1+pt20cpu, torch-sparse 0.6.17+pt20cpu, test by Intel on 4/11/2023.</div>
                    <div class="k_plink1 k_intext1blue1"><sup>3</sup>Performance varies by use, configuration and other
                        factors. Learn more at &nbsp;<a href="#">www.Intel.com/PerformanceIndex.</a>.
                    </div>
                </div>
            </div>
        </div>
    </section>
    <div id="footer"></div>
    <script>
        // navbar include  
        fetch('../y_index/y_navbar.html')
            .then(response => response.text())
            .then(data => {
                document.getElementById('navbar').innerHTML = data;
            });
        // footer include 
        fetch('../y_index/y_footer.html')
            .then(response => response.text())
            .then(data => {
                document.getElementById('footer').innerHTML = data;
            });
    </script>
     <script>
        document.addEventListener('DOMContentLoaded', function () {
            const tabLinks = document.querySelectorAll('.k_tab-container ul li a');
            const tabContents = document.querySelectorAll('.k_custom-tab-content');

            function setActiveTab(tabId) {
                tabContents.forEach(content => {
                    content.classList.remove('active');
                });
                tabLinks.forEach(link => {
                    link.classList.remove('active');
                });

                document.getElementById(tabId).classList.add('active');
                document.querySelector(`[data-tab="${tabId}"]`).classList.add('active');
            }

            tabLinks.forEach(link => {
                link.addEventListener('click', function (e) {
                    e.preventDefault();
                    const tabId = this.getAttribute('data-tab');
                    setActiveTab(tabId);
                });
            });

            setActiveTab('gaming');
        });
    </script>
    <script src="https://cdn.jsdelivr.net/npm/@splidejs/splide@4.1.4/dist/js/splide.min.js"></script>
    <script src="../js/jquery-3.7.1.js"></script>

    <script src="../js/owl.carousel.min.js"></script>
    <script src="../js/rushita.js"></script>
</body>

</html>