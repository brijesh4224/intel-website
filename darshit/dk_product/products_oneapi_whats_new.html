<!DOCTYPE html>
<html lang="en">

<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>Intel® Software News Updates</title>

    <link rel="stylesheet"
        href="/css/dk_developer_edge_iot_&_5G_optimize_fine_tuning_and_deployment_of_LLMs_on_an_ai_pc.css">

    <!-- header footer -->
    <link rel="stylesheet" href='/css/yatri.css'>

    <link href="https://cdn.jsdelivr.net/npm/bootstrap@5.0.2/dist/css/bootstrap.min.css" rel="stylesheet"
        integrity="sha384-EVSTQN3/azprG1Anm3QDgpJLIm9Nao0Yz1ztcQTwFspd3yD65VohhpuuCOmLASjC" crossorigin="anonymous">
    <script src="https://cdn.jsdelivr.net/npm/bootstrap@5.0.2/dist/js/bootstrap.bundle.min.js"
        integrity="sha384-MrcW6ZMFYlzcLA8Nl+NtUVF0sA7MsXsP1UyJoMp4YLEuNSfAP+JcXn/tWtIaxVXM"
        crossorigin="anonymous"></script>
    <link href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/6.6.0/css/all.min.css" rel="stylesheet">
</head>

<style>
    .VK_ai_navigation{
        display: block !important;
    }
</style>

<body>

    <!-- header -->
    <div id="navbar"></div>

    <!-- Optimize Fine-Tuning and Deployment of LLMs on an AI PC -->
    <section>
        <div class="mv_intel_amx_bg_color">
            <div class="container">
                <div class="row mv_intel_amx_content">
                    <div class="col-md-12 col-sm-12 mv_intel_amx_item">
                        <div class="mv_intel_amx">
                            <h1><a style="color: #fff; font-weight: 300; font-size: 2.25rem;" href="">Intel® Software News Updates</a></h1>
                            <p style="margin-bottom: 20px; font-size: 1.25rem;">Get the latest info on products and services that meet your needs.</p>
                            <a class="dk_learn" href="">Sign Up</a>
                        </div>
                    </div>
                </div>
            </div>
        </div>
    </section>

    <section class="container py-5">
        <div class="row">
            <div class="d-flex justify-content-end col-xl-10 py-3 d-md-none">
                <i class="fa-solid fa-print fs-4 px-2 " style="color:#0068B5"></i>
                <i class="fa-regular fa-envelope fs-4 px-2" style="color:#0068B5"></i>
            </div>
            <div class="col-lg-3 col-md-4">
                <!-- nav -->
                <div class="VK_client_app_navigation VK_ai_navigation">
                    <div class="justify-content-center align-items-center overflow-hidden flex-nowrap mb-4">
                        <ul class="VK_ai_nav_bar list-unstyled m-0">
                            <li>
                                <a href="#dk_november_2024" class="text-dark text-decoration-none d-block">
                                    November 2024
                                </a>
                            </li>
                            <li>
                                <a href="#dk_october_2024" class="text-dark text-decoration-none d-block VK_ai_nav_link">
                                    October 2024
                                </a>
                            </li>
                            <li>
                                <a href="#dk_september_2024"
                                    class="text-dark text-decoration-none d-block VK_ai_nav_link">
                                    September 2024
                                </a>
                            </li>
                            <li>
                                <a href="#dk_August_2024" class="text-dark text-decoration-none d-block VK_ai_nav_link">
                                    August 2024
                                </a>
                            </li>
                            <li>
                                <a href="#dk_june_2024" class="text-dark text-decoration-none d-block VK_ai_nav_link">
                                    June 2024
                                </a>
                            </li>
                            <li>
                                <a href="#dk_may_2024" class="text-dark text-decoration-none d-block VK_ai_nav_link">
                                    May 2024
                                </a>
                            </li>
                            <li>
                                <a href="#dk_april_2024" class="text-dark text-decoration-none d-block VK_ai_nav_link">
                                    April 2024
                                </a>
                            </li>
                            <li>
                                <a href="#dk_march_2024" class="text-dark text-decoration-none d-block VK_ai_nav_link">
                                    March 2024
                                </a>
                            </li>
                            <li>
                                <a href="#dk_february_2024" class="text-dark text-decoration-none d-block VK_ai_nav_link">
                                    February 2024
                                </a>
                            </li>
                            <li>
                                <a href="#dk_january_2024" class="text-dark text-decoration-none d-block VK_ai_nav_link">
                                    January 2024
                                </a>
                            </li>
                            <li>
                                <a href="#dk_december_2023" class="text-dark text-decoration-none d-block VK_ai_nav_link">
                                    December 2023
                                </a>
                            </li>
                            <li>
                                <a href="#dk_november_2023" class="text-dark text-decoration-none d-block VK_ai_nav_link">
                                    November 2023 
                                </a>
                            </li>
                        </ul>
                    </div>
                </div>
                <div class="dk_things_code_main">
                    <div class="dk_things_code">
                        <h6><b>What's New</b></h6>
                        <ul class="ps-3">   
                            <li><p>The 2025.0 Intel® Software Development Tools Are Here: Marking the 5th Anniversary of oneAPI
                                   <a class="b_special_a2" href="">Read</a></p>
                            </li>
                            <li><p>Announcing General Availability of Object Storage on Intel® Tiber™ AI Cloud
                                   <a class="b_special_a2" href="">Read</a></p>
                            </li>
                            <li><p>Inflection AI Launches Enterprise AI Running on Intel® Gaudi® 3 and Intel® Tiber™ AI Cloud
                                   <a class="b_special_a2" href="">Read</a></p>
                            </li>
                            <li><p>Intel Launches Xeon 6 and Gaudi 3, Enabling the Next-Generation of AI Solutions 
                                   <a class="b_special_a2" href="">Read</a></p>
                            </li>
                            <li><p>Deliver AI Faster on Next-Gen Intel® Core™ Ultra AI PCs
                                   <a class="b_special_a2" href="">Read</a></p>
                            </li>
                        </ul>
                        <a class="dk_button" href="">Software News on Intel Newsroom</a>
                    </div>
                </div>
            </div>
            <div class="col-lg-9 col-md-8">
                <div class="d-md-flex justify-content-end col-xl-10 py-3 d-none">
                    <i class="fa-solid fa-print fs-4 px-2 " style="color:#0068B5"></i>
                    <i class="fa-regular fa-envelope fs-4 px-2" style="color:#0068B5"></i>
                </div>
                <div class="col-xl-10">
                    <p>&nbsp;</p>
                    <div style="padding-bottom: 16px;">
                    <p>&nbsp;</p>
                    <section id="dk_november_2024">
                        <h3 style="font-weight: 300;">The 2025.0 Intel® Software Development Tools Are Here, Marking the 5th Anniversary of oneAPI</h3>
                        <p class="mt-3">November 17, 2024 | <a style="color: blue;" href="">Intel® Software Development Tools</a></p>
                        <p>Today, Intel released its 2025.0 developer tools—all powered by oneAPI—marking the <a class="b_special_a1" href="">5<sup>th</sup> anniversary of the oneAPI programming model&nbsp;</a> with expanded performance optimizations and open-standards coverage to support the latest innovations in multiarchitecture, hardware-agnostic software development and deployment, edge to cloud.</p>
                        <p style="text-align:center"><a style="padding: 5px 20px;" class="dk_button" href="">Explore &amp; download</a></p>
                        <h4>3 Key Benefits</h4>
                        <ul>
                            <li><strong>More Performance on Intel Platforms</strong> – Achieve up to 3x higher GenAI performance on 6<sup>th</sup> Gen Intel® Xeon® processors (P-cores) with <a href="" style="color:blue; text-decoration:none !important">oneDNN</a>, Intel-optimized AI frameworks, and Intel® AMX<sup>1</sup>; achieve up to 2.5x better HPCG performance with MRDIMM<sup>2</sup> and <a href="" style="color:blue; text-decoration:none !important">oneMKL</a>; develop high-performance AI on the PC—including LLM development—with optimized tools to unlock the power of Intel® Core™ Ultra processors (Series 2); and improve security and encryption with <a href="" style="color:blue; text-decoration:none !important">Intel® Cryptography Primitives Library</a>.</li>
                            <li><strong>More Access to Industry-Standard Tools</strong> – Get even more from your existing development workflows using industry-leading AI frameworks and performance libraries with even more built-in Intel optimizations, including native support for PyTorch 2.5 on CPUs and GPUs; achieve optimal performance across CPU, GPU, and AI accelerators from the latest LLMs—Llama 3.2, Qwen2, Phi-3, and more—with <a href="" style="color:blue; text-decoration:none !important">Intel AI tools</a>; and streamline your software setup with our <a href="\" style="color:blue; text-decoration:none !important">toolkit selector</a> to install full kits or right-sized sub-bundles.</li>
                            <li><strong>More Hardware Choices </strong>– Enjoy increased multi-vendor, multiarchitecture support, including faster CUDA*-to-SYCL* migration with the <a href="" style="color:blue; text-decoration:none !important">Intel® DPC++ Compatibility Tool</a> that auto-migrates over 100 APIs used by popular AI, HPC, and rendering apps; achieve near-native performance on CPU and GPU for numeric compute with Intel® Distribution for Python; get 4x speedup of GPU kernels for algorithms with <a href="" style="color:blue; text-decoration:none !important">oneDPL</a>; and gain future system flexibility and prevent lock-in through cross-hardware AI-acceleration libraries, including Triton, JAX, and OpenXLA*.</li>
                        </ul>

                        <h4>The Nuts & Bolts</h4>
                        <p>Here's the collection for those interested in diving into the component-level details.</p>
                        <p><strong>Compilers</strong></p>
                        <ul>
                            <li><a href="" style="color:blue; text-decoration:none !important">Intel oneAPI DPC++/C++ Compiler</a> adds optimizations tailored for Intel® Xeon® 6 processors and Intel® Core™ Ultra processors, enables dynamic execution and flexible programming for Intel GPUs with new SYCL Bindless Textures support, streamlines development with new LLVM sanitizers to detect and troubleshoot device code issues, and enhances OpenMP standards conformance for 5.x and 6.0 plus add a more user-friendly optimization report that includes OpenMP offloading details.</li>
                            <li><a href="" style="color:blue; text-decoration:none !important">Intel® Fortran Compiler</a> adds several enhancements, including Fortran 2023 standard features such as the AT Edit Descriptor for cleaner output, conditional TEAMS construct execution with the new IF clause for OpenMP 6.0, and support for arrays of co-arrays and “standard-semantics” option to precisely control application standards compliance; updates Fortran Developer Guide and reference documentation with refreshed code samples and added support for Fortran 2018 and 2023 Fortran language features.</li>
                        </ul>
                        <p><strong>Performance Libraries</strong></p>
                        <ul>
                            <li><a href="" style="color:blue; text-decoration:none 
                            !important">Intel® oneAPI Math Kernel Library</a> (oneMKL) introduces performance optimizations across multiple domains—BLAS, LAPACK, FFT, &nbsp;and others—for developers targeting Xeon 6 processors with P-cores. It also adds significant improvements for HPC workload execution using single-precision 3D real in-place FFT on Intel® Data Center GPU Max Series and makes available new distribution models and data types for RNG using SYCL device API.</li>
                            <li><a href="" style="color:blue; text-decoration:none 
                            !important">Intel® oneAPI Data Analytics Library</a> (oneDAL) enables calculation of SHAP (SHapley Additive exPlanations) values for binary classification models, which are required for explainability random forest (RF) algorithms.</li>
                            <li><a href="" style="color:blue; text-decoration:none 
                            !important">Intel® oneAPI Deep Neural Network Library</a> (oneDNN) maximizes efficiency and performance with tailored optimizations for the latest Intel® platforms—spanning server, desktop, and mobile—including significantly faster performance for large language models (LLMs) and Scaled Dot-Product Attention subgraphs.</li>
                            <li><a href="" style="color:blue; text-decoration:none 
                            !important">Intel® oneAPI Threading Building Blocks</a> (oneTBB) improves scalability for task_group, flow_graph, and parallel_for_each so multi-threaded applications run faster; introduces try_put_and_wait experimental API for faster results using oneTBB flow graph to process overlapping messages on a shared graph.</li>
                            <li><a href="" style="color:blue; text-decoration:none 
                            !important">Intel® oneAPI Collective Communications Library</a> (oneCCL) improves workload performance and scalability with enhancements to Key-Value store, which allows workloads to scale up to an even larger number of nodes, and performance improvements to key collectives such as Allgather, Allreduce, and Reduce-scatter.</li>
                            <li><a href="" style="color:blue; text-decoration:none 
                            !important">Intel® MPI Library</a> offers a full MPI 4.0 implementation, including partitioned communication, improved error handling, and Fortran 2008 support; and improves scale-out/scale-up performance on both Xeon 6 processors with P-core pinning and Intel GPUs via optimizations for MPI_Allreduce.</li>
                            <li><a href="" style="color:blue; text-decoration:none 
                            !important">Intel® oneAPI DPC++ Library</a> (oneDPL) accelerates GPU kernels up to 4x<sup>3</sup> for algorithms including reduce, scan and many other functions. Range-based algorithms with over 20 new C++20 standard ranges and views accelerate highly parallel code execution on multiarchitecture devices.</li>
                            <li><a href="" style="color:blue; text-decoration:none 
                            !important">Intel® Integrated Performance Primitives</a> (Intel® IPP) adds CET-enabled protection (Control-flow Enforcement Technology), cutting-edge, hardware-enforced security measures that safeguard software against attacks and exploitation risks.</li>
                            <li><a href="" style="color:blue; text-decoration:none 
                            !important">Intel® Cryptography Primitives Library</a> (formerly Intel® IPP) enables developers to dispatch on Xeon 6 processors, turbocharging RSA encryption (2k, 3k, 4k) with multi-buffer capabilities and hashing with an enhanced SM3 algorithm.</li>
                            </ul>
                      <p><strong>Analyzers &amp; Debuggers</strong></p>
                      <ul>
                        <li><a href="" style="color:blue; text-decoration:none !important">Intel® DPC++ Compatibility Tool</a> saves time and effort when migrating CUDA code and CMake build script to SYCL via auto-migration of more APIs used by popular AI, HPC, and rendering applications; migrated code is easy to comprehend with SYCLcompat, easy to debug with CodePin, and runs performantly on NVIDIA GPUs.</li>
                        <li><a href="" style="color:blue; text-decoration:none !important">Intel® VTune™ Profiler</a> adds support for Intel Xeon 6 processors with P-cores and Core Ultra processors (Series 2), plus profiling support for Python 3.11, improving productivity with the ability to focus Python profiling to areas of interest and control performance data collection with <a href="" style="color:blue; text-decoration:none !important">Intel® ITT APIs</a>.</li>
                        <li><a href="" style="color:blue; text-decoration:none !important">Intel® Advisor</a> increases developers’ ability to identify bottlenecks, optimize code, and achieve peak performance on the latest Intel platforms; introduces a more adaptable kernel-matching mechanism—flexible kernel matching and XCG integration—to identify and analyze code regions relevant to specific optimization goals.</li>
                        <li><a href="" style="color:blue; text-decoration:none !important">Intel® Distribution for GDB*</a> rebases to GDB 15, staying current and aligned with the latest enhancements supporting effective application debug; adds support for Core Ultra processors (Series 2) on Windows*; and enhances developer experience, both on the command line and when using Microsoft* Visual Studio and Visual Studio Code*, by boosting the debugger performance and refining the user interface.</li>
                    </ul>
                    <p><strong>AI &amp; ML Tools, Frameworks, and Accelerated Python</strong></p>
                    <ul>
                        <li><a href="" style="color:blue; text-decoration:none !important">Intel® Distribution for Python*</a> provides drop-in, near-native performance on CPU and GPU for numeric compute; Data Parallel Extension for Python (dpnp) and Data Parallel Control (dpctl) expand compatibility, adding NumPy 2.0 support in the runtime and providing asynchronous execution of offloaded operations.</li>
                        <li><a href="" style="color:blue; text-decoration:none !important">Intel AI Tools</a> latest release ensures current and future GenAI foundation models—Llama 3.2, Qwen2, Phi-3 family, and more—perform optimally across Intel CPUs, GPUs, and AI accelerators.</li>
                        <li><a href="" style="color:blue; text-decoration:none !important">Triton</a> (open source GPU programming for neural networks) enables developers to achieve peak performance and kernel efficiency on Intel GPUs thanks to it being fully optimized for Intel Core Ultra and Data Center GPU Max Series processors and available upstream in stock PyTorch.</li>
                        <li><a href="" style="color:blue; text-decoration:none !important">Native Support for PyTorch 2.5</a> is accessible on Intel’s Data Center GPUs, Core Ultra processors, and client GPUs, where it can be used to develop on Windows with out-of-the-box support for Intel® Arc™ Graphics and Intel® Iris® XE Graphics GPUs.</li>
                        <li>Simplify enterprise GenAI adoption and reduce the time to production of hardened, trusted solutions by adopting the open platform project, <a href="" style="color:blue; text-decoration:none !important">OPEA</a>, part of LF AI &amp; Data. Now at release 1.0, OPEA continues to gain momentum with over 40 partners, including AMD, BONC, ByteDance, MongoDB, and Rivos.</li>
                        <li>Seamlessly run&nbsp;<a href="" style="color:blue; text-decoration:none !important">JAX</a>&nbsp;models on Intel® Data Center GPU Max and Flex with Intel® Extension for <a href="" style="color:blue; text-decoration:none !important">OpenXLA*</a>, an Intel-optimized PyPI package based on&nbsp;<a href="" style="color:blue; text-decoration:none !important">PJRT</a>&nbsp;plugin mechanism.</li>
                    </ul>
                    <p style="text-align:center"><a style="padding: 5px 20px;" class="dk_button" href="">Explore &amp; download the tools</a>&nbsp;</p>

                    <p><strong>Footnotes</strong></p>
                    <p><sup>1</sup> See [9A2] at intel.com/processorclaims: Intel® Xeon® 6. Results may vary.</p>
                    <p><sup>2</sup> See [9H10] at intel.com/processorclaims: Intel® Xeon® 6. Results may vary.</p>
                    <p><sup>3</sup> See <a href="" style="color:blue; text-decoration:none !important" title="">oneDPL product page</a></p>

                    <p>&nbsp;</p>
                    <h3 style="font-weight: 350; margin: 1rem 0 11px;">oneAPI Turns 5!</h3>
                    <p>November 17, 2024 | <a href="" style="color:blue; text-decoration:none !important">What is oneAPI?</a>, <a href="" style="color:blue; text-decoration:none !important">oneAPI Developer Page</a></p>
                    <h4>Happy 5<sup>th</sup> Anniversary to the open, standards-based, multiarchitecture programming initiative for accelerator architectures</h4>

                    <p><img alt="" height="141" src="/img/darshit_image/logo-oneapi.png" style="float:left" width="250"></p>
                    <p>Launched at Supercomputing 2019, the oneAPI initiative not only fostered permanent change in how the global developer ecosystem approaches heterogeneous programming, it’s become the foundation for building, optimizing, and deploying high-performance software that can run on any vendor architecture. &nbsp;</p>
                    <p>With hundreds of contributors, over 4.3 million installations, and 6.8 million developers using it via Intel® Software and AI Tools (explore the <a href="" style="color:blue; text-decoration:none !important">2025.0 release</a>), oneAPI is arguably one of the most eminent programming standards, a point further underscored by its adoption in 2023 by the Unified Acceleration (UXL) Foundation, hosted by Linux Foundation. UXL’s mission: &nbsp;to deliver an open-standard accelerator programming model that simplifies development of performant, cross-platform applications. It marks yet another critical step in driving innovation, with oneAPI as a key component.</p>
                    <p>All that in just 5 years. (Imagine what the next 5 will bring.)</p>
                    <p>If you haven’t tried oneAPI, you can get the gist of it <a href="" style="color:blue; text-decoration:none !important">here</a> and download the 2025.0 tools <a href="" style="color:blue; text-decoration:none !important">here</a>.</p>
                    <h4><strong>Celebrating oneAPI’s 5<sup>th</sup> Anniversary – What the Ecosystem is Saying</strong></h4>
                    <p>&nbsp;</p>

                    <div class="d-flex">
                        <div class="">
                            <i class="fa-solid fa-quote-left" style="font-size: 65px; color: #E5E6E6; padding-right: 15px;"></i>
                        </div>
                        <div class="">
                            <div class="mv_together_content">
                                <p class="mb-2" style="font-weight: 300;"><i>The Performance improvements achieved with Intel’s latest Xeon platform will support our efforts in wider adoption of HE, particularly in improving data analysis and insights, as well as product innovation around areas such as anti-financial crime.</i></p>
                                <p>Nikolai Larbalestier, Senior Vice President, Enterprise Architecture, NASDAQ</p>
                            </div>
                        </div>
                    </div>

                    <p>&nbsp;</p>
                    <p>&nbsp;</p>

                    <div class="d-flex">
                        <div class="">
                            <i class="fa-solid fa-quote-left" style="font-size: 65px; color: #E5E6E6; padding-right: 15px;"></i>
                        </div>
                        <div class="">
                            <div class="mv_together_content">
                                <p class="mb-2" style="font-weight: 300;"><i>oneAPI has revolutionized the way we approach heterogeneous computing by enabling seamless development across architectures. Its open, unified programming model has accelerated innovation in fields from AI to HPC, unlocking new potential for researchers and developers alike. Happy 5th Anniversary to oneAPI!</i></p>
                                <p>– Dr. Gal Oren, Asst Professor, Dept. of Computer Science, Israel Institute of Technology</p>
                            </div>
                        </div>
                    </div>

                    <p>&nbsp;</p>
                    <p>&nbsp;</p>

                    <div class="d-flex">
                        <div class="">
                            <i class="fa-solid fa-quote-left" style="font-size: 65px; color: #E5E6E6; padding-right: 15px;"></i>
                        </div>
                        <div class="">
                            <div class="mv_together_content">
                                <p class="mb-2" style="font-weight: 300;"><i>Intel's commitment to their oneAPI software stack is a testament to their developer-focused, open-standards commitment. As oneAPI celebrates its 5th Anniversary, it provides comprehensive and performant implementations of OpenMP and SYCL for CPUs and GPUs, bolstered by an ecosystem of library and tools to make the most of Intel processors.</i></p>
                                <p>– Dr. Tom Deakin, Sr. Lecturer, Head of Advanced HPC Research Group, University of Bristol</p>
                            </div>
                        </div>
                    </div>

                    <p>&nbsp;</p>
                    <p>&nbsp;</p>

                    <div class="d-flex">
                        <div class="">
                            <i class="fa-solid fa-quote-left" style="font-size: 65px; color: #E5E6E6; padding-right: 15px;"></i>
                        </div>
                        <div class="">
                            <div class="mv_together_content">
                                <p class="mb-2" style="font-weight: 300;"><i>Celebrating 5 years of oneAPI. In ExaHyPE, oneAPI has been instrumental in implementing the numerical compute kernels for hyperbolic equation systems, making a huge different in performance with SYCL providing the ideal abstraction and agnosticism for exploring these variations. This versatility enabled our team, together with Intel engineers, to publish three distinct design paradigms for our kernels.</i></p>
                                <p>– Dr. Tobias Weinzierl, Director, Institute for Data Science, Durham University</p>
                            </div>
                        </div>
                    </div>

                    <p>&nbsp;</p>
                    <p>&nbsp;</p>

                    <div class="d-flex">
                        <div class="">
                            <i class="fa-solid fa-quote-left" style="font-size: 65px; color: #E5E6E6; padding-right: 15px;"></i>
                        </div>
                        <div class="">
                            <div class="mv_together_content">
                                <p class="mb-2" style="font-weight: 300;"><i>Happy 5th Anniversary, oneAPI! We’ve been partners since the private beta program in 2019. We are currently exploring energy-efficient solutions for simulations in material science and data analysis in bioinformatics with different accelerators. For that, the components of oneAPI, its compilers with backends for various GPUs and FPGAs, oneMKL, and the performance tools VTune Profiler and Advisor, are absolutely critical.</i></p>
                                <p>– Dr. Thomas Steinke, Head of Supercomputing Department, Zuse Institute Berlin</p>
                            </div>
                        </div>
                    </div>

                    <p>&nbsp;</p>
                    <p>&nbsp;</p>

                    <div class="d-flex">
                        <div class="">
                            <i class="fa-solid fa-quote-left" style="font-size: 65px; color: #E5E6E6; padding-right: 15px;"></i>
                        </div>
                        <div class="">
                            <div class="mv_together_content">
                                <p class="mb-2" style="font-weight: 300;"><i>GROMACS was an early adopter of SYCL as a performance-portability backend, leveraging it to run on multi-vendor GPUs. Over the years, we’ve observed significant improvements in the SYCL standard and the growth of its community. This underscores the importance of open standards in computational research to drive innovation and collaboration. We look forward to continued SYCL development, which will enable enhancements in software performance and increase programmer productivity.</i></p>
                                <p>– Andrey Alekseenko, Researcher, Department of Applied Physics, KTH Royal Institute of Technology</p>
                            </div>
                        </div>
                    </div>

                    <p>&nbsp;</p>
                    <p>&nbsp;</p>

                    <div class="d-flex">
                        <div class="">
                            <i class="fa-solid fa-quote-left" style="font-size: 65px; color: #E5E6E6; padding-right: 15px;"></i>
                        </div>
                        <div class="">
                            <div class="mv_together_content">
                                <p class="mb-2" style="font-weight: 300;"><i>Using the Intel® oneAPI Base Toolkit, [GE HealthCare] successfully migrated code, which requires heavy processing and is extensively used in ultrasound diagnostics solutions, to SYCL. This is a big step forward on the way to a single, open, standards-based programming model for heterogeneous computing. The migrated code efficiently runs on different GPU platforms and achieves competitive performance.</i></p>
                                <p>– Arcady Kempinsky, Sr. Lead Software Architect, GE HealthCare</p>
                            </div>
                        </div>
                    </div>

                    <p>&nbsp;</p>
                    <p>&nbsp;</p>

                    <div class="d-flex">
                        <div class="">
                            <i class="fa-solid fa-quote-left" style="font-size: 65px; color: #E5E6E6; padding-right: 15px;"></i>
                        </div>
                        <div class="">
                            <div class="mv_together_content">
                                <p class="mb-2" style="font-weight: 300;"><i>Using Intel® oneAPI Base Toolkit, we have successfully implemented GE HealthCare's proprietary TrueFidelity DL, a deep learning image reconstruction algorithm available across much of the company's CT portfolio. The open source SYCL compiler provides near entitlement AI/DL inferencing performance for several NVIDIA GPU devices. Based on GE Healthcare experience with OpenCL software, code portability is crucial to protect our software development investment and reuse the software across different platforms and vendors.</i></p>
                                <p>– Mark Valkenburgh, Sr. Director, Global & Strategic Alliances, GE</p>
                            </div>
                        </div>
                    </div>

                    <p>&nbsp;</p>
                    <p class="mb-0">&nbsp;</p>

                    <p class="mb-0">See other testimonials:</p>
                    <ul>
                        <li><a href="" style="color:blue; text-decoration:none !important">AI &amp; Machine Learning Ecosystem Developer Resources</a></li>
                        <li><a href="" style="color:blue; text-decoration:none !important">HPC Ecosystem Developer Resources</a></li>
                    </ul>

                    </section>
                    </div>
                    <p>&nbsp;</p>

                    <section id="dk_october_2024">
                        <h4 style="font-weight: 300;">Announcing General Availability of Object Storage on Intel® Tiber™ AI Cloud</h4>
                        <p>October 17, 2024 | <a class="b_special_a1" href="">Intel® Tiber™ AI Cloud</a></p>
                        <p>Today Intel announced the availability of a new object storage service on its AI Cloud, providing scalable, durable, and cost-effective data storage that meets the demanding requirements of modern data and AI workloads.</p>
                        <p>It’s built on the powerful and open source MinIO platform, which is compatible with the S3 API (AWS’ Simple Storage Service), ensuring easy integration with existing applications and tools.</p>
                        <p style="text-align:center"><a style="padding: 5px 20px;" class="dk_button" href="">Learn more</a></p>
                        <p class="mb-0">Customer benefits include:</p>
                        <ul>
                            <li><strong>Scalability &amp; flexibility</strong> – Can handle massive data storage needs, whether gigabytes or petabytes, to ensure your storage infrastructure grows with your business.</li>
                            <li><strong>Performance</strong> – Optimized for fast data access and retrieval, ensuring data is always accessible and can be processed quickly, including AI/ML workloads.</li>
                            <li><strong>Cost-effective storage</strong> – Enables businesses of all sizes to store vast amounts of data without breaking the bank.</li>
                            <li><strong>Robust security </strong>– Incorporates encryption at rest and in transit and includes robust access controls.</li>
                            <li><strong>Easy integration</strong> – Is purpose-built to integrate seamlessly with your existing workflows and applications spanning backup and recovery, data archiving, data lake use, and more.</li>
                            <li><strong>Enhanced data management</strong> – Manage your data efficiently with features like versioning, lifecycle policies, and metadata management.</li>
                        </ul>
                        <hr>
                        <p>&nbsp;</p>
                        <p>&nbsp;</p>
                        <h3 style="font-weight: 300;">Inflection AI Launches Enterprise AI Running on Intel® Gaudi® 3 and Intel® Tiber™ AI Cloud</h3>
                        <p>October 7, 2024 | <a class="b_special_a1" href="">Inflection AI-Intel collaboration</a>, <a class="b_special_a1" href="" class="">Intel® Tiber™ AI Cloud</a></p>
                        <p><strong>New collaboration delivers turnkey AI-powered platform to drive high-impact results for enterprises</strong></p>
                        <p>Today Inflection AI and Intel announced a collaboration to accelerate the adoption and impact of AI for the world’s largest enterprises. Inflection AI is launching Inflection 3.0, an industry-first, enterprise-grade AI platform, delivering empathetic, conversational and employee-friendly AI capabilities—powered by Intel® Gaudi® 3 accelerators on Intel® Tiber™ AI Cloud—that provides the control, customization, and scalability required for complex, large-scale deployments.</p>
                        <p style="text-align:center"><a style="padding: 5px 20px;" class="dk_button" href="">Learn more</a></p>
                        
                        <p>&nbsp;</p>

                    <div class="d-flex">
                        <div class="">
                            <i class="fa-solid fa-quote-left" style="font-size: 65px; color: #E5E6E6; padding-right: 15px;"></i>
                        </div>
                        <div class="">
                            <div class="mv_together_content">
                                <p class="mb-2" style="font-weight: 300;"><i>“Together, we’re giving enterprise customers ultimate control over their AI,” said Markus Flierl, CVP of Intel Tiber Cloud Services. “By integrating Inflection AI with Intel Tiber AI Cloud and Gaudi 3, we are providing an open ecosystem of software, price and performance, and scalability,  unlocking the critical roadblocks to enterprise AI adoption and the secure, purpose-built, employee-specific, and culture-oriented AI tools customers need.”</i></p>
                                <p>Markus Flierl, CVP of Intel Tiber Cloud Services
                                </p>
                            </div>
                        </div>
                    </div>
                    <p>&nbsp;</p>
                    <p><strong>Why it matters</strong></p>
                    <p>Building an AI platform is complex, requiring extensive infrastructure; time to develop, train, and fine-tune models; and a multitude of engineers, data scientists, and application developers.</p>
                    <p>With Inflection 3.0, enterprise customers now have access to a complete AI platform that supercharges their employees with a virtual AI co-worker trained on their company data, policies and culture. And running it on Gaudi 3 in the Intel Tiber AI cloud offers high performance, robust software and efficiency, ultimately delivering industry-leading performance, speed and scalability in a cost-effective way for high-impact results.</p>
                    
                    <div class="d-flex justify-content-center">
                        <img class="w-75" src="/img/darshit_image/logo-tiber-ai-cloud-inflection-ai-rwd.png" alt="">    
                        <hr>
                    </div>
                    </section>

                    <section id="dk_september_2024">
                        <h4 style="font-weight: 350; margin: 2.5rem 0 11px;">Intel Launches Xeon 6 and Gaudi 3, Enabling the Next-Generation of AI Solutions</h3>
                            <p>September 24, 2024 | <a class="b_special_a1" href="">Xeon 6 with P-Cores</a>, <a class="b_special_a1" href="">Gaudi 3 AI Accelerator</a></p>
                            <p>Today, Intel launched Intel® Xeon® 6 processors with Performance cores (P-cores) and Intel® Gaudi® 3 AI accelerators, bolstering the company’s commitment to deliver powerful AI systems with optimal performance-per-watt and lower TCO.</p>
                            <p>Highlights of these two major updates to Intel’s AI-focused data center portfolio include:<br>
                                &nbsp;</p>

                                <ul>
                                    <li><strong>Intel Xeon 6 with P-cores </strong>is designed to handle compute-intensive workloads with exceptional efficiency, delivering twice the performance of its predecessor<sup>1</sup>. It features increased core count, double the memory bandwidth, and AI acceleration capabilities embedded in every core.<br>
                                    &nbsp;</li>
                                    <li><strong>Intel Gaudi 3 AI Accelerator </strong>is specifically optimized for large-scale generative AI, boasting 64 Tensor processor cores and 8 matrix multiplications engines to accelerate deep neural network computations. It includes 128 Gigabytes of HBM2e memory for training and inference and 24 200-Gigabit Ethernet ports for scalable networking, and it offers up to 20% more throughput and 2x price/performance vs NVIDIA H100 for inference of Llama 2 70B<sup>2</sup>.</li>
                                </ul>
                                <p class="mb-0">&nbsp;</p>
                                <p style="text-align:center"><a style="padding: 5px 20px;" class="dk_button" href="">Get the details</a></p>

                                <p style="text-align:center"><img alt="" height="163" src="/img/darshit_image/newsroom-intel-xeon-6-e-cores-1.jpg" width="290"></p>

                                <p style="text-align:center"><img alt="" height="340" src="/img/darshit_image/gaudi3-reference-board-wordmark-dm.png" width="340"></p>
                                <hr>
                                <p>&nbsp;</p>
                                <p class="mb-0">&nbsp;</p>

                                <h3 style="font-weight: 350; margin: 2.5rem 0 11px;">Seekr Launches Self-Service AI Enterprise Platform on Intel</h3>
                                <p>September 4, 2024 | <a class="b_special_a1" href="">SeekrFlow</a>, <a class="b_special_a1" href="">Intel® Tiber Developer Cloud</a></p>
                                <p><strong>Deploy trusted AI with Seekr at a superior price-performance running on Intel® Tiber™ Developer Cloud</strong></p>
                                <p><img alt="" height="113" src="/img/darshit_image/logo-seekr-rwd.png" style="float:left" width="200">Today Seekr announced its enterprise-ready platform, SeekrFlow, is now available in the Intel® Tiber™ Developer Cloud, running on high-performance, cost-efficient Intel® Gaudi® AI accelerators.</p>
                                <p>SeekrFlow is a complete end-to-end platform for training, validating, deploying, and scaling trusted enterprise AI applications, reducing the cost and complexity of AI adoption and lessening hallucinations.</p>
                                <p style="text-align:center"><a style="padding: 5px 20px;" class="dk_button" href="">Learn more</a></p>
                                <p><strong>Why it matters</strong></p>
                                <p>In short, customer advantage.</p>
                                <p>By using Intel’s cloud for developing and deploying AI at scale while also leveraging the power of SeekrFlow to run Trusted AI—and doing this all in one place—customers gain excellent price-performance, access to Intel CPUs, GPUs and AI accelerators, and flexibility with an open AI software stack.</p>
                                <hr>
                                <p>&nbsp;</p>
                                <p class="mb-0">&nbsp;</p>
                                <h3 style="font-weight: 350; margin: 2.5rem 0 11px;">Deliver AI Faster on Next-Gen Intel® Core™ Ultra AI PCs</h3>
                                <p>September 3, 2024 | <a class="b_special_a1" href="">Jumpstart AI Development</a>, <a class="b_special_a1" href="">Develop for the AI PC</a></p>
                                <p><img alt="" height="113" src="/img/darshit_image/newsroom-intel-core-ultra-processor-badge.jpg" style="float:left" width="200">Today Intel introduced next-gen Intel® Core™ Ultra processors (code-named Lunar Lake), revealing breakthroughs in efficiency, compute, and AI performance in the latest AI PCs.</p>
                                <p>ISVs, developers, AI engineers, and data scientists can take advantage of the client platform’s AI horsepower for their work—AI PCs are great for developing and optimizing models, applications, and solutions.</p>
                                <ul>
                                    <li>Simplify and accelerate AI training and inference using open source foundational models, optimized frameworks like PyTorch and TensorFlow, and <a class="b_special_a1" href="">Intel® OpenVINO™ toolkit</a>.</li>
                                    <li>Tap into the AI PC’s cutting-edge capabilities such as Intel® AVX-512 and Intel® AI Boost by leveraging <a class="b_special_a1" href="">Intel® Software Development Tools</a> to gain performance and development productivity.</li>
                                    <li>Port your existing CPU/GPU code using <a class="b_special_a1" href="">oneAPI</a> heterogeneous programming and optimize it to run faster while drawing up to 40% less power.</li>
                                </ul>
                                <p>Before the end of 2024, Intel Core Ultra processor-based platforms with integrated software development kits (SDKs) will also be available in <a class="b_special_a1" href="">Intel® Tiber Developer Cloud</a>.</p>
                                <p style="text-align:center"><a style="padding: 5px 20px;" class="dk_button" href="">Get the details</a></p>
                                <hr>
                            </section>
                            <p>&nbsp;</p>
                            <p class="mb-0">&nbsp;</p>

                    <section id="dk_August_2024">
                        <h3 style="font-weight: 350; margin: 2.5rem 0 11px;">AI Everywhere: 2024.2 Intel® Software Development & AI Tools Are Here</h3>
                        <p>Aug. 9 , 2024 | <a class="b_special_a1" href="" rel="noreferrer noopener">Intel® Software Development Tools</a>, <a class="b_special_a1"    href="">Intel® Tiber™ Developer Cloud</a>&nbsp;</p>
                        <h3 style="font-weight: 400; margin: 2.5rem 0 11px;">The fast path to performant, production-ready AI </h3>
                        <p>The latest release of Intel’s oneAPI and oneAPI-powered AI tools are tuned to help developers more easily deliver high-performance AI applications (and HPC, too) with faster time-to-solution, increased hardware choice, and improved reliability. And for building and deploying AI in a production cloud environment, check out new hardware and services in Intel® Tiber™ Developer Cloud.&nbsp;&nbsp;</p>
                        <p style="text-align:center"><a style="padding: 5px 20px;" class="dk_button" href="" rel="noreferrer noopener">Explore &amp; download</a>&nbsp;</p>
                        <h3>3 Key Benefits&nbsp;</h3>
                        <ul>
                            <li><strong>Faster, More Responsive AI </strong>– Achieve up to 2x higher GenAI performance on upcoming Intel® Xeon® 6 processors (P-cores) with <a class="b_special_a1" href="" rel="noreferrer noopener">oneDNN</a>, Intel-optimized AI frameworks, and Intel® AMX<sup>3</sup>&nbsp;and up to 1.6 better performance for workloads including analytics and media (with Xeon 6 E-Cores)<sup>4</sup>. Experience improved LLM inference throughput and scalability on AI PCs – including upcoming client processors (codenamed <a class="b_special_a1" href="" rel="noreferrer noopener">Lunar Lake</a>) for unmatched future-ready AI compute, and <a class="b_special_a1" href="" rel="noreferrer noopener">3.5x AI throughput</a> over the previous generation<sup>5</sup>. The tools support <a class="b_special_a1" href="" rel="noreferrer noopener">500+ models</a> such as Llama 3.1 and Phi-3. Deploy and scale production AI on a managed, cost-efficient infrastructure with Intel Tiber Developer Cloud.&nbsp;</li>
                            <li><strong>Greater Choice &amp; Control </strong>– Maximize performance for AI and HPC workloads on all Intel CPUs and GPUs through continued upstream optimizations to industry-standard AI frameworks. Run and deploy <a class="b_special_a1" href="" rel="noreferrer noopener">PyTorch 2.4 on Intel </a><a class="b_special_a1" href="" rel="noreferrer noopener">GPU</a><a class="b_special_a1" href="" rel="noreferrer noopener">s</a><a class="b_special_a1" href="" rel="noreferrer noopener"> </a>with minimal coding efforts for easier deployment on ubiquitous hardware. Increase application efficiency and control through optimizations in oneMKL, oneTBB, and oneDPL and enhanced SYCL* Graph capabilities in Intel® oneAPI DPC++/C++ Compiler. This release introduces broad tools support for Xeon 6 (E-cores and upcoming P-cores) and Lunar Lake processors for accelerating AI, technical, enterprise, and graphics compute workloads.&nbsp;</li>
                            <li><strong>Simplified Code Optimization </strong>– Speed up AI training and inference performance with Intel® VTune™ Profiler’s platform-aware optimizations, wider framework, and new hardware codename Grand Ridge processors. For easier CUDA* code porting to SYCL*, automatically migrate 100+ more CUDA APIs with the Intel® DPC++ Compatibility Tool; and pinpoint inconsistencies in CUDA-to-SYCL code migration using CodePin instrumentation.&nbsp;</li>
                        </ul>
                        <h3 style="font-weight: 350; margin: 2.5rem 0 11px;">The Nuts & Bolts </h3>
                        <p>For those interested in diving into component-level details, here’s the collection. Foundational tools are bundled in the <a class="b_special_a1" href="" rel="noreferrer noopener">Intel® oneAPI Base Toolkit</a> and <a class="b_special_a1" href="" rel="noreferrer noopener">Intel® HPC Toolkit</a>. For AI tools get just what you need in a <a class="b_special_a1" href="" rel="noreferrer noopener">selector tool</a>.&nbsp;&nbsp;</p>
                        <p>Compilers&nbsp;</p>
                        <ul>
                            <li><a class="b_special_a1" href="" rel="noreferrer noopener">Intel oneAPI DPC++/C++ Compiler</a> includes enhanced SYCL Graph capabilities featuring pause/resume support for better control and increased performance tuning; delivers more SYCL performance on Windows* with default context enabled; and introduces SPIR-V support and OpenCL™ query support with the latest release of the kernel compiler for greater compute kernel flexibility and optimization.&nbsp;</li>
                            <li><a class="b_special_a1" href="" rel="noreferrer noopener">Intel® Fortran Compiler</a> adds integer overflow control options (-fstrict-overflow, Qstrict-overflow[-], and -fnostrict-overflow) to ensure correct functionality; expands conformance enhancements for the latest OpenMP standards, including 5.x and 6.0, for increased thread-usage control and more powerful loop optimizations; and adds OpenMP runtime library extensions for memory management, performance, and efficiency.&nbsp;</li>
                        </ul>
                        <p>Libraries&nbsp;</p>
                        <ul>
                            <li><a class="b_special_a1" href="" rel="noreferrer noopener">Intel® Distribution for Python*</a> adds sorting and summing functions to the Data Parallel Control Library for improved productivity; and provides a new family of cumulative and improved linear algebra functions to Data Parallel Extension for NumPy* for increased performance.&nbsp;&nbsp;</li>
                            <li><a class="b_special_a1" href="" rel="noreferrer noopener">Intel® oneAPI Deep Neural Network Library</a> (oneDNN) delivers production-quality optimizations that increase performance on Intel’s AI-enhanced client processors and server platforms, and boosts AI workload efficiency with support for int8 and int4 weight decompression in matmul, which accelerates LLMs for faster insights and results.&nbsp;</li>
                            <li><a class="b_special_a1" href="" rel="noreferrer noopener">Intel® oneAPI Math Kernel Library</a> (oneMKL) introduces enhanced performance of 2D and 3D real and complex FFT targeted for Intel® Max Series GPUs.&nbsp;</li>
                            <li><a class="b_special_a1" href="" rel="noreferrer noopener">Intel® oneAPI Data Analytics Library</a> (oneDAL) extends sparsity functions across its algorithms by adding DPC++ sparse gemm and gemy primitives and sparsity support for the logloss function primitive.&nbsp;</li>
                            <li><a class="b_special_a1" href="" rel="noreferrer noopener">Intel® oneAPI DPC++ Library</a> (oneDPL) adds new C++ Standard Template Library inclusive_scan algorithm extension, which enables developers to write parallel programs for multiarchitecture devices and improves existing algorithms on Intel and other vendor GPUs.&nbsp;</li>
                            <li><a class="b_special_a1" href="" rel="noreferrer noopener">Intel® oneAPI Collective Communications Library</a> (oneCCL) introduces multiple enhancements that improve system resources utilization such as memory and I/O for even better performance.&nbsp;</li>
                            <li><a class="b_special_a1" href="" rel="noreferrer noopener">Intel® oneAPI Threading Building Blocks</a> (oneTBB) optimizes thread and multi-thread synchronization, which reduces startup latency on 5th Gen Intel Xeon processors and speeds OpenVINO™ toolkit performance up to 4x on ARM CPUs, including Apple Mac*; enhanced parallel_reduce improves data movement to avoid extra copying.&nbsp;</li>
                            <li><a class="b_special_a1" href="" rel="noreferrer noopener">Intel® Integrated Performance Primitives</a> (Intel® IPP) adds optimization patch for zlip 1.3.1 to improve compression ratio and throughput in data-compression tasks, and adds accelerated image-processing capabilities on select color-conversion functions using Intel® AVX-512 VNNI on Intel GPUs.&nbsp;</li>
                            <li><a class="b_special_a1" href="" rel="noreferrer noopener">Intel® IPP Cryptography</a> expands security across government agencies and the private sector, including NIST FIPS 140-3 compliance, and enhances data protection with optimized LMS post-quantum crypto algorithm for single buffer implementation. It also optimizes AES-GCM performance on Intel Xeon and Intel® Core™ Ultra processors via a simplified new code sample, and streamlines development with Clang 16.0 compiler support for Linux*.&nbsp;</li>
                            <li><a class="b_special_a1" href="">Intel® MPI Library</a> increases application performance on machines with multiple Network Interface Cards by enabling developers to pin specific threads to individual NICs; and adds optimizations for GPU-aware broadcasts, RMA peer-to-peer device-initiated communications, intranode thread-splits, and Infiniband* tuning for 5th Gen Intel Xeon processors.&nbsp;</li>
                        </ul>
                        <p>AI &amp; ML Tools &amp; Frameworks&nbsp;</p>
                        <ul>
                            <li>PyTorch* 2.4 now provides <a class="b_special_a1" href="" rel="noreferrer noopener">initial support for Intel® Max Series GPUs</a>, which brings Intel GPUs and the SYCL* software stack into the official PyTorch stack to help further accelerate AI workloads.&nbsp;&nbsp;</li>
                            <li><a class="b_special_a1" href="" rel="noreferrer noopener">Intel Extension for PyTorch*</a> provides better tuning for CPU performance for Bert_Large, Stable Diffusion using FP16 optimizations in eager mode. Popular&nbsp; <a class="b_special_a1" href="" rel="noreferrer noopener">LLM models </a>are optimized for Intel GPUs using <a class="b_special_a1" href="" rel="noreferrer noopener">weight-only quantization (WOQ)</a> to reduce the amount of memory access without losing accuracy while still improving performance.&nbsp;&nbsp;</li>
                            <li><a class="b_special_a1" href="" rel="noreferrer noopener">Intel Neural Compressor</a> improves INT8 and INT4 LLM model performance using SmoothQuant and WOQ algorithms in more than 15+ popular LLM quantization&nbsp; <a class="b_special_a1" href="" rel="noreferrer noopener">recipes</a>. Take advantage of in-place mode in WOQ to reduce memory footprint when running the quantization process. Improve model accuracy&nbsp; with <a class="b_special_a1" href="" rel="noreferrer noopener">AutoRound</a>, a low-bit quantization method for LLM inference to fine-tune rounding values and minmax values of weights in fewer steps. New Wanda and DSNOT pruning algorithms for PyTorch LLM help improve performance during AI inferencing while the SNIP algorithm enables scaling models on multi-card or multi-nodes (CPU).&nbsp;</li>
                        </ul>
                        <p>Analysis, Debug and Code Migration Tools&nbsp;</p>
                        <ul>
                            <li><a class="b_special_a1" href="" rel="noreferrer noopener">Intel® VTune™ Profiler</a> enables deeper insights into sub-optimal oneCCL communication, adds support for .NET8, and supports upcoming codename Grand Ridge processors. A technical preview feature allows developers to get a high-level view of potential bottlenecks in software performance analysis before exploring top-down microarchitecture metrics for deeper analysis.&nbsp;</li>
                            <li><a class="b_special_a1" href="" rel="noreferrer noopener">Intel® DPC++ Compatibility Tool</a> accelerates visual AI and imaging applications on multivendor GPUs via option-enabled migration to SYCL* image API extension; auto-compares kernel run logs and reports differences for migrated SYCL code; and can migrate 126 commonly-used CUDA APIs.&nbsp;&nbsp;</li>
                            <li><a class="b_special_a1" href="" rel="noreferrer noopener">Intel® Distribution for GDB*</a> supports Core Ultra processors on Windows*; adds Land Variable Watch Window to monitor and analyze variables and enhance application stability faster and more efficiently in VS Code*; and expands Control-flow Enforcement Technology (CET) to strengthen application security.&nbsp;</li>
                        </ul>
                        <p style="text-align:center"><a style="padding: 5px 20px;" class="dk_button" href="">Explore &amp; download the tools&nbsp;</a></p>
                        <p>Get deeper details with a developer’s perspective on new features <a class="b_special_a1" href="" rel="noreferrer noopener">in this blog</a> and in <a class="b_special_a1" href="" rel="noreferrer noopener">tools release notes</a>.&nbsp;</p>
                        <h4>Build &amp; Deploy AI Solutions at Scale in Intel Tiber Developer Cloud&nbsp;</h4>
                        <p>Develop and deploy AI models, applications, and production workloads on the latest Intel architecture using an open software stack that’s built on oneAPI and includes popular foundational models and optimized tools and frameworks.&nbsp;</p>
                        <p class="mb-0">New hardware and services—access:&nbsp;</p>
                        <ul>
                            <li>Virtual machines with Intel® Max Series GPUs&nbsp;</li>
                            <li>GenAI Jupyter notebooks with Intel® Gaudi® 2 accelerators&nbsp;</li>
                            <li>Intel® Kubernetes Service with container deployment via K8s APIs&nbsp;</li>
                            <li>Intel Xeon 6 preproduction systems in the preview environment&nbsp;</li>
                        </ul>
                        <p style="text-align:center"><a style="padding: 5px 20px;" class="dk_button" href="" rel="noreferrer noopener">Learn more &amp; get started</a>&nbsp;</p>
                        <hr>
                        <p>&nbsp;</p>
                        <p class="mb-0">&nbsp;</p>
                    </section>
                    <section id="dk_june_2024">
                        <h3 style="font-weight: 350; margin: 2.5rem 0 11px;">Intel® Gaudi® 2 Enables a Lower Cost Alternative for AI Compute and GenAI</h3>
                        <p>June 12, 2024 | <a class="b_special_a1" href="">Intel® Gaudi® 2 AI Accelerator</a>, <a class="b_special_a1"  href="">Intel® Tiber™ Developer Cloud</a></p>
                        <p><img alt="" height="141" src="/img/darshit_image/newsroom-gaudi2.jpg" style="float:left" width="250">Today, MLCommons published results of its industry AI performance benchmark: MLPerf Training v4.0. Intel’s results illustrate the choice Intel Gaudi 2 AI accelerators offer to enterprises and customers.</p>
                        <p>Intel submitted results on a large Gaudi 2 system (1,024 Gaudi 2 accelerators) trained in the Intel Tiber Developer Cloud to demonstrate the AI accelerator’s performance and scalability—it can handily train 70B-175B parameter LLMs—as well as Tiber Developer Cloud’s capacity for efficiently training MLPerf’s GPT-3 175B<sup>1</sup> parameter benchmark model.</p>
                        <p><strong>Results</strong></p>
                        <p>Gaudi 2 continues to be the only MLPerf-benchmarked alternative for AI compute to the Nvidia H100. Trained in the Tiber Developer Cloud, Intel’s GPT-3 results for time-to-train (TTT) of 66.9 minutes on an AI system of 1,024 Gaudi accelerators proves strong Gaudi 2 scaling performance on ultra-large LLMs within a developer cloud environment<sup>1</sup>.</p>
                        <p>The benchmark suite also featured a new measurement: fine-tuning the Llama 2 70B parameter model using LoRA (Low-Rank Adaptation, a fine-tuning method for large language and diffusion models). Intel’s submission achieved TTT of 78.1 minutes on eight Gaudi 2 accelerators.</p>
                        <p style="text-align:center"><a style="padding: 5px 20px;" class="dk_button" href="">Get the details</a></p>
                        <p><strong>How Gaudi provides AI value to customers</strong></p>
                        <p>High costs have priced too many enterprises out of the market. Intel Gaudi is starting to change that. At Computex, Intel announced that a standard AI kit including eight Intel Gaudi 2 accelerators with a universal baseboard (UBB) offered to system providers at $65,000 is estimated to be one-third the cost of comparable competitive platforms. A kit including eight Intel Gaudi 3 accelerators with a UBB lists at $125,000, estimated to be two-thirds the cost of comparable competitive platforms<sup>2</sup>.</p>
                        <p><strong>The value of Intel Tiber Developer Cloud</strong></p>
                        <p>Intel’s cloud provides enterprise customers a unique, managed, and cost-efficient platform to develop and deploy AI models, applications, and solutions—from single nodes to large cluster-level compute capacity. This platform increases access to Gaudi for AI compute needs—in the Tiber Developer Cloud, Intel makes its accelerators, CPUs, GPUs, an open AI software stack, and other services are easily accessible. <a class="b_special_a1" href="">Learn more</a>.</p>
                        <p class="mb-0"><strong>More resources</strong></p>
                        <ul>
                            <li><a class="b_special_a1" href="">MLCommons</a></li>
                            <li><a class="b_special_a1" href="">MLPerf 4.0 Training benchmark results</a></li>
                            <li><a class="b_special_a1" href="">Llama 2 70B: An MLPerf Inference Benchmark for LLMs</a></li>
                        </ul>
                        <p style="color: #bbb;"><sup>1</sup> MLPerf's GPT-3 measurement is conducted on a 1% representative slice of the entire model as determined by the participating companies who collectively devise the MLCommons benchmark.</p>
                        <p style="color: #bbb;"><sup>2</sup> Pricing guidance for cards and systems is for modeling purposes only. Please consult your original equipment manufacturer (OEM) of choice for final pricing. Results may vary based upon volumes and lead times.</p>
                        <p style="color: #bbb;">For workloads and configurations, visit MLCommons.org. Results may vary.</p>
                        <hr>
                        <p>&nbsp;</p>
                        <p class="mb-0">&nbsp;</p>
                    </section>

                    <section id="dk_may_2024">
                        <h3 style="font-weight: 350; margin: 2.5rem 0 11px;">More than 500 AI Models Run Optimized on Intel® Core™ Ultra Processors</h3>
                        <p>May 1, 2024 | &nbsp;<a class="b_special_a1" href="">Intel® Core™ Ultra Processor family</a></p>
                        <p><strong>Intel builds the PC industry’s most robust AI PC toolchain</strong></p>
                        <p><img alt="" height="141" src="/img/darshit_image/newsrsoom-intel-core-ultra-wafer.jpg" style="float:left" width="250">Today, Intel announced it has surpassed 500 pre-trained AI models running optimized on new Intel® Core™ Ultra processors, the industry’s premier AI PC processor available in the market.</p>
                        <p>The models span more than 20 categories of local AI inferencing: large language, diffusion, super resolution, object detection, image classification and segmentation, and computer vision, among others. They include Phi-2, Mistral, Llama, BERT, Whisper, and Stable Diffusion 1.5.</p>
                        <p>This is a landmark moment for Intel’s efforts to nurture and support the AI PC transformation—the Intel Core Ultra processor is the fastest growing AI PC processor to date; it feature new AI experiences, immersive graphics, and optimal battery life; and it’s the most robust platform for AI PC development, with more AI models, frameworks, and runtimes enabled than any other processor vendor.</p>
                        <p>All 500 models can be deployed across CPU, GPU, and NPU. They are available across popular industry sources such as OpenVINO Model Zoo, Hugging Face, ONNX Model Zoo, and PyTorch.</p>
                        <p style="text-align:center"><a style="padding: 5px 20px;" class="dk_button" href="">Get the details</a></p>
                        <p><strong>Additional resources</strong></p>
                        <ul>
                            <li><a class="b_special_a1" href="">Software development tools for Intel® Core™ Ultra Processors</a></li>
                            <li><a class="b_special_a1" href="">Get started with AI PC development</a></li>
                        </ul>
                        <hr>
                        <p>&nbsp;</p>
                        <p class="mb-0">&nbsp;</p>
                    </section>

                    
                    <section id="dk_april_2024">
                        <h3 style="font-weight: 350; margin: 2.5rem 0 11px;">Canonical Ubuntu* 24.04 LTS Release Optimized by Intel® Technology</h3>
                        <p>April 25, 2024  | &nbsp;<a class="b_special_a1" href=""> Ubuntu 24.04 LTS, Intel® QAT, </a>
                            <a class="b_special_a1" href=""> Intel® TDX</a></p>
                        <p><strong>Intel builds the PC industry’s most robust AI PC toolchain</strong></p>
                        <p><img alt="" height="141" src="/img/darshit_image/logo-canonical-color-transparent.png" style="float:left" width="250">Today, Canonical announced the release of Ubuntu* 24.04 LTS (codenamed Noble Numbat). This 10<sup>th</sup> Long Term Supported release merges advancements in performance engineering and confidential computing, including integration of Intel® QuickAssist Technology (Intel® QAT) for workload acceleration on CPU and support for Intel® Trust Domain Extensions (Intel® TDX) to strengthen confidential computing in private data centers.</p>
                        <p class="mb-0">&nbsp;</p>
                        <p>&nbsp;</p>
                        <div class="d-flex">
                            <div class="">
                                <i class="fa-solid fa-quote-left" style="font-size: 65px; color: #E5E6E6; padding-right: 15px;"></i>
                            </div>
                            <div class="">
                                <div class="mv_together_content">
                                    <p class="mb-2" style="font-weight: 300;"><i>“Ubuntu is a natural fit to enable the most advanced Intel features. Canonical and Intel have a shared philosophy of enabling performance and security at scale across platforms.”</i></p>
                                    <p>– Mark Skarpness, VP and GM of System Software Engineering, Intel Corporation
                                    </p>
                                </div>
                            </div>
                        </div>
                        <p class="">&nbsp;</p>
                        <p class="">&nbsp;</p>
                        <p class="mb-0"><strong>Release Highlights</strong><br>
                            &nbsp;</p>
                            <ul>
                                <li><strong>Performance-engineering tools </strong>– Includes the latest Linux* 6.8 kernel with improved syscall performance, nested KVM support on ppc64el, features to reduce kernel task scheduling delays, and frame pointers enabled by default on all 64-bit architectures for more complete CPU and off-CPU profiling.</li>
                                <li><strong>Intel® QAT integration </strong>– Enables accelerated encryption and compression, reduce CPU utilization, and improve networking and storage application performance on 4<sup>th</sup> Gen and new Intel® Xeon® Scalable processors.</li>
                                <li><strong>Intel® TDX support </strong>– The release seamlessly supports the extensions on both the host and guest sides, with no changes required to the application layer, greatly simplifying the porting and migration of existing workloads to a confidential computing environment.</li>
                                <li><strong>Increased developer productivity </strong>– Includes Python* 3.12, Ruby 3.2, PHP 8.3, and Go 1.22, with additional focus dedicated to the developer experience for .NET, Java, and Rust.</li>
                            </ul>  
                            <p style="text-align: center;"><a style="padding: 5px 20px;" class="dk_button" href="">Learn more</a><br>
                                <a class="b_special_a1" href="">Download Ubuntu 24.04 LTS</a><br>
                                <a class="b_special_a1" href="">Noble Numbat Deep Dive</a></p>  
                                <p><strong>About Canonical</strong></p>
                                <p><a href="http://canonical.com">Canonical</a>, the publisher of Ubuntu, provides open source security, support, and services. Its portfolio covers critical systems, from the smallest devices to the largest clouds, from the kernel to containers, from databases to AI.&nbsp;</p>
                                <hr>
                                <p>&nbsp;</p>
                                <p class="mb-0">&nbsp;</p>
                        <h3 style="font-weight: 350; margin: 2.5rem 0 11px;">Seekr Grows AI Business with Big Cost Savings on Intel® Tiber™ Developer Cloud</h3>
                        <p>April 10, 2024 | &nbsp;<a class="b_special_a1" href="">Intel® Tiber® Developer Cloud</a></p>
                        <p><strong>Trustworthy AI for content evaluation and generation at reduced costs</strong></p>
                        <p>&nbsp;</p>
                        <p><img alt="" height="98" src="/img/darshit_image/logo-seekr-rwd (1).png" style="float:left" width="175">Named one of the most innovative companies of 2024 by Fast Company, <a class="b_special_a1" href="">Seekr</a> is using the Intel® Tiber™ Developer Cloud<sup>1</sup> to build, train, and deploy advanced LLMs on cost-effective clusters running on the latest Intel hardware and software, including Intel® Gaudi® 2 AI accelerators. This strategic collaboration to accelerate AI helps Seekr meet the enormous demand for compute capacity while reducing its cloud costs and increasing workload performance.</p>
                        <p><strong>Solution overview at a glance</strong></p>
                        <p>Two of Seekr’s popular products, Flow and Align, help customers leverage AI to deploy and optimize their content and advertising strategies and to train, build, and manage the entire LLM pipeline using scalable and composable workflows.</p>
                        <p>This takes immense compute capacity which, historically, would require a significant infrastructure investment and considerable cloud costs.</p>
                        <p>By moving their production workloads from on-premise to Intel Tiber Developer Cloud, Seekr is now able to employ the power and capacity of Intel hardware and software technologies—including thousands of Intel Gaudi 2 cards—to build its LLMs, and do so at a <strong>fraction of the price</strong> and with <strong>exceptionally high performance</strong>.</p>
                        <p style="text-align:center"><a style="padding: 5px 20px;" class="dk_button" href="">Learn more →</a></p>
                        <p style="text-align:center"><a class="b_special_a1" href="">Read the case study</a> (includes benchmarks)</p>
                        <p><strong>About Seekr</strong></p>
                        <p>Seekr builds large language models (LLMs) that identify, score, and generate reliable content at scale; the company’s goal is to make the Internet safer and more valuable to use while solving their customers’ need for brand trust. Its customers include Moderna, SimpliSafe, Babbel, Constant Contact, and Indeed.</p>
                        <p style="color: #bbb;"><sup>1</sup> Formerly “Intel® Developer Cloud”; now part of the Intel® Tiber™ portfolio of enterprise business solutions.</p>
                        <hr>
                        <p class="mb-0">&nbsp;</p>
                        <p class="mb-0">&nbsp;</p>

                        <h3 style="font-weight: 350; margin: 2.5rem 0 11px;">Intel Vision 2024 Unveils Depth & Breadth of Open, Secure, Enterprise AI</h3>
                        <p>April 9, 2024</p>
                        <p>At <a class="b_special_a1" href="">Intel Vision 2024</a>, Intel CEO Pat Gelsinger introduced new strategies, next-gen products and portfolios, customers, and collaborations spanning the AI continuum.</p>
                        <p>Topping the list is Intel® Tiber™, a rich portfolio of complementary business solutions to streamline deployment of enterprise software and services across AI, cloud, edge, and trust and security; and the Intel® Gaudi® 3 accelerator, bringing more performance, openness, and choice to enterprise GenAI.</p>
                        <p>More than 20 customers showcased their leading AI solutions running on Intel® architecture, with LLM/LVM platform providers Landing.ai, Roboflow, and Seekr demonstrating how they use Intel Gaudi 2 accelerators on the Intel® Tiber™ Developer Cloud to develop, fine-tune, and deploy their production-level solutions.</p>
                        <p>Specific to collaborations, Intel announced them with Google Cloud, Thales, and Cohesivity, each of whom is leveraging Intel’s confidential computing capabilities—including Intel® Trust Domain Extensions (Intel® TDX), Intel® Software Guard Extensions (Intel® SGX), and Intel® Tiber™ Trust Services<sup>1</sup> attestation service—in their cloud instances.</p>
                        <p>A lot more was revealed, including formation of the Open Platform for Enterprise AI and Intel’s expanded AI roadmap inclusive of 6<sup>th</sup> Gen Intel® Xeon® processors with E- and P-cores and silicon for client, edge, and connectivity.</p>
                        <p style="text-align:center"><a style="padding: 5px 20px;" class="dk_button" href="">Read the press release</a>&nbsp;</p>
                        <p class="mb-0">&nbsp;</p>
                        <div class="d-flex">
                            <div class="">
                                <i class="fa-solid fa-quote-left" style="font-size: 65px; color: #E5E6E6; padding-right: 15px;"></i>
                            </div>
                            <div class="">
                                <div class="mv_together_content">
                                    <p class="mb-2" style="font-weight: 300;"><i>“We’re seeing incredible customer momentum and demonstrating how Intel’s open, scalable systems, powered by Intel Gaudi, Xeon, Core Ultra processors, Ethernet-enabled networking, and open software, unleash AI today and tomorrow, bringing AI everywhere for enterprises.”</i></p>
                                    <p>– Pat Gelsinger, CEO, Intel
                                    </p>
                                </div>
                            </div>
                        </div>
                        <p class="mb-0">&nbsp;</p>
                        <p class="mb-0">&nbsp;</p>
                        <p><strong>Highlights</strong></p>
                        <p><strong><img alt="" height="113" src="/img/darshit_image/newsroom-intel-tiber-logo.jpg" style="float:left" width="200">Intel Tiber portfolio of business solutions</strong> simplifies the deployment of enterprise software and services, including for AI, making it easier for customers to find complementary solutions that fit their needs, accelerate innovation, and unlock greater value without compromising on security, compliance, or performance. Full rollout is planned in the 3<sup>rd</sup> quarter of 2024.&nbsp;<a class="b_special_a1" href="">Explore Intel Tiber now</a>.</p>
                        <p><strong>Intel Gaudi 3 AI accelerator</strong> promises 4x more compute and 1.5x increase in memory bandwidth over Gaudi 2 and is projected to outperform NVIDIA H100 by an average of 50% on inference and 60% on power efficiency for LLaMa 7B and 70B and Falcon 180B LLMs. It will be available the 2<sup>nd</sup> quarter of 2024, including in the Intel Developer Cloud.</p>
                        <p><strong>Intel Tiber Developer Cloud’s latest release</strong> includes new hardware and services that boost compute capacity, including bare metal as a service (BMaaS) options that host large-scale clusters of Gaudi 2 accelerators and Intel® Max Series GPUs, VMs running on Gaudi 2, storage as a service (StaaS) including file storage, and Intel® Kubernetes Service for cloud-native AI workloads.</p>
                        <p>Find out how <a class="b_special_a1" href="">Seekr</a> used Intel Developer Cloud to deploy a trustworthy LLM for content generation and evaluation at scale.</p>
                        <p style="text-align:center"><a style="padding: 5px 20px;" class="dk_button" href="">Case Study</a>&nbsp;<a style="padding: 5px 20px;" class="dk_button" href="">Blog</a></p>
                        <p><strong>Confidential computing collaborations</strong> with Thales and Cohesity increase trust and security and decrease risk for enterprise customers.<br>
                            &nbsp;</p>
                            <ul>
                                <li><a class="b_special_a1" href="">Thales</a>, a leading global tech and security provider, announced a data security solution comprised of its own CipherTrust Data Security Platform on Google Cloud Platform for end-to-end data protection and Intel Tiber Trust Services for confidential computing and trusted cloud-independent attestation. This will give enterprises additional controls to protect data at rest, in transit, and in use.</li>
                            </ul>
                            <p style="text-align:center"><a class="dk_button" style="padding: 5px 20px;" href="">Press Release</a> <a class="dk_button" style="padding: 5px 20px;" href="">Blog</a><br>
                                &nbsp;</p>
                                <ul>
                                    <li><a class="b_special_a1" href="">Cohesity</a>, a leader in AI-powered data security and management, announced the addition of confidential computing capabilities to Cohesity Data Cloud. The solution leverages its Fort Knox cyber vault service for data-in-use encryption, in tandem with Intel SGX and Intel Tiber Trust Services to reduce the risk posed by bad actors accessing data while it’s being processed in main memory. This is critical for regulated industries such as financial services, healthcare, and government.</li>
                                </ul>
                                <p style="text-align:center"><a class="dk_button"
                                    style="padding: 5px 20px;" href="">Press Release</a>&nbsp;<a class="dk_button"
                                    style="padding: 5px 20px;" href="">Blog</a></p>

                                    <p><strong>Explore more</strong></p>
                                    <ul>
                                        <li><a class="b_special_a1" href="">Intel’s Enterprise Software Portfolio</a></li>
                                        <li><a class="b_special_a1" href="">Intel Tiber Developer Cloud</a></li>
                                        <li><a class="b_special_a1" href="">Intel® Confidential Computing Solutions</a></li>
                                        <li><a class="b_special_a1" href="">Intel TDX</a></li>
                                        <li><a class="b_special_a1" href="">Intel SGX</a></li>
                                    </ul>
                                    <p style="color: #bbb;"><sup>1</sup> Formerly Intel® Trust Authority</p>
                                    <hr>
                                    <p class="mb-0">&nbsp;</p>
                                    <p class="mb-0">&nbsp;</p>
                    </section>

                    <section id="dk_march_2024">
                        <h3 style="font-weight: 350; margin: 2.5rem 0 11px;">Just Released: Intel® Software Development Tools 2024.1</h3>
                        <p>March 28, 2024 | <a class="b_special_a1" href="">Intel® Software Development Tools</a></p>
                        <p><strong>Accelerate code with confidence on the world’s first SYCL 2020-conformant toolchain</strong></p>
                        <p>The 2024.1 Intel® Software Development Tools are now available and include <strong>a major milestone</strong> for accelerated computing:&nbsp; <a class="b_special_a1" href="">Intel® oneAPI DPC++/C++ Compiler</a> has become <a class="b_special_a1" href=""><strong>the</strong> <strong>first compiler</strong></a> to adopt the full <a class="b_special_a1" href="">SYCL 2020 specification</a>.</p>
                        <p>Why is this important?</p>
                        <p>Having a SYCL 2020-conformant compiler means developers can have confidence that their code is future-proof—it’s portable and reliably performant across the diversity of existing and future-emergent architectures and hardware targets, including GPUs.</p>

                        <p class="">&nbsp;</p>
                        <div class="d-flex">
                            <div class="">
                                <i class="fa-solid fa-quote-left" style="font-size: 65px; color: #E5E6E6; padding-right: 15px;"></i>
                            </div>
                            <div class="">
                                <div class="mv_together_content">
                                    <p class="mb-2" style="font-weight: 300;"><i>“SYCL 2020 enables productive heterogeneous computing today, providing the necessary controls to write high-performance parallel software for the complex reality of today’s software and hardware. Intel’s commitment to supporting open standards is again showcased as they become a SYCL 2020 Khronos Adopter.”</i></p>
                                    <p>– Dr. Tom Deakin, Lecturer in Advanced Computer Systems, University of Bristol and Chair of the SYCL Working Group for Khronos
                                    </p>
                                </div>
                            </div>
                        </div>
                        <p class="mb-0">&nbsp;</p>
                        <p class="mb-0">&nbsp;</p>
                        <p style="text-align:center"><a style="padding: 5px 20px;" class="dk_button" href="">Explore &amp; download the tools</a></p>
                        <p><strong>Key Benefits</strong><br>
                            &nbsp;</p>
                            <ol>
                                <li><strong>Code with Confidence &amp; Build Faster </strong>– Optimize parallelization for higher performance and productivity in modern C++ code via the Intel oneAPI DPC++/C++ Compiler, now with full SYCL 2020 conformance; explore new multiarchitecture features across AI, HPC, and distributed computing; and access relevant AI Tools faster and more easily with an expanded set of <a class="b_special_a1" href="">web-based selector</a> options.</li>
                                <li><strong>Accelerate AI Workloads &amp; Lower Compute Costs </strong>– Achieve performance improvements on new Intel CPUs and GPUs, including up to 14x with oneDNN on 5<sup>th</sup> Gen Intel® Xeon® Scalable processors<sup>1</sup>; 10x to 100x out-of-the-box acceleration of popular deep learning frameworks and libraries such as PyTorch* and TensorFlow*<sup>2</sup>; and faster gradient boosting inference across XGBoost, LightGBM, and CatBoost. Perform parallel computations at reduced cost with Intel® Extension for Scikit-learn* algorithms.</li>
                                <li><strong>Increase Innovation &amp; Expand Deployment</strong> – Tune once and deploy universally with more efficient code offload using SYCL Graph, now available on multiple SYCL backends in the Intel oneAPI DPC++/C++ Compiler; ease CUDA-to-SYCL migration of more CUDA APIs in the Intel® DPC++ Compatibility Tool; and explore time savings in a CodePin Tech Preview (new SYCLomatic feature) to auto-capture test vectors and start validation immediately after migration. Codeplay adds new support and capabilities to its oneAPI plugins for NVIDIA and AMD GPUs.</li>
                            </ol> 
                            <p>&nbsp;</p>
                            <p><strong>The Nuts &amp; Bolts</strong></p>
                            <p>For those of you interested in diving into the component-level deets, here’s the collection.</p>
                            <p class="mb-0">Compilers</p>
                            <ul>
                                <li><a class="b_special_a1" href="">Intel oneAPI DPC++/C++ Compiler</a> is the first compiler to achieve SYCL 2020 conformance, giving developers confidence that their SYCL code is portable and reliably performs on the diversity of current and emergent GPUs. Enhanced SYCL Graph allows for seamless integration of multi-threaded work and thread-safe functions with applications and is now available on multiple SYCL backends, enabling tune-once-deploy-anywhere capability. Expanded conformance to OpenMP 5.0, 5.1, 5.2, and TR12 language standards enables increased performance.</li>
                                <li><a class="b_special_a1" href="">Intel® Fortran Compiler</a> adds more Fortran 2023 language features including improved compatibility and interoperability between C and Fortran code, simplified trigonometric calculations, and predefined data types to improve code portability and ensure consistent behavior; makes OpenMP offload programming more productive; and increases compiler stability.</li>
                            </ul>    
                            
                            <p class="mb-0">Performance Libraries</p>
                            <ul>
                                <li><a class="b_special_a1" href="">Intel® oneAPI Math Kernel Library</a> (oneMKL) introduces new optimizations and functionalities to reduce the data transfer between Intel GPUs and the host CPU, enables the ability to reproduce results of BLAS level 3 operations on Intel GPUs from run-to-run through CNR, and streamlines CUDA-to-SYCL porting via the addition of CUDA-equivalent functions.</li>
                                <li><a class="b_special_a1" href="">Intel® oneAPI Data Analytics Library</a> (oneDAL) enables gradient boosting inference acceleration across XGBoost*, LightGBM*, and CatBoost* without sacrificing accuracy; improves clustering by adding spare K-Means support to automatically identify a subset of the features used in clustering observations.</li>
                                <li><a class="b_special_a1" href="">Intel® oneAPI Deep Neural Network Library</a> (oneDNN) adds support for GPT-Q to improve LLM performance, fp8 data type in primitives and Graph API, fp16 and bf16 scale and shift arguments for layer normalization, and opt-in deterministic mode to guarantee results are bitwise identical between runs in a fixed environment.</li>
                                <li><a class="b_special_a1" href="">Intel® oneAPI DPC++ Library</a> (oneDPL) adds a specialized sort algorithm to improve app performance on Intel GPUs, adds transform_if variant with mask input for stencil computation needs, and extends C++ STL style programming with histogram algorithms to accelerate AI and scientific computing.</li>
                                <li><a class="b_special_a1" href="">Intel® oneAPI Collective Communications Library</a> (oneCCL) optimizes all key communication patterns to speed up message passing in a memory-efficient manner and improve inference performance.</li>
                                <li><a class="b_special_a1" href="">Intel® Integrated Performance Primitives</a> expands features and support for quantum computing, cybersecurity, and data compression, including XMSS post-quantum hash-based cryptographic algorithm (tech preview), FIPS 140-3 compliance, and updated LZ4 lossless data compression algorithm for faster data transfer and reduced storage requirements in large data-intensive applications. &nbsp;</li>
                                <li><a class="b_special_a1" href="">Intel® MPI Library</a> adds new features to improve application performance and programming productivity, including GPU RMA for more efficient access to remote memory and MPI 4.0 support for Persistent Collectives and Large Counts.</li>
                            </ul>
                            <p class="mb-0">AI &amp; ML Tools &amp; Frameworks</p>
                            <ul>
                                <li><a class="b_special_a1" href="">Intel® Distribution for Python*</a> expands the ability to develop more future-proof code, including Data Parallel Control (dpctl) library’s 100% conformance to the Python Array API standard and support for NVIDIA devices; Data Parallel Extension for NumPy* enhancements for linear algebra, data manipulation, statistics, data types, plus extended support for keyword arguments; and Data Parallel Extension for Numba* improvements to kernel launch times.</li>
                                <li><a class="b_special_a1" href="">Intel Extension for Scikit-learn</a> reduces the computational costs on GPUs by making computations only on changed dataset pieces with Incremental Covariance and performing parallel GPU computations using SPMD interfaces. &nbsp;&nbsp;</li>
                                <li><a class="b_special_a1" href="">Intel® Distribution of Modin</a>* delivers significant enhancements in security and performance, including a robust security solution that ensures proactive identification and remediation of data asset vulnerabilities, and performance fixes to optimize asynchronous execution. (Note: in the 2024.2 release, developers will be able to access Modin through upstream channels.)</li>
                            </ul>
                            <p class="mb-0">Analyzers &amp; Debuggers</p>
                            <ul>
                                <li><a class="b_special_a1" href="">Intel® VTune™ Profiler</a> expands the ability to identify and understand the reasons of implicit USM data movements between Host and GPU causing performance inefficiencies in SYCL applications; adds support for .NET 8, Ubuntu* 23.10, and FreeBSD* 14.0.</li>
                                <li><a class="b_special_a1" href="">Intel® Distribution for GDB*</a> rebases to GDB 14, staying current and aligned with the latest application debug enhancements; enables the ability to monitor and troubleshoot memory access issues in real time; and adds large General Purpose Register File debug mode support for more comprehensive debugging and optimization of GPU-accelerated applications.</li>
                            </ul>
                            <p class="mb-0">Rendering &amp; Ray Tracing</p>
                            <ul>
                                <li><a class="b_special_a1" href="">Intel® Embree</a> adds enhanced error reporting for SYCL platform and driver to smooth the transition of cross-architecture code; improves stability, security, and performance capabilities.</li>
                                <li><a class="b_special_a1" href="">Intel® Open Image Denoise</a> fully supports multi-vendor denoising across all platforms: x86 and ARM CPUs (including ARM support on Windows*, Linux*, and macOS*) and Intel, NVIDIA, AMD, and Apple GPUs.</li>
                            </ul>
                            <p style="text-align:center"><a style="padding: 5px 20px;" class="dk_button" href="">Explore &amp; download the tools</a></p>
                            <p>&nbsp;</p>
                            <p class="mb-0"><strong>More Resources</strong></p>
                            <ul>
                                <li><a class="b_special_a1" href="">Intel Compiler First to Achieve SYCL 2020 Conformance</a></li>
                                <li><a class="b_special_a1" href="">A Dev's Take on the 2024.1 Release</a></li>
                                <li>Download Codeplay oneAPI plugins: <a class="b_special_a1" href="">NVIDIA GPUs</a> | <a class="b_special_a1" href="">AMD GPUs</a></li>
                            </ul>
                            <p style="color:#bbb;"><strong>Footnotes</strong></p>
                            <p style="color:#bbb;">1 <a href="" style="color:blue; text-decoration:underline 
                            !important">Performance Index:&nbsp; 5th Gen Intel Xeon Scalable Processors</a><br>
                                2 <a href="" style="color:blue; text-decoration:underline 
                                !important">Software AI accelerators: AI performance boost for free</a></p>
                            <hr>
                            <p class="mb-0">&nbsp;</p>
                            <p class="mb-0">&nbsp;</p>

                        <h3 style="font-weight: 350; margin: 2.5rem 0 11px;">Gaudi and Xeon Advance Inference Performance for Generative AI</h3>
                        <p>March 27, 2024 | <a href="" style="color:blue; text-decoration:underline 
                        !important">Intel® Developer Cloud</a>, <a href="" style="color:blue; text-decoration:underline 
                        !important">MLCommons</a></p>
                        <p><strong>Newest MLPerf results for Intel® Gaudi 2 accelerators and 5<sup>th</sup> Gen Intel® Xeon® processors demonstrate Intel is raising the bar for GenAI performance.</strong></p>
                        <p>Today, MLCommons published results of the industry standard MLPerf v4.0 benchmark for inference, inclusive of Intel’s submissions for its Gaudi 2 accelerators and 5<sup>th</sup> Gen intel Xeon Scalable processors with Intel® AMX.</p>
                        <p>As the only benchmarked alternative to NVIDIA H100* for large language and multi-model models, Gaudi 2 offers compelling price/performance, important when gauging the total cost of ownership. On the CPU side, Intel remains the only server CPU vendor to submit MLPerf results (and Xeon is the host CPU for many accelerator submissions).</p>
                        <p>Get the details and results <a class="b_special_a1" href="">here</a>.</p>
                        <p><strong>Try them in the Intel® Developer Cloud</strong></p>
                        <p>You can evaluate 5<sup>th</sup> Gen Xeon and Gaudi 2 in the Intel Developer Cloud, including running small- and large-scale training (LLM or generative AI) and inference production workloads at scale and managing AI compute resources. Explore the subscription options and sign up for an account <a class="b_special_a1" href="">here</a>.</p>
                        <hr>
                        <p class="mb-0">&nbsp;</p>
                        <p class="mb-0">&nbsp;</p>

                        <h3 style="font-weight: 350; margin: 2.5rem 0 11px;">Intel Open Sources Continuous Profiler Solution, Automating Always-On CPU Performance Analysis</h3>
                        <p>March 11, 2024 | <a href="" style="color:blue; text-decoration:underline !important">Intel® Granulate™ Cloud Optimization Software</a></p>
                        <p><strong>A continuous, autonomous way to find runtime efficiencies and simplify code optimization.</strong></p>
                        <p>Today, Intel has released to open source the Continuous Profiler optimization agent, serving as another example of the company’s open ecosystem approach to catalyze innovation and boost productivity for developers.</p>
                        <p>As its name indicates, Continuous Profiler keeps perpetual oversight on CPU utilization, thereby offering developers, performance engineers, and DevOps an always-on and autonomous way to identify application and workload runtime inefficiencies.</p>
                        <p><strong>How it works</strong></p>
                        <p>It combines multiple sampling profilers into a single flame graph, which is a unified visualization of what the CPU is spending time on and, in particular, where high latency or errors are happening in the code.</p>
                        <p><strong>Why you want it</strong></p>
                        <p>Continuous Profiler comes with numerous unique features to help teams find and fix performance errors and smooth deployment, is compatible with Intel Granulate’s continuous optimization services, can be deployed cluster-wide in minutes, and supports a range of programming languages without requiring code changes.</p>
                        <p>Additionally, it’s <a class="b_special_a1" href="">SOC2-certified</a> and held to Intel's high security standards, ensuring reliability and trust in its deployment, and is used by global companies including Snap Inc. (portfolio includes Snapchat and Bitmoji), ironSource (app business platform), and ShareChat (social networking platform).</p>
                        <p style="text-align:center"><a style="padding: 5px 20px;" class="dk_button" href="">Read the press release</a><strong> </strong></p>
                        <p class="mb-0"><strong>Learn more</strong></p>
                        <ul>
                            <li><a class="b_special_a1" href="">Get Continuous Profiler on GitHub</a></li>
                            <li><a class="b_special_a1" href="">Intel Granulate continuous profiling</a></li>
                            <li><a class="b_special_a1" href="">Request a Granulate demo</a></li>
                        </ul>
                        <hr>
                        <p class="mb-0">&nbsp;</p>
                        <p class="mb-0">&nbsp;</p>
                    </section>

                    <section id="dk_february_2024">
                        <h3 style="font-weight: 350; margin: 2.5rem 0 11px;">Intel® Software at KubeCon Europe 2024</h3>
                        <p>February 29, 2024 | <a href="" style="color:blue; text-decoration:underline !important">Intel® Software @ KubeCon Europe 2024</a></p>
                        <p><strong><img alt="" height="113" src="/img/darshit_image/software-kaleidescope-visual-clear.png" style="float:left" width="200">Intel’s Enterprise Software Portfolio enables K8s scalability for enterprise applications</strong></p>
                        <p>Meet <strong>Intel enterprise software experts</strong> at KubeCon Europe 2024 (March 19-22) and discover how you can streamline and scale deployments, reduce Kubernetes costs, and achieve end-to-end security for data.</p>
                        <p>Plus, attend the session <a class="b_special_a1" href="">Above the Clouds with American Airlines</a> to learn how one of the world’s top airlines achieved 23% cost reductions for their largest cloud-based workloads using Intel® Granulate™ software.</p>
                        <p><strong>Why Intel Enterprise Software for K8s?</strong></p>
                        <p>Because its Enterprise Software portfolio is purpose-built to accelerate cloud-native applications and solutions more efficiently, at scale, paving a faster way to AI. Meaning you can run production-level Kubernetes workloads the right way—easier to manage, secure, &nbsp;and efficiently scalable.</p>
                        <p class="mb-0">In a nutshell, you get:</p>
                        <ul>
                            <li>Optimized performance with reduced costs</li>
                            <li>Better models with streamlined workflow</li>
                            <li>Confidential computing that’s safe, secure, and compliant</li>
                        </ul>
                        <p><strong>Stop by Booth #J17</strong> to have a conversation about the depth and breadth of Intel’s enterprise software solutions.</p>
                        <p style="text-align:center"><a style="padding: 5px 20px;" class="dk_button" href="">Explore Intel @ KubeCon EU 2024&nbsp;→</a></p>
                        <p style="text-align:center"><a class="b_special_a1" href="">Book a demo&nbsp;→</a></p>
                        <p><strong>More resources</strong></p>
                        <ul>
                            <li><a class="b_special_a1" href="">Learn more and register</a></li>
                            <li><a class="b_special_a1" href="">Explore the schedule</a></li>
                        </ul>
                        <hr>
                        <p class="mb-0">&nbsp;</p>
                        <p class="mb-0">&nbsp;</p>
                        
                        <h3 style="font-weight: 350; margin: 2.5rem 0 11px;">Prediction Guard Offers Customers LLM Reliability and Security via Intel® Developer Cloud</h3>
                        <p>February 22, 2024 | <a href="" style="color:blue; text-decoration:underline !important">Intel® Developer Cloud</a></p>
                        <p><img alt="" height="113" src="/img/darshit_image/prediction-guard-article-1-figure-2.png" style="float:left" width="200">AI startup <a class="b_special_a1" href="">Prediction Guard</a> is now hosting its LLM API in the secure, private environment of <strong>Intel Developer Cloud</strong>, taking advantage of Intel’s resilient computing resources to deliver peak performance and consistency in cloud operations for its customers’ GenAI applications.</p>
                        <p>Prediction Guard’s AI platform enables enterprises to harness the full potential of large language models while mitigating security and trust issues such as hallucinations, harmful outputs, and prompt injections.</p>
                        <p>By moving to Intel Developer Cloud, the company can offer its customers significant and reliable computing power as well as the latest AI hardware acceleration, libraries, and frameworks: it’s currently leveraging Intel® Gaudi® 2 AI accelerators, the Intel/Hugging Face collaborative Optimum Habana library, and Intel extensions for PyTorch and Transformers.</p>

                        <p class="">&nbsp;</p>
                        <div class="d-flex">
                            <div class="">
                                <i class="fa-solid fa-quote-left" style="font-size: 65px; color: #E5E6E6; padding-right: 15px;"></i>
                            </div>
                            <div class="">
                                <div class="mv_together_content">
                                    <p class="mb-2" style="font-weight: 300;"><i>“For certain models, following our move to Intel Gaudi 2, we have seen our costs decrease while throughput has increased by 2x.”</i></p>
                                    <p>– Daniel Whitenack, founder, Prediction Guard
                                    </p>
                                </div>
                            </div>
                        </div>
                        <p class="mb-0">&nbsp;</p>
                        <p class="mb-0">&nbsp;</p>
                        <p style="text-align:center"><a style="padding: 5px 20px;" class="dk_button" href="">Read the case study&nbsp;→</a></p>
                        <p><strong>Learn more</strong></p>
                        <p>Prediction Guard is part of the <a class="b_special_a1" href="">Intel® Liftoff for Startups</a>, a free program for early-stage AI and machine learning startups that helps them innovate and scale across their entrepreneurial journey.</p>
                        <hr>
                        <p class="mb-0">&nbsp;</p>
                        <p class="mb-0">&nbsp;</p>

                        <h3 style="font-weight: 350; margin: 2.5rem 0 11px;">New Survey Unpacks the State of Cloud Optimization for 2024</h3>
                        <p>February 20, 2024 | <a href="" style="color:blue; text-decoration:underline !important">Intel® Granulate™ software</a></p>
                        <p>A newly released global survey conducted by the Intel® Granulate™ cloud-optimization team assessed key trends and strategies in cloud computing among DevOps, Data Engineering, and IT leaders at 413 organizations spanning multiple industries.</p>
                        <p>Among the findings, the #1 and #2 priorities for the majority of organizations (over 2/3) were cloud cost reduction and application performance improvement. And yet, 54% do not have a team dedicated to cloud-based workload optimization.</p>
                        <p class="mb-0">Get the report today to learn more trends, including:</p>
                        <ul>
                            <li>Cloud optimization priorities and objectives</li>
                            <li>Assessment of current optimization efforts</li>
                            <li>The most costly and difficult-to-optimize cloud-based workloads</li>
                            <li>Optimization tools used in the tech stack</li>
                            <li>Innovations for 2024</li>
                        </ul>
                        <p style="text-align:center">&nbsp;<a style="padding: 5px 20px;" class="dk_button" href="">Download the report&nbsp;→</a><br>
                            <a class="b_special_a1" href="">Request a demo&nbsp;→</a></p>
                            <hr>
                            <p>&nbsp;</p>
                            <p>&nbsp;</p>
                    </section>

                    <section id="dk_january_2024">
                        <h3 style="font-weight: 350; margin: 2.5rem 0 11px;">American Airlines Achieves 23% Cost Reductions for Cloud Workloads using Intel® Granulate™</h3>
                        <p>January 29, 2024 | <a href="" style="color:blue; text-decoration:underline !important">Intel® Granulate™ Cloud Optimization Software</a></p>
                        <p>American Airlines (AA) partnered with Intel Granulate to optimize its most challenging workloads, which were stored in a Databricks data lake, and also mitigate the challenges of an untenable data-management price tag.</p>
                        <p>After deploying the Intel Granulate solution, which delivers autonomous and continuous optimization with no code changes or development efforts required, AA was able to free up engineering teams to process and analyze data at optimal pace and scale, run job clusters with 37% fewer resources, and reduce costs across all clusters by 23%.</p>
                        <p style="text-align:center"><a style="padding: 5px 20px;" class="dk_button" href="">Read the case study&nbsp;→</a><br>
                            <a class="b_special_a1" href="">Request a demo&nbsp;→</a></p>
                            <p style="color: #bbb;"><em>Intel, the Intel logo, and Granulate are trademarks of Intel Corporation or its subsidiaries</em></p>
                            <hr>
                            <p class="mb-0">&nbsp;</p>
                            <p class="mb-0">&nbsp;</p>   
                            
                        <h3 style="font-weight: 350; margin: 2.5rem 0 11px;">Now Available: the First Open Source Release of Intel® SHMEM</h3>
                        <p>January 10, 2024 | <a href="" style="color:blue; text-decoration:underline !important">Intel® SHMEM</a> [GitHub]</p>    
                        <p>V1.0.0 of this open source library extends the <a class="b_special_a1" href="">OpenSHMEM</a> programming model to support Intel® Data Center GPUs using the SYCL cross-platform C++ programming environment.</p>
                        <p>OpenSHMEM (SHared MEMory) is a parallel programming library interface standard that enables Single Program Multiple Data (SPMD) programming of distributed memory systems. This allows users to write a single program that executes many copies of the program across a supercomputer or cluster of computers.</p>
                        <p><strong>Intel® SHMEM</strong> is a C++ library that enables applications to use OpenSHMEM communication APIs with device kernels implemented in SYCL. It implements a Partitioned Global Address Space (PGAS) programming model and includes a subset of host-initiated operations in the current OpenSHMEM standard and new device-initiated operations callable directly from GPU kernels.</p>
                        <p class="mb-0"><strong>Feature Highlights</strong></p>
                        <ul>
                            <li>Supports the Intel® Data Center GPU Max Series</li>
                            <li>Device and host API support for OpenSHMEM 1.5-compliant point-to-point RMA, Atomic Memory Operations, Signaling, Memory Ordering, and Synchronization Operations</li>
                            <li>Device and host API support for OpenSHMEM collective operations</li>
                            <li>Device API support for SYCL work-group and sub-group level extensions of Remote Memory Access, Signaling, Collective, Memory Ordering, and Synchronization Operations</li>
                            <li>Support of C++ template function routines replacing the C11 Generic selection routines from the OpenSHMEM spec</li>
                            <li>GPU RDMA support when configured with Sandia OpenSHMEM with suitable Libfabric providers for high-performance networking services</li>
                            <li>Choice of device memory or USM for the SHMEM Symmetric Heap</li>
                        </ul>
                        <p style="text-align:center"><a class="b_special_a1" href=""><strong>Read the blog for all the details</strong></a><br>
                            (written by 3 Sr. Software Engineers @ Intel)</p>
                            <p class="mb-0"><strong>More resources</strong></p>
                            <ul>
                                <li><a class="b_special_a1" href="">Complete Intel SHMEM spec</a></li>
                                <li><a class="b_special_a1" href="">OpenSHMEM standard</a> [PDF]</li>
                            </ul> 
                            <hr>
                            <p class="mb-0">&nbsp;</p>
                            <p class="mb-0">&nbsp;</p>   
                    </section>

                    <section id="dk_december_2023">
                        <h3 style="font-weight: 350; margin: 2.5rem 0 11px;">Updated: Codeplay oneAPI Plugins for NVIDIA GPUs</h3>
                        <p>December 23, 2023</p>
                        <p>The recent release of <a class="b_special_a1" href="">2024.0.1 Intel® Software Development Tools</a>, comprised of oneAPI and AI tools, include noteworthy additions and improvements to Codeplay’s oneAPI plugins for NVIDIA GPUs.</p>
                        <p>The highlights:</p>
                        <ul>
                            <li><strong>Bindless Images</strong> – a SYCL extension that represents a significant overhaul of the current SYCL 2020 images API.
                        
                            <ul style="list-style-type:circle">
                                <li>Users gain more flexibility over their memory and images.</li>
                                <li>Enables hardware sampling and fetching capabilities for various image types like mipmaps and new&nbsp; ways to copy images like sub-region copies.</li>
                                <li>Offers interoperability features with external graphics APIs like Vulkan and image-manipulation flexibility for integration with Blender.</li>
                            </ul>
                            </li>
                            <li><strong>SYCL Support</strong>
                            <ul style="list-style-type:circle">
                                <li><em>Non-uniform groups</em> – allows developers to perform synchronization operations across some subset of the work items in a workgroup or subgroup.</li>
                                <li><em>Peer-to-peer access</em> – in a multi-GPU system, this may result in lower latency and/or better bandwidth in memory accesses across devices.</li>
                                <li><em>Experimental version of SYCL-Graph</em> – lets developers define ahead of time the operations they want to submit to the GPU, improving performance and saving time.</li>
                            </ul>
                            </li>
                        </ul>
                        <p>Additionally, the <strong>AMD plugin </strong>continues on the path of beta and toward production release in 2024.</p>
                        <p class="mb-0"><strong>Get the plugins</strong></p>
                        <ul>
                            <li><a class="b_special_a1" href="">oneAPI for NVIDIA GPUs</a></li>
                            <li><a class="b_special_a1" href="">oneAPI for AMD GPUs</a></li>
                            <li>Open source from the repos</li>
                        </ul>
                        <p class="mb-0"><strong>More resources</strong></p>
                        <ul>
                            <li><a class="b_special_a1" href="">Read the Codeplay blog</a></li>
                            <li><a class="b_special_a1" href="">Read the blog on the 2024 Intel tools release</a></li>
                        </ul>
                        <hr>
                        <p class="mb-0">&nbsp;</p>
                        <p class="mb-0">&nbsp;</p>

                        <h3 style="font-weight: 350; margin: 2.5rem 0 11px;">Intel’s Newest AI Acceleration CPUs + 2024.0 Software Development Tools = Innovation at Scale</h3>
                        <p>December 14, 2023 | <a href="" style="color:blue; text-decoration:underline !important">AI Everywhere keynote replay</a>, <a href="" style="color:blue; text-decoration:underline !important">Intel® Software Developer Tools 2024.0</a></p>
                        <p><strong>Powering and optimizing AI workloads across data center, cloud, and edge.&nbsp;</strong></p>
                        <p>Today marks the official launch of Intel’s latest AI acceleration platforms: 5th Gen Intel® Xeon® Scalable processors (codenamed Emerald Rapids) and Intel® Core™ Ultra processors (codenamed Meteor Lake). Announced by Pat Gelsinger at the “AI Everywhere” event this morning from Nasdaq in NYC, these systems provide developers and data scientists flexibility and choice for accelerating AI innovation at scale.&nbsp;&nbsp;</p>
                        <p>And the newly released <a class="b_special_a1" href="" rel="noreferrer noopener">Intel® Software Development Tools 2024.0</a> are ready to support applications and solutions targeting these platforms.&nbsp;&nbsp;</p>
                        <p>Here are some of the ways:&nbsp;</p>
                        <p><strong>Targeting 5th Gen Intel® Xeon® Scalable processors&nbsp;</strong></p>
                        <p>The 5th Gen is an evolution of the 4th Gen Intel Xeon platform and delivers impressive performance per watt plus outsized performance and TCO in AI, database, networking, and HPC.&nbsp;</p>
                        <p class="mb-0">Intel’s 2024.0 release of optimized tools, libraries, and AI frameworks powered by oneAPI give developers the keys to maximizing application performance by activating the advanced capabilities of Xeon—both 4th and 5th Gen, as well as Intel® Xeon® CPU Max Series:&nbsp;</p>
                        <ul>
                            <li>Intel® Advanced Matrix Extensions (Intel® AMX) built-in AI accelerator&nbsp;</li>
                            <li>Intel® QuickAssist Technology (Intel® QAT) integrated workload accelerator&nbsp;</li>
                            <li>Intel® Data Streaming Accelerator (Intel® DSA) for high-bandwidth, low-latency data movement&nbsp;</li>
                            <li>Intel® In-Memory Analytics Accelerator (Intel® IAA) for very high throughput compression and decompression + primitive analytic functions&nbsp;</li>
                        </ul>
                        <p style="text-align:center"><a class="b_special_a1" href="" rel="noreferrer noopener">Software Tools for 4th &amp; 5th Gen Intel Xeon &amp; Max Series Processors</a>&nbsp;</p>
                        <p><strong>Targeting Intel Core Ultra processors&nbsp;</strong></p>
                        <p>This combined CPU, GPU, and NPU (neural processing unit) platform is built on the new Intel 4 process and delivers an optimal balance of power efficiency and performance, immersive experiences, and dedicated AI&nbsp; acceleration for gaming, content creation, and productivity on the go.&nbsp;</p>
                        <p class="mb-0">Intel’s 2024.0 release helps ISVs, developers, and professional content creators optimize gaming, content creation, AI, and media applications by putting into action the new platform’s cutting-edge features, including:&nbsp;</p>
                        <ul>
                            <li>Intel® AVX-512&nbsp;</li>
                            <li>Intel® AI Boost and inferencing acceleration&nbsp;</li>
                            <li>AV1 encode/decode&nbsp;</li>
                            <li>Ray-traced hardware acceleration&nbsp;</li>
                        </ul>
                        <p style="text-align:center"><a class="b_special_a1" href="">Software Tools for Intel Core Ultra Processor</a>&nbsp;</p>
                        <p class="mb-0"><strong>Learn more&nbsp;</strong></p>
                        <ul>
                            <li><a class="b_special_a1" href="" rel="noreferrer noopener">Watch the keynote replay</a>&nbsp;</li>
                            <li><a class="b_special_a1" href="" rel="noreferrer noopener">Read the press release</a>&nbsp;</li>
                            <li>Access a new quick start guide:&nbsp; <a class="b_special_a1" href="" rel="noreferrer noopener">Accelerate AI with Intel® AMX</a> using PyTorch and TensorFlow optimizations, and OpenVINO™ toolkit&nbsp;</li>
                        </ul>
                        <div class="">
                            <img class="w-100" src="/img/darshit_image/newsroom-ai-everywhere-event.png" alt="">
                        </div>
                        <hr>
                        <p class="mb-0">&nbsp;</p>
                        <p class="mb-0">&nbsp;</p>
                    </section>

                    <section id="dk_november_2023">
                        <h3 style="font-weight: 350; margin: 2.5rem 0 11px;">Now Available: 2024 Release of Intel Development Tools</h3>
                        <p>November 20, 2023 | <a href="" style=" font-size: 13px; color: blue; text-decoration-line: underline !important;">Intel® Software Development Tools</a></p>
                        <p><strong>Expanding Multiarchitecture Performance, Porting &amp; Productivity for AI &amp; HPC&nbsp;&nbsp;</strong></p>
                        <p>The 2024 Intel® Software Development Tools are available, bringing to developers even more multiarchitecture capabilities to accelerate and optimize AI, HPC, and rendering workloads across Intel CPUs, GPUs, and AI accelerators. Powered by oneAPI (now driven by the Unified Acceleration Foundation), the tools are based on open standards and broad coverage for C++, OpenMP, SYCL, Fortran, MPI and Python.&nbsp;</p>
                        <p style="text-align:center"><a style="padding: 5px 20px;" class="dk_button" href="">Explore &amp; download</a>&nbsp;</p>
                        <p><strong>5 Key Benefits&nbsp;</strong></p>
                        <p>(There are many, many more. See all the deets <a class="b_special_a1" href="">here</a>. Read the blog <a class="b_special_a1" href="">here</a>.)<br>
                            &nbsp;</p>
                            <ol>
                                <li><strong>Future-Ready Programming</strong> – Accelerates performance on the latest Intel GPUs including added support for Python, Modin, XGBoost, and rendering; supports upcoming 5th Gen Intel® Xeon® Scalable and Intel® Core™ Ultra CPUs; and expands AI and HPC capabilities via broadened standards coverage across multiple tools.&nbsp;</li>
                                <li><strong>AI Acceleration</strong> – Speeds up AI and machine learning on Intel CPUs and GPUs with native support through Intel-optimized PyTorch and TensorFlow frameworks and improvements to data-parallel extensions in Python.&nbsp;</li>
                                <li><strong>Vector Math Optimizations</strong> – oneMKL integrates RNG offload on target devices for HPC simulations, statistical sampling, and more on x86 CPUs and Intel GPUs, and supports FP16 datatype on Intel GPUs.&nbsp;</li>
                                <li><strong>Expanded CUDA-to-SYCL Migration</strong> – Intel® DPC++ Compatibility Tool (based on open source SYCLomatic) adds CUDA library APIs and 20 popular applications in AI, deep learning, cryptography, scientific simulation, and imaging.&nbsp;</li>
                                <li><strong>Advanced Preview Features</strong> – These evaluation previews include C++ parallel STL for easy GPU offload, dynamic device selection to optimize compute node resource usage, SYCL graph for reduced GPU offload overhead thread composability to prevent thread oversubscription in OpenMP, and profile offloaded code to NPUs.&nbsp;</li>
                            </ol>
                            <p><strong>Discover the Power of Intel CPUs &amp; GPUs + oneAPI</strong><br>
                                </p>
                                <ul>
                                    <li><a class="b_special_a1" href="">The ATLAS Experiment achieves performance gains</a> by implementing heterogeneous particle reconstruction on Intel GPUs optimized by Intel software tools, including benchmarking of SYCL and CUDA code on Intel and NVIDIA GPUs.&nbsp;</li>
                                    <li><a class="b_special_a1" href="">STAC-A2 Benchmark implementation</a> for oneAPI sets records on Intel GPUs versus NVIDIA.&nbsp;</li>
                                    <li><a class="b_special_a1" href="">VMware and Intel deliver jointly validated AI stack</a> to unlock private AI everywhere for model development and deployment.&nbsp;&nbsp;</li>
                                </ul>   
                                <hr>
                                <p class="mb-0">&nbsp;</p> 
                                <p class="mb-0">&nbsp;</p>

                         <h3 style="font-weight: 350; margin: 2.5rem 0 11px;"></strong>Intel oneAPI Software Tools &amp; Libraries Receive <em>HPCwire Reader’s Choice Award</em></h3>
                         <p>November 13, 2023</p>
                         <p>&nbsp;</p> 
                        <div class="row">
                            <div class="col-md-4 align-content-center">
                                <img class="w-100" src="/img/darshit_image/reinders-readers-award-hpcwire-2023-cropped.png.rendition.intel.web.336.252.png" alt="">
                            </div>
                            <div class="col-md-8">
                                <p>Super News!<i> HPCwire </i>just announced its editors’ and readers choice awards for 2023—and Intel oneAPI software development tools and libraries landed the top readers’ choice for the <a class="b_special_a1" href="">best HPC Programming Tool or Technology</a>. With developers and HPC experts driving new levels of HPC and AI innovation, this honor voted by them validates the importance of open, standards-based multiarchitecture programming. oneAPI has received either the editors’ or readers’ award each year since 2020. Thank you for this highly-esteemed accolade.</p>
                            </div>
                        </div>
                        <p class="mb-0">&nbsp;</p>
                        <p class="mb-0">&nbsp;</p> 
                        <hr>
                        <p class="mb-0">&nbsp;</p>
                        <p class="mb-0">&nbsp;</p> 

                        <h3 style="font-weight: 350; margin: 2.5rem 0 11px;">Accelerate & Scale AI Workloads in Intel® Developer Cloud</h3>
                        <p>September 20, 2023 | <a href="" style="color:blue; text-decoration:underline !important">Intel® Developer Cloud</a></p>
                        <p><strong>Built for developers : access the latest Intel® CPUs, GPUs, and AI accelerators</strong></p>
                        <p>As announced at Intel Innovation 2023, Intel® Developer Cloud is now publicly available. The platform offers developers, data scientists, researchers, and organizations a development environment with direct access to current and, in some cases, pre-release Intel hardware plus software services and tools, all in service to help them build, test, and optimize products and solutions for the newest tech features and bring them to market faster.</p>
                        <p>Both free and paid subscription tiers are available.</p>
                        <p style="text-align:center"><a style="padding: 5px 20px;" class="dk_button" href="">Explore &amp; sign up now&nbsp;→</a></p>
                        <p>The current complement of hardware and software includes:<br></p>
                            <ul>
                                <li>Hardware
                                <ul style="list-style-type:circle">
                                    <li>4<sup>th</sup> Gen Intel® Xeon® Scalable processors (single-node and multiarchitecture platforms and clusters)</li>
                                    <li>Intel® Xeon® CPU Max Series (for high bandwidth memory workloads)</li>
                                    <li>Intel® Data Center GPU Max Series (targeting the most demanding computing workloads)</li>
                                    <li>Habana® Gaudi®2 AI accelerator (for deep learning tasks)<br>
                                    &nbsp;</li>
                                </ul>
                                </li>
                                <li>Software &amp; Services
                                <ul style="list-style-type:circle">
                                    <li>Run small- and large-scale AI training, model optimization, and inference workloads such as Meta AI Llama 2, Databricks Dolly, and more</li>
                                    <li>Utilize small to large VMs, full systems, or clusters</li>
                                    <li>Access software tools including the Intel® oneAPI Base, HPC, and Rendering toolkits; Intel® Quantum SDK; AI tools and optimized frameworks such as Intel® OpenVINO™ toolkit, Intel-optimized TensorFlow and PyTorch, Intel® Neural Compressor, Intel® Distribution for Python, and several more</li>
                                </ul>
                                </li>
                            </ul>    
                            <p>And more will be added all the time.</p>
                            <p><a class="b_special_a1" href="">Sign up today</a>.</p>
                            <p style="    color: #bbb;"><em>Intel, the Intel logo and Gaudi are trademarks of Intel Corporation or its subsidiaries.</em></p>
                            <hr>
                            <p class="mb-0">&nbsp;</p>
                            <p class="mb-0">&nbsp;</p>

                         <h3 style="font-weight: 350; margin: 2.5rem 0 11px;">Intel Innovation 2023 At a Glance</h3>
                         <p>September 20, 2023 | <a href="" style="color:blue; text-decoration:underline !important">Intel® Innovation</a></p>
                         <p>Intel’s premier 2-day developer event was attended by nearly 2,000 attendees who participated in a wealth of sessions—keynotes from CEO Pat Gelsinger, other Intel leaders, and industry luminaries; hands-on labs; tech-insights panels; training sessions; and more—focused on the latest breakthroughs in AI spanning hardware, software, services, and advanced technologies.</p>
                         <p>There were many highlights and announcements. Here are 6 of them:<br></p>
                            <ul>
                                <li><strong>Welcome to the “Siliconomy”. </strong>Pat introduced the term in his opening—a new era of global expansion where computing is foundational to a bigger opportunity and better future for every person on the planet—and its role in a world where AI is delivering a generational shift in computing. <a class="b_special_a1" href="">Read his Siliconomy editorial</a> [PDF]</li>
                                <li><strong>Intel® Developer Cloud general availability.</strong>&nbsp;Developers can accelerate and scale AI in this free and paid development environment with access to the latest Intel hardware and software to build, test, optimize, and deploy AI and HPC applications and workloads. Includes a depth and breadth of hardware and software tools &amp; services such as 4<sup>th</sup> Gen Intel® Xeon® Scalable &amp; Max Series processors, Intel® Data Center GPU Max Series processors, Habana® Gaudi®2 AI accelerators, oneAPI tools and Intel-optimized AI tools and frameworks, and SaaS options such as Hugging Face BLOOM, Meta AI Llama 2, Databricks Dolly, and many more. <a class="b_special_a1" href="">Explore Intel Developer Cloud</a>.</li>
                                <li><strong>Intel joins the Unified Acceleration (UXL) Foundation.</strong> An evolution of the oneAPI open programming model, the Linux Foundation formed the UXL Foundation to establish cross-industry collaboration on an open-standard accelerator programming model that simplifies development of cross-platform applications. Read the blogs from <a class="b_special_a1" href="">Sanjiv Shah</a> (GM Developer Software @ Intel) and <a class="b_special_a1" href="">Rod Burns</a> (VP Ecosystem @ Codeplay)</li>
                                <li><strong>Intel® Certified Developer – MLOps Professional</strong>. This new certification program, taught by MLOps experts, uses self-paced modules, hands-on labs, and practicums to teach you how to incorporate compute awareness into the AI solution design process, maximizing performance across the AI pipeline. <a class="b_special_a1" href="">Explore the program</a>.</li>
                                <li><strong>Intel® Trust Authority</strong>. This suite of trust and security services provides customers with assurance that their apps and data are protected on the platform of their choice, including multiple cloud, edge, and on-premises environments. <a class="b_special_a1" href="">Explore Intel Trust Authority</a> | <a class="b_special_a1" href="">Start a 30-day free trial</a>.</li>
                                <li><strong>New Enterprise Software &amp; Services portfolio</strong>. The new collection is designed to solve some of the biggest enterprise challenges by delivering a scalable, sustainable tech stack with built-in, silicon-based security. Includes products that <a class="b_special_a1" href="">simplify security</a> [Intel Trust Authority], <a class="b_special_a1" href="">deliver enterprise AI with more ROI</a> [Intel Developer Cloud + Cnvrg.io], and <a class="b_special_a1" href="">improve application performance with real-time autonomous workload optimization</a> [Intel® Granulate].</li>
                            </ul>  
                            <div class="mb-3">
                                <img class="w-100" src="/img/darshit_image/newsroom-innovation-2023-gelsinger-rehearsal-2.jpg" alt="">
                            </div>  
                            <p><strong>More to explore:</strong><br></p>
                                <ul>
                                    <li><a class="b_special_a1" href="">Day 1 news release</a></li>
                                    <li><a class="b_special_a1" href="">Day 2 news release</a></li>
                                    <li><a class="b_special_a1" href="">Bringing AI Everywhere – the AI Story</a></li>
                                </ul>
                                <p style="color: #bbb;"><em>Intel, the Intel logo and Gaudi are trademarks of Intel Corporation or its subsidiaries.</em></p>
                                <hr>
                                <p class="mb-0">&nbsp;</p>    
                                <p class="mb-0">&nbsp;</p>

                        <h3 style="font-weight: 350; margin: 2.5rem 0 11px;">Unified Acceleration Foundation Forms to Drive Open, Accelerated Compute & Cross-Platform Performance</h3>
                        <p>September 19, 2023 |&nbsp;<a href="" style="color:blue; text-decoration:underline !important">Unified Acceleration Foundation</a></p>
                        <p>Today, the Linux Foundation announced the formation of the Unified Acceleration (UXL) Foundation, a cross-industry group committed to delivering an open-standard, accelerator programming model that simplifies development of performant, cross-platform applications.</p>
                        <p>An <strong>evolution of the oneAPI initiative</strong>, the UXL Foundation marks the next critical step in driving innovation and implementing the oneAPI specification across the industry. It includes a distinguished list of participating organizations and partners, including Arm, Fujitsu, Google Cloud, Imagination Technologies, Intel and Qualcomm Technologies, Inc., and Samsung. These industry leaders have come together to promote open source collaboration and development of a cross-architecture, unified programming model.</p>
                            
                        
                        <p class="">&nbsp;</p>
                        <div class="d-flex">
                            <div class="">
                                <i class="fa-solid fa-quote-left" style="font-size: 65px; color: #E5E6E6; padding-right: 15px;"></i>
                            </div>
                            <div class="">
                                <div class="mv_together_content">
                                    <p class="mb-2" style="font-weight: 300;"><i>“The Unified Acceleration Foundation exemplifies the power of collaboration and the open-source approach. By uniting leading technology companies and fostering an ecosystem of cross-platform development, we will unlock new possibilities in performance and productivity for data-centric solutions.”</i></p>
                                    <p>— Jim Zemlin, Executive Director, Linux Foundation</p>
                                </div>
                            </div>
                        </div>
                        <p class="mb-0">&nbsp;</p>
                        <p class="mb-0">&nbsp;</p>
                        <p style="text-align:center"><a style="padding: 5px 20px;" class="dk_button" href="">Learn more &amp; get involved →</a></p>
                        <p><strong>More resources</strong></p>
                        <ul>
                            <li><a class="b_special_a1" href="">Our kid’s graduating from college!</a>, <em>Sanjiv Shah, GM of Developer Software Engineering, Intel</em></li>
                            <li><a class="b_special_a1" href="">Announcing the Unified Acceleration (UXL) Foundation</a>, <em>Rod Burns, VP Ecosystem @ Codeplay Software</em></li>
                        </ul>
                        <hr>
                        <p class="mb-0">&nbsp;</p>

                        <h3 style="font-weight: 350; margin: 2.5rem 0 11px;">Pre-set AI Tool Bundles Deliver Enhanced Productivity</h3>
                        <p>August 21, 2023 |&nbsp;<a href="" style="color:blue; text-decoration:underline !important">AI Tools Selector (beta)</a></p>
                        <p><strong>Choose the tools you need with new, flexible AI tool installation service</strong></p>
                        <p>Intel's AI Tools Selector (beta) is now available, delivering streamlined package installation of popular deep learning frameworks, tools, and libraries. Install them individually or in pre-set bundles for data analytics, classic machine learning, deep learning, and inference optimization.</p>
                        <p>The tools:</p>
                        <ul>
                            <li>Deep learning frameworks:
                            <ul style="list-style-type:circle">
                                <li>Intel® Extension for TensorFlow</li>
                                <li>Intel® Extension for PyTorch</li>
                            </ul>
                            </li>
                            <li>Tools &amp; libraries:
                            <ul style="list-style-type:circle">
                                <li>Intel® Optimization for XGBoost</li>
                                <li>Intel® Optimization for Scikit-learn</li>
                                <li>Intel® Distribution of Modin</li>
                                <li>Intel® Neural Compressor</li>
                            </ul>
                            </li>
                            <li>SDKs &amp; Command-line Interfaces (CLIs):
                            <ul style="list-style-type:circle">
                                <li>cnvrg.io SDK <a class="b_special_a1" href="">v2 in Python</a></li>
                            </ul>
                            </li>
                        </ul>
                        <p>All are available via conda, pip, or Docker package managers.</p>
                        <p style="text-align:center"><a style="padding: 5px 20px;" class="dk_button" href="">Bookmark the AI Tools Selector (beta)&nbsp;→</a></p>
                        <hr>
                        <p class="mb-0">&nbsp;</p>
                        <p class="mb-0">&nbsp;</p>

                        <h3 style="font-weight: 350; margin: 2.5rem 0 11px;">Speed Up AI & Gain Productivity with Advances in Intel AI Tools</h3>
                        <p>August 11, 2023 | <a href="" style="color:blue; text-decoration:underline !important">Intel® AI Analytics Toolkit</a>, <a href="" style="color:blue; text-decoration:underline !important">oneDAL</a>, <a href="" style="color:blue; text-decoration:underline !important">oneDNN</a>, <a href="" style="color:blue; text-decoration:underline !important">oneCCL</a></p>
                        <p><strong>Calling all AI practitioners, performance engineers, and framework builders ...</strong></p>
                        <p>Speed up deep learning and machine learning on Intel® CPUs and GPUs with the just-released <strong>2023.2 Intel® AI Analytics Toolkit</strong> and <strong>updated oneAPI libraries</strong>.</p>
                        <p>The latest advances in these tools help improve performance, enhance productivity, and increase cross-platform code portability for end-to-end data science and analytics pipelines.</p>
                        <p><strong>The Highlights</strong></p>
                        <p class="mb-0"><strong>Improved Performance</strong></p>
                        <ul>
                            <li><strong>Faster deep learning</strong> with PyTorch 2.0 compatibility and experimental support for Intel® Arc™ A-Series Graphics cards with <a class="b_special_a1" href="">Intel® Extension for PyTorch</a>. If TF is more your jam, <a class="b_special_a1" href="">Intel® Extension for TensorFlow</a> makes it easier to take full advantage of new CPU optimizations to streamline execution, memory allocation, and task scheduling.</li>
                            <li><strong>Faster, classic machine learning</strong> with <a class="b_special_a1" href="">Intel® Extension for Scikit-learn</a>, now featuring CPU optimizations for extremely random trees and <a class="b_special_a1" href="">Intel® oneAPI Data Analytics Library</a> (oneDAL) distributed algorithms. For GPUs, the <a class="b_special_a1" href="">Intel® Optimization for XGBoost</a> now supports Intel® Data Center GPU Max Series.</li>
                            <li><strong>Accelerated data preprocessing</strong> with pandas 2.0 support in <a class="b_special_a1" href="">Intel® Distribution for Modin</a>, which combines faster memory-efficient operations with the scaling benefits of parallel and distributed computing.</li>
                        </ul>
                        <p class="mb-0"><strong>Enhanced Productivity</strong></p>
                        <ul>
                            <li><strong>New</strong> <strong>model compression automation</strong> in <a class="b_special_a1" href="">Intel® Neural Compressor</a> delivers streamlined quantization, easier accuracy debugging, validation for popular new LLMs, and better framework compatibility with PyTorch, TensorFlow, and ONNX-Runtime.</li>
                            <li><strong>Improved prediction accuracy for training &amp; inference </strong>with new missing values support when using daal4py Model Builders to convert gradient boosting models to use optimized algorithmic building blocks found in <a class="b_special_a1" href="">oneDAL</a>.</li>
                        </ul>
                        <p class="mb-0"><strong>Increased Portability</strong></p>
                        <ul>
                            <li><strong>Expanded hardware choice</strong> including support for ARM, NVIDIA, and AMD platforms as well as new performance optimizations in Intel CPUs and GPUs such as simpler debug and diagnostics and an experimental Graph compiler backend. All available using <a class="b_special_a1" href="">Intel® oneAPI Deep Neural Network Library</a> (oneDNN).</li>
                            <li><strong>Enhanced scaling efficiency</strong> in the cross-platform <a class="b_special_a1" href="">Intel® oneAPI Collective Communication Library</a> (oneCCL) features new support for Intel® Data Streaming Accelerator, found in 4<sup>th</sup> Gen Intel® Xeon® Scalable processors.</li>
                        </ul>

                        <p><strong>Learn More</strong></p>
                        <p style="text-align:center"><a style="padding: 5px 20px;" class="dk_button" href="">Download the Intel AI Analytics Toolkit&nbsp;→</a></p>
                        <p style="text-align:center">Explore the <a class="b_special_a1" href="">release notes</a> for more details</p>

                        <hr>
                        <p class="mb-0">&nbsp;</p>
                        <p class="mb-0">&nbsp;</p>

                        <h3 style="font-weight: 350; margin: 2.5rem 0 11px;">Advancing AI Everywhere: Intel Joins the PyTorch Foundation</h3>
                        <p>August 10, 2023 |&nbsp;<a href="" style="color:blue; text-decoration:underline !important">PyTorch Optimizations from Intel</a></p>
                        <p>Intel has just joined the PyTorch Foundation as a Premier member and will take a seat on its Governing Board to help accelerate the development and democratization of PyTorch.</p>
                        <p>According to its website, the Foundation “is a neutral home for the deep learning community to collaborate on the open source PyTorch framework and ecosystem.” Its mission is “to drive adoption of AI and deep learning tooling by fostering and sustaining an ecosystem of open source, vendor-neutral projects with PyTorch.”</p>
                        <p>It’s a good fit. Intel has been contributing to the framework since 2018, an effort precipitated by the vision of democratizing access to AI through ubiquitous hardware and open software. As an example, the newest Intel PT optimizations and features are regularly released in the <em>Intel® Extension for PyTorch</em> before they’re upstreamed into stock PyTorch. This advanced access to pre-stock-version enhancements helps data scientists and software engineers maintain a competitive edge, developing AI applications that take advantage of the latest hardware technologies.</p>
                        <p style="text-align:center"><a style="padding: 5px 20px;" class="dk_button" href="">Get the full story →</a></p>
                        <p style="text-align:center"><a class="b_special_a1" href="">Download the Intel® Extension for PyTorch</a></p>
                        <hr>
                        <p class="mb-0">&nbsp;</p>
                        <p class="mb-0">&nbsp;</p>

                        <h3 style="font-weight: 350; margin: 2.5rem 0 11px;">Proven Performance Improvements with Intel/Accenture AI Reference Kits</h3>
                        <p>July 24, 2023 |&nbsp;<a href="" style="color:blue; text-decoration:underline !important">AI Reference Kits</a></p>
                        <p><strong>These Pre-Configured Kits Simplify AI Development</strong></p>
                        <p>Likely you’ve seen mention of them here—a total of 34 free, drop-in solutions for AI workloads spanning consumer products, energy and utilities, financial services, health and life sciences, manufacturing, retail, and telecommunications.</p>
                        <p>The new news is that multiple industries are <strong>seeing measurable benefits</strong> from leveraging the code and capabilities inherent in them.</p>
                        <p>Here’s a sampling:</p>
                        <ul>
                            <li>Using the AI reference kit designed to set up interactions with an enterprise conversational AI chatbot was found to inference in batch mode <strong>up to 45% faster</strong> with oneAPI optimizations.<a class="b_special_a1" href=""><sup>1</sup>&nbsp;</a></li>
                            <li>The AI reference kit designed to automate visual quality control inspections for Life Sciences demonstrated <strong>training up to 20% faster and inferencing 55% faster</strong> for visual defect detection with oneAPI optimizations.<a class="b_special_a1" href=""><sup>2</sup></a></li>
                        </ul>
                        <p>To predict utility-asset health and deliver higher service reliability, there is an AI reference kit that provides <strong>up to a 25% increase in prediction accuracy</strong>.<a class="b_special_a1" href=""><sup>3</sup></a></p>

                        <p>&nbsp;</p>

                        <div class="align-content-center">
                            <div class="dk_diagarm_stack">
                                <!-- Convenient Software Model -->
                                <div class="mv_industry_download" data-bs-toggle="modal"
                                    data-bs-target="#mv_convenient_software_model">
                                    <i class="fa-solid fa-up-right-and-down-left-from-center"></i>
                                    <a href=""></a>
                                </div>
                                <img class="w-100"
                                    src="/img/darshit_image/newsroom-reference-kit-infographic.jpg.rendition.intel.web.1920.1080.jpg"
                                    alt="">
                            </div>
                        </div>

                        <!-- Convenient Software Model -->
                        <div class="modal" id="mv_convenient_software_model" tabindex="-1">
                            <div class="modal-dialog mv_industry_dialog">
                                <div class="modal-content mv_industry_model_content">
                                    <div class="modal-body mv_industry_body">
                                        <button type="button" data-bs-dismiss="modal" aria-label="Close">
                                            <span><i class="fa-solid fa-xmark"></i></span>
                                        </button>
                                        <div class="mv_enlarged-image">
                                            <img src="/img/darshit_image/newsroom-reference-kit-infographic.jpg.rendition.intel.web.1920.1080.jpg" alt="">
                                        </div>
                                    </div>
                                </div>
                            </div>
                        </div>

                        <p>&nbsp;</p>

                        <p style="text-align:center"><a style="padding: 5px 20px;" class="dk_button" href="">Get the full story&nbsp;→</a></p>
                        <p style="text-align:center"><a class="b_special_a1" href="">Learn more about the AI ref kits&nbsp;→</a></p>
                        <p style="text-align:center"><a class="b_special_a1" href="">Explore them all and download one or all for FREE&nbsp;→</a></p>
                        <hr>
                        <p class="mb-0">&nbsp;</p>
                        <p class="mb-0">&nbsp;</p>

                        <h3 style="font-weight: 350; margin: 2.5rem 0 11px;">Now Available: 2023.2 Release of Intel® oneAPI Tools</h3>
                        <p>July 20, 2023 | <a href="" style="color:blue; text-decoration:underline !important">Intel® oneAPI Tools</a></p>
                        <p><strong>Extending &amp; strengthening software development for open, multiarchitecture computing. </strong></p>
                        <p>The just-released 2023.2 Intel® oneAPI tools bring the freedom of multiarchitecture software development to Python, simplify migration from CUDA to open SYCL, and ramp performance on the latest GPU and CPU hardware.</p>
                        <p style="text-align:center"><a style="padding: 5px 20px;" class="dk_button" href="">Get the details →</a></p>
                        <p><strong>Benefits of the 2023.2 Release</strong></p>
                        <p class="mb-0">If you haven’t updated your tools to the oneAPI multiarchitecture versions—or if you haven’t tried them at all—here are <strong>5 benefits of doing so</strong> with this release:</p>
                        <ol>
                            <li><strong>Simplified Migration from CUDA to Performant SYCL</strong> – Developers now can experience streamlined CUDA-to-SYCL migration for popular applications such as AI, deep learning, cryptography, scientific simulation, and imaging; plus, the new release supports additional CUDA APIs, the latest version of CUDA, and FP64 for broader migration coverage.</li>
                            <li><strong>Faster &amp; More Accurate AI Inferencing</strong> – The addition of NaN (Not a Number) values support during inference streamlines pre-processing and boosts prediction accuracy for models trained on incomplete data.</li>
                            <li><strong>Accelerated AI-based Image Enhancement on GPUs</strong> – Intel® Open Image Denoise ray-tracing library now supports GPUs from Intel and other vendors, providing hardware choice for fast, high-fidelity, AI-based image enhancements.</li>
                            <li><strong>Faster Python for AI &amp; HPC </strong>– This release introduces the beta version Data Parallel Extensions for Python, extending numerical Python capabilities to GPUs for NumPy and cuPy functions, including Numba compiler support.</li>
                            <li><strong>Streamlined Method to Write Efficient Parallel Code</strong> – Intel® Fortran Compiler extends support for DO CONCURRENT Reductions, a powerful feature that allows the compiler to execute loops in parallel and significantly improve code performance while making it easier to write efficient and correct parallel code.</li>
                        </ol>
                        <p><strong>2023.2 Highlights at the Tool Level</strong></p>
                        <p class="mb-0">Compilers &amp; SYCL Support</p>
                        <ul>
                            <li><a class="b_special_a1" href="">Intel® oneAPI DPC++/C++ Compiler</a> sets the <strong>immediate command lists</strong> feature as its default, benefitting developers looking to offload computation to Intel® Data Center GPU Max Series.</li>
                            <li><a class="b_special_a1" href="">Intel® oneAPI DPC++ Library</a> (oneDPL) improves performance of the C++ STD Library sort and scan algorithms when running on Intel® GPUs; this speeds up these commonly used algorithms in C++ applications.</li>
                            <li><a class="b_special_a1" href="">Intel® DPC++ Compatibility Tool</a> (based on the open source SYCLomatic project) adds support for CUDA 12.1 and more function calls, streamlines migration of CUDA to SYCL across numerous domains (AI, cryptography, scientific simulation, imaging, and more), and adds FP64 awareness to migrated code to ensure portability across Intel GPUs with and without FP64 hardware support.</li>
                            <li><a class="b_special_a1" href="">Intel® Fortran Compiler</a> adds support for DO CONCURRENT Reduction, a powerful feature that can significantly improve the performance of code that performs reductions while making it easier to write efficient parallel code.</li>
                        </ul>

                        <p class="mb-0">AI Frameworks &amp; Libraries</p>
                        <ul>
                            <li><a class="b_special_a1" href="">Intel® Distribution of Python</a> introduces Parallel Extensions for Python (beta) which extends the CPU programming model to GPU and increases performance by enabling CPU and GPU for NumPy and CuPy.</li>
                            <li><a class="b_special_a1" href="">Intel® oneAPI Deep Neural Network Library (oneDNN)</a> enables faster training &amp; inference for AI workloads; simpler debug &amp; diagnostics; support for graph neural network (GNN) processing; and improved performance on a multitude of processors such as 4<sup>th</sup> Gen Intel® Xeon® Scalable processors and GPUs from Intel and other vendors.</li>
                            <li><a class="b_special_a1" href="">Intel® oneAPI Data Analytics Library</a> (oneDAL) Model Builder feature adds missing values for NaN support during inference, streamlining pre-processing and boosting prediction accuracy for models trained on incomplete data.</li>
                        </ul>

                        <p class="mb-0">Performance Libraries</p>
                        <ul>
                            <li><a class="b_special_a1" href="">Intel® oneAPI Math Kernel Library</a> (oneMKL) drastically reduces kernel launch time on Intel Data Center GPU Max and Flex Series processors; introduces LINPACK benchmark for GPU.</li>
                            <li><a class="b_special_a1" href="">Intel® MPI Library</a> boosts message-passing performance for 4<sup>th</sup> Gen Intel Xeon Scalable and Max CPUs, and adds important optimizations for Intel GPUs.</li>
                            <li><a class="b_special_a1" href="">Intel® oneAPI Threading Building Blocks</a> (oneTBB) algorithms and Flow Graph nodes now can accept new types of user-provided callables, resulting in a more powerful and flexible programming environment.</li>
                            <li><a class="b_special_a1" href="">Intel® Cryptography Primitives Library</a> multi-buffer library now supports XTS mode of the SM4 algorithm, benefitting developers by providing efficient and secure ways of encrypting data stored in sectors, such as storage devices.</li>
                        </ul>

                        <p class="mb-0">Analysis &amp; Debug</p>
                        <ul>
                            <li><a href="/content/www/us/en/develop/tools/oneapi/components/vtune-profiler.html">Intel® VTune™ Profiler</a> delivers insights into GPU-offload tasks and execution, improves application profiling support for BLAS level-3 routines on Intel GPUs, and identifies Intel Data Center GPU Max Series devices in the platform diagram.</li>
                            <li><a href="/content/www/us/en/developer/tools/oneapi/distribution-for-gdb.html">Intel® Distribution for GDB</a> rebases to GDB 13, staying current and aligned with the latest enhancements supporting effective application debug and debug for Shared Local Memory (SLM).</li>
                        </ul>

                        <p class="mb-0"><strong>Learn More</strong></p>
                        <ul>
                            <li><a class="b_special_a1" href="">Explore Intel oneAPI &amp; AI tools&nbsp;→</a></li>
                            <li>New to SYCL? <a class="b_special_a1" href="">Get started here&nbsp;→</a></li>
                            <li><a class="b_special_a1" href="">Bookmark the oneAPI Training Portal</a> – Learn the way you want to with learning paths, tools, on-demand training, and opportunities to share and showcase your work.</li>
                        </ul>

                        <p class="utility-text-2"><strong>Notices and Disclaimers</strong></p>
                        <p class="utility-text-2">Codeplay is an Intel company.</p>
                        <p class="utility-text-2">Performance varies by use, configuration and other factors. Learn more at <a href="" style="color:blue; text-decoration:underline !important">www.Intel.com/PerformanceIndex</a>. Results may vary.&nbsp;</p>
                        <p class="utility-text-2">Performance results are based on testing as of dates shown in configurations and may not reflect all publicly available updates. &nbsp;&nbsp;</p>
                        <p class="utility-text-2">No product or component can be absolutely secure. Your costs and results may vary.&nbsp;&nbsp;</p>
                        <p class="utility-text-2">Intel technologies may require enabled hardware, software or service activation.&nbsp;</p>
                        <p class="utility-text-2">Intel does not control or audit third-party data. You should consult other sources to evaluate accuracy</p>
                        <hr>
                        <p class="mb-0">&nbsp;</p> 
                        <p class="mb-0">&nbsp;</p>

                        <h3 style="font-weight: 350; margin: 2.5rem 0 11px;">Blender 3.6 LTS Includes Hardware-Accelerated Ray Tracing through Intel® Embree on Intel® GPUs</h3>
                        <p>June 29, 2023 | <a href="" style="color:blue; text-decoration:underline !important">Intel® Embree</a>, <a href="" style="color:blue; text-decoration:underline !important">Blender 3.6 LTS</a></p>
                        <p>Award-winning Intel® Embree is now part of the Blender 3.6 LTS release. With this addition of Intel’s high-performance ray tracing library, content creators can now take advantage of hardware-accelerated rendering for Cycles on Intel® Arc™ GPUs and Intel® Data Center Flex and Max Series GPUs while significantly decreasing rendering times with no loss in fidelity.</p>

                        <p><br>
                            The 3.6 release also includes premier AI-based denoising through Intel® Open Image Denoise. Both tools are part of the <a class="b_special_a1" href="">Intel® oneAPI Rendering Toolkit</a> (Render Kit), a set of open source rendering and ray tracing libraries for creating high-performance, high-fidelity visual experiences.<br>
                            &nbsp;</p>
                        
                            <ul>
                                <li>Read the blog (includes benchmarks)</li>
                                <li><a class="b_special_a1" href="">Watch the demo</a> [6:20]</li>
                                <li><a class="b_special_a1" href="">Download Blender 3.6 LTS</a></li>
                                <li><a class="b_special_a1" href="">Download the Render Kit</a></li>
                            </ul>
                            <hr>
                            <p class="mb-0">&nbsp;</p>
                            <p class="mb-0">&nbsp;</p>

                         <h3 style="font-weight: 350; margin: 2.5rem 0 11px;">UKAEA Makes Fusion a Reality using Intel® Hardware and oneAPI Software Tools</h3>
                         <p>June 29, 2023 | <a href="" style="color:blue; text-decoration:underline !important">Intel® oneAPI Tools</a></p>
                         <p>Using Intel® hardware, oneAPI tools, and distributed asynchronous object storage (DAOS), the UK Atomic Energy Authority and the Cambridge Open Zettascale Lab are developing the next-generation engineering tools and processes necessary to design, certify, construct, and regulate the world’s first fusion powerplants in the United Kingdom. This aligns with the U.K.’s goals to accelerate the roadmap to commercial fusion power by the early 2040s.</p>
                         <p>The UKAEA team used supercomputing and AI to design the fusion power plant virtually. It will subsequently run a number of HPC workloads on a variety of architectures, including 4th Gen Intel® Xeon® processors as well as multi-vendor GPUs and FPGAs.</p>
                         <p><strong>Why This Matters</strong><br>
                            Being able to program once for multiple hardware is key. By using oneAPI open, standards-based, multiarchitecture programming, the UKAEA team can overcome barriers of code portability and deliver performance and development productivity without vendor lock-in.</p>
                        <p class="mb-0"><strong>Learn more:</strong></p>  
                        <ul>
                            <li><a class="b_special_a1" href="">Read the press release</a></li>
                            <li><a class="b_special_a1" href="">Read the case study</a></li>
                        </ul> 
                        
                        <p class="mb-0"><strong>Resources:</strong></p>
                        <ul>
                            <li><a class="b_special_a1" href="">Learn about oneAPI</a></li>
                            <li><a class="b_special_a1" href="">Learn about UKAEA</a></li>
                            <li><a class="b_special_a1" href="">Intel® oneAPI Tools</a></li>
                            <li><a class="b_special_a1" href="">4<sup>th</sup> Gen Intel Xeon Scalable Processors</a></li>
                        </ul>
                        <hr>
                        <p>&nbsp;</p>
                        <p>&nbsp;</p>

                        <h3 style="font-weight: 350; margin: 2.5rem 0 11px;">Introducing the oneAPI Construction Kit</h3>
                        <p>June 5, 2023</p>
                        <p><strong>Codeplay brings open, standards-based SYCL programming to new, custom, and specialist hardware</strong></p>
                        <p>Today Codeplay announced the latest extension of the oneAPI ecosystem with an open source project that allows code written in SYCL to run on custom architectures for HPC and AI.</p>
                        <p>The <strong>oneAPI Construction Kit</strong> includes a reference implementation for RISC-V vector processors but can be adapted for a range of processors, making it easy to access a wealth of supported SYCL libraries.</p>
                        <p>A benefit for users of custom architectures, rather than having to learn a new custom language, they can instead use SYCL to write high-performance applications efficiently – using a single codebase that works across multiple architectures. This means less time spent on porting efforts and maintaining separate codebases for different architectures, and more time for innovation.</p>
                        <p class="mb-0"><strong>What’s Inside the New Kit:</strong></p>
                        <ul>
                            <li>A framework for bringing oneAPI support to new and innovative hardware – such as specialized AI accelerators</li>
                            <li>Support for x86, ARM, and RISC-V targets</li>
                            <li>Documentation</li>
                            <li>Reference Design</li>
                            <li>Tutorials</li>
                            <li>Modular Software Components</li>
                        </ul>

                        <p class="mb-0"><strong>Learn More &amp; Get It</strong></p>
                        <ul>
                            <li>Get it free at <a class="b_special_a1" href="">developer.codeplay.com</a></li>
                            <li><a class="b_special_a1" href="">Watch the demo</a> [2:32]</li>
                            <li><a class="b_special_a1" href="">Read the blog</a> from Codeplay Principal SW Engineer, Colin Davidson</li>
                            <li>Get the <a class="b_special_a1" href="">documentation</a></li>
                        </ul>
                        <hr>
                        <p class="mb-0">&nbsp;</p>
                        <p class="mb-0">&nbsp;</p>
                         
                        <h3 style="font-weight: 350; margin: 2.5rem 0 11px;">Intel Delivers AI-Accelerated HPC Performance, Uplifted by oneAPI</h3>
                        <p>May 22, 2023 |&nbsp;<a href="" style="color:blue; text-decoration:underline !important">Intel® oneAPI Tools</a></p>
                        <p><strong>ISC’23 takeaway: Broadest, most open HPC+AI portfolio powers performance, generative AI for science</strong></p>
                        <p>Intel’s keynote at <a class="b_special_a1" href="">International Super Computing 2023</a> underscored how the company is making multiarchitecture programming easier for an open ecosystem, as well as driving competitive performance for diverse HPC and AI workloads based on a broad product portfolio of CPUs, GPUs, AI accelerators, and oneAPI software.</p>
                        <p>Here are the highlights.</p>
                        <p class="mb-0">Hardware:</p>
                        <ul>
                            <li>Independent software vendor Ansys showed the Intel® Data Center GPU Max Series outperforms NVIDIA H100 by 50% on AI-accelerated HPC applications, in addition to an average improvement of 30% over H100 on diverse workloads.<sup>*</sup></li>
                            <li>The Habana Gaudi 2 deep learning accelerator delivers up to 2x faster AI performance over NVIDIA A100 for DL training and inference.<sup>*</sup></li>
                            <li>Intel® Xeon CPUs (including the Max Series and 4<sup>th</sup> Gen) deliver, respectively, 65% speedup over AMD Genoa for bandwidth-limited problems and 50% average speed-up over AMD Milan.<sup>*</sup></li>
                        </ul>
                        <p class="mb-0">Software:</p>
                        <ul>
                            <li>Worldwide, about 90% of all developers benefit from or use software developed for or optimized by Intel.<sup>*</sup></li>
                            <li>oneAPI has been demonstrated on diverse CPU, GPU, FPGA and AI silicon from multiple hardware providers, addressing the challenges of single-vendor accelerated programming models.</li>
                            <li>New features in the latest oneAPI tools—such as OpenMP GPU offload, extended support for OpenMP and Fortran, and optimized TensorFlow and PyTorch frameworks and AI tools—unleash the capabilities of Intel’s most advanced HPC and AI CPUs and GPUs.</li>
                            <li>Real-time, ray-traced scientific visualization with hardware acceleration is now available on Intel GPUs, and AI-based denoising completes in milliseconds.</li>
                        </ul>
                        <p>The oneAPI SYCL standard implementation has been shown to outperform NVIDIA native system languages; case in point: DPEcho SYCL code run on Max Series GPU outperformed by 48% the same CUDA code run on NVIDIA H100.</p>

                        <p class="">&nbsp;</p>
                        <div class="d-flex">
                            <div class="">
                                <i class="fa-solid fa-quote-left" style="font-size: 65px; color: #E5E6E6; padding-right: 15px;"></i>
                            </div>
                            <div class="">
                                <div class="mv_together_content">
                                    <p class="mb-2" style="font-weight: 300;"><i>ntel is committed to serving the HPC and AI community with products that help customers and end-users make breakthrough discoveries faster. Our product portfolio spanning Xeon Max Series CPUs, Max Series GPUs, 4th Gen Xeon and Gaudi 2 are outperforming the competition on a variety of workloads, offering energy and total cost of ownership advantages, democratizing AI and providing choice, openness and flexibility.</i></p>
                                    <p>Jeff McVeigh, Intel corporate VP and GM of the Super Compute Group</p>
                                </div>
                            </div>
                        </div>
                        <p class="mb-0">&nbsp;</p>
                        <p class="mb-0">&nbsp;</p>
                        <p style="text-align:center"><a style="padding: 5px 20px;" class="dk_button" href="">Read the full story</a></p>
                        <p style="text-align:center">&nbsp;</p>
                        <p class="utility-text-2"><a class="b_special_a1" href="">*See press release and disclaimers and configurations for details.&nbsp;</a></p>
                        <hr>
                        <p class="mb-0">&nbsp;</p>
                        <p class="mb-0">&nbsp;</p>

                        <h3 style="font-weight: 350; margin: 2.5rem 0 11px;">Intel Flex Series GPUs Expanded with Open Software Stack</h3>
                        <p>May 18, 2023 |&nbsp;<a href="" style="color:blue; text-decoration:underline !important">Software for Intel® Data Center GPU Flex Series</a></p>
                        <p><strong>New software updates optimize workloads for cloud gaming, AI inference, media acceleration &amp; digital content creation</strong></p>
                        <p>Introduced as a flexible, general-purpose GPU for the data center and the intelligent visual cloud, the&nbsp;<a class="b_special_a1" href="">Intel® Data Center GPU Flex Series</a>&nbsp;was expanded with new production-level software to optimize workloads for cloud gaming, AI inference, media acceleration, digital content creation, and more. This GPU platform has an open and full software stack, no licensing fees, and a unified programming model for CPUs and GPUs for performance and productivity via&nbsp;<a class="b_special_a1" href="">oneAPI</a>.</p>
                        <p class="mb-0"><strong>New Software Capability Highlights:</strong></p>
                        <ul>
                            <li><strong>Windows Cloud Gaming</strong> – Tap into the GPU’s power for remote gaming with a new reference stack.</li>
                            <li><strong>AI Inference</strong> – Boost deep learning and visual inference in applications used for&nbsp;smart city, library indexing and compliance, AI-guided video enhancement, intelligent traffic management, smart buildings and factories, and retail.</li>
                            <li><strong>Digital Content Creation</strong> –&nbsp;Deliver real-time rendering tapping into dedicated hardware acceleration, complete&nbsp;AI-based denoising in milliseconds.</li>
                            <li><strong>Autonomous Driving </strong>– Utilize Unreal Engine 4 to advance training and validation of AD systems.</li>
                        </ul>
                        <p>Learn what comprises the open software stack, available tools, and how to <a class="b_special_a1" href="">get started with pre-configured containers</a>.</p>
                        <p style="text-align:center"><a style="padding: 5px 20px;" class="dk_button" href="">Get the details</a></p>
                        <hr>
                        <p class="mb-0">&nbsp;</p>
                        <p class="mb-0">&nbsp;</p>


                        <h3 style="font-weight: 350; margin: 2.5rem 0 11px;">2023.1.1 Release of Intel AI Analytics Toolkit Includes New Features & Fixes</h3>
                        <p>May 3, 2023 |&nbsp;<a href="" style="color:blue; text-decoration:underline !important">Intel® AI Analytics Toolkit</a></p>
                        <p>The latest release of the AI Kit continues to help AI developers, data scientists, and researchers accelerate end-to-end data science and analytics pipelines on Intel® architecture.</p>
                        <p style="text-align:center"><a style="padding: 5px 20px;" class="dk_button" href="">Get it now</a></p>

                        <p><strong>Highlights</strong></p>
                        <ul>
                            <li><a class="b_special_a1" href=""><strong>Intel® Neural Compressor</strong></a> optimizes auto- and multi-node tuning strategy and large language model (LLM) memory.</li>
                            <li><a class="b_special_a1" href=""><strong>Intel® Distribution of Modin</strong></a> introduces a new, experimental NumPy API that provides basic support for distributed numerical calculations.</li>
                            <li><a class="b_special_a1" href=""><strong>Model Zoo for Intel® Architecture</strong></a> now supports Intel® Data Center GPU Max Series and extends support for dataset downloader and data connectors.</li>
                            <li><a class="b_special_a1" href=""><strong>Intel® Extension for TensorFlow</strong></a> now supports TensorFlow 2.12 and adds Ubuntu 22.04 and Red Hat Enterprise Linux 8.6 to the list of supported platforms.</li>
                            <li><a class="b_special_a1" href=""><strong>Intel® Extension for PyTorch</strong></a> is now compatible with Intel® oneAPI Deep Neural Network Library (oneDNN) 3.1, which improves on PyTorch 1.13 operator coverage.&nbsp;</li>
                        </ul>
                        <p>See the <a class="b_special_a1" href="">AI KIt release notes</a> for full details.</p>

                        <p class="mb-0"><strong>More References</strong></p>
                        <ul>
                            <li><a class="b_special_a1" href="">Ready to use AI &amp; Analytics code samples</a></li>
                            <li><a class="b_special_a1" href="">Essential Tools for Jumpstarting AI Development Projects</a></li>
                            <li><a class="b_special_a1" href="">Intel Neural Compressor Tuning Strategies</a> [GitHub]</li>
                            <li><a class="b_special_a1" href="">10-Minute Quick-start Guide for Modin</a></li>
                        </ul>
                        <p class="mb-0">&nbsp;</p>
                        <hr>
                        <p class="mb-0">&nbsp;</p>


                        <h3 style="font-weight: 350; margin: 2.5rem 0 11px;">Explore Ready-to-Use Code Samples for CPUs, GPUs, and FPGAs</h3>
                        <p>April 20, 2023 | <a href="" style="color:blue; text-decoration:underline !important">oneAPI &amp; AI Code Samples</a></p>
                        <p>Intel’s newly launched <strong>Code Samples portal</strong> provides direct access to a sizable (and always growing) collection of open source, high-quality, ready-to-use code that can be used to develop, offload, and optimize multiarchitecture applications.</p>
                        <p>Each sample is purpose-built to help any developer at any level understand concepts and techniques for adapting parallel programming methods to heterogeneous compute; they span high-performance computing, code and performance optimization, AI and machine learning, and scientific or general graphics rendering.</p>
                        <p>No matter their experience level, developers can find a variety of useful samples—all resident in the GitHub repository—with helpful instructions and commented code.</p>
                        <p style="text-align:center"><a class="b_special_a1" href="">Bookmark the Code Samples page→</a></p>
                        <p style="text-align:center"><a style="padding: 5px 20px;" class="dk_button" href="">Get the details</a></p>
                        <p class="mb-0">&nbsp;</p>
                        <hr>
                        <p class="mb-0">&nbsp;</p>
                        
                        <h3 style="font-weight: 350; margin: 2.5rem 0 11px;">VMWare-Intel Collaboration Delivers Video and Graphics Acceleration via AV1 Encode/Decode on Intel® GPUs</h3>
                        <p>April 11, 2023 | <a href="" style="color:blue; text-decoration:underline !important">Intel® Arc™ Graphics</a>, <a href="" style="color:blue; text-decoration:underline !important">Intel® Data Center GPU Flex Series</a></p>
                        <p><strong>Next-gen, multimedia codec offers more compression efficiency and performance</strong></p>
                        <p>The latest release of <a class="b_special_a1" href="">VMware Horizon</a> supports <a class="b_special_a1" href="">Intel®&nbsp;GPUs</a> and provides media acceleration enabled by <a class="b_special_a1" href="">Intel®&nbsp;oneAPI Video Library</a> (oneVPL). With Intel GPU support, VMware customers have greater choice, flexibility, and cost options on a wider range of hardware systems for deployment without being locked to a single GPU vendor. Running VMware Horizon on systems with Intel GPUs does not require license server setup, licensing costs, or ongoing support costs.&nbsp;</p>

                        <p>This Horizon release for desktops and servers utilizes AV1 encoding, optimized by oneVPL, on both <strong>Intel®&nbsp;Arc™ graphics</strong> and <strong>Intel®&nbsp;Data Center GPU Flex Series</strong>. The solution also delivers fast hardware encoding on supported Intel®&nbsp;X<sup>e</sup> architecture-based and newer GPUs (integrated and discrete). With a GPU-backed virtual machine (VM), users can have a better media experience with improved performance, reduced latency, more consistent frames per second, and lower CPU utilization.&nbsp;&nbsp;&nbsp;</p>

                        <p style="text-align:center"><a style="padding: 5px 20px;" class="dk_button" href="">Get the details</a></p>
                        <p class="mb-0">&nbsp;</p>
                        <hr>

                        <h3 style="font-weight: 350; margin: 2.5rem 0 11px;">Now Available: Intel® oneAPI 2023.1 Tools</h3>
                        <p>April 4, 2023 | <a href="" style="color:blue; text-decoration:underline !important">Intel® oneAPI and AI Tools</a></p>
                        <h3 style="font-weight: 500;">Delivering new performance and code-migration capabilities</h3>
                        <p>The just-released Intel® oneAPI 2023.1 tools augment the latest Intel® architecture features with high-bandwidth memory analysis, photorealistic ray tracing and path guiding, and extended CUDA-to-SYCL code migration support. Additionally, they continue to support the latest update of Codeplay’s oneAPI plugins for <a class="b_special_a1" href="">NVIDIA</a> and <a class="b_special_a1" href="">AMD</a> that make it easier to write multiarchitecture SYCL code. (These free-to-download plugins deliver quality improvements, support Joint_matrix extension and CUDA 11.8/testing 12, and enable gfx1032 for AMD. The AMD plugin backend now works with ROCm 5.x driver.)</p>
                        <p style="text-align:center"><a style="padding: 5px 20px;" class="dk_button" href="">Get the details</a></p>
                        <p><strong>2023.1 Highlights:</strong></p>
                        <p class="mb-0">Compilers &amp; SYCL Support</p>
                        <ul>
                            <li><a class="b_special_a1" href="">Intel® oneAPI DPC++/C++ Compiler</a> delivers AI acceleration with BF16 full support, auto-CPU dispatch, and SYCL kernel properties, and adds more SYCL 2020 and OpenMP 5.0 and 5.1 features to improve productivity and boost CPU and GPU performance.</li>
                            <li><a class="b_special_a1" href="">Intel® oneAPI DPC++ Library</a> (oneDPL) improves performance of the sort, scan, and reduce algorithms.</li>
                            <li><a class="b_special_a1" href="">Intel® DPC++ Compatibility Tool</a> (based on the open source SYCLomatic project) delivers easier CUDA-to-SYCL code migration with support for the latest release of CUDA’s headers, and adds more equivalent SYCL language and oneAPI library mapping functions such as runtime, math, and neural network domains.</li>
                        </ul>

                        <p class="mb-0">Performance Libraries</p>
                        <ul>
                            <li><a class="b_special_a1" href="">Intel® oneAPI Math Kernel Library</a> (oneMKL) improves data center GPU performance via new real FFTs, plus 1D and 2D optimizations, random number generators, and Sparse BLAS and LAPACK inverse optimizations.</li>
                            <li><a class="b_special_a1" href="">Intel® MPI Library</a> enhances performance for collectives using GPU buffers and default process pinning on CPUs with E-cores and P-cores.</li>
                            <li><a class="b_special_a1" href="">Intel® oneAPI Threading Building Blocks</a> (oneTBB) improves robustness of thread-creation algorithms on Linux and provides full support of Thread Sanitizer on macOS and full-hybrid Intel® CPU support. &nbsp;</li>
                            <li><a class="b_special_a1" href="">Intel® oneAPI Data Analytics Library</a> (oneDAL) is reduced in size by 30%.</li>
                            <li><a class="b_special_a1" href="">Intel® oneAPI Collective Communications Library (oneCCL)</a> improves scaling efficiency of the Scaleup algorithms for <em>Alltoall</em> and<em> Allgather</em> and adds collective selection for scaleout algorithm for device (GPU) buffers.</li>
                            <li><a class="b_special_a1" href="">Intel® Integrated Performance Primitives (Intel® IPP)</a> expands cryptography offerings with CCM/GCM modes, which enables Crypto Multi-Buffer for greater performance compared to scalar implementations, and adds support for asymmetric cryptographic algorithm SM2 for key exchange protocol and encryption/decryption APIs.</li>
                        </ul>

                        <p class="mb-0">Analysis &amp; Debug</p>
                        <ul>
                            <li><a class="b_special_a1" href="">Intel® VTune™ Profiler</a> identifies the best profile to gain performance utilizing high-bandwidth memory (HBM) on Intel® Xeon® Processor Max Series.&nbsp;It displays X<sup>e</sup> Link cross-card traffic issues such as CPU/GPU imbalances, stack-to-stack traffic, and throughput and bandwidth bottlenecks on Intel® Data Center GPU Max Series.</li>
                            <li><a class="b_special_a1" href="">Intel® Distribution for GDB</a> adds debug support for Intel® Arc™ GPUs on Windows and improves the debug performance on Linux for Intel discrete GPUs.</li>
                        </ul>

                        <p class="mb-0">Rendering &amp; Visual Computing</p>
                        <ul>
                            <li><a class="b_special_a1" href="">Intel® Open Path Guiding Library (Intel® Open PGL)</a> is integrated in Blender and Chaos V-Ray and provides state-of-the-art path-guiding methods for rendering.</li>
                            <li><a class="b_special_a1" href="">Intel® Embree</a> supports Intel Arc GPUs&nbsp;and Intel® Data Center GPU Flex Series, and delivers performance increases on 4<sup>th</sup> Gen Intel® Xeon® processors per <a class="b_special_a1" href="">Phoronix benchmarks</a>.</li>
                            <li><a class="b_special_a1" href="">Intel® OSPRay Studio</a> add functionality from open Tiny EXR, Tiny DNG (for .tiff files), and Open Image IO.</li>
                        </ul>

                        <h4 style="font-weight: 500;">oneAPI tools drive ecosystem innovation</h4>
                        <p class="mb-0">oneAPI tools adoption is ramping multiarchitecture programming on new accelerators, and the ecosystem is rapidly pioneering unique solutions using the open, standards-based, unified programming model. Here are the most recent:</p>
                        <ul>
                            <li><strong>Cross-platform: </strong><a class="b_special_a1" href="">Purdue University</a> launched a oneAPI Center of Excellence to advance AI and HPC teaching in the United States.</li>
                            <li><strong>Cloud: </strong><a class="b_special_a1" href="">University of Tennessee</a> launched oneAPI Center-of-Excellence Research which enabled a cloud-based Rendering as a Service (RaaS) learning environment for students.</li>
                            <li><strong>AI:</strong> Hugging Face accelerated PyTorch Transformers on 4<sup>th</sup> Gen Intel Xeon processors (explore <a class="b_special_a1" href="">part 1</a> and <a class="b_special_a1" href="">part 2</a>), and HippoScreen <a class="b_special_a1" href="">increased AI performance by 2.4x</a> to improve efficiency and build deep learning models.</li>
                            <li><strong>Graphics &amp; Ray Tracing: </strong>Thousands of artists, content creators, and 3D experts can easily access advanced ray tracing, denoising, and path guiding capabilities through Intel rendering libraries integrated in popular renderers including Blender, Chaos V-Ray, and <a class="b_special_a1" href="">DreamWorks open source MoonRay</a>.</li>
                        </ul>

                        <p class="mb-0"><strong>Learn More</strong></p>
                        <ul>
                            <li><a class="b_special_a1" href="">Explore Intel oneAPI &amp; AI tools &gt;</a></li>
                            <li>New to SYCL? <a class="b_special_a1" href="">Get started here &gt;</a></li>
                            <li><a class="b_special_a1" href="">Bookmark the oneAPI Training Portal</a> – Learn the way you want to with learning paths, tools, on-demand training, and opportunities to share and showcase your work.</li>
                        </ul>
                        <p class="utility-text-2"><strong>Notices and Disclaimers</strong><br>
                            Codeplay is an Intel company.<br>
                            Performance varies by use, configuration and other factors. Learn more at <a href="" style="color:blue; text-decoration:underline !important">www.Intel.com/PerformanceIndex</a>. Results may vary.&nbsp;<br>
                            Performance results are based on testing as of dates shown in configurations and may not reflect all publicly available updates. &nbsp;&nbsp;<br>
                            No product or component can be absolutely secure. Your costs and results may vary.&nbsp;&nbsp;<br>
                            Intel technologies may require enabled hardware, software or service activation.&nbsp;<br>
                            Intel does not control or audit third-party data. You should consult other sources to evaluate accuracy</p>
                        
                        <p>&nbsp;</p>

                        <h3><a id="purdue-coe" name="purdue-coe"></a><strong>Purdue Launches oneAPI Center of Excellence to Advance AI &amp; HPC Teaching in the U.S.</strong></h3>
                        <p>March 27, 2023 | <a href="http://www.oneapi.io" style="color:blue; text-decoration:underline !important">oneAPI</a>, <a href="" style="color:blue; text-decoration:underline !important">Intel® oneAPI Toolkits</a></p>
                        <h4><strong>Building oneAPI multiarchitecture programming concepts into the ECE curriculum</strong></h4>
                        <p>Purdue University will establish a oneAPI Center of Excellence on its West Lafayette campus. Facilitated through Purdue University’s <a class="b_special_a1" href="">Elmore Family School of Electrical and Computer Engineering</a> (ECE), the center will take students’ original AI and HPC research projects to the next level through teaching oneAPI in the classroom.</p>
                        <p>The facility will use curated content from Intel including teaching kits and certified instructor courses, and students will have access to the latest Intel® hardware and software via the <a class="b_special_a1" href="">Intel® Developer Cloud</a>.</p>

                        <p class="">&nbsp;</p>
                        <div class="d-flex">
                            <div class="">
                                <i class="fa-solid fa-quote-left" style="font-size: 65px; color: #E5E6E6; padding-right: 15px;"></i>
                            </div>
                            <div class="">
                                <div class="mv_together_content">
                                    <p class="mb-2" style="font-weight: 300;"><i>“Purdue’s track record as one of the most innovative universities in America with its world-changing research, programs and culture of inclusion is a perfect fit for the oneAPI Center of Excellence. By giving Purdue students access to the latest AI software and hardware, we’ll see the next generation of developers, scientists and engineers delivering innovations that will change the world. We’re excited to assist Purdue in embracing the next giant leap in accelerated computing.”</i></p>
                                    <p>– Scott Apeland, Director of Intel Developer Relations</p>
                                </div>
                            </div>
                        </div>
                        <p class="mb-0">&nbsp;</p>
                        <p class="mb-0">&nbsp;</p>
                        <p class="intro-paragraph"><a style="padding: 5px 20px;" class="dk_button" href="">Learn more</a></p>
                        <p class="mb-0">&nbsp;</p>
                        <hr>
                        <p class="mb-0">&nbsp;</p>


                        <h3><strong>Just Released the 6 Final AI Reference Kits</strong></h3>
                        <p>March 24, 2023 |&nbsp;<a href="" style="color:blue; text-decoration:underline !important">AI Reference Kits</a></p>
                        <h4><strong>A Total of 34 Kits to Streamline AI Solutions</strong></h4>
                        <p class="mb-0">The final six AI reference kits, powered by oneAPI, are now available to help data scientists and developers more easily and quickly develop and deploy innovative business solutions with maximum performance on Intel® hardware:</p>
                        <ol>
                            <li><a class="b_special_a1" href=""><strong>Visual Process Discovery</strong></a> for detecting UI elements in real time from inputted website screenshots (e.g., buttons, links, texts, images, headings, fields, labels, iframes) that users interacted with.</li>
                            <li><a class="b_special_a1" href=""><strong>Text Data Generation</strong></a> for generating synthetic text, such as the provided source dataset, using a large language model (LLM).</li>
                            <li><a class="b_special_a1" href=""><strong>Image Data Generation</strong></a><strong> </strong>for generating synthetic images using generative adversarial networks (GANs).</li>
                            <li><a class="b_special_a1" href=""><strong>Voice Data Generation</strong></a> for translating input text data to generate speech using transfer learning with VOCODER models.</li>
                            <li><a class="b_special_a1" href=""><strong>AI Data Protection</strong></a> for minimizing challenges with PII (personally identifiable information) in the design and development stages such as data masking, data de-identification, and anonymization.&nbsp;</li>
                            <li><a class="b_special_a1" href=""><strong>Engineering Design Optimization</strong></a><strong> </strong>for helping manufacturing engineers generate realistic designs whilst reducing manufacturing costs and accelerating product development processes.<br>
                            &nbsp;</li>
                        </ol>
                        <p><a style="padding: 5px 20px;" class="dk_button" href="">Learn more about the AI ref kits</a></p>
                        <hr>
                        <p class="mb-0">&nbsp;</p>
                        <p class="mb-0">&nbsp;</p> 


                        <h3><a id="MoonRay" name="MoonRay"></a><strong>DreamWorks Animation’s Open Source MoonRay Software Optimized via Intel® Embree</strong></h3>
                        <p>March 15, 2023 | <a href="" style="color:blue; text-decoration:underline !important">Intel® oneAPI Rendering Toolkit</a></p>
                        <h4>Advancing Open Rendering Innovation</h4>
                        <p>DreamWorks Animation’s production renderer is now open source, <strong>with photo-realistic ray-tracing acceleration provided by <a class="b_special_a1" href="">Intel® Embree</a></strong>, a high-performance ray-tracing library that’s part of the oneAPI Rendering Toolkit.</p>
                        <p>Formerly an in-house Monte Carlo ray tracer, Dreamworks’ MoonRay team worked with beta testers to adapt the code base—including enhancements and features—so it could be built and run outside of the company’s pipeline environment.</p>

                        <p class="">&nbsp;</p>
                        <div class="d-flex">
                            <div class="">
                                <i class="fa-solid fa-quote-left" style="font-size: 65px; color: #E5E6E6; padding-right: 15px;"></i>
                            </div>
                            <div class="">
                                <div class="mv_together_content">
                                    <p class="mb-2" style="font-weight: 300;"><i>“As part of this release and in collaboration with DreamWorks, MoonRay users have access to Intel® technologies, Intel Embree, and oneAPI tools, as building blocks for an open and performant rendering ecosystem.”</i></p>
                                    <p>– Anton Kaplanyan, VP graphics research, Intel</p>
                                </div>
                            </div>
                        </div>
                        <p class="mb-0">&nbsp;</p>
                        <p class="mb-0">&nbsp;</p>
                        <p class="intro-paragraph"><a style="padding: 5px 20px;" class="dk_button" href="">Learn more</a></p>
                        <p>Download <a class="b_special_a1" href="">Intel Embree code samples</a> [GitHub]</p>
                        <hr>
                        <p class="mb-0">&nbsp;</p>
                        <p class="mb-0">&nbsp;</p>

                        <h3><a id="AIKit-2023-1" name="AIKit-2023-1"></a><strong>2023.1 Release of Intel® AI Analytics Toolkit Supports Newest Intel® GPUs &amp; CPUs</strong></h3>
                        <p>February 10, 20232 | <a href="" style="color:blue; text-decoration:underline !important">Intel® AI Analytics Toolkit</a> (AI Kit), <a href="" style="color:blue; text-decoration:underline !important">AI Reference Kits</a></p>
                        <h4><strong>Powered by oneAPI to Maximize Multiarchitecture Performance</strong></h4>
                        <p>Today Intel launched the newest release of its AI Kit, with tools optimized to set free the full power of the latest GPUs (Intel® Data Center GPU Max Series and Intel® Data Center GPU Flex Series) and CPUs (4th Gen Intel® Xeon® Scalable and Intel® Xeon® Max Series processors).</p>
                        <p>Using the latest Toolkit, developers and data scientists can more effectively and efficiently accelerate end-to-end training and inference of their AI workloads, particularly on the new hardware.</p>
                        <p style="text-align:center"><strong>Download the 2023.1 Intel AI Analytics Toolkit</strong></p>
                        <p style="text-align:center"><a style="padding: 5px 20px;" class="dk_button" href="">Download</a></p>
                        <p class="mb-0">&nbsp;</p>
                        <p><strong>New Software Features and Hardware Support</strong></p>
                        <p>Here are some of the highlights. Get the full details in the <a class="b_special_a1" href="">release notes</a>.</p>
                        <p class="mb-0"><a class="b_special_a1" href="">Intel® Neural Compressor</a></p>
                        <ul>
                            <li>Build DL models optimized for improved inference and performance with quantization and distillation; includes support for Intel® Extension for TensorFlow v1.1.0, Intel® Extension for PyTorch v1.13.0, PyTorch 1.13, and TensorFlow 2.10.</li>
                            <li>Enable tuning strategy refinement, training for sparsity (block wise) enhancements, and Neural Coder integration.</li>
                        </ul>
                        <p class="mb-0"><a class="b_special_a1" href="">oneDNN</a></p>
                        <ul>
                            <li>In Intel Xeon processors, deliver superior DL performance by enabling advanced capabilities (including Intel® AMX, Intel® AVX-512, VNNI, and bfloat16).</li>
                            <li>In Data Center GPUs, deliver the same with Intel® XMX.</li>
                        </ul>
                        <p class="mb-0"><a class="b_special_a1" href="">Model Zoo for Intel® Architecture</a> [GitHub]</p>
                        <ul>
                            <li>New precisions—BF32 and FP16 for PyTorch BERT Large + Intel Neural Compressor INT8 quantized models—support TensorFlow image-recognition topologies ResNet50, ResNet101, MobileNetv1, and Inception v3).</li>
                            <li>Supports Intel® Data Center Flex Series for Intel Optimization for PyTorch and Intel Extension for TensorFlow.</li>
                        </ul>
                        <p class="mb-0"><a class="b_special_a1" href="">Intel® Extension for TensorFlow</a> [GitHub]</p>
                        <ul>
                            <li>Supports Intel Data Center GPUs and includes Intel® Optimization for Horovod v0.4 to support distributed training on the new GPU Max Series.</li>
                            <li>Co-works with stock TensorFlow 2.11 and 2.10.</li>
                        </ul>
                        <p class="mb-0"><a class="b_special_a1" href="">Intel® Optimization for PyTorch</a></p>
                        <ul>
                            <li>Improve training and inference with native Windows support for ease-of-use/integration and BF16 and INT8 operator optimizations with oneDNN quantization backend.</li>
                            <li>Improve performance on the new Intel CPUs and GPUs when used with Intel’s PyTorch extension.</li>
                        </ul>
                        <p class="mb-0"><a class="b_special_a1" href="">ntel® GPU Support</a></p>
                        <ul>
                            <li>oneDNN and optimized deep learning frameworks, including TensorFlow and PyTorch, enable Intel® Xe Matrix Extensions (Intel® XMX) on the data center GPUs delivering increased, competitive performance across a wide range of market segments.</li>
                            <li>Additional performance gains are provided by Intel’s extensions for TensorFlow and PyTorch, both of which have native GPU support.</li>
                        </ul>
                        <p class="mb-0">&nbsp;</p>

                        <p><br>
                            <strong>Learn More</strong><br></p>
                            <ul>
                                <li><a href="" style="color:blue; text-decoration:underline !important">Build, Deploy &amp; Scale AI Solutions across the Enterprise</a></li>
                                <li><a href="" style="color:blue; text-decoration:underline !important">Intel® AI &amp; Machine Learning Tools</a></li>
                                <li>Explore workload types, oneAPI tools, and other resources for the <a href="" style="color:blue; text-decoration:underline !important">new GPUs</a> and <a href="" style="color:blue; text-decoration:underline !important">CPUs</a></li>
                                <li><a href="" style="color:blue; text-decoration:underline !important">AI Analytics Code Samples</a> [GitHub]</li>
                                <li><a href="" style="color:blue; text-decoration:underline !important">Intel Extension for PyTorch</a> [GitHub]</li>
                                <li><a href="" style="color:blue; text-decoration:underline !important">Intel Extension for TensorFlow</a> [GitHub]
                                <hr>
                                <p>&nbsp;</p>
                                </li>
                            </ul>
                            <p class="mb-0">&nbsp;</p>


                        <h3><a id="" name="AIRefKits-Feb2023"></a><strong>Now Available: 6 New AI Reference Kits</strong></h3>
                        <p>February 10, 20232 |<a href="" style="color:blue; text-decoration:underline !important">AI Reference Kits</a></p>
                        <h4>Next 6 AI Reference Kits Bolster AI Acceleration Across Multiple Industries and Architectures… FREE</h4>
                        <p>Since the fall of 2022, Intel has collaborated with Accenture to introduce AI reference kits covering industries such as energy &amp; utilities, financial services, health &amp; life sciences, retail, semiconductor, and telecommunications.</p>
                        <p>Today, <strong>6 more join the list</strong> (almost 30 total!). All are powered by oneAPI and can be applied freely to an increasing complement of AI workloads.</p>
                        <p style="text-align:center"><strong>Learn more and download the AI Ref Kits</strong></p>
                        <p style="text-align:center"><a style="padding: 5px 20px;" class="dk_button" href="">Learn more</a>&nbsp; &nbsp;<a style="padding: 5px 20px;" class="dk_button" href="">Download</a></p>
                        <p><strong>The Rundown</strong></p>
                        <p>Below is an overview of the next AI Ref Kits available, which are powered by oneAPI including optimized frameworks and oneAPI libraries, tools, and other components to maximize AI performance on Intel® hardware:</p>
                        <ol>
                            <li><a class="b_special_a1" href=""><strong>Traffic Camera Object Detection</strong></a> for developing a computer vision model to predict the risk of vehicle accidents by analyzing images from traffic cameras in real time.</li>
                            <li><a class="b_special_a1" href=""><strong>Computational Fluid Dynamics</strong></a> for developing a deep learning model to numerically solve equations calculating fluid-flow profiles.</li>
                            <li><a class="b_special_a1" href=""><strong>AI Structured Data Generation</strong></a> for developing a model to synthetically generate structured data, including numeric, categorical, and time series.&nbsp;</li>
                            <li><a class="b_special_a1" href=""><strong>Structural Damage Assessment</strong></a><strong> </strong>for developing a computer vision model using satellite images to assess the severity of damage caused by natural disasters.&nbsp;</li>
                            <li><a class="b_special_a1" href=""><strong>Vertical Search Engine</strong></a> for developing a natural language processing (NLP) model for semantic search through documents.</li>
                            <li><a class="b_special_a1" href=""><strong>Data Streaming Anomaly Detection</strong></a> for developing a deep learning model to help detect anomalies in sensor data that monitors equipment conditions.</li>
                        </ol>
                        <p><strong>Learn More</strong></p>
                        <ul>
                            <li><a href="" style="color:blue; text-decoration:underline !important">Intel Releases AI Reference Kits</a> [press release]</li>
                            <li><a href="" style="color:blue; text-decoration:underline !important">Intel Releases Open Source Reference Kits</a> [blog]
                            <hr>
                            <p>&nbsp;</p>
                            </li>
                        </ul>
                        <p>&nbsp;</p>

                        <h3><a id="" name="spr-pvc-launch"></a><strong>Just Launched: New Intel® CPUs and GPUs</strong></h3>
                        <p>January 10, 2023 |&nbsp;<a href="" style="color:blue; text-decoration:underline !important">Intel® oneAPI and AI Tools</a></p>
                        <p><img alt="" height="90" src="/img/darshit_image/badge-xeon-processor-centered.png" width="90"><img alt="" height="85" src="/img/darshit_image/newsroom-intel-xeon-cpu-max-series-badge.png" width="151"><img alt="" height="85" src="/img/darshit_image/oneapi-logo.png" width="151"><img alt="" height="85" src="/img/darshit_image/newsroom-data-ctr-gpu-max-badge.png" width="151"></p>
                        <p>Today, Intel marked one of the most important product launches in company history with the unveiling of its highly anticipated CPU and GPU architectures:<br>
                            &nbsp;</p>
                            <ul>
                                <li><strong>4th Gen Intel® Xeon® Scalable processors</strong> (code-named Sapphire Rapids)</li>
                                <li><strong>Intel® Xeon® CPU Max Series</strong> (code-named Sapphire Rapids HBM)</li>
                                <li><strong>Intel® Data Center GPU Max Series</strong> (code-named Ponte Vecchio)</li>
                            </ul>
                            <p>These feature-rich product families bring scalable, balanced architectures that integrate CPU and GPU with the oneAPI open software ecosystem, delivering a leap in data center performance, efficiency, security, and new capabilities for AI, the cloud, the network, and exascale.</p>
                            <p><strong>Scale a Single Code Base across Even More Architectures</strong></p>
                            <p>When coupled with the <a href="" style="color:#0070c0; text-decoration:none !important">2023 Intel® oneAPI and AI tools</a>, developers can create single source, portable code that fully activates the advanced capabilities and built-in acceleration features of the new hardware.<br></p>
                                <ul>
                                    <li><strong>4th Gen Intel Xeon &amp; Intel Max Series (CPU) processors</strong> provide a range of features for managing power and performance at high efficiency, including these instruction sets and built-in accelerators: Intel® Advanced Matrix Extensions, Intel® QuickAssist Technology, Intel® Data Streaming Accelerator, and Intel® In-Memory Analytics Accelerator.<sup>1 </sup>
                                
                                    <ul style="list-style-type:circle">
                                        <li>Activate Intel® AMX support for int8 and bfloat16 data types using oneAPI performance libraries such as oneDNN, oneDAL, and oneCCL.</li>
                                        <li>Drive orders of magnitude for training and inference into TensorFlow and PyTorch AI frameworks which are powered by oneAPI and already optimized to enable Intel AMX.</li>
                                        <li>Deliver fast HPC applications that scale with techniques in vectorization, multithreading, multi-node parallelization, and memory optimization using the Intel® oneAPI Base Toolkit and Intel® oneAPI HPC Toolkit.</li>
                                        <li>Deliver high-fidelity applications for scientific research, cosmology, motion pictures, and more that leverage all of the system memory space for even the largest data sets using the Intel® oneAPI Rendering Toolkit.</li>
                                        <li><a href="" style="color:#0070c0; text-decoration:none !important">Explore workload types, oneAPI tools, and other resources for these new CPUs &gt;</a></li>
                                    </ul>
                                    </li>
                                    <li><strong>Intel Data Center GPU Max Series</strong> is designed for breakthrough performance in data-intensive computing models used in AI and HPC such as physics, financial, services, and life sciences. This is Intel’s highest performing, highest density discrete GPU—it has more than 100 billion transistors and up to 128 X<sup>e</sup> cores.
                                    <ul style="list-style-type:circle">
                                        <li>Activate the hardware’s innovative features—Intel® X<sup>e</sup> Matrix Extensions, vector engine, Intel® X<sup>e</sup> Link, data type flexibility, and more—and realize maximum performance using oneAPI and AI Tools.</li>
                                        <li>Migrate CUDA* code to SYCL* for easy portability across multiple architectures—including the new GPU as well as those from other vendors—with code migration tools to simplify the process.</li>
                                        <li><a href="" style="color:#0070c0; text-decoration:none !important">Explore workload types, oneAPI tools, and other resources for the new GPU &gt;</a></li>
                                    </ul>
                                    </li>
                                </ul>
                                <hr>
                                <p class="">“The launch of 4th Gen Xeon Scalable processors and the Max Series product family is a pivotal moment in fueling Intel’s turnaround, reigniting our path to leadership in the data center, and growing our footprint in new arenas.” –<em> Sandra Rivera, Intel Executive VP and GM of Datacenter and AI Group</em></p>
                                <hr>

                        <p><strong>Learn More</strong></p>
                        <ul>
                            <li><a class="b_special_a1" href="">Get the details</a></li>
                            <li><a href="" style="color:#0070c0; text-decoration:none !important">New Intel oneAPI 2023 Tools Maximize Value of Upcoming Intel Hardware</a></li>
                            <li><a href="" style="color:#0070c0; text-decoration:none !important">Compare CPUs, GPUs, and FPGAs for oneAPI Compute Workloads</a></li>
                            <li>[Programming Guide] <a href="" style="color:#0070c0; text-decoration:none !important">Port Intel® C++ Compiler Classic to Intel® oneAPI DPC++/C++ Compiler</a></li>
                            <li>[On-Demand Webinar] <a href="" style="color:#0070c0; text-decoration:none !important">Tune Applications on CPUs &amp; GPUs with an LLVM*-Based Compiler from Intel</a></li>
                        </ul>
                        <p style="color: #bbb;"><sup>1</sup>The Intel Max Series processor (CPU) also offers 64 gigabytes of high bandwidth memory (HBM2e), significantly increasing data throughput for HPC and AI workloads.</p>
                        <hr>
                        <p>&nbsp;</p>

                        <h3><a id="" name="oneapi-2023-tools"></a><strong>Intel’s 2023 oneAPI &amp; AI Tools Now Available in the Intel® Developer Cloud</strong></h3>
                        <p>December 16, 2022 | <a href="" style="color:blue; text-decoration:underline !important">Intel® oneAPI and AI Tools</a>, <a href="" style="color:blue; text-decoration:underline !important">Intel® Developer Cloud</a>, <a href="" style="color:blue; text-decoration:underline !important">oneAPI initiative</a></p>
                        <p><strong>Optimized, Standards-based, Multiarchitecture Performance </strong></p>
                        <p>Just announced today, Intel® oneAPI and AI 2023 tools are now available in the Intel Developer Cloud and have started rolling out through regular distribution channels.</p>
                        <p>This release continues to empower developers with multiarchitecture performance and productivity, delivering optimized support for Intel’s upcoming portfolio of CPU and GPU architectures and advanced capabilities:<br></p>
                            <ul>
                                <li>4th Gen Intel® Xeon® Scalable Processors and the Intel® Xeon® Processor Max Series (formerly codenamed Sapphire Rapids) with Intel® Advanced Matrix Extensions (Intel® AMX), Quick assist Technology (QAT), Intel® AVX-512, bfloat16, and more</li>
                                <li>Intel® Data Center GPUs, including Flex Series with hardware AV1 encode and Max Series (formerly codenamed Ponte Vecchio) with datatype flexibility and Intel® X<sup>e</sup> Link, Intel® X<sup>e</sup> Matrix Extensions (Intel® XMX), vector engine, and other features</li>
                                <li>Existing Intel® CPUs, GPUs, and FPGAs<br>
                                &nbsp;</li>
                            </ul>

                            <div class="mb-3">
                                <img class="w-100" src="/img/darshit_image/intel-oneapi-cross-architecture.png" alt="">
                            </div>

                            <p><strong>The Highlights: What’s New in the 2023 oneAPI and AI Tools</strong><br></p>
                            
                            <p>Compilers &amp; SYCL Support<br></p>
                            <ul>
                                <li><a class="b_special_a1" href="">Intel® oneAPI DPC++/C++ Compiler</a> improves CPU and GPU offload performance and broadens SYCL language support for improved code portability and productivity</li>
                                <li><a class="b_special_a1" href="">Intel® oneAPI DPC++ Library</a> (oneDPL) expands support of the C++ standard library in SYCL kernels with additional heap and sorting algorithms and adds the ability to use OpenMP for thread-level parallelism.</li>
                                <li><a class="b_special_a1" href="">Intel® DPC++ Compatibility Tool</a> (based on the open source SYCLomatic project) improves migration of CUDA library APIs, including those for runtime and drivers, cuBLAS, and cuDNN.</li>
                            </ul>
                            <ul>
                                <li><a class="b_special_a1" href="">Intel® Fortran Compiler</a> provides full Fortran language standards support through Fortran 2018; implements coarrays, eliminating the need for external APIs such as MPI or OpenMP; expands OpenMP 5.0 and 5.1 offloading features; adds DO CONCURRENT GPU offload; and improves optimizations for source-level debugging.<br>
                                &nbsp;</li>
                            </ul>

                            <p>Performance Libraries<br></p>
                            <ul>
                                <li><a class="b_special_a1" href="">Intel® oneAPI Math Kernel Library</a> increases CUDA library function API compatibility coverage for BLAS and FFT; for Ponte Vecchio, leverages Intel® XMX to optimize matrix multiply computations for TF32, FP16, BF16, and INT8 data types.</li>
                                <li><a class="b_special_a1" href="">Intel® oneAPI Threading Building Blocks</a> improves support and use of the latest C++ standard for parallel_sort, offers an improved synchronization mechanism to reduce contention when multiple task_arena calls are used concurrently, and adds support for Microsoft Visual Studio 2022 and Windows Server 2022. &nbsp;</li>
                                <li><a class="b_special_a1" href="">Intel® oneAPI Video Processing Library</a> supports the industry’s first hardware AV1 codec in the Intel Data Center GPU Flex Series and Intel® Arc™ processors; expands OS support for RHEL9, CentOS Stream 9, SLES15Sp4, and Rocky 9 Linux; and adds parallel encoding feature to sample_multi_transcode.<br>
                                &nbsp;</li>
                            </ul>

                            <p>Analysis &amp; Debug<br></p>
                            <ul>
                                <li><a class="b_special_a1" href="">Intel® VTune™ Profiler</a> enables ability to identify MPI imbalance issues via its Application Performance Snapshot feature.</li>
                                <li><a class="b_special_a1" href="">Intel® Advisor</a> adds automated roofline analysis for Intel Data Center GPU MAX Series to identify and prioritize memory, cache, or compute bottlenecks and understand their causes, and delivers actionable recommendations for optimizing data-transfer reuse costs of CPU-to-GPU offloading.<br>
                                &nbsp;</li>
                            </ul>

                            <p>AI and Analytics<br></p>
                            <ul>
                                <li><a class="b_special_a1" href="">Intel® AI Analytics Toolkit</a> can now be run natively on Windows with full parity to Linux except for distributed training (GPU support is coming in Q1 2023).</li>
                                <li><a class="b_special_a1" href="">Intel® oneAPI Deep Neural Network Library</a> further supports delivery of superior deep learning performance by enabling advanced features in 4th Gen Intel Xeon Scalable Processors including Intel AMX, AVX-512, VNNI, and bfloat16.</li>
                                <li><a class="b_special_a1" href="">Intel® Distribution of Modin</a> integrates with new heterogeneous data kernels (HDK) solution in the back end, enabling AI solution scale from low-compute resources to large- or distributed-computed resources.<br>
                                &nbsp;</li>
                            </ul>

                            <p>Rendering &amp; Visual Computing<br></p>
                            <ul>
                                <li><a class="b_special_a1" href="">Intel® oneAPI Rendering Toolkit</a> includes the Intel® Implicit SPMD Program Compiler runtime library for fast SIMD performance on CPUs.</li>
                                <li><a class="b_special_a1" href="">Intel® Open Volume Kernel Library</a> increases memory-layout efficiency for VDB volumes and adds an AVX-512 8-wide CPU device mode for increased workload performance.</li>
                                <li><a class="b_special_a1" href="">Intel® OSPRay</a> and <a class="b_special_a1" href="">Intel® OSPRay Studio</a> add features for multi-segment deformation motion blur for mesh geometry, primitive, and objects; face-varying attributes for mesh and subdivision geometry; new light capabilities such as photometric light types; and instance ID buffers to create segmentation images for AI training.</li>
                            </ul>
                            <p class="mb-0">&nbsp;</p>

                            <p class="mb-0"><strong>Learn More</strong></p>
                            <ul>
                                <li><a class="b_special_a1" href="">See the benchmarks &gt;</a></li>
                                <li><a class="b_special_a1" href="">Get the full details &gt;</a></li>
                                <li><a class="b_special_a1" href="">Get a free Developer Cloud account &gt;</a></li>
                                <li><a class="b_special_a1" href="">Compare Benefits of CPUs, GPUs, and FPGAs for oneAPI Workloads &gt;</a></li>
                                <li>New to SYCL? <a class="b_special_a1" href="">Get started here &gt;</a></li>
                                <li><a class="b_special_a1" href="">Bookmark the oneAPI Training Portal</a> – Learn the way you want to with learning paths, tools, on-demand training, and opportunities to share and showcase your work.</li>
                            </ul>
                            <hr>
                            <p class="">&nbsp;</p>
                            <p class="mb-0">&nbsp;</p>

                            <h3><a id="" name="codeplay-plugins"></a><strong>Codeplay Announces oneAPI Plugins for Nvidia and AMD GPUs</strong></h3>
                            <p><strong>December 16, 2022 | <a href="" style="color:blue; text-decoration:underline !important">Codeplay Software</a> </strong></p>
                            <p><strong><img alt="" height="141" src="/img/darshit_image/logo-codeplay-16x9.png" style="float:left" width="250">Multiarchitecture, multivendor programming just got easier.</strong></p>
                            <p>Today, Codeplay Software<sup>1</sup> announced expanding oneAPI support for Nvidia and AMD GPUs via compiler plugins, enabling developers to target a broader set of platforms and architectures.</p>
                            <p>The Details:</p>
                            <ul>
                                <li>These plugins seamlessly work with the 2023 <a class="b_special_a1" href="">Intel® oneAPI DPC++/C++ Compiler</a><sup>2</sup>&nbsp;and many popular libraries.</li>
                                <li>Specific to the oneAPI Nvidia GPU plugin, Codeplay is providing complementary, enterprise-ready Priority Support, enabling developers to get accelerated responses directly from Codeplay engineers and more.</li>
                                <li>Codeplay is additionally providing a <em>beta release </em>of the oneAPI AMD GPU plugin that can be used with the Intel® oneAPI DPC++/C++ Compiler.</li>
                            </ul>
                            <p class="mb-0">&nbsp;</p>
                            <p style="text-align:center"><a class="b_special_a1" href=""><strong>Get the full story here &gt;</strong></a><br>
                                <a class="b_special_a1" href="">Download the Nvidia GPU plugin &gt;</a><br>
                                <a class="b_special_a1" href="">Download the AMD GPU plugin &gt;</a></p>
                            <p class="mb-0">&nbsp;</p>
                            <p class="mb-0"><strong>More from Codeplay:</strong></p>
                            <ul>
                                <li><a class="b_special_a1" href="">Expanding Our Open Standards with Intel</a></li>
                                <li><a class="b_special_a1" href="">Building an Open Standard Heterogeneous Software Platform on oneAPI</a></li>
                                <li><a class="b_special_a1" href="">SYCL Training Program</a></li>
                                <li><a class="b_special_a1" href="">oneAPI Solutions &amp; Contributions</a></li>
                            </ul>
                            <p class="">&nbsp;</p>
                            <p class="utility-text-2"><sup>1</sup>Codeplay is an Intel company<br>
                                <sup>2</sup>The oneAPI for Nvidia and AMD plugins can be used with the Intel® oneAPI DPC++/C++ Compiler 2023.0 or later version (the compiler is a component of the Intel® oneAPI Base Toolkit).</p>
                                <hr>
                                <p class="\mb-0">&nbsp;</p>
                                <p class="\mb-0">&nbsp;</p>

                            <h3><a id="" name="spec1-2release"></a><strong>oneAPI Spec 1.2 Release PLUS New Members Added to Steering Committee </strong></h3>   
                            <p>November 14, 2022 | <a href="" style="color:blue; text-decoration:underline !important">oneAPI initiative</a></p> 
                            <p>The <a class="b_special_a1" href="">oneAPI Specification 1.2</a> is comprised of a major new release of the oneDNN specification which includes the brand new <a class="b_special_a1" href="">oneDNN Graph API</a>, bringing enhanced performance by enabling a larger scope of deep neural network (DNN) compute graph functionality.</p>
                            <p class="mb-0">Additional features include:</p>
                            <ul>
                                <li>Updates and extensions to DPC++ (oneAPI’s open source SYCL implementation)</li>
                                <li>Enhancements to oneMKL, with new routines for the BLAS libraries</li>
                                <li>oneVPL’s addition of a new API for processing camera RAW data and more</li>
                                <li>Level Zero’s addition of a fabric topology discovery API and sRGB support for image copy</li>
                            </ul>
                            <p><strong>oneAPI Community Forum Expansion</strong></p>
                            <p class="mb-0">Led by Rod Burns, VP of Ecosystem at Codeplay Software, the forum has added the following new members to its steering committee:</p>
                            <ul>
                                <li>Kevin Harms from Argonne National Labs – Performance Engineering Team Lead, MS in Computer Science</li>
                                <li>Penporn Koanantakool from Google – Sr. Software Engineer, Ph.D in Computer Science</li>
                                <li>Robert Cohn from Intel – Sr. Principal Engineer, Ph.D in Computer Science</li>
                            </ul>
                            <p><a style="padding: 5px 20px;" class="dk_button" href=""><strong>Get the details &gt;</strong></a></p>
                            <hr>
                            <p class="mb-0">&nbsp;</p>
                            <p class="mb-0">&nbsp;</p>

                            <h4 style="font-weight: 300;"><a id="" name="supercomputing22"></a>Intel @ Supercomputing 2022 – Open, Accelerated Computing for HPC and AI</h4>
                            <p>November 09, 2022 | <a href="" style="color:blue; text-decoration:underline !important">Intel® oneAPI and AI Toolkits</a>, <a href="" style="color:blue; text-decoration:underline !important">oneAPI initiative</a></p>
                            <p>A lot of developer goodness was announced today by Jeff McVeigh, Intel VP and GM of its Super Computing group, Here are the highlights.</p>

                            <h3><strong>oneAPI and AI Tools 2023 Release</strong></h3>
                            <p>Available in December, Intel’s oneAPI and AI 2023 tools will provide optimized support for powerful new architectures, including the 4th Gen Intel® Xeon® Scalable Processor, Intel® Xeon® Processor Max Series (formerly codenamed Sapphire Rapids HBM), and Intel® Data Center GPU Max Series (formerly codenamed Ponte Vecchio).</p>
                            <p class="mb-0">These standards-based tools continue to help developers deliver multiarchitecture performance and productivity. New HPC and AI features include:</p>
                            <ul>
                                <li><strong><em>HPC and General Compute</em></strong> – Select tools support OpenMP 5.1, Intel® oneAPI DPC++/C++ Compiler provides improved SYCL language support, and Intel® Fortran Compiler fully implements F2003, F2008 and F2018 standards across Intel® CPUs and GPUs.&nbsp;</li>
                                <li><strong><em>AI</em></strong> – Optimizations for TensorFlow and PyTorch accelerate performance on current and upcoming Intel CPUs and GPUs. Extended quantization and distillation capabilities in the Intel® Neural Compressor deliver faster AI inference. These features are bundled in the Intel® AI Analytics Toolkit powered by oneAPI.&nbsp;</li>
                                <li><strong><em>Code Portability</em></strong> – Enhanced CUDA-to-SYCL code migration functions simplify creating single-source code for multiarchitecture systems.&nbsp;</li>
                            </ul>
                            <p>Other enhancements for this release were previewed at <a class="b_special_a1" href="">Intel® Innovation</a> on Oct. 28.</p>
                            <p><a style="padding: 5px 20px;" class="dk_button" href="">Learn more&nbsp;&gt;</a></p>

                            <h3><strong>7 New AI Reference Kits Released</strong></h3>
                            <p>To accelerate industry-driven solutions for AI, Intel recently released 7 new AI reference kits to address key business issues. The kits are powered by oneAPI and include optimized frameworks and oneAPI libraries, tools, and other components to maximize AI performance on Intel® hardware. The new kits target:</p>
                            <ul>
                                <li>Health &amp; Life Sciences - speech-to-text AI &nbsp;</li>
                                <li>Retail – personalize experiences with customer segmentation, automate purchase prediction, demand forecasting, order-to-delivery forecasting</li>
                                <li>Financial Services - loan default risk prediction</li>
                                <li>Cross-industry - network intrusion detection</li>
                            </ul>
                            <p>These kits join 9 others for a <strong>total of 16</strong>. Get them now via <a class="b_special_a1" href="">Intel</a> or on <a class="b_special_a1" href="">GitHub</a>.</p>

                            <h3><strong>New oneAPI Center of Excellence Focuses on Earthquake Research</strong></h3>
                            <p>The Southern California Earthquake Center with the San Diego Supercomputer Center at UC San Diego is hosting a <a class="b_special_a1" href="">new oneAPI Center of Excellence</a>. The center’s focus addresses the challenges of numerically simulating the dynamics of fault rupture and seismic ground motion in realistic 3D models. It will optimize <a class="b_special_a1" href="">Anelastic Wave Propagation – Olsen, Day, Cui (AWP-ODC) software</a>, an open source simulation code, using oneAPI to create portable, high-performance, multiarchitecture code for advanced HPC systems.&nbsp;&nbsp;</p>

                            <p>The Anelastic Wave Propagation code is used extensively by the SCEC community, the National Science Foundation consortium, and scientists and researchers in real-world seismic hazard simulations and research domains. It enables computational productions from standard “forward” simulations (computing three-component seismograms, i.e., records of earthquake phenomena) to multiple-source “reciprocal” simulations (calculating seismic hazard estimates for sites of interest). The computational outcomes allow for ground motion predictions that help decision-makers reduce seismic risk by improving building codes and increasing community resilience to earthquake hazards.&nbsp;</p>

                            <p>This oneAPI Center of Excellence joins 28 others around the globe working to accelerate oneAPI through research, code optimizations and implementations, and training programs.</p>

                            <p><a style="padding: 5px 20px;" class="dk_button" href="">Learn more&nbsp;&gt;</a></p>
                            <hr>
                            <p class="mb-0">&nbsp;</p>
                            <p class="mb-0">&nbsp;</p>

                            <h4 style="font-weight: 300;"><a id="" name="oneapi-2022.3"></a>Intel® oneAPI 2022.3 Tools Available</h4>
                            <p>October 10, 2022 | <a href="" style="color:blue; text-decoration:underline !important">Intel® oneAPI and AI Toolkits</a>, <a href="" style="color:blue; text-decoration:underline !important">oneAPI initiative</a></p>
                            <p><strong><img alt="" height="169" src="/img/darshit_image/logo-oneapi-color-rgb-rwd.png" style="float:left" width="300">Enabling an Open, Multiarchitecture World</strong></p>
                            <p>The newest update of <a href="" style="color:blue; text-decoration:underline !important">Intel® oneAPI Toolkits</a> and standalone tools is now available for direct download and/or use in the <a href="" style="color:blue; text-decoration:underline !important">Intel® DevCloud for oneAPI</a>. More than 30 tools are included in this release, each optimized to deliver improved performance and expanded capabilities for data-centric workloads.</p>
                            <p>Intel oneAPI Toolkits are purpose-built to optimize and accelerate cross-architecture and heterogeneous computing, delivering to developers open choice without sacrificing performance or functionality.</p>
                            <p>The toolkits provide compilers, languages, libraries, and analysis and debug tools that implement industry standards including SYCL*, C++, C, Python, Fortran, MPI, and OpenMP* as well as optimized versions of popular AI frameworks and Python libraries.</p>

                            <p><strong>2022.3 Highlights:</strong></p>
                            <p class="mb-0">Compilers</p>
                            <ul>
                                <li><a href="" style="color:blue; text-decoration:underline !important">Intel® oneAPI DPC++/C++ Compiler</a> adds more SYCL 2020 features to improve programming productivity on various hardware accelerators including GPUs and FPGAs and enhances OpenMP 5.x compliance.</li>
                                <li><a href="" style="color:blue; text-decoration:underline !important">Intel® Fortran Compiler</a> adds Fortran 2008 and 2018 coarrays, DLLImport/DLLExport, DO CONCURRENT offload support, and -int and additional -check compiler options.</li>
                            </ul>

                            <p class="mb-0">CUDA*-to-SYCL Porting</p>
                            <ul>
                                <li><a href="" style="color:blue; text-decoration:underline !important">Intel® DPC++ Compatibility Tool</a> supports more complete CUDA-to-SYCL code migration by adding support for CUDA 11.7 header files and CUDA runtimes and driver APIs including cuDNN, NCCL, Thrust, cuBLAS, and cuFFT.</li>
                                <li>The <a href="" style="color:blue; text-decoration:underline !important">SYCLomatic Project</a> expands Intel’s support of open computing with an open source version of the Compatibility Tool, which enables community collaboration to advance adoption of the SYCL standard.</li>
                            </ul>

                            <p class="mb-0">Performance Libraries</p>
                            <ul>
                                <li><a href="" style="color:blue; text-decoration:underline !important">Intel® oneAPI Math Kernel Library</a> adds BLAS GPU device-timing support to ensure faster and easier detecting of exceptions and quicker recovery; improves portability and compatibility by extending OpenMP cluster offload capability to support the OpenMP 5.1 spec for LAPACK.</li>
                                <li><a href="" style="color:blue; text-decoration:underline !important">Intel® oneAPI DPC++ Library</a> expands support of the C++ standard library in SYCL kernels with nine additional heap and sorting algorithms to simplify the coding of common functions.</li>
                                <li><a href="" style="color:blue; text-decoration:underline !important">Intel® oneAPI Video Processing Library</a> includes the ability to provide extensive data about what is encoded, thereby opening up opportunities for quality improvement and algorithm innovation.</li>
                            </ul>

                            <p class="mb-0">Analysis &amp; Debug Tools</p>
                            <ul>
                                <li><a href="" style="color:blue; text-decoration:underline !important">Intel® VTune™ Profiler</a>, <a href="" style="color:blue; text-decoration:underline !important">Intel® Advisor,</a> and <a href="" style="color:blue; text-decoration:underline !important">Intel® Inspector</a> include recent versions of 3<sup>rd</sup> party components including function and security updates.</li>
                                <li><a href="" style="color:blue; text-decoration:underline !important">Intel® Distribution for GDB*</a> enhances usability and stability for seamless GPU-side debugging.</li>
                                <li><a href="" style="color:blue; text-decoration:underline !important">Intel® Cluster Checker</a> supports the IBM Spectrum LSF* workload management platform for demanding, distributed HPC environments.</li>
                            </ul>

                            <p class="mb-0">Rendering &amp; Ray Tracing</p>
                            <ul>
                                <li><a href="" style="color:blue; text-decoration:underline !important">Intel® Open Volume Kernel Library</a> improves performance and memory efficiencies and adds support for VDB volumes (packed/contiguous data layouts for temporally constant volumes) and Intel® AVX-512 8-wide CPU device mode.</li>
                                <li><a href="" style="color:blue; text-decoration:underline !important">Intel® OSPRay</a> supports primitive, object, and instance ID buffers as framebuffer channels, and face-varying attributes for mesh and subdivision geometry.</li>
                                <li><a href="" style="color:blue; text-decoration:underline !important">Intel® Embree</a> supports the Intel oneAPI DPC++/C++ Compiler.</li>
                            </ul>
                            <p><a style="padding: 5px 20px;" class="dk_button" href="">Get all the details &gt;</a></p>

                            <p><a href="" style="color:blue; text-decoration:underline !important">Bookmark the oneAPI Training Portal</a> – Learn the way you want to with learning paths, tools, on-demand training, and opportunities to share and showcase your work.</p>
                            <p>&nbsp;</p>


                            <h4 style="font-weight: 300;"><a id="" name="oneapi-forum"></a>oneAPI Initiative Expands to a Community Forum for Open Accelerated Computing</h4>
                            <p>September 28, 2022 | <a href="" style="color:blue; text-decoration:underline !important">oneAPI Initiative &amp; Specification</a></p>
                            <p>The future of oneAPI is shifting to a community forum to address the evolving needs of developers, software vendors, national labs, researchers, and silicon vendors.</p>
                            <p>Why? To build on the progress made on <a class="b_special_a1" href="">oneAPI</a> adoption and implementations across multiple architectures and vendors.</p>
                            <p><strong>Codeplay</strong> will lead in establishing the forum to grow and coordinate the oneAPI developer community—its history driving open standards and cross-platform experience with SYCL* development and oneAPI implementations uniquely position it to facilitate these next steps.</p>
                            <p><strong>Benefits</strong></p>
                            <p>The forum will lead to greater community participation and guide the continuing evolution of oneAPI to enable more cross-architecture, multivendor implementations, and rapid adoptions.</p>
                            <p>Codeplay, in concert with the community, will provide additional details on the transition in the next quarter.</p>
                            <p class="mb-0"><strong>Get the details</strong></p>
                            <ul>
                                <li><a class="b_special_a1" href="">Join the oneAPI community and participate in collaborations</a></li>
                                <li>Read blogs for more details: <a class="b_special_a1" href="">oneAPI Expands to a Community forum by Sanjiv Shah (Intel VP)</a> | <a class="b_special_a1" href="">Building an Open Standard, Open-Source Heterogeneous Software Platform by Rod Burns (Codeplay Software VP)</a></li>
                            </ul>
                            <hr>
                            <p class="mb-0">&nbsp;</p>
                            <p class="mb-0">&nbsp;</p>


                            <h3 style="font-weight: 300;"><a id="" name="oneapi-2023"></a>Sneak Peek: 2023 Intel® oneAPI Tools</h3>
                            <p>September 28, 2022 | <a href="" style="color:blue; text-decoration:underline !important">Intel® oneAPI Toolkits</a></p>
                            <p><strong><img alt="" height="169" src="/img/darshit_image/oneapi-logo (1).png" style="float:left" width="300">New Enhancements Coming in December</strong></p>
                            <p>Winter is coming. Which means that Intel® oneAPI tools (toolkits and standalone tools) are on the precipice of revving to improved and optimized versions that are purpose-built to help developers continually deliver applications and solutions that work across multiple architectures—CPU, GPU, FPGA, and more.</p>
                            <p class="mb-0">The 2023 release includes enhancements to its standards-based developer products that are optimized for the latest and upcoming architectures (solely or in combination) such as:</p>
                            <ul>
                                <li>4th Gen Intel® Xeon® Scalable Processor</li>
                                <li>Intel® Data Center GPU codenamed Ponte Vecchio</li>
                                <li>Intel® Data Center GPU Flex Series</li>
                                <li>Intel® Arc™ Graphics</li>
                                <li>Intel® Agilex™ FPGAs</li>
                            </ul>
                            <p>New top features include:</p>
                            <ul>
                                <li><strong>HPC and General Compute</strong> – Enhanced CUDA-to-SYCL code migration functions simplify creating performant single source code for multiarchitecture systems. The Intel® oneAPI DPC++/C++ Compiler provides improved SYCL language support and the Intel® Fortran Compiler fully implements F2003, F2008 and F2018 standards across Intel CPUs and GPUs.</li>
                                <li><strong>Artificial Intelligence</strong> – TensorFlow* and PyTorch* are optimized for the 4th gen Xeon Scalable processor and Ponte Vecchio. Extended quantization and distillation capabilities in the Intel® Neural Compressor deliver faster AI inference. These features are bundled in the Intel® AI Analytics Toolkit powered by oneAPI.</li>
                            </ul>
                            <p>The tools begin shipping in December.</p>
                            <hr>
                            <p class="mb-0">&nbsp;</p>
                            <p class="mb-0">&nbsp;</p>


                            <h4 style="font-weight: 300;"><a id="" name="6-new-COEs"></a>Announcing 6 New oneAPI Centers of Excellence</h4>
                            <p>September 28, 2022 | <a href="" style="color:blue; text-decoration:underline !important">Academic Centers of Excellence</a></p>
                            <p>Six new oneAPI Centers of Excellence recently joined the oneAPI community. They will focus on accelerating oneAPI development on multiarchitecture systems by optimizing key software codes, creating new implementations, porting strategic applications to oneAPI, and developing and broadly sharing new curriculum to enable and expand oneAPI adoption.</p>
                            <p>The six new oneAPI Centers are:</p>
                            <ul>
                                <li><a class="b_special_a1" href=""><strong>Science and Technology Facilities Council</strong></a> will accelerate exascale software development on multiarchitecture systems using the SYCL* standard and oneAPI with specific focus on optimizing two prominent open source HPC software codes: a C++ coupling library called Multiscale Universal Interface (MUI) and a high-fidelity Computational Fluid Dynamics code called Xcompact3d. Both are integral within the UK’s ExCALIBUR exascale programme and part of its landscape for developing future exascale computing capabilities, providing accelerated computing platforms that can handle upwards of a trillion of calculations per second.&nbsp;</li>
                                <li><strong>School of Software and Microelectronics of Peking University</strong>&nbsp;is expanding teaching and practical usage of oneAPI programming, including developing and teaching classes and broadly sharing the new local language curriculum to enable and expand oneAPI adoption at universities in the People’s Republic of China.</li>
                                <li><strong>Technion Israel Institute of Technology</strong> is facilitating studies in contemporary scientific computing on CPUs, GPUs, and other accelerators using oneAPI and <a class="b_special_a1" href="">Intel® Developer Cloud</a>. Advanced courses using oneAPI and OpenMP* will expand to other universities. Undergraduate projects will also port select open source HPC and AI applications via oneAPI to OpenMP/SYCL and optimize their performance.</li>
                                <li><a class="b_special_a1" href=""><strong>University of California San Diego</strong></a><strong> </strong>will focus on enabling high-performance molecular dynamics simulations in Amber via <a class="b_special_a1" href="">oneAPI</a>—CPUs and accelerators—at its Supercomputer Center.</li>
                                <li><strong>University of Utah</strong> in collaboration with the Lawrence Livermore National Laboratory is focused on developing portable, scalable, and performant data compression techniques by accelerating <a class="b_special_a1" href="">ZFP compression software</a> using oneAPI on multiple architectures to advance exascale computing.&nbsp;</li>
                                <li><strong>Zuse Institute Berlin</strong> is focused on using oneAPI for energy-efficient HPC computing by delivering portable implementations on GPUs and FPGAs.&nbsp;</li>
                            </ul>

                            <p>To date, 28 oneAPI Centers of Excellence are driving oneAPI open accelerated compute adoption around the world.</p>
                            <p>Learn more: <a class="b_special_a1" href="">oneAPI Centers of Excellence</a></p>
                            <hr>
                            <p class="mb-0">&nbsp;</p>
                            <p class="mb-0">&nbsp;</p>

                            <h4 style="font-weight: 300;"><a class="" id="" name="3-AI-Ref-Kits"></a>Now Available: 3 New AI Reference Kits</h4>
                            <p>September 28, 2022 | <a href="" style="color:blue; text-decoration:underline !important">AI Reference Kits</a></p>
                            <p><strong>Solve important business problems.</strong></p>
                            <p>Building on a set of AI SW Reference Kits released in July (in collaboration with Accenture), three new <a class="b_special_a1" href="">AI application reference kits</a> powered by oneAPI are now available for healthcare to help clinicians with disease prediction, medical imaging diagnostics, and document automation. The kits can be downloaded from <a class="b_special_a1" href="">Intel</a> or <a class="b_special_a1" href="">GitHub</a>.</p>
                            <p>A continuing drumbeat of new AI reference kit releases will continue through 2023.&nbsp;</p>
                            <hr>
                            <p class="mb-0">&nbsp;</p>
                            <p class="mb-0">&nbsp;</p>


                            <h4 style="font-weight: 300;"><a id="" name="RHODS-Intel"></a>Joint Solution with Red Hat Accelerates AI, New Data Science Developer Program</h4>
                            <p>September 28, 2022&nbsp;</p>
                            <p><strong>New Enhancements Coming in December</strong></p>
                            <p class="mb-0">&nbsp;</p>
                            <p><img alt="" height="169" src="/img/darshit_image/logo-red-hat-intel-rwd.png" style="float:left" width="300">Intel and Red Hat introduced a new joint solution that combines Intel’s AI hardware and software portfolio with Red Hat OpenShift Data Science (RHODS), an AI platform that enables data scientists and developers to work together to create, test, and build intelligent applications.</p>
                            <p>This solution enables developers to train and deploy their models using the <a class="b_special_a1" href="">Intel® AI Analytics Toolkit</a> and <a class="b_special_a1" href="">OpenVINO™ tools,</a> which are powered by oneAPI.&nbsp;</p>
                            <p>Red Hat is also working to make the Habana Gaudi* training accelerator available on its service to deliver cost-efficient, high-performance, deep-learning model training and deployment. Additionally, a joint Intel and Red Hat <a class="b_special_a1" href="">AI developer program</a> will enable developers to learn, test, and deploy AI software directly from both the RHODS sandbox and the <a class="b_special_a1" href="">Intel® Developer Cloud</a>.</p>
                            <p><strong>Learn more</strong>: <a class="b_special_a1" href="">Developer Resources from Intel &amp; Red Hat</a> | <a class="b_special_a1" href="">Boost OpenShift Data Science with Intel® AI Analytics Toolkit</a></p>
                            <hr>
                            <p class="mb-o">&nbsp;</p>
                            <p class="mb-o">&nbsp;</p>

                            <h4 style="font-weight: 300;"><a id="" name="devcloud-beta"></a>For a Limited Time: Get Beta Access to New Intel® Technologies</h4>
                            <p>September 27, 2022 | <a href="" style="color:blue; text-decoration:underline !important">Intel® Developer Cloud</a></p>
                            <p><strong><img alt="" height="225" src="/img/darshit_image/devcloud-overview-step1-1x1.png" style="float:left" width="300">New technologies are a click away in the expanded Intel® Developer Cloud.</strong></p>
                            <p>As noted by Intel CEO <em>Pat Gelsinger</em> during his keynote at <a class="b_special_a1" href="">Intel® Innovation</a>, a limited beta trial opportunity is now open to for the newly expanded <a class="b_special_a1" href="">Intel® Developer Cloud</a>.</p>
                            <p>Starting right now, approved developers and customers can get early access to Intel technologies—from a few months to a full year ahead of product availability—and try out, test, and evaluate them on Intel’s enhanced, cloud-based service platform.</p>
                            <p>The beta trial includes new and upcoming Intel compute and accelerator platforms such as:</p>
                            <ul>
                                <li>4th&nbsp;Gen Intel® Xeon®&nbsp;Scalable&nbsp;Processors&nbsp;(Sapphire Rapids)</li>
                                <li>Intel® Xeon&nbsp;4th Gen® processor with high bandwidth memory (HBM)</li>
                                <li>Intel®&nbsp;Data Center GPU&nbsp;codenamed&nbsp;Ponte Vecchio</li>
                                <li>Intel® Data Center GPU&nbsp;Flex Series</li>
                                <li>Habana® Gaudi®2&nbsp;Deep Learning accelerators</li>
                            </ul>
                            <p>Registration and prequalification is required.</p>
                            <p><strong>Visit </strong><a href="" style="color:blue; text-decoration:underline !important"><strong>cloud.intel.com</strong></a><strong> to get started.</strong></p>
                            <p>&nbsp;</p>


                            <h3 style="font-weight: 300;"><a id="Intel-TensorFlow" name="Intel-TensorFlow"></a>Intel Among Official TensorFlow Build Collaborators</h3>
                            <p>September 21, 2022 | <a href="" style="color:blue; text-decoration:underline !important">TensorFlow install with pip</a></p>
                            <p><img alt="" height="210" src="/img/darshit_image/tensorflow-native-windows.png" style="float:left" width="300">Intel has officially partnered with Google to take ownership of developing and releasing TensorFlow Windows Native CPU builds, starting with <strong>TensorFlow 2.10</strong>. This close collaboration with Google underscores Intel’s commitment to deliver optimal experience for TensorFlow developers on Windows platforms.</p>
                            <p><a style="padding: 5px 20px;" class="dk_button" href="">Get the details &gt;</a></p>
                            <hr>
                            <p class="">&nbsp;</p>
                            <p class="">&nbsp;</p>

                            <h3 style="font-weight: 300;"><a id="TencentDB" name="TencentDB"></a>Tencent Achieves Up to 85% Performance Boost using oneAPI Tools</h3>
                            <p>September 12, 2022 | <a href="" style="color:blue; text-decoration:underline !important">Intel® oneAPI DPC++/C++ Compiler</a>, <a href="" style="color:blue; text-decoration:underline !important">Intel® VTune™ Profiler</a></p>

                            <p class="">&nbsp;</p>
                            <div class="d-flex">
                                <div class="">
                                    <i class="fa-solid fa-quote-left" style="font-size: 65px; color: #E5E6E6; padding-right: 15px;"></i>
                                </div>
                                <div class="">
                                    <div class="mv_together_content">
                                        <p class="mb-2" style="font-weight: 300;"><i>Tencent’s results with optimizing MySQL demonstrate the importance both of using up-to-date [Intel® oneAPI] developer tools like the Intel oneAPI DPC++/C++ Compiler and the latest optimization techniques using Intel VTune Profiler. The significant improvements in performance yield either faster time-to-results or more results for business-critical applications.</i></p>
                                        <p>Joe Curley, Intel VP and GM, Intel Software Products & Ecosystem group</p>
                                    </div>
                                </div>
                            </div>
                            <p class="mb-0">&nbsp;</p>
                            <p class="mb-0">&nbsp;</p>

                            <p>Tencent significantly enhanced the performance of its database hosting service, <a class="b_special_a1" href="">TencentDB for MySQL</a>. Based on the open source relational database management system MySQL and built on Intel® Xeon® processors, performance increased by using the advanced Intel® oneAPI DPC++/C++ Compiler and Intel® VTune™ Profiler (part of the Intel® oneAPI Base Toolkit).</p>
                            <p><strong>Why It Matters</strong></p>
                            <p>Distributed data storage serves a critical role across industries and use cases, including internet, finance and e-commerce. Solutions like TencentDB for MySQL provide developers with a service for distributed data storage that supports easy setup, operation and expansion of relational databases in the cloud.</p>
                            <p><a style="padding: 5px 20px;" class="dk_button" href="">Read the story &gt;</a></p>
                            <hr>
                            <p class="mb-0">&nbsp;</p>
                            <p class="mb-0">&nbsp;</p>

                            <h4 style="font-weight: 300;"><a id="" name="blender-radioss"></a>From Rendering to HPC, Intel® oneAPI Tools are Optimizing Open Source Solutions</h4>
                            <p>September 8, 2022 | <a href="" style="color:blue; text-decoration:underline !important">Intel® oneAPI Base Toolkit</a>, <a href="" style="color:blue; text-decoration:underline !important">Intel® oneAPI HPC Toolkit</a>, <a href="" style="color:blue; text-decoration:underline !important">Intel® oneAPI Rendering Toolkit</a></p>
                            <p>New this week, two popular and powerful applications, Blender 3.3 and Radioss (which now has an open source version: OpenRadioss), are optimized by very different (and very important) oneAPI tools and capabilities that benefit developers.</p>
                            <p>Check them out:</p>


                            <h3><strong>Blender Cycles Provides Full Support for Intel Discrete GPUs</strong></h3>
                            <p>Starting with <a class="b_special_a1" href="">Blender 3.3</a>, the Cycles rendering engine now includes oneAPI as a rendering device API with support for <a class="b_special_a1" href="">Intel® Arc™ A-series discrete graphics</a> and <a class="b_special_a1" href="">Intel®<sup> </sup>Data Center GPU Flex Series</a>. The new support is implementing SYCL, by The Khronos Group, an open, standards-based language that provides multivendor CPU and GPU code development. This is a first step in an evolutionary development approach that aims to free Blender creators and users from being locked into single, proprietary architecture and programming.</p>
                            <p>Cycles is a ray tracing renderer in Blender with complex path-tracing scenes, geometry notes, indirect lighting and dense geometry for final frames. Over the years, Intel’s contributions to Blender include development consulting, integrating advanced ray tracing capabilities, and training. Intel<sup>®</sup> Embree, the <a class="b_special_a1" href="">academy award-winning</a> 3D ray tracing kernel library, was integrated into Blender several years ago, delivering high-fidelity photorealism and supporting many films and projects. In 2019, Intel® Open Image Denoise was added, helping artists and studios deliver final frame image quality in less time.</p>

                            <h3><strong>Altair Unveils OpenRadioss</strong></h3>
                            <p class="">&nbsp;</p>
                            <div class="d-flex">
                                <div class="">
                                    <i class="fa-solid fa-quote-left" style="font-size: 65px; color: #E5E6E6; padding-right: 15px;"></i>
                                </div>
                                <div class="">
                                    <div class="mv_together_content">
                                        <p class="mb-2" style="font-weight: 300;"><i>Altair taking OpenRadioss into the open source community enables developers who want to solve critical problems in structural analysis like crash simulation access to the benefits of open source development. Intel’s commitment to open source development is reflected in collaboration with Altair using open oneAPI compilers, libraries, and developer tools that help them productively maximize value from their high-performance hardware.</i></p>
                                        <p>Joe Curley, Intel VP and GM, Intel Software Products & Ecosystem group</p>
                                    </div>
                                </div>
                            </div>
                            <p class="mb-0">&nbsp;</p>
                            <p class="mb-0">&nbsp;</p>

                            <p>Altair has moved <a class="b_special_a1" href="">Radioss</a>—a leading analysis solution to improve the crashworthiness, safety, and manufacturability of complex designs—to open source as OpenRadioss. Altair engineers used several tools in the Intel<sup>®</sup> oneAPI Base and HPC Toolkits to optimize the software.</p>
                            <p><a style="padding: 5px 20px;" class="dk_button" href="">Learn more &gt;</a>&nbsp;<a style="padding: 5px 20px;" class="dk_button" href="">Watch the video &gt;</a></p>
                            <hr>
                            <p class="mb-0">&nbsp;</p>
                            <p class="mb-0">&nbsp;</p>

                            <h3 style="font-weight: 300;"><a id="" name="DC-GPU"></a>New Intel® Data Center GPU Flex Series for the Intelligent Visual Cloud Uses an Open Software Stack</h3>
                            <p>Aug. 24, 2022 |&nbsp;<a href="" style="color:blue; text-decoration:underline !important">oneVPL</a>&nbsp;|&nbsp;<a href="" style="color:blue; text-decoration:underline !important">Intel® VTune™ Profiler</a></p>
                            <p>Unveiled today, the Intel® Data Center GPU Flex Series is a versatile and seamless hardware with an open software solution stack that brings much-needed flexibility and performance to intelligent visual cloud workloads.</p>
                            <p class="mb-0">It delivers:</p>
                            <ul>
                                <li>5x media transcode throughput performance and 2x decode throughput performance at half the power of competitive solutions<sup>6</sup></li>
                                <li>More than 30% bandwidth improvement for significant total cost of ownership (TCO) savings</li>
                                <li>Broad support for popular media tools, APIs, frameworks, and the latest codecs</li>
                            </ul>
                            <p>The Intel Flex Series GPU is designed to flexibly handle a wide range of workloads—media delivery, cloud gaming, AI, metaverse, more—without compromising performance or quality, while lowering and optimizing TCO. The GPU frees users from the constraints of siloed and proprietary environments and reduces the need for data centers to use separate, discrete solutions.</p>

                            <div class="mb-3">
                                <img class="w-100" src="/img/darshit_image/dc-gpu-flex-swstack-cropped.jpeg" alt="">
                            </div>
                            <p>Developers can access a comprehensive software stack that combines open source components and tools to effectively realize the Flex Series GPU capabilities for visual cloud workloads. Intel’s oneAPI tools empower developers to deliver accelerated applications and services, including <a class="b_special_a1" href="">oneVPL</a>, <a class="b_special_a1" href="">Intel® VTune™ Profiler</a>, and many more.</p>

                            <p>Watch for more details on easy downloadable software packages coming soon. &nbsp;</p>
                            <p><strong>Learn More: </strong><a class="b_special_a1" href="">Intel News Byte</a> |<strong> </strong><a class="b_special_a1" href="">Intel Flex Series GPU</a></p>
                            <p class="mb-0">&nbsp;</p>
                            <p class="mb-0">&nbsp;</p>

                            <h3 style="font-weight: 300;"><a id="" name="fabio"></a>3D Artist’s Visuals Come to Life through Intel Hardware &amp; Advanced Ray Tracing</h3>
                            <p>August 16, 2022 | <a href="" style="color:blue; text-decoration:underline !important">Intel® Open VKL</a>, <a href="" style="color:blue; text-decoration:underline !important">Intel® oneAPI Rendering Toolkit</a></p>
                            <p>Intel® Advanced Ray Tracing + Intel’s mobile HX processors deliver high performance for professional workflows and amazing content creation.</p>
                            <p>Intel recently released the Intel® Open VKL <a class="b_special_a1" href="">plugin</a> for RenderMan*. It works with Pixar Animation’s Renderman—one of the world’s most versatile renderers for VFX and animation—and utilizes Intel® Open Volume Kernel Library to provide significant performance improvements for final-frame volumetric rendering.</p>
                            <p>The powerful combo of Renderman, Intel Open VKL, and 12<sup>th</sup> Gen Intel® Core™ HX processors helps artists like <a class="b_special_a1" href="">Fabio Sciedlarczyk</a> render compute-intensive volumetric content more quickly, including fire, water, air, clouds, and smoke. That performance allows him more time to craft a visually stunning story. In this video, see how Sciedlarczyk used these tools to build amazing photoreal visuals, producing them on-the-go without sacrificing performance while dramatically reducing compile times on his mobile workstation.</p>

                            <p class="">&nbsp;</p>
                            <div class="d-flex">
                                <div class="">
                                    <i class="fa-solid fa-quote-left" style="font-size: 65px; color: #E5E6E6; padding-right: 15px;"></i>
                                </div>
                                <div class="">
                                    <div class="mv_together_content">
                                        <p class="mb-2" style="font-weight: 300;"><i>These days, with the tools I have available, computer graphics is becoming a medium of almost no restrictions. And Intel is continually pushing the boundaries of what’s possible.</i></p>
                                        <p>Fabio Sciedlarczyk, Looks development artist</p>
                                    </div>
                                </div>
                            </div>
                            <p class="mb-0">&nbsp;</p>
                            <p class="mb-0">&nbsp;</p>

                            <div class="mb-3">
                                <img class="w-100" src="/img/darshit_image/maxresdefault.jpg" alt="">
                            </div>
                            <p>The open source plugin is available free to the public on <a class="b_special_a1" href="">GitHub</a> and aligns with Intel’s open software strategy to foster innovation and broad adoption by content creators and developers across the software ecosystem. Intel Open VKL is part of the Intel® oneAPI Rendering Toolkit.</p>
                            <p class="mb-0"><strong>More Resources</strong></p>
                            <ul>
                                <li><a class="b_special_a1" href="">Deploy Stunning Hi-Fi Graphics with Intel® Advanced Ray Tracing</a></li>
                                <li><a class="b_special_a1" href="">12th Gen Intel Core HX Processors Launch as World’s Best Mobile Workstation Platform</a> [press release]</li>
                                <li><a class="b_special_a1" href="">Talking Tech: 12th Gen Intel Core HX Mobile Workstation Processors</a> [Watch – 13:46]</li>
                            </ul>
                            <p class="mb-0">&nbsp;</p>
                            <p class="mb-0">&nbsp;</p>

                            <h3 style="font-weight: 300;"><a id="" name="aible-collaboration"></a>Intel and Aible Team Up to Fast-Track AI</h3>
                            <p>August 9, 2022 |&nbsp;<a href="" style="color:blue; text-decoration:underline !important">Aible</a>, <a href="" style="color:blue; text-decoration:underline !important">Intel® AI Analytics Toolkit</a></p>
                            <p>Intel® Xeon® Scalable processors, along with software optimizations, enable business results within 30 days.</p>
                            <p>Intel’s collaboration with Aible, a cloud-based AI/ML platform solution provider, enables customers to deliver datacenter-based AI applications and initiatives faster and with better TCO without increasing complexity.</p>
                            <p>When paired with AI-accelerated Intel® Xeon® Scalable processors plus AI-optimized tools: oneAPI Deep Neural Network Library (oneDNN) + others from Intel® AI Analytics Toolkit, Aible’s technology provides a serverless-first approach that trains machine learning modules faster than other server-oriented solutions.</p>
                            <p><strong><a class="b_special_a1" href="">Learn more &amp; see the benchmark &gt;</a></strong></p>
                            <p><a style="padding: 5px 20px;" class="dk_button" href="">Read the case study &gt;</a></p>
                            <p class="">&nbsp;</p>


                            <h3 style="font-weight: 300;"><a id="" name="hi-fi-graphics"></a>Deploy Stunning Hi-Fi Graphics with Intel® Advanced Ray Tracing</h3>
                            <p>August 8, 2022 |&nbsp;<a href="" style="color:blue; text-decoration:underline !important">[NEW!] Intel® Arc™ Pro A-series graphics</a>, <a href="" style="color:blue; text-decoration:underline !important">Intel® Open VKL plugin for RenderMan*</a>, <a href="" style="color:blue; text-decoration:underline !important">Intel® Open Path Guiding Library</a>, <a href="" style="color:blue; text-decoration:underline !important">SIGGRAPH 2022</a></p>
                            <h4>Newly Unveiled: Intel®&nbsp;Arc™ Pro GPUs, Intel®&nbsp;Open VKL Plugin for Renderman*, and Open Path Guiding Library</h4>
                            
                            <div style="margin: 3rem 0rem;">
                                <div class="row">
                                    <div class="col-md-3">

                                    </div>
                                    <div class="col-md-9">
                                        <p>	
                                            Just in time for SIGGRAPH 2022, Intel introduced new GPU hardware and software technologies that accelerate high-fidelity graphics. These innovations showcase the next step in the company’s mission to provide open, end-to-end, platform-wide solutions for performance scaling across consumer and high-end laptops, workstations, data center/render farm, cloud - to the world’s largest supercomputers.</p>
                                    </div>
                                </div>
                            </div>

                            <p><strong>Highlights</strong></p>
                            <p>The <strong>Intel Arc Pro A-series professional range of GPUs</strong> feature built-in ray-tracing hardware, industry-first AV1 hardware encoding acceleration, and machine learning capabilities. <a class="b_special_a1" href=""><strong>Learn more &gt;</strong></a></p>
                            <p class="mb-0"><strong>New Intel® Advanced Ray Tracing technologies</strong> enable sophisticated ray tracing, visual compute, high-fidelity, and visualization capabilities.</p>
                            <ul>
                                <li><a class="b_special_a1" href="">Intel® Open VKL plugin for Renderman*</a> provides significant improvements for final-frame volumetric rendering.</li>
                                <li><a class="b_special_a1" href="">Intel® Open Path Guiding Library</a>, the industry’s first open-source library, enables users to easily integrate state-of-the-art path-guiding methods into their renderers.</li>
                            </ul>
                            <p><strong>Cross-industry collaborations with global leaders</strong> in standards-based solutions are continuously advancing graphics innovations, with the latest including:</p>
                            <ul>
                                <li><a class="b_special_a1" href="">DreamWorks Animation</a> announced plans to release its MCRT renderer, MoonRay*, as open source software later this year. The renderer’s photoreal ray-tracing performance is supported by two open source tools in the Intel® oneAPI Rendering Toolkit (Render Kit): Intel® Embree ray tracing kernel library for advanced rendering features, and Intel® Implicit SPMD Program Compiler (Intel® ISPC) for vector instruction parallelism.</li>
                                <li><a class="b_special_a1" href="">Blender* 3.3</a> is available in beta where oneAPI programming delivers one codebase support on Linux* and Windows* across Intel Arc GPUs and upcoming Intel data center GPUs.</li>
                                <li>Intel collaborated with leading Unity asset publisher Procedural Worlds on creating the <a class="b_special_a1" href="">Intel® Game Dev AI Toolkit with Gaia ML (for Unity)</a>. It enables developers to bring machine learning capabilities to their gaming experiences.</li>
                                <li><a class="b_special_a1" href="">Foundry’s Modo* 16.0</a> release adds new support to its real-time viewport for upcoming Intel Arc GPUs.</li>
                            </ul>
                            <p><strong>Attending SIGGRAPH 2022?</strong></p>
                            <p>If so, visit the <a class="b_special_a1" href="">Intel Booth (<strong>#427</strong>)</a> to see demos showcasing innovative usages including Topaz and SketchUp running on the just-announced Intel Arc Pro graphics, and SideFX, Blender, and RenderMan optimized by the Render Kit on Intel GPUs and CPUs.</p>
                            <p class="mb-0"><strong>Discover More</strong></p>
                            <ul>
                                <li><a class="b_special_a1" href="">Intel Newsbyte</a></li>
                                <li><a class="b_special_a1" href="">Deploy Stunning Hi-Fi Graphics with Advanced Ray Tracing</a></li>
                                <li><a class="b_special_a1" href="">Open Path-Guided Rendering Made Easier</a></li>
                            </ul>
                            <p class="mb-0">&nbsp;</p>
                            <p class="mb-0">&nbsp;</p>


                            <h3 style="font-weight: 300;"><a id="" name="AI-reference-kits"></a>Intel Releases Open Source AI Reference Kits to Simplify Development</h3>
                            <p>July 12, 2022 |&nbsp; <a href="" style="color:blue; text-decoration:underline !important">Intel AI Dev Tools</a></p>
                            <p>Intel released the first set of open-source AI reference kits specifically designed to make AI more accessible to organizations in on-prem, cloud, and edge environments.&nbsp;</p>
                            <p>First introduced at <a class="b_special_a1" href="">Intel Vision</a>, these kits include AI model code, training data, end-to-end machine learning pipeline instructions, libraries, and Intel® oneAPI components for cross-architecture performance.</p>
                            <p class="mb-0">The First Kits Available Today</p>
                            <ul>
                                <li><a class="b_special_a1" href="">Utility Asset Health</a> – This predictive analytics model was trained to help utilities deliver higher service reliability.</li>
                                <li><a class="b_special_a1" href="">Visual Quality Control</a> – Automate VQ control inspections for life sciences, including pharma to help improve the quality of the pills and lower the cost of operations.</li>
                                <li><a class="b_special_a1" href="">Customer Chatbot for the Enterprise</a> – This conversational AI chatbot model was trained using over 4,000 utterances from the Airline Travel Information Systems dataset to provide 94% predictive accuracy.</li>
                                <li><a class="b_special_a1" href="">Intelligent Document Indexing</a> – Automate the processing and categorizing of millions of documents via faster routing and lower manual labor costs.</li>
                            </ul>
                            <p><a style="padding: 5px 20px;" class="dk_button" href="">Get the details &gt;</a></p>

                            <p class="">&nbsp;</p>
                            <div class="d-flex">
                                <div class="">
                                    <i class="fa-solid fa-quote-left" style="font-size: 65px; color: #E5E6E6; padding-right: 15px;"></i>
                                </div>
                                <div class="">
                                    <div class="mv_together_content">
                                        <p class="mb-2" style="font-weight: 300;"><i>Innovation thrives in an open, democratized environment and Intel’s AI tools and framework optimizations are built on the foundations of an open, standards-based, unified oneAPI programming model. These Project Apollo reference kits, built with components of Intel’s End-to-End AI software portfolio, will enable millions of developers and data scientists to quickly and easily introduce AI into their applications or boost their existing AI/ML implementations. This will help deliver a wide range of intelligent solutions across several use cases and industries.</i></p>
                                        <p>Wei Li, Intel vice president and general manager of AI and Analytics</p>
                                    </div>
                                </div>
                            </div>
                            <p class="mb-0">&nbsp;</p>
                            <p class="mb-0">&nbsp;</p>
                            <p><a style="padding: 5px 20px;" class="dk_button" href="">Download the Software for Free</a></p>
                            <p class="mb-0">&nbsp;</p>
                            <p class="mb-0">&nbsp;</p>

                            <h3 style="font-weight: 300;"><a id="" name="intel-google-advance-hpc"></a>Intel &amp; Google Cloud Provide Turnkey, Optimized Solution for HPC Workloads</h3>
                            <p>July 6, 2022 |&nbsp; <a href="" style="color:blue; text-decoration:underline !important">Intel® oneAPI Base Toolkit</a>, <a href="\" style="color:blue; text-decoration:underline !important">Intel® oneAPI HPC Toolkit</a></p>
                            <p>Intel and Google are working together to drive high-performance computing forward on Google Cloud with the release of the <a class="b_special_a1" href="">Cloud HPC Toolkit</a>. This new resource provides access to tools from the <a class="b_special_a1" href="">Intel® oneAPI Base and HPC Toolkits</a>—including <em>Intel® MPI Library</em> and <em>Intel® oneAPI Math Kernel Library</em>—to optimize performance through <a class="b_special_a1" href="">Intel® Select Solutions for Simulations &amp; Modeling</a>. These new tools improve compile times and speed of results and offer multi-vendor acceleration in SYCL.</p>
                            <p><strong>Why It’s Important</strong></p>
                            <p>In a nutshell, the new Toolkit simplifies adoption of robust high-performance cloud computing by removing the challenges inherent in groking and overcoming unfamiliar development concepts and tools. (These can result in slow deployment for demanding workloads, software incompatibilities, and subpar performance.)</p>

                            <p class="">&nbsp;</p>
                            <div class="d-flex">
                                <div class="">
                                    <i class="fa-solid fa-quote-left" style="font-size: 65px; color: #E5E6E6; padding-right: 15px;"></i>
                                </div>
                                <div class="">
                                    <div class="mv_together_content">
                                        <p class="mb-2" style="font-weight: 300;"><i>Using Cloud HPC Toolkit with an Intel Select Solutions for Simulations & Modeling blueprint brings the added benefit of automatically spinning up a hardware-software configuration that has been rigorously tested and optimized for real-world performance, eliminating guesswork.</i></p>
                                        <p>Ilias Katsardis – HPC Solution Lead – Google</p>
                                    </div>
                                </div>
                            </div>
                            <p class="mb-0">&nbsp;</p>
                            <p class="mb-0">&nbsp;</p>
                            <p><a style="padding: 5px 20px;" class="dk_button" href="">Read the Story &gt;</a></p>
                            <p class="mb-0"><strong>Explore More</strong></p>
                            <ul>
                                <li><a class="b_special_a1"  href="">Intel MPI Library</a></li>
                                <li><a class="b_special_a1"  href="">Intel oneAPI Math Kernel Library</a></li>
                                <li><a class="b_special_a1"  href="">Google Cloud blog</a></li>
                                <li><a class="b_special_a1"  href="">Video: Accelerate Workloads in Google Cloud Using Intel® oneAPI Toolkits</a></li>
                            </ul>
                            <p class="mb-0">&nbsp;</p>
                            <p class="mb-0">&nbsp;</p>

                            <h3 style="font-weight: 300;"><a id="" name="vtune-profiler-2022.3"></a>Now Available: Intel® VTune™ Profiler 2022.3</h3>
                            <p>June 7, 2022 | <a href="" style="color:blue; text-decoration:underline !important">Intel® VTune™ Profiler</a></p>
                    
                           <p><img alt="Intel VTune Profiler 2022.3" height="233" src="/img/darshit_image/vtune-22-3-interface-rwd.png" style="float:left" width="300"></p>
                           <p>Find and optimize performance bottlenecks fast across CPU, GPU, and FPGA systems.</p>
                           <p><strong>What’s New?</strong></p>
                           <ul>
                            <li>Supports DirectML API to pinpoint host-side API call inefficiencies and their causes</li>
                            <li>Enables developers to identify memory-transfer-related bottlenecks for GPU computing tasks which use USM extension of OpenCL™ API via analyzing CPU-side stacks.</li>
                        </ul>
                        <p class="mb-0"><a style="padding: 5px 20px;" class="dk_button" href="">Download it today &gt;</a></p>
                        <p>Learn more at <strong><a class="b_special_a1" href="">software.intel.com/vtune</a></strong></p>
                        <p class="">&nbsp;</p>

                        <h3 style="font-weight: 300;"><a id="" name="Intel-Codeplay"></a>Intel to Acquire Codeplay Software</h3>
                        <p>June 1, 2022 | <a href="" style="color:blue; text-decoration:underline !important">oneAPI Specification</a></p>
                        
                        <p><img alt="Intel to Acquire Codeplay Software" height="168" src="/img/darshit_image/codeplay-splash-newsroom-rwd.jpg" style="float:left" width="299"></p>
                        <p>Intel is further advancing its support of the oneAPI ecosystem through an agreement to acquire Codeplay Software, a global leader in cross-architecture, open, standards-based developer technologies.&nbsp;</p>
                        <p class="mb-0">Codeplay is globally recognized for its expertise and leadership in SYCL, the Khronos Group’s open-standard programming model used in oneAPI, and its significant contributions to the industry ranging from open-ecosystem activities like SYCL and OpenCL™ to RISC-V, automotive software safety, and medical imaging.&nbsp;</p>
                        <p>Codeplay has extensively delivered products supporting diverse hardware platforms globally, embracing the mission of bringing oneAPI to the masses.</p>

                        <p class="">&nbsp;</p>
                            <div class="d-flex">
                                <div class="">
                                    <i class="fa-solid fa-quote-left" style="font-size: 65px; color: #E5E6E6; padding-right: 15px;"></i>
                                </div>
                                <div class="">
                                    <div class="mv_together_content">
                                        <p class="mb-2" style="font-weight: 300;"><i>Bolstered by the strength of Intel, Codeplay will be able to extend the delivery of SYCL solutions into cross-architecture and multi-vendor products, based on open standards and the open source ecosystems upon which they are built.</i></p>
                                        <p>Joe Curley - VP & GM - Intel Software Products & Ecosystem</p>
                                    </div>
                                </div>
                            </div>
                            <p class="mb-0">&nbsp;</p>
                            <p class="mb-0">&nbsp;</p>
                            <p><a style="padding: 5px 20px;" class="dk_button" href="">Explore the details &gt;</a></p>
                            <p class="">&nbsp;</p>
                    

                        <h3 style="font-weight: 300;"><a id="" name="ISC2022"></a>Intel at ISC 2022 Focuses on Sustainable, Open HPC-AI</h3>
                        <p>May 31, 2022 | <a href="" style="color:blue; text-decoration:underline !important">Intel @ ISC 2022</a></p>  
                        <p><img alt="" src="/img/darshit_image/isc-high-performance-logo-rwd.png" style="float:left"></p>
                        <p class="mb-0">At International SuperComputing 2022, Jeff McVeigh, VP of Super Compute Group, highlighted Intel’s HPC leadership technologies that are being used to accelerate innovation for a more sustainable and open HPC-AI, including how:</p>
                        <ul>
                            <li>Intel software and oneAPI extend across the software stack to provide tools, platforms and software IP to help developers produce scalable, better-performing, more efficient code that take advantage of the latest silicon innovations without the burden of refactoring code.</li>
                            <li>Two new Intel oneAPI Centers of Excellence join the ecosystem, bringing the total to 22 universities and labs working across the globe to increase oneAPI capabilities and adoption.</li>
                        </ul>
                        <p><a style="padding: 5px 20px;" class="dk_button" href="">Read and watch Jeff’s editorial &gt;</a></p>

                        <h4 style="font-weight: 400;">Introducing the New Intel oneAPI Centers of Excellence</h4>
                        <ul>
                            <li><a class="b_special_a1" href="">University of Bristol</a> is developing best practices for achieving performance portability at exascale using oneAPI and the Khronos Group* SYCL abstraction layer for cross-platform programming. The goal: ensure scientific codes can achieve high performance on massive heterogeneous supercomputing systems.</li>
                            <li><a class="b_special_a1" href="">Centre for Development of Advanced Computing</a> (CDAC) is building a base of skilled instructors who deliver oneAPI training to India HPC and AI communities. CDAC will scale training broadly in the country through its infrastructure and teach oneAPI in top universities.</li>
                        </ul>

                        <h4>More to Discover</h4>
                        <ul>
                            <li><a class="b_special_a1" href="">oneAPI Centers of Excellence</a></li>
                            <li><a class="b_special_a1" href="">Intel® Student Ambassador Program for oneAPI</a></li>
                        </ul>
                        <p class="">&nbsp;</p>


                        <h3 style="font-weight: 300;"><a id="" name="heidelberg-and-oneMKL"></a>Heidelberg University Drives Heterogeneous Computing with oneMKL Open-source Interfaces</h3>
                        <p>May 25, 2022 |&nbsp; <a href="" style="color:blue; text-decoration:underline !important">Intel® oneAPI Math Kernel Library</a>, <a href="" style="color:blue; text-decoration:underline !important">oneAPI Specification</a></p>
                        <p><a class="b_special_a1" href="">Heidelberg U</a> has recently enabled ROCm support for random number generation and BLAS in Intel® oneAPI Math Kernel Library (oneMKL) interfaces. This is a new and significant community contribution to the oneMKL interfaces project, part of the oneAPI industry initiative that provides SYCL-based APIs for math algorithms focused on CPUs and compute-accelerator architectures.</p>
                        <p>This work—adding into the project support for rocRAND and rocBLAS—now makes it possible to generate random numbers and perform linear algebra computations using the hipSYCL compiler to achieve near-native performance in cross-platform applications written in hipSYCL. Additionally, it makes oneMKL open-source interfaces the first oneAPI component with upstream support for other SYCL implementations apart from DPC++.</p>
                        <p><a style="padding: 5px 20px;" class="dk_button" href="">Read all the details &gt;</a></p>
                        <p class="mb-0"><strong>Additional resources</strong></p>
                        <ul>
                            <li>Learn more of <a class="b_special_a1" href="">oneAPI specification hipSYCL work at Heidelberg University</a></li>
                            <li>Learn about <a class="b_special_a1" href="">Heidelberg University’s engineering vision with the oneAPI project</a></li>
                            <li>Understand more about other <a class="b_special_a1" href="">key contributors to the oneAPI CoE ecosystem</a></li>
                            <li>Learn more about the oneAPI initiative at <a class="b_special_a1" href="">oneapi.io</a>.&nbsp;&nbsp;&nbsp;</li>
                            <li>Start <a class="b_special_a1" href="">developing with the oneMKL open-source interfaces</a></li>
                        </ul>

                        <p class="">&nbsp;</p>
                        <h3 style="font-weight: 300;"><a id="" name="onednn-tensorflow2.9"></a>oneDNN AI Optimizations Turned Enabled by Default in TensorFlow 2</h3>
                        <p>May 25, 2022 |&nbsp; <a href="" style="color:blue; text-decoration:underline !important">Intel® oneAPI Deep Neural Network Library</a></p>
                        <p>In the latest release of <a class="b_special_a1" href="">TensorFlow 2.9</a>, performance improvements are delivered by Intel® oneAPI Deep Neural Network Library (oneDNN) enabled by Google as the default backend CPU optimization for x86 packages. This applies to all Linux x86 packages and for CPUs with neural-network-focused hardware features like AVX512_VNNI, AVX512_BF16, and AMX vector and matrix extensions found on 2nd gen Intel® Xeon® Scalable processors and newer CPUs.</p>
                        <p>These optimizations accelerate key performance-intensive operations such as convolution, matrix multiplication, and batch normalization, with up to <a class="b_special_a1" href="">3 times</a> performance improvements compared to versions without oneDNN acceleration.</p>
                        <p><strong>Why It’s Important</strong></p>
                        <p>While there is an emphasis today on AI accelerators like GPUs for machine learning and deep learning, CPUs remain a primary player in all stages of the AI workflow—ubiquitous across most personal devices, workstations, and data centers. These default optimizations will help enable millions of developers who already use TensorFlow to achieve productivity gains, faster time to train, and efficient utilization of compute.</p>
                        <p>Performance gains will benefit applications spanning natural language processing, image and object recognition, autonomous vehicles, fraud detection, medical diagnosis and treatment, and more.</p>
                        <p><a style="padding: 5px 20px;" class="dk_button" href="">Learn more &gt;</a></p>
                        <p class="mb-0"><strong>Get the Software</strong></p>
                        <ul>
                            <li>Download oneDNN <a class="b_special_a1" href="">standalone</a> or as part of the <a class="b_special_a1" href="">Intel® oneAPI Base Toolkit</a>.</li>
                            <li>Download <a class="b_special_a1" href="">Intel® Optimization for TensorFlow</a> standalone or as part of the <a class="b_special_a1" href="">Intel® oneAPI AI Analytics Toolkit</a>.</li>
                        </ul>
                        <p class="mb-0"><strong>More Resources</strong></p>
                        <ul>
                            <li>Discover<a href="/content/www/us/en/developer/topic-technology/artificial-intelligence/overview.html"> Intel AI Software Tools</a></li>
                            <li>Read the <a href="http://blog.tensorflow.org/2022/05/whats-new-in-tensorflow-29.html?linkId=8066981">TensorFlow 2.9 Release blog</a></li>
                        </ul>
                        <p class="">&nbsp;</p>


                        <h3 style="font-weight: 300;"><a id="" name="syclomatic"></a>Intel Open Sources SYCLomatic Migration Tool to Help Developers Create Heterogeneous Code</h3>
                        <p>May 15, 2022 | <a href="" style="color:blue; text-decoration:underline !important">Data Parallel C++/SYCL</a></p>

                        <p><img alt="" class="floatLeft" height="186" src="/img/darshit_image/sycl-codesnippet.jpg" style="float:left" width="330">Intel recently released an open-source tool to migrate code to SYCL through a project called <a href="https://github.com/oneapi-src/SYCLomatic">SYCLomatic</a>; it helps developers more easily port CUDA code to SYCL and C++ to accelerate cross-architecture programming for heterogeneous architectures. This open-source project enables community collaboration to advance adoption of the SYCL standard, a key step in freeing developers from a single-vendor proprietary ecosystem.</p>
                        <p><strong>How the SYCLomatic Tool Works</strong></p>
                        <p>SYCLomatic assists developers in porting CUDA code to SYCL, typically migrating 90-95% of CUDA code automatically to SYCL code. To finish the process, developers complete the rest of the coding manually and then custom tune to the desired level of performance.</p>
                        <p>According to James Reinders, Intel oneAPI evangelist, “<em>Migrating to C++ with SYCL gives code stronger ISO C++ alignment, multivendor support to relieve vendor lock-in, and support for multiarchitecture to provide flexibility in harnessing the full power of new hardware innovations. SYCLomatic offers a valuable tool to automate much of the work, allowing developers to focus more on custom tuning than porting.”</em></p>

                        <div class="mb-3">
                            <img class="w-100" src="/img/darshit_image/syclomatic-tool.png" alt="">
                        </div>

                        <p>SYCLomatic is a GitHub project. Developers are encouraged to use the tool and provide feedback and contributions to advance the tool’s evolution.</p>
                        <p><a style="padding: 5px 20px;" class="dk_button" href="">Learn more &gt;</a></p>
                        <p class="">&nbsp;</p>

                        <h3 style="font-weight: 300;"><a id="" name="oneapi-2022.2"></a>Now Available: Intel® oneAPI Toolkits 2022.2</h3>
                        <p>May 18, 2022 | <a href="" style="color:blue; text-decoration:underline !important">oneAPI</a>, <a href="" style="color:blue; text-decoration:underline !important">Intel® oneAPI Toolkits</a></p>
                        <p>The latest <a class="b_special_a1" href="">Intel® oneAPI Tools</a> are now available for direct download and/or use in the <a class="b_special_a1" href="">Intel® DevCloud</a>. This release includes updates to all Toolkits (including 30+ individual tools)—each optimized to deliver improved performance and expanded capabilities for data-centric workloads.</p>
                        <p><strong>2022.2 highlights:</strong></p>
                        <p class="mb-0">Intel® Arc™ (Discrete) GPUs for Media, Gaming, and AI workloads</p>
                        <ul>
                            <li>Use cross-architecture <a class="b_special_a1" href="">Intel® oneAPI software tools</a> to create immersive end-user experiences across technologies, platform capabilities, software, and AI-accelerated processing on the GPU combined with the CPU.</li>
                            <li>Delivers up to 50x performance improvement over video-software encode with the industry’s first hardware-accelerated AV1 codec, enabled by <a class="b_special_a1" href="">Intel® oneAPI Video Processing Library</a> (oneVPL). [Benchmark reference below]</li>
                            <li>Includes deep learning support via the oneAPI-powered <a class="b_special_a1" href="">Intel® Distribution of OpenVINO™ toolkit</a> and <a class="b_special_a1" href="">Intel® oneAPI Deep Neural Networks Library</a> (oneDNN) as well as performance-tuning insights with <a class="b_special_a1" href="">Intel® VTune™ Profiler</a>.</li>
                        </ul>
                        <p class="mb-0">Compilers</p>
                        <ul>
                            <li><a class="b_special_a1" href="">Intel® oneAPI DPC++/C++ Compiler</a> adds more SYCL* 2020 features to improve developer productivity for programming various hardware accelerators such as GPUs and FPGAs, enhances OpenMP* 5.1 compliance, and improves performance of OpenMP reductions for compute offload.</li>
                            <li><a class="b_special_a1" href="">Intel® Fortran Compiler</a>, based on modern LLVM technology, adds support for parameterized-derived types, F2018 IEEE Compare, and VAX structures support, and expands support for OpenMP 5.0 with Declare Mapper for scalars support.</li>
                        </ul>
                        <p class="mb-0">High-Performance Libraries</p>
                        <ul>
                            <li><a class="b_special_a1" href="">oneMKL</a> adds MKL_VERBOSE GPU support for the BLAS Domain and CPU support for the transpose domain for improved visibility during debugging.</li>
                            <li><a class="b_special_a1" href="">oneCCL</a> now supports Intel® Instrumentation and Tracing Technology profiling, opening new insights with tools such as VTune Profiler.</li>
                            <li><a class="b_special_a1" href="">oneTBB</a> improves support and use of the latest C++ standard for parallel_sort, plus adds fully functional features for task_arena extension, collaborative_all_once, adaptive mutexes, heterogeneous overloads for concurrent_hash_map, and task_scheduler_handle.</li>
                            <li>oneVPL supports multiple hardware adapters and expanded development environments, plus MPEG2 decode in a CPU implementation to improve codec coverage for systems that do not have dedicated hardware.</li>
                            <li><a class="b_special_a1" href="">Intel® MPI Library</a> enables better resource planning and control at an application level with GPU pinning, plus adds multi-rail support to improve application internode communication bandwidth.</li>
                        </ul>
                        <p class="mb-0">Analysis Tools</p>
                        <ul>
                            <li><a class="b_special_a1" href="">Intel® Advisor</a> adds user recommendations and sharing, including optimizing data-transfer reuse costs of CPU-to-GPU offloading, details of GPU Roofline kernels and Offload Modeling, and seeing offloaded parts of the code at source level (including performance metrics) in a GPU Roofline perspective.</li>
                            <li>Intel® VTune™ Profiler opens the ability to identify performance inefficiencies related to Intel® VT-d for latest-generation server platforms, supports Intel Arc GPUs, and is available as a Docker container.</li>
                        </ul>
                        <p class="mb-0">AI Workload Acceleration</p>
                        <ul>
                            <li><a class="b_special_a1" href="">Intel® Extension for TensorFlow*</a> adds faster model loading, improvements in efficient element-wise Eigen operations, and support for additional fusions such as matmul biasadd-g.</li>
                            <li>Additional functionality and productivity for <a class="b_special_a1" href="">Intel® Extension for Scikit-learn*</a> and <a class="b_special_a1" href="">Intel® Distribution of Modin*</a> through new features, algorithms and performance improvements such as Minkowski and Chebyshev distances in kNN and acceleration of the t-SNE algorithm.</li>
                            <li>Acceleration for AI deployments with quantization and accuracy controls in the <a class="b_special_a1" href="">Intel® Neural Compressor</a>, making great use of low-precision inferencing across supported Deep Learning Frameworks.&nbsp;</li>
                            <li>Support of new PyTorch model inference and training workloads via <a class="b_special_a1" href="">Model Zoo for Intel® Architecture</a>, extending support to include Python 3.9, TensorFlow v2.8.0, PyTorch v1.10.0, and IPEX v1.10.0.</li>
                        </ul>
                        <p class="mb-0">Scientific Visualization with Rendering &amp; Ray Tracing</p>
                        <ul>
                            <li><a class="b_special_a1" href="">Intel® Open Volume Kernel Library</a> adds support for IndexToObject affine transform and constant cell data for Structured Volumes.</li>
                            <li><a class="b_special_a1" href="">Intel® OSPRay</a> and <a class="b_special_a1" href="">Intel® OSPRay Studio</a> now include support for Multi-segment Deformation Motion Blur for mesh geometry, plus new light features and optimizations.</li>
                            <li><a class="b_special_a1" href="">Intel® Implicit SPMD Program Compiler Run Time</a> (ISPCRT) library is included in the package.</li>
                        </ul>
                        <p class="mb-0">FPGAs</p>
                        <ul>
                            <li><a class="b_special_a1" href="">Intel® FPGA Add-On for oneAPI Base Toolkit</a> enables users to specify an exact, min, or max latency between read and write access on memories and pipes and provides the ability to implement arithmetic floating point operations involving a constant with either DSPs and ALMs or only ALMs.</li>
                        </ul>
                        <p><a style="padding: 5px 20px;" class="dk_button" href="">Get the details &gt;</a></p>

                        <div class="">
                            <img class="w-100" src="/img/darshit_image/onevplbench-av1-intel-arc-6may22-rwd.png" alt="">
                        </div>
                        <p>&nbsp;</p>

                        <h3 style="font-weight: 300;"><a id="" name="gromacs-oneapi"></a>GROMACS &amp; oneAPI Aid in Open Source Drug Discovery</h3>
                        <p>May 5, 2022 | <a href="" style="color:blue; text-decoration:underline !important">oneAPI Spec</a>, <a href="" style="color:blue; text-decoration:underline !important">Intel® oneAPI Tools</a></p>
                        <p><img alt="" height="186" src="/img/darshit_image/gromacs-oneapi-drug-discovery-rwd.png" style="float:left" width="330"></p>
                        <p><strong>GROMACS, accelerated by SYCL, oneAPI, and multiarchitecture tools, has strong performance on GPUs based on Intel Xe Architecture</strong></p>
                        <p>The recent <a class="b_special_a1" href="">GROMACS</a> 2022 release was extended to multi-vendor architectures, including current and upcoming GPUs based on Intel Xe Architecture. &nbsp;</p>
                        <p>The team, led by Erik Lindahl from Stockholm University &amp; Royal Institute of Technology, ported GROMACS’ CUDA code, which only runs on Nvidia hardware, to SYCL using the <a class="b_special_a1" href="">Intel® DPC++ Compatibility Tool</a>; the tool typically automates 90%-95% of the code<sup>1,2</sup>. The result: A single, portable, cross-architecture-ready code base that significantly streamlines development and provides flexibility for deployment in multiarchitecture environments.</p>
                        <p>The software’s accelerated compute was made possible by using Intel oneAPI cross-architecture tools—oneAPI DPC++/C++ Compiler, oneAPI libraries, and HPC analysis and cluster tools.</p>

                        <p class="">&nbsp;</p>
                            <div class="d-flex">
                                <div class="">
                                    <i class="fa-solid fa-quote-left" style="font-size: 65px; color: #E5E6E6; padding-right: 15px;"></i>
                                </div>
                                <div class="">
                                    <div class="mv_together_content">
                                        <p class="mb-2" style="font-weight: 300;"><i>With GROMACS 2022’s full support of SYCL and oneAPI, we extended GROMACS to run on new classes of hardware. We’re already running production simulations on current Intel Xe architecture-based GPUs as well as the upcoming Intel Xe architecture-based GPU development platform Ponte Vecchio via the Intel® DevCloud. Performance results at this stage are impressive – a testament to the power of Intel hardware and software working together. Overall, these optimizations enable diversity in hardware, provide high-end performance, and drive competition and innovation so that we can do science faster, and lower costs downstream.</i></p>
                                        <p>— Erik Lindahl</p>
                                    </div>
                                </div>
                            </div>
                            <p class="mb-0">&nbsp;</p>
                            <p class="mb-0">&nbsp;</p>
                            <p><a style="padding: 5px 20px;" class="dk_button" href="">Read the whole story &gt;</a>&nbsp;<a style="padding: 5px 20px;" class="dk_button" href="">Watch the video &gt;</a></p>
                            <p><strong>About GROMACS</strong></p>
                            <p>GROMACS is a molecular dynamics package designed for simulations of protein, lipids, and nucleic acids. Its simulations contribute to the identification of crucial pharmaceutical solutions for conditions such as breast cancer, COVID-19, and Type 2 diabetes, and the international distributed-computing initiative <a class="b_special_a1" href="">Folding@home</a>.</p>
                            <p style="color: #bbb;"><sup>1</sup>The team ported GROMACS’ Nvidia CUDA code to&nbsp; Data Parallel C++ (DPC++), which is a SYCL implementation for oneAPI, in order to create new cross-architecture-ready code.&nbsp;</p>
                            <p style="color: #bbb;"><sup>1</sup>The team ported GROMACS’ Nvidia CUDA code to&nbsp; Data Parallel C++ (DPC++), which is a SYCL implementation for oneAPI, in order to create new cross-architecture-ready code.&nbsp;</p>
                            <p>&nbsp;</p>

                            <h3 style="font-weight: 300;"><a id="" name="develop-for-alchemist"></a>Cross-architecture Dev Tools Deliver Incredible End-User Experiences on New GPU Systems</h3>
                            <p>March 31, 2022 |&nbsp;<a class="b_special_a1" href="">Intel® Software Tools</a>, <a class="b_special_a1" href="">Intel® Graphics Performance Analyzers</a>, <a class="b_special_a1" href="">Intel® oneAPI Video Processing Library</a></p>

                            <p><img alt="" height="180" src="/img/darshit_image/intel-arc-wallpaper.jpg" style="float:left" width="320"></p>
                            <p>If you’re a content creator or game developer, new <a class="b_special_a1" href="">Intel® Evo™</a>&nbsp;laptops equipped with <strong>Intel Arc A-Series GPUs</strong> empower you to create immersive end-user experiences with innovation across technologies, software, and AI-accelerated processing.</p>
                            <p>And <a class="b_special_a1" href="">Intel® software tools</a> are a big part of helping developers liberate Intel Arc graphics capabilities and optimize applications for maximum visual performance on the GPU combined with Intel CPUs. Using them, you can:<br> &nbsp;</p>

                            <ul> 
                                <li><strong>Analyze and optimize graphics bottlenecks</strong>. Use <a class="b_special_a1" href="">Intel® Graphics Performance Analyzers</a> to profile graphics and game applications and ramp up profiling abilities with ray tracing, system-level profiling, and <a class="b_special_a1" href="">X<sup>e&nbsp;</sup>Super Sampling (XeSS) capabilities</a>. Capture streams and traces, optimize shaders, and identify the most expensive events with support for multiple APIs (DX, Vulkan, OpenGL, OpenCL, etc.). <a class="b_special_a1" href="">Download</a></li> 
                                <li><strong>Accelerate compute-intensive tasks</strong>. Identify the most time-consuming parts of CPU and GPU code. Visualize thread behaviors to quickly find and fix concurrency problems using <a class="b_special_a1" href="">Intel® VTune™ Profiler</a>. <a class="b_special_a1" href="">Download</a></li> 
                                <li><strong>Speed up media processing and cloud game streaming</strong>. <a class="b_special_a1" href="">Intel® oneAPI Video Processing Library</a> (oneVPL) enables hardware AV1 encode and decode support, and <a class="b_special_a1" href="">Intel® Deep Link</a> via Hyper Encode APIs, delivering up to <strong>1.4x faster</strong><sup>1</sup> single stream transcoding when taking advantage of multiple Intel accelerators in a platform. For content creators already using Handbrake and DaVinci Resolve, oneVPL is integrated into the latest versions. <a class="b_special_a1" href="">Download</a></li> 
                                <li><strong>Integrate AI and machine learning</strong>. For game developers, the <a class="b_special_a1" href="">Intel® Game Dev AI Toolkit</a> delivers a spectrum of AI-powered capabilities, from immersive world creation to real-time game-object-style transfer visualizations. <a class="b_special_a1" href="">Download</a></li> 
                            </ul>
                            <p><a style="padding: 5px 20px;" class="dk_button" href="">Learn more &gt;</a></p>
                            <p style="color: #bbb;">1. Up to 40% higher FPS in video encoding through an internal release of HandBrake on integrated Intel Xe graphics + discrete Intel Arc graphics compared to using Intel Arc graphics alone. Handbrake running on Alchemist pre-production silicon. As of October 2021.</p>
                            <p>&nbsp;</p>

                            <h3 style="font-weight: 300;"><a id="" name="soda-coe-for-scikit-learn"></a>Soda Announces Intel oneAPI Center of Excellence to Support Scikit-learn Performance across Architectures</h3>
                            <p>March 31, 2022 |&nbsp;<a class="b_special_a1" href="">Intel® Extension for SciKit-learn*</a></p>
                            <p>The <a class="b_special_a1" href="">Social Data research team</a> (Soda) at&nbsp;<a class="b_special_a1" href="">Inria</a>, France’s national research institute for digital science and technology, is establishing an <strong>Intel oneAPI Center of Excellence</strong> to focus on developing hardware-optimized performance boosters for scikit-learn, one of the most widely used machine learning libraries.</p>
                            <p>This scikit-learn extension will deliver more efficient machine learning by using oneAPI <a class="b_special_a1" href="">numba_dppy</a> or DPC++ components. Additionally, the implementation will be packaged in an independently-managed project possibly maintained by scikit-learn core developers, Intel engineers, and other interested community members.</p>
                            
                        <p class="">&nbsp;</p>
                        <div class="d-flex">
                            <div class="">
                                <i class="fa-solid fa-quote-left" style="font-size: 65px; color: #E5E6E6; padding-right: 15px;"></i>
                            </div>
                            <div class="">
                                <div class="mv_together_content">
                                    <p class="mb-2" style="font-weight: 300;"><i>Heterogenous computing is inevitable. It happens when a host schedules computational tasks to different processors and accelerators like CPUs and GPUs. This partnership will make scikit-learn more performant and energy-efficient on multi-architecture systems.</i></p>
                                    <p>Olivier Grisel, scikit-learn maintainer, Inria</p>
                                </div>
                            </div>
                        </div>
                        <p class="mb-0">&nbsp;</p>
                        <p class="mb-0">&nbsp;</p>
                        <p><a style="padding: 5px 20px;" class="dk_button" href="http://team.inria.fr/soda/soda-intel-partnership/">Learn more&nbsp;&gt;</a></p>
                        <p><strong>About Soda</strong><br>
                            The Social Data research team specializes in computational and statistical research in data science and machine learning—including scikit-learn optimizations—to harness large databases focused on health and social sciences.</p>
                            <hr>
                            <p class="mb-0">&nbsp;</p>
                            <p class="mb-0">&nbsp;</p>


                        <h3 style="font-weight: 300;"><a id="" name="compilers-available-in-vs"></a>Intel Compilers Available in VS Marketplace</h3>
                        <p>March 10, 2022 |&nbsp;<a class="b_special_a1" href="">Intel® oneAPI DPC++/C++ Compiler</a></p>
                        <p>Now there are more ways to download multi-parallelism-supporting compilers. LLVM-based DPC++/C++/C compilers for Windows* can now be downloaded from the Visual Studio Marketplace.</p>
                        <p class="mb-0">Feature Highlights:</p>
                        <ul>
                            <li>Include extensions that support productive development of fast, multicore, vectorized, and cluster-based applications.</li>
                            <li>Support the latest C/C++ language and OpenMP* standards.</li>
                            <li>Support multiple parallelism models and high-performance libraries including oneTBB, oneMKL, oneVPL, and Intel® IPP.</li>
                            <li>Can be used to build mixed-language applications with C++, Visual Basic, C#, and more.</li>
                        </ul>
                        <p><a style="padding: 5px 20px;" class="dk_button" href="">Learn more and get the free download&nbsp;&gt;</a><br>
                            &nbsp;</p>
                            <hr>
                            <p class="mb-0">&nbsp;</p>
                            <p class="">&nbsp;</p>

                        <h3 style="font-weight: 300;"><a id="" name=""></a>Intel Investing in Growth Opportunities Enabled by Software</h3> 
                        <p>February 22, 2022 |&nbsp;<a class="b_special_a1" href="">Intel® oneAPI Tools</a></p>  
                        
                        <p class="mb-0">&nbsp;</p>
                        <p class="mb-0">&nbsp;</p>
                        <div class="mb-2">
                            <img class="w-100" src="/img/darshit_image/sotware-value-realization.jpg" alt="">
                        </div>

                        <p>At Intel’s 2022 Investor Meeting, product updates included next-generation Intel® Xeon® and client CPUs and Ponte Vecchio/Arctic Sound-M GPUs that will accelerate data center, AI, and other segment workloads, along with the software to make this all happen.</p>
                        <p>Intel’s Software-First strategy was noted in <a class="b_special_a1" href="">Executive Breakout sessions</a>.<br>
                            &nbsp;</p>

                            <ul>
                                <li><strong>Greg Lavender</strong>, Sr. Vice President, CTO, and GM of Intel Software and Advanced Technology Group, discussed in <a class="b_special_a1" href="">an editorial</a> and <a class="b_special_a1" href="">presentation</a> how open, standards-based, cross-architecture programming through <a class="b_special_a1" href="">oneAPI</a> and <a class="b_special_a1" href="">Intel® oneAPI Toolkits</a> delivers performance and development productivity across &nbsp;advanced architectures.</li>
                                <li><strong>Raja Koduri</strong>, Sr. Vice President and GM of Intel Accelerated Computing Systems &amp; Graphics Group, outlined the combined power of hardware and software fronting Intel’s Media and HPC-AI Super Compute Strategies. Highlights:
                                <ul>
                                    <li>Intel® Xeon® processors and an open ecosystem, including <a class="b_special_a1" href="">oneAPI Video Processing Library</a>, <a class="b_special_a1" href="">Intel® oneAPI AI Analytics Library</a>, and OpenVINO™ toolkit, deliver high-density, real-time broadcast and premium content to meet global demands where 80% of Internet traffic is video.<sup>1</sup></li>
                                    <li>Upcoming Artic Sound-M GPU will deliver a seamless media supercomputer with leadership transcode performance that addresses quality, latency, and density requirements for desktop and cloud gaming, with an AI analytics engine. It will be the industry’s only open-source media solution stack for streaming, gaming, and analytics, and the industry’s first GPU with AV1 encode that delivers over 30% bandwidth improvement at the same quality.<sup>2</sup></li>
                                    <li>Billions of lines are code are optimized for Xeon, which powers 85% of super computers.<sup>3</sup> This sets a strong, seamless ecosystem foundation for the fierce combo of Intel Xeon&nbsp;Sapphire Rapids + Ponte Vecchio GPU, where oneAPI unleashes developers to utilize a range of CPUs and accelerators using a single codebase.</li>
                                </ul>
                                </li>
                            </ul>    

                            <p><strong>Learn more</strong><br></p>
                                <ul>
                                    <li><a class="b_special_a1" href="">Intel Technology Roadmaps &amp; Milestones</a>&nbsp;</li>
                                    <li><a class="b_special_a1" href="">Intel’s Software Advantage, Decoded</a></li>
                                    <li><a class="b_special_a1" href="">Software at Intel: Open &amp; Designed with Security in Mind</a></li>
                                    <li>Raja Koduri’s <a class="b_special_a1" href="">Accelerated Computing &amp; Graphics presentation</a></li>
                                    <li><a class="b_special_a1" href="">oneAPI</a> | <a class="b_special_a1" href="">Intel® oneAPI Toolkits</a></li>
                                </ul>
                                <p style="color: #bbb;"><sup>1</sup>Source Cisco Global 2021 Forecast Highlights<br>
                                    <sup>2</sup>Source: Mhojhos Research<br>
                                    <sup>3</sup>Based on TOP500 list over the past decade<br>
                                    &nbsp;</p>
                                    <hr>
                                    <p class="">&nbsp;</p>
                                    <p class="">&nbsp;</p>

                        

                        <h3 style="font-weight: 300;"><a id="" name="darmstadt-university-excellence-center"></a>Technical University of Darmstadt Establishes Intel oneAPI Center of Excellence</h3>
                        <p>February 14, 2022 |&nbsp;<a class="b_special_a1" href="">Intel® oneAPI Tools</a></p>
                        <p>The Technical University of Darmstadt (TU Darmstadt) Embedded Systems and Applications Group announces establishing an Intel oneAPI Center of Excellence (CoE). The center’s objective is to accelerate data parallel computing and simulation software used in medical and pharmaceutical research powered by <a class="b_special_a1" href="">oneAPI</a> open cross-architecture programming.</p>
                        <p>Together with Intel, the university will port an accelerated version of the <a class="b_special_a1" href="">Autodock</a> application to create a single code base that can be efficiently optimized and tuned for multiple hardware architecture targets.&nbsp;</p>
                        <p>Additionally, TU Darmstadt is working on a next-gen parallel implementation of <a class="b_special_a1" href="">Autodock-GPU</a>, which aims to speed up drug-discovery simulations by parallel execution across CPUs, GPUs, and FPGAs.</p>
                        <p>“The new oneAPI Center of Excellence is an exciting step forward for the multiarchitecture SYCL language and oneAPI,” says Joe Curley, vice president and general manager of Intel Software Products and Ecosystem division. “This collaboration with TU-Darmstadt team provides a path for medical and pharmaceutical researchers to use AutoDOCK-GPU productively on the hardware of their choice.”<br>
                            &nbsp;</p>

                    </section>

                </div>
            </div>
            <p class="mb-0">&nbsp;</p>
        </div>
    </section>

    <section style="border-top: 1px solid #d7d7d7;" class="container py-5">
        <h4 class="h6">Product and Performance Information</h4>
        <div style="font-size: .75rem;" class="disclaimer"><sup>1</sup> See&nbsp;<a href="" style="color:blue; text-decoration:none !important">intel.com/processorclaims</a>: Intel Xeon 6.&nbsp;&nbsp;Results may vary.</div>
        <div style="font-size: .75rem;" class="disclaimer"><sup>2</sup> See&nbsp;<a href="" style="color:blue; text-decoration:none !important">intel.com/processorclaims</a>: Intel Gaudi 3. Results may vary.</div>
        <div style="font-size: .75rem;" class="disclaimer"><sup>3</sup><a class="b_special_a1" href="" rel=""> Intel® Advanced Matrix Extensions</a> in Xeon processors. See <a class="b_special_a1" href="" rel="">Intel® Xeon® Processors - Server, Data Center, and AI Processors</a> and (9A10)&nbsp;at <a class="b_special_a1" href="" rel="">intel.com/processorclaims</a><a class="b_special_a1" href="" rel="">: Intel® Xeon® 6</a></div>
        <di style="font-size: .75rem;"v class="disclaimer"><sup>4</sup><a class="b_special_a1" href="" rel=""> Intel® Advanced Matrix Extensions</a> in Xeon processors. See <a class="b_special_a1" href="" rel="">Intel® Xeon® Processors - Server, Data Center, and AI Processors</a> and (9A10) at <a class="b_special_a1" href="" rel="">intel.com/processorclaims</a><a class="b_special_a1" href="" rel="">: Intel® Xeon® 6</a></di>
        <div style="font-size: .75rem;" class="disclaimer"><sup>5</sup><a class="b_special_a1" href="" rel=""> Intel Unveils Lunar Lake Architecture</a></div>
        <div style="font-size: .75rem;" class="disclaimer"><sup>6</sup> Performance varies by use, configuration and other factors. Learn more at <a class="b_special_a1" href="">www.Intel.com/PerformanceIndex.</a>
        </div>
        <div style="font-size: .75rem;" class="disclaimer"><sup>7</sup> Performance varies by use, configuration and other factors. Learn more at&nbsp;<a class="b_special_a1" href="" title="">www.Intel.com/PerformanceIndex.</a>
        </div>
    </section>

    <!-- footer -->
    <div id="footer"></div>

    <!-- script header and footer -->
    <script>
        // navbar include  
        fetch('/y_index/y_navbar.html')
            .then(response => response.text())
            .then(data => {
                document.getElementById('navbar').innerHTML = data;
            });
        // footer include 
        fetch('/y_index/y_footer.html')
            .then(response => response.text())
            .then(data => {
                document.getElementById('footer').innerHTML = data;
            });
    </script>

    <!-- nav script -->
    <script>
        document.addEventListener('DOMContentLoaded', function () {
            const nav = document.querySelector('.VK_client_app_navigation');
            const navLinks = document.querySelectorAll('.VK_ai_nav_bar a');
            const sections = document.querySelectorAll('section[id]');
            let navOffset = nav.offsetTop;

            // Add smooth scrolling to all links
            navLinks.forEach(link => {
                link.addEventListener('click', function (e) {
                    e.preventDefault();
                    document.querySelector(this.getAttribute('href')).scrollIntoView({
                        behavior: 'smooth'
                    });
                });
            });

            // Sticky Navigation
            window.addEventListener('scroll', () => {
                if (window.pageYOffset >= navOffset) {
                    nav.classList.add('VK_sticky_nav_bar');
                } else {
                    nav.classList.remove('VK_sticky_nav_bar');
                }
                // Section highlighting
                sections.forEach(section => {
                    const sectionTop = section.offsetTop - nav.clientHeight;
                    const sectionHeight = section.clientHeight;
                    console.log(sectionTop);
                    console.log(sectionHeight);
                    if (window.pageYOffset >= sectionTop && window.pageYOffset <= sectionTop + sectionHeight) {
                        navLinks.forEach(link => {
                            link.classList.remove('active');
                            if (link.getAttribute('href') === `#${section.id}`) {
                                link.classList.add('active');

                                // Ensure the active link is visible in the nav bar
                                const navBar = document.querySelector('.VK_ai_nav_bar');
                                const activeLink = document.querySelector('.VK_ai_nav_bar a.active');
                                const linkRect = activeLink.getBoundingClientRect();
                                const navBarRect = navBar.getBoundingClientRect();

                                if (linkRect.left < navBarRect.left || linkRect.right > navBarRect.right) {
                                    activeLink.scrollIntoView({ inline: 'center', behavior: 'smooth' });
                                }
                            }
                        });
                    }
                });
            });
        });
    </script>

    <!-- copy script -->
    <script>
        document.addEventListener("DOMContentLoaded", () => {
            document.querySelectorAll(".mv_copy_icon").forEach((icon) => {
                icon.addEventListener("click", async function () {
                    try {
                        const toolbar = this.closest(".mv_code_toolbar");
                        const codeBlock = toolbar.querySelector(".code-content");
                        const codeContent = codeBlock.innerText;

                        // Use Clipboard API to copy text
                        await navigator.clipboard.writeText(codeContent);

                        // Hide the copy icon and show the "Copied!" message
                        const message = toolbar.querySelector(".mv_copy_message");
                        this.classList.add("hidden"); // Hide the copy icon
                        message.classList.remove("hidden"); // Show the "Copied!" message

                        // Hide the message and show the icon again after 2 seconds
                        setTimeout(() => {
                            message.classList.add("hidden");
                            this.classList.remove("hidden");
                        }, 2000); // Adjust delay as needed

                    } catch (err) {
                        console.error('Failed to copy text: ', err);
                    }
                });
            });
        });
    </script>

</body>

</html>

