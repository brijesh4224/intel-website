<!DOCTYPE html>
<html lang="en">

<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>Baidu BigSQL: Faster Spark Interactive Queries</title>

    <!-- font family -->
    <link href="https://fonts.cdnfonts.com/css/intel-clear" rel="stylesheet">

    <!-- boootstap file -->
    <link href="https://cdn.jsdelivr.net/npm/bootstrap@5.0.2/dist/css/bootstrap.min.css" rel="stylesheet"
        integrity="sha384-EVSTQN3/azprG1Anm3QDgpJLIm9Nao0Yz1ztcQTwFspd3yD65VohhpuuCOmLASjC" crossorigin="anonymous">

    <!-- all.min file -->
    <link rel="stylesheet" href="/css/all.min.css">

    <!-- costom css file -->
    <link rel="stylesheet" href="/css/d_home.css">

    <!-- https://www.intel.com/content/www/us/en/customer-spotlight/stories/baidu-bigsql-customer-story.html -->

</head>

<body>

    <div id="navbar"></div>

    <!-- Banner section start -->

    <section class="d_numetabanner">
        <div class="d_container">
            <div class="d_heading text-start">
                <h2 class="h3">Baidu BigSQL: Faster Spark Interactive Queries</h2>
                <p>To lower TCO and maintain performance, Baidu deployed Intel® Optane™ persistent memory to optimize
                    its ad hoc query service.</p>
            </div>
        </div>
    </section>

    <!-- Banner section end -->

    <section class="d_summery d_p-40">
        <div class="d_container">
            <div class="row m-0">
                <div class="d-flex justify-content-end pb-3 pb-sm-0">
                    <i class="fa-solid fa-print fs-4 px-2 " style="color:#0068B5"></i>
                    <i class="fa-regular fa-envelope fs-4 px-2" style="color:#0068B5"></i>
                </div>
            </div>
            <div class="row m-0">
                <div class="col-xs-12 col-sm-4 col-lg-3">
                    <div class="d_left">
                        <div class="d_box">
                            <h2>At a glance:</h2>
                            <ul>
                                <li class="pb-1">Baidu’s BigSQL data processing platform is based on Spark SQL and has
                                    many features and performance enhancements that improve on it.</li>
                                <li>To lower TCO while ensuring satisfactory performance, Baidu deployed Intel® Optane™
                                    persistent memory and used it to optimize its ad hoc query service—Tuling. Supported
                                    by Intel Optane PMem, the cluster offloaded more than 30% of the workload from
                                    Tuling1. Additionally, the average query latency reduced by 20%</li>
                            </ul>
                            <div class="d_cta mt-3">
                                <a href="" class="d-block d-sm-inline-block text-center">Download the one-page
                                    summary</a>
                            </div>
                        </div>
                    </div>
                </div>
                <div class="col-xs-12 col-sm-8 col-lg-9">
                    <div class="d_right">
                        <p></p>
                        <p>Over the past few years, the world’s data volume has grown almost exponentially, which means
                            companies, especially tech companies, are facing greater challenges in meeting service time
                            requirements. Apache Spark, a unified analytics engine for large-scale and high-performance
                            data processing, is designed to meet this challenge. One module of Apache Spark—Spark SQL is
                            widely used for working with structured data in large data centers. Baidu’s BigSQL data
                            processing platform is based on Spark SQL and has many features and performance enhancements
                            that improve on it.</p>
                        <div class="row m-0 d_say1" id="">
                            <div class="col-xs-12 col-ms-12 col-sm-12 col-md-12">
                                <div class="d_box h-100">
                                    <div class="d-flex">
                                        <i class="fa-solid fa-quote-left me-3 fs-1" style="color: #E5E6E6;"></i>
                                        <div>
                                            <p>In order for Baidu Big SQL to provide users with high-performance ad hoc
                                                query services, large memory is needed to cache hot data locally on
                                                compute nodes to avoid DFS I/O slowing performance down. With Intel
                                                Optane persistent memory, we managed to ensure outstanding cache
                                                performance, while at the same time greatly improving cluster processing
                                                and achieving significant TCO benefits.”—LI Shiyong, Senior System
                                                Engineer, Baidu</p>
                                        </div>
                                    </div>
                                </div>
                            </div>
                        </div>
                        <p></p>
                        <p>One important enhancement pertains to meeting sub-second performance requirements for
                            interactive queries. This is where Intel and Baidu collaborated to create the Optimized
                            Analytics Package (OAP) for Spark Platform project. OAP is designed to leverage the columnar
                            data format and user-defined indexes built over selected columns, leading to improved data
                            scanning efficiency. It also adopts a fine-grained in-memory data caching strategy to remove
                            I/O bottlenecks in disks and networks, maximizing performance to sub-seconds.</p>
                        <p>As Baidu’s business expands, the scale of hot data grows rapidly. Memory scaling is needed to
                            deliver the same level of performance that users demand. However, the high cost of Dynamic
                            Random-Access Memory (DRAM) adds increasing pressure to the Total Cost of Ownership (TCO).
                            To lower TCO while ensuring satisfactory performance, Baidu and Intel collaborated and
                            introduced <a href="">Intel® Optane™ persistent memory (PMem)</a> as a more cost-efficient
                            solution to replace DRAM.</p>
                        <p>Baidu’s internal testing has demonstrated that Intel Optane PMem improves OAP cache
                            performance and performance-per-dollar output when compared to solutions without PMem,
                            leading to direct business impacts such as the optimization of its ad hoc query service,
                            Tuling, by offloading its workload and reducing average query latency.</p>
                        <p></p>
                        <h2 class="d_head d_fw3">Baidu BigSQL with OAP</h2>
                        <p>One fundamental characteristic of Spark SQL is that it is designed to deliver optimized
                            performance for batch processing. However, some of Baidu’s service queries have totally
                            different characteristics. They are called interactive queries. Usually, they query over a
                            large dataset with specific filtering conditions, serving the dedicated purpose of
                            identifying a relatively small amount of data. Users expect this small amount of queried
                            data to be returned in seconds or even sub-seconds, instead of the usual minutes or hours
                            seen in batch processing, which is usually not possible for the current Spark SQL
                            implementation.</p>
                        <p>To solve this problem, Baidu and Intel collaborated and implemented OAP, which uses index and
                            caching techniques to accelerate interactive query response. By integrating OAP, Baidu
                            BigSQL successfully achieved the desired level of interactive query performance.</p>
                        <p></p>
                        <div class="d_img">
                            <img src="/img/darshan_image/img836.jpg" alt="">
                        </div>
                        <p></p>
                        <p><i>Figure 1. Baidu BigSQL and OAP Integration.</i></p>
                        <p></p>
                        <p>When a query has specific filtering conditions, indexes can be created over the columns with
                            such conditions. By creating and storing a full B+ Tree index side-by-side with the columnar
                            data file, OAP can identify target rows by quickly searching through the B+ Tree index, and
                            skip unnecessary data scans over backend storage such as HDFS. Furthermore, the index file
                            is separated from the original data file. This makes it possible to create or drop indexes
                            without the need to rewrite the original data files.</p>
                        <p></p>
                        <div class="d_img">
                            <img src="/img/darshan_image/img837.jpg" alt="">
                        </div>
                        <p></p>
                        <p><i>Figure 2. OAP Cache & Index Concept.</i></p>
                        <p></p>
                        <p>To further reduce query response time from seconds to sub-seconds, OAP optimizes index and
                            data access with cache. By caching the index and data in memory, index loading and data
                            scanning get orders of magnitude faster, avoiding disk and network I/O overhead when reading
                            from distributed file systems. What’s more, index and data can be configured with separate
                            caches, enabling independent eviction and memory space management for both.</p>
                        <p>Additionally, now that the cache is at the column level, it is possible to cache the columns
                            required for the query exclusively. And based on the Least-Recently-Used (LRU) policy, those
                            least-recently-used data items will be evicted from the cache if maximum capacity is
                            reached, allowing more recent data items to be cached. Guided by this policy, an advanced
                            cache manager is implemented in Baidu BigSQL to proactively populate hot columns, and retire
                            columns no longer required in cache.</p>
                        <p></p>
                        <h2 class="d_head d_fw3">Baidu BigSQL Optimization with Intel Optane Persistent Memory</h2>
                        <p>When the data scale is small, Baidu BigSQL can deliver optimal performance by caching index
                            or data in DRAM. However, as Baidu’s business continues to grow, datasets are rapidly
                            evolving in size. When cache space becomes too small to accommodate large amount of hot
                            data, performance will suffer.</p>
                        <p>The simple solution is to add more DRAM, but there are several disadvantages. First, the
                            price-per-GB is high, putting great pressure on TCO. Second, memory is a precious resource
                            for computation, especially so in Spark’s environment where the total DRAM capacity that can
                            be configured on each node is limited. Third, even though DRAM has higher random-access
                            bandwidth and lower latency, such benefits will be wasted when it is used for caching large
                            data blocks and characterizing sequential access. To find more cost-effective alternatives,
                            Baidu and Intel worked together to integrate Intel Optane PMem.</p>
                        <p>Intel Optane PMem is an innovative technology that delivers a unique and affordable
                            combination of large memory capacity and persistence. It represents a new class of memory
                            and storage technology, explicitly architected for data centers. It offers several key
                            benefits that match the specific requirements of Baidu BigSQL:</p>
                        <ul>
                            <li>High bandwidth for sequential read</li>
                            <li>Large capacity and affordable cost</li>
                        </ul>
                        <p>Intel Optane PMem supports two operating modes. When configured for Memory Mode, the
                            applications perceive a pool of volatile memory no differently than they do on DRAM-only
                            systems; when configured in App Direct Mode, the application can direct how to use available
                            space. Since OAP cache has the specific purpose of indexing and inputting data, App Direct
                            Mode is used to ensure the application has full control of how to use the device. In
                            addition, the cache can be repopulated from backend storage and does not need to be
                            persistent. OAP uses the memkind library to access PMem without persistency and
                            corresponding performance penalties.</p>
                        <p>To use PMem in place of DRAM, Intel extended OAP to allow memory manager plugins, and
                            implemented a PMem-based memory manager to allow the allocation of cache space in PMem.
                            Users can switch between DRAM and PMem, or even mix the two, for instance using DRAM to
                            cache index while using PMem to cache data.</p>
                        <p>Additionally, to fully integrate PMem with Baidu’s specific OS environment, Baidu and Intel
                            carried out further wide-ranging collaborations in areas including hardware, operating
                            system, and libraries.</p>
                        <p>To validate the performance and benefits of Intel Optane PMem in OAP, Baidu conducted several
                            evaluations and internal tests, first with decision support benchmark queries and then with
                            Baidu’s real workload queries. The main objective was to test and understand the
                            cost-efficiency of PMem.</p>
                        <p>In the case of testing with decision support benchmark queries, firstly the dataset size is
                            capped at 1 TB, and DRAM and PMem are configured at the same capacity. Test results show
                            that they are both able to cache all the data, and PMem is only slightly behind DRAM in
                            performance (11.7%), while its cost is a lot lower2. When the dataset reaches 3 TB, and DRAM
                            and PMem are at the same cost, DRAM can no longer cache all the data due to its lower
                            capacity. In comparison, PMem does not only have higher capacity to cache all the data, it
                            shows much better performance—6 times better2. DRAM has poor performance in the second
                            scenario because when data size greatly exceeds cache size, DRAM needs to read data from
                            backend storage frequently which delays the response time. Decision support benchmark query
                            tests show clear evidence that when at the same cost level, Intel Optane PMem can provide
                            larger capacity and higher performance than DRAM.</p>
                        <p></p>
                        <div class="d_img">
                            <img src="/img/darshan_image/img838.jpg" alt="">
                        </div>
                        <p></p>
                        <p><i>Figure 3. DRAM and Intel Optane PMem Comparison Tests Decision.</i></p>
                        <p></p>
                        <p>The next stage of testing is based on the same two scenarios, but with Baidu’s actual
                            workload and a slightly different approach. In the first scenario, both DRAM and PMem are
                            tested to cache 50% of the frequently used columns. Results show that the PMem caching speed
                            is only about 12% lower than DRAM2. And since its cost is disproportionally lower, it is the
                            more cost-efficient solution. In the second scenario (DRAM and PMem at same cost), only PMem
                            has the capacity to cache all the hot data columns and it demonstrates a 22% performance
                            improvement, while avoiding 30% of I/O requests to underlying systems</p>
                        <p>Based on these test results, Baidu concluded that Intel Optane PMem can replace DRAM in
                            BigSQL as a more cost-efficient cache solution. Since then, Baidu deployed PMem in BigSQL,
                            and used it to optimize its ad hoc query service—Tuling. Supported by Intel Optane PMem, the
                            cluster offloaded more than 30% of the workload from Tuling1. Additionally, after deploying
                            PMem, the average query latency reduced by 20%1. The Spark/OAP performance per PMem server
                            instance improved by 50% on Tuling Spark SQL workload, at an additional cost of only 20%</p>
                        <p></p>
                        <h2 class="d_head d_fw3">Outlook</h2>
                        <p>Emerging trends are driving big data technologies to change and evolve. The focus is shifting
                            from providing key functionalities to cloud based solutions, with in-depth optimizations to
                            meet performance targets and reduce cost. In the future, as Baidu’s BigSQL becomes cloud
                            based, Intel Optane PMem will bring to it more significant advantages in terms of
                            performance and TCO.</p>
                        <p>And beyond input data cache acceleration for Spark SQL, with its high capacity and high
                            bandwidth, PMem has an even bigger role to play in Spark-based machine learning and deep
                            learning scenarios which require many computational iterations in order to process very
                            large volumes of data. Furthermore, Spark shuffle can be optimized to access PMem through
                            RDMA and utilize it as shuffle storage, further reducing shuffle latency and improving
                            performance.</p>
                        <p>Going forward, Baidu and Intel will continue working together to optimize Spark. As Intel
                            Optane PMem and <a href="">2nd Generation Intel® Xeon® Scalable Processors</a> become more
                            advanced, Baidu and Intel will be able to leverage them to introduce more acceleration
                            features to Spark, pushing performance and cost-efficiency to the next level.</p>
                        <p><a href="">Download the PDF ›</a></p>
                    </div>
                </div>
            </div>
        </div>
    </section>

    <!-- Related Stories section start -->

    <section class="d_p-40 d_story">
        <div class="d_container">
            <div class="row m-0">
                <div class="col-xs-12 col-sm-9 col-lg-10">
                    <h2 class="d_fw3">Explore Related Stories</h2>
                </div>
                <div class="col-xs-12 col-sm-3 col-lg-2">
                    <div class="d_cta">
                        <a href="/M_Solutions/m_sol_re_Customer_Spotlight.html"
                            class="d-block d-sm-inline-block text-center">Intel Customer Spotlight <i
                                class="fa-solid fa-arrow-right ms-1"></i></a>
                    </div>
                </div>
            </div>
            <div class="row m-0 g-3">
                <div class="col-xs-12 col-ms-6 col-sm-6 col-lg-3">
                    <div class="d_box">
                        <div class="d_img mb-3">
                            <img src="/img/darshan_image/img839.png" alt="">
                        </div>
                        <h3><a href="">Tokopedia Supports Growing Userbase</a></h3>
                    </div>
                </div>
                <div class="col-xs-12 col-ms-6 col-sm-6 col-lg-3">
                    <div class="d_box">
                        <div class="d_img mb-3">
                            <img src="/img/darshan_image/img840.png" alt="">
                        </div>
                        <h3><a href="">PhoenixNAP Brings Scalability to Metadata Search</a></h3>
                    </div>
                </div>
                <div class="col-xs-12 col-ms-6 col-sm-6 col-lg-3">
                    <div class="d_box">
                        <div class="d_img mb-3">
                            <img src="/img/darshan_image/img841.png" alt="">
                        </div>
                        <h3><a href="">Storm Reply Taps EC2 C7i Instances on CPUs for LLM</a></h3>
                    </div>
                </div>
                <div class="col-xs-12 col-ms-6 col-sm-6 col-lg-3">
                    <div class="d_box">
                        <div class="d_img mb-3">
                            <img src="/img/darshan_image/img842.png" alt="">
                        </div>
                        <h3><a href="">Gcore Defends Against DDOS Attacks</a></h3>
                    </div>
                </div>
            </div>
        </div>
    </section>

    <!-- Related Stories section end -->

    <!-- Explore Related Products and Solutions section start -->

    <section class="d_numentapro">
        <div class="d_p-48">
            <div class="d_container">
                <div class="row m-0">
                    <div class="col-xs-12">
                        <h3>Explore Related Products and Solutions</h3>
                    </div>
                </div>
                <div class="d_p-48 pb-0">
                    <div class="row g-3 m-0">
                        <div class="col-xs-12 col-sm-6 col-lg-4">
                            <div class="row">
                                <div class="d_img mb-3">
                                    <img src="/img/darshan_image/img843.avif" alt="">
                                </div>
                                <h3><a href="">Intel® Xeon® Scalable Processors</a></h3>
                                <p>Drive actionable insight, count on hardware-based security, and deploy dynamic
                                    service delivery with Intel® Xeon® Scalable processors.</p>
                                <p><a href="">Learn more</a></p>
                            </div>
                        </div>
                        <div class="col-xs-12 col-sm-6 col-lg-4">
                            <div class="row">
                                <div class="d_img mb-3">
                                    <img src="/img/darshan_image/img844.jpg" alt="">
                                </div>
                                <h3><a href="">Intel® Optane™ Persistent Memory</a></h3>
                                <p>Extract more actionable insights from data – from cloud and databases, to in-memory analytics, and content delivery networks.</p>
                                <p><a href="">Learn more</a></p>
                            </div>
                        </div>
                        <div class="col-xs-12 col-sm-6 col-lg-4">
                            <div class="row">
                                <div class="d_img mb-3">
                                    <img src="/img/darshan_image/img845.jpg" alt="">
                                </div>
                                <h3><a href="">Baidu, an Intel® Partner Alliance CCS Provider</a></h3>
                                <p>Baidu AI Cloud is a leading enterprise in IT and in the internet industry, focused on cloud computing, big data, and AI services, providing stable cloud servers, cloud hosts, cloud storage, CDN, and much more</p>
                                <p><a href="">Partner with Baidu</a></p>
                            </div>
                        </div>
                    </div>
                </div>
            </div>
        </div>
    </section>

    <!-- Explore Related Products and Solutions section End -->

    <!-- linklist section start -->

    <section class="d_linklist">
        <div class="d_p-48">
            <div class="d_container">
                <div class="row m-0">
                    <div class="col-xs-12 col-ms-6 col-sm-4 col-xl-4">
                        <div class="d_box">
                            <h3><b>Customer Stories and Case Studies</b></h3>
                            <p>Explore the latest customer stories, case studies, and news releases highlighting
                                data-centric innovations.</p>
                            <ul>
                                <li><a href="/M_Solutions/m_sol_re_Customer_Spotlight.html">Intel Customer Spotlight</a>
                                </li>
                                <li><a href="">Intel Newsroom</a></li>
                            </ul>
                        </div>
                    </div>
                    <div class="col-xs-12 col-ms-6 col-sm-4 col-xl-4">
                        <div class="d_box">
                            <h3><b>Data Center Workloads</b></h3>
                            <p>Learn how Intel® technologies can help provide the scalability needed for high-demand
                                workloads and applications.</p>
                            <ul class="">
                                <li><a href="/d_partner/d_analytics.html">Advanced Analytics</a></li>
                                <li><a href="/Product/B1_24_AI Overview">Artificial Intelligence (AI)</a></li>
                                <li><a href="/d_partner/d_cloud-computing.html">Cloud Computing</a></li>
                                <li><a href="/d_partner/d_help.html">High Performance Computing (HPC) </a></li>
                            </ul>
                        </div>
                    </div>
                    <div class="col-xs-12 col-ms-6 col-sm-4 col-xl-4">
                        <div class="d_box">
                            <h3><b>Data Center Insights</b></h3>
                            <p>Get the latest information about Intel data center performance, flexibility, and
                                scalability.</p>
                            <ul>
                                <li><a href="/d_partner/d_cloud-community.html">Cloud Service Provider Resources</a>
                                </li>
                                <li><a href="/M_Solutions/m_sol_bs_5G.html">Network Transformation & Communications
                                        Technology</a></li>
                            </ul>
                        </div>
                    </div>
                </div>
            </div>
        </div>
    </section>

    <!-- linklist section end -->

    <div class="d_p3 d_awsdis d_dis" id="resources">
        <div class="d_container">
            <h4>Product and Performance Information</h4>
            <div class="d_list">
                <sub>1</sub>
                <p class="mb-0 ms-1">The production performance data was given on August 16, 2019. For more complete information about these test results, please contact Baidu. Intel does not control or audit third-party data. You should consult other sources to evaluate accuracy.
                </p>
            </div>
            <div class="d_list">
                <sub>2</sub>
                <p class="mb-0 ms-1">The evaluation performance data was given on January 31, 2019. For more complete information about these test results, please contact Baidu. Intel does not control or audit third-party data. You should consult other sources to evaluate accuracy.
                </p>
            </div>
        </div>
    </div>

    <div id="footer"></div>

    <!-- Jquery js file -->
    <script src="/js/jquery-3.7.1.js"></script>

    <!-- Bootstrap js file -->
    <script src="https://cdn.jsdelivr.net/npm/bootstrap@5.0.2/dist/js/bootstrap.bundle.min.js"
        integrity="sha384-MrcW6ZMFYlzcLA8Nl+NtUVF0sA7MsXsP1UyJoMp4YLEuNSfAP+JcXn/tWtIaxVXM"
        crossorigin="anonymous"></script>

    <!-- Fontawesome js file -->
    <!-- <script src="/js/all.min.js"></script> -->

    <!-- custom js file -->
    <script src="/js/darshan.js"></script>

    <script>
        // navbar include  
        fetch('/y_index/y_navbar.html')
            .then(response => response.text())
            .then(data => {
                document.getElementById('navbar').innerHTML = data;
            });
        // footer include 
        fetch('/y_index/y_footer.html')
            .then(response => response.text())
            .then(data => {
                document.getElementById('footer').innerHTML = data;
            });
    </script>

</body>

</html>