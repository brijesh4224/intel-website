<!DOCTYPE html>
<html lang="en">

<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>Q8-Chat LLM: Generative AI on Intel® CPUs</title>
    <link href="https://cdn.jsdelivr.net/npm/bootstrap@5.0.2/dist/css/bootstrap.min.css" rel="stylesheet"
        integrity="sha384-EVSTQN3/azprG1Anm3QDgpJLIm9Nao0Yz1ztcQTwFspd3yD65VohhpuuCOmLASjC" crossorigin="anonymous">

    <link href=" https://fonts.cdnfonts.com/css/intel-clear " rel="stylesheet">
    <link rel="stylesheet" href="../css/owl.carousel.min.css">
    <link rel="stylesheet" href="../css/yatri.css">
    <link rel="stylesheet" href="../css/rushita.css">
    <link rel="stylesheet" href="../css/rushita_automotive.css">

    <link rel="stylesheet" href="../css/owl.theme.default.min.css">
    <style>
        * {
            font-family: 'Intel Clear', sans-serif;
        }

        .dk_new_options_table {
            border: none !important;
            justify-content: center !important;
            text-align: center !important;
        }

        .dk_new_options_table thead tr td {
            margin-left: 0;
            max-width: fit-content;
            white-space: normal;
            overflow: auto;
            background: #fff;
            padding: 1rem;
            text-align: left;
            border-left: .125rem solid #e2e2e2;
            font-weight: 700 !important;
        }

        .dk_new_options_table thead tr:nth-child(even) td {
            background-color: #f7f7f7;
        }

        .mv_intel_amx h2 {
            font-weight: 300;
        }

        .mv_intel_amx {
            font-size: 1.25rem;
        }

        .mv_intel_amx_bg_color {
            background-color: #0068B5;
        }

        .mv_intel_amx_content {
            padding-right: 200px;
        }

        .mv_intel_amx_item {
            align-content: center;
        }

        .mv_intel_amx {
            color: #fff;
            padding: 1rem;
        }

        .mv_intel_amx h3 {
            font-weight: 300;
        }

        .mv_intel_amx p {
            margin-top: 1.5rem;
            margin-bottom: 0rem;
        }

        .mv_intel_amx_image {
            padding: 1rem;
        }

        .mv_intel_amx_image img {
            width: 100%;
            /* height: 199px; */
        }

        .mv_intel_amx_heading_text {
            font-size: 1.2rem;
            line-height: 1.15;
        }

        .VK_sidebar_active_link {
            color: #262626;
            font-weight: 700;
        }

        .VK_sidebar_active_link:hover {
            color: #262626;
        }

        .VK_print_email_font span {
            font-size: 1.375rem;
        }

        .VK_side_bar_postion_stickey {
            position: sticky;
            top: 0px;
            z-index: 3;
            background-color: #fff;
        }

        .VK_side_heading {
            font-size: 26px;
            font-weight: 400;
        }

        .VK_sidebar_dropdown P {
            margin-left: .313rem !important;
            margin-bottom: .313rem !important;
        }

        .VK_sidebar_dropdown details {
            margin-left: .313rem !important;
            margin-bottom: .313rem !important;
        }

        code {
            color: #000 !important;
            background-color: #E6E6E6;
        }

        .k_btn {
            height: 80px;
        }

        .code-simple {
            background-color: #E6E6E6;
        }

        pre {
            white-space: pre-line !important;
        }
    </style>
</head>

<body>
    <div id="navbar"></div>

    <section class="m_ai_tdrop">
        <div>
            <button class="btn dropdown-toggle" type="button" data-bs-toggle="dropdown" aria-expanded="false">
                Developers
            </button>
            <ul class="dropdown-menu">
                <li><a class="dropdown-item m_dropActive"
                        href="../dhruvin_developer-tools/ds_Developer-Zone.html">Overview</a></li>
                <li><a class="dropdown-item m_dropActive"
                        href="../rushita_Solutions/k_solutions_in_Viewall_SDF_Industrial-Automation_Control-flow-Enforcement_Technology.html">Topics
                        & Technologies</a></li>
                <li><a class="dropdown-item m_dropActive"
                        href="../dhruvin_developer-tools/ds_Development-Tools.html">Tools</a></li>
                <li><a class="dropdown-item m_dropActive"
                        href="../rushita_Solutions/k_solutions_in_Viewall_SDF_Industrial-Automation_Hardware-Platforms.html">Hardware
                        Platforms</a></li>
                <li><a class="dropdown-item m_dropActive"
                        href="../dhruvin_developer-tools/ds_Resource-Documentation-Center.html">Resources &
                        Documentation</a></li>
                <li><a class="dropdown-item m_dropActive" href="../dhruvin_developer-tools/ds_Learn.html">Learn</a>
                </li>
                <li><a class="dropdown-item m_dropActive"
                        href="../dhruvin_developer-tools/ds_Communities-and-Events.html">Community & Events</a></li>
                <li><a class="dropdown-item m_dropActive"
                        href="../dhruvin_developer-tools/ds_Developer-Programs.html">Developer Programs</a></li>
                <li><a class="dropdown-item m_dropActive" href="../dhruvin_developer-tools/ds_Get-Help.html">Get
                        Help</a></li>
            </ul>
        </div>


        <div class="m_ai_shlash">/</div>
        <div>
            <button class="btn dropdown-toggle" type="button" data-bs-toggle="dropdown" aria-expanded="false">
                Tools
            </button>
            <ul class="dropdown-menu">
                <li><a class="dropdown-item m_dropActive" href="../Product/B20_developer_catelog.html">Software
                        Catalog</a></li>
                <li><a class="dropdown-item m_dropActive" href="../Product/B17_oneapi.html">oneAPI</a></li>
                <li><a class="dropdown-item m_dropActive"
                        href="../rushita_Solutions/k_solutions_Intel-Tiber™Edge-Platform.html">Intel® Tiber™ Edge
                        Platform</a></li>
                <li><a class="dropdown-item m_dropActive" href="../Product/B10_intel_Quarts.html">FPGA</a></li>
                <li><a class="dropdown-item m_dropActive" href="../VK_developers/VK_technology_sdk.html">Intel®
                        Active Management Technology SDK</a></li>
                <li><a class="dropdown-item m_dropActive" href="../VK_developers/VK_intel_adviser.html">Intel®
                        Advisor</a></li>
                <li><a class="dropdown-item m_dropActive" href="#">Intel® AI Reference Models</a></li>
                <li><a class="dropdown-item m_dropActive"
                        href="../rushita_Solutions/k_solutions_Intel-Collaboration-Suite-for-WebRTC.html">Intel®
                        Collaboration Suite for WebRTC SDK</a>
                </li>
                <li><a class="dropdown-item m_dropActive" href="../Product/B1_19_Intel_AICloud.html">Intel® Tiber™
                        AI Cloud</a></li>
                <li><a class="dropdown-item m_dropActive"
                        href="../rushita_Solutions/k_solutions_Intel-Distribution-for-Python.html">Intel® Distribution
                        for Python*</a></li>
                <li><a class="dropdown-item m_dropActive"
                        href="../rushita_Solutions/k_solutions_Intel-Distribution-for-GDB.html">Intel® Distribution for
                        GDB*</a></li>
                <li><a class="dropdown-item m_dropActive" href="#">Intel® DPC++ Compatibility Tool</a></li>
                <li><a class="dropdown-item m_dropActive" href="#">Intel® Dynamic Application Loader</a></li>
                <li><a class="dropdown-item m_dropActive"
                        href="../rushita_Solutions/k_solutions_Topics_viewall_Cloud-Insider-Program_AI-Frameworks-and-Tools.html">Frameworks</a>
                </li>
                <li><a class="dropdown-item m_dropActive" href="#">Intel® Embree</a></li>
                <li><a class="dropdown-item m_dropActive" href="../VK_developers/VK_ai_scikit.html">Intel® Extension
                        for Scikit-learn*</a></li>
                <li><a class="dropdown-item m_dropActive"
                        href="../rushita_Solutions/k_solutions_Intel-Fortran-Compiler.html">Intel® Fortran Compiler</a>
                </li>
                <li><a class="dropdown-item m_dropActive" href="#">Intel® Graphics Performance Analyzers</a></li>
                <li><a class="dropdown-item m_dropActive"
                        href="../rushita_Solutions/k_solutions_Intel-HE-Toolkit.html">Intel® Homomorphic Encryption
                        Toolkit</a></li>
                <li><a class="dropdown-item m_dropActive"
                        href="../rushita_Solutions/k_solutions_Intel-In-Band-Manageability.html">Intel® In-Band
                        Manageability</a></li>
                <li><a class="dropdown-item m_dropActive"
                        href="../rushita_Solutions/k_solutions_Intel-Cryptography-Primitives-Library.html">Intel®
                        Integrated Performance Primitives</a></li>
                <li><a class="dropdown-item m_dropActive" href="../rushita_Solutions/">Intel® Integrated Simulation
                        Infrastructure with
                        Modeling</a></li>
                <li><a class="dropdown-item m_dropActive"
                        href="../rushita_Solutions/k_solutions_Instruction-Set-Architecture(ISA)Extensions.html">Instruction
                        Set Architecture (ISA) Extensions</a>
                </li>
                <li><a class="dropdown-item m_dropActive"
                        href="../rushita_Solutions/k_solutions_Intel-Intelligent-Storage-Acceleration-Library.html">Intel®
                        Intelligent Storage Acceleration Library
                        (Intel® ISA-L)</a></li>
                <li><a class="dropdown-item m_dropActive" href="#">Modin*</a></li>
                <li><a class="dropdown-item m_dropActive" href="#">Intel® MPI Library</a></li>
                <li><a class="dropdown-item m_dropActive" href="#">Intel® Neural Compressor</a></li>
                <li><a class="dropdown-item m_dropActive" href="#">OpenCL™ Runtime</a></li>
                <li><a class="dropdown-item m_dropActive" href="#">Intel® Open Image Denoise</a></li>
                <li><a class="dropdown-item m_dropActive" href="#">Intel® Open Path Guiding Library (Intel® Open
                        PGL)</a></li>
                <li><a class="dropdown-item m_dropActive" href="#">Pin</a></li>
                <li><a class="dropdown-item m_dropActive" href="#">Intel® Platform Analysis Library</a></li>
                <li><a class="dropdown-item m_dropActive" href="#">Intel Tools for OpenCL™ Software</a></li>
                <li><a class="dropdown-item m_dropActive" href="#">Intel Tools for OpenCL™ Applications</a></li>
                <li><a class="dropdown-item m_dropActive" href="#">Intel® OpenSWR</a></li>
                <li><a class="dropdown-item m_dropActive" href="#">OpenVINO™ Toolkit</a></li>
                <li><a class="dropdown-item m_dropActive" href="#">Intel® Open Volume Kernel Library</a></li>
                <li><a class="dropdown-item m_dropActive" href="#">Intel® Optimization for XGBoost*</a></li>
                <li><a class="dropdown-item m_dropActive" href="#">Intel® OSPRay</a></li>
                <li><a class="dropdown-item m_dropActive" href="#">Intel® OSPRay for Hydra*</a></li>
                <li><a class="dropdown-item m_dropActive" href="#">Intel® OSPRay Studio</a></li>
                <li><a class="dropdown-item m_dropActive" href="#">PyTorch* Optimizations from Intel</a></li>
                <li><a class="dropdown-item m_dropActive" href="#">TensorFlow* Optimizations from Intel</a></li>
                <li><a class="dropdown-item m_dropActive" href="#">Intel® Rendering Toolkit</a></li>
                <li><a class="dropdown-item m_dropActive" href="#">Intel® Smart Edge Open</a></li>
                <li><a class="dropdown-item m_dropActive" href="#">Intel® Software Guard Extensions</a></li>
                <li><a class="dropdown-item m_dropActive" href="#">Intel® Secure Device Onboard</a></li>
                <li><a class="dropdown-item m_dropActive" href="#">Intel® Software Development Emulator</a></li>
                <li><a class="dropdown-item m_dropActive" href="#">Intel® Trust Domain Extensions (Intel® TDX)</a>
                </li>
                <li><a class="dropdown-item m_dropActive" href="#">Intel® Quantum SDK</a></li>
                <li><a class="dropdown-item m_dropActive" href="#">Intel® Query Processing Library (Intel® QPL)</a>
                </li>
                <li><a class="dropdown-item m_dropActive" href="#">Intel® Video Processing Library</a></li>
                <li><a class="dropdown-item m_dropActive" href="#">Intel® VTune™ Profiler</a></li>
                <li><a class="dropdown-item m_dropActive" href="#">Resellers</a></li>
            </ul>
        </div>
        <div class="m_ai_shlash">/</div>
        <div>
            <button class="btn dropdown-toggle" type="button" data-bs-toggle="dropdown" aria-expanded="false">
                oneAPI
            </button>
            <ul class="dropdown-menu">
                <li><a class="dropdown-item m_dropActive" href="#">Overview</a></li>
                <li><a class="dropdown-item m_dropActive" href="#">Data Parallel C++/SYCL*</a></li>
                <li><a class="dropdown-item m_dropActive" href="#">Toolkits</a></li>
                <li><a class="dropdown-item m_dropActive" href="#">Tech Articles & How-Tos</a></li>
                <li><a class="dropdown-item m_dropActive" href="#">Components</a></li>
                <li><a class="dropdown-item m_dropActive" href="#">Code Samples</a></li>
                <li><a class="dropdown-item m_dropActive" href="#">Training</a></li>
                <li><a class="dropdown-item m_dropActive" href="#">Documentation</a></li>
                <li><a class="dropdown-item m_dropActive" href="#">Support</a></li>
            </ul>
        </div>
        <div class="m_ai_shlash">/</div>
        <div>
            <button class="btn dropdown-toggle" type="button" data-bs-toggle="dropdown" aria-expanded="false">
                Training
            </button>
            <ul class="dropdown-menu">
                <li><a class="dropdown-item m_dropActive" href="#">Overview</a></li>
                <li><a class="dropdown-item m_dropActive" href="#">Catalog</a></li>
                <li><a class="dropdown-item m_dropActive" href="#">Academic Program</a></li>
                <li><a class="dropdown-item m_dropActive" href="#">Experts</a></li>
                <li><a class="dropdown-item m_dropActive" href="#">Developer Summit</a></li>
                <li><a class="dropdown-item m_dropActive" href="#">Essentials of SYCL*</a></li>
                <li><a class="dropdown-item m_dropActive" href="#">FPGA Development Flow Using Intel® oneAPI Base Toolkit</a></li>
                <li><a class="dropdown-item m_dropActive" href="#">Heterogeneous Programming Using Numba-Data Parallel Python*</a></li>
                <li><a class="dropdown-item m_dropActive" href="#">AI Tools Samples Workflow</a></li>
                <li><a class="dropdown-item m_dropActive" href="#">Intel® oneAPI Math Kernel Library (oneMKL) Essentials</a></li>
                <li><a class="dropdown-item m_dropActive" href="#">Machine Learning using oneAPI</a></li>
                <li><a class="dropdown-item m_dropActive" href="#">Migrate from CUDA* to C++ with SYCL*</a></li>
                <li><a class="dropdown-item m_dropActive" href="#">OpenMP* Offload Basics</a></li>
                <li><a class="dropdown-item m_dropActive" href="#">Optimize GPU Apps with the Intel® oneAPI Base Toolkit</a></li>
                <li><a class="dropdown-item m_dropActive" href="#">Intel® OSPRay Essentials</a></li>
                <li><a class="dropdown-item m_dropActive" href="#">Performance, Portability & Productivity</a></li>
                <li><a class="dropdown-item m_dropActive" href="#">Workflow for a CUDA* to SYCL* Migration</a></li>
            </ul>
        </div>
       
        <div class="m_ai_shlash">/</div>
        <div class="m_ai_httl">Q8-Chat LLM: Generative AI on Intel® CPUs
        </div>
    </section>
    <section class="k_bgblue py-5">
        <div class="k_container11">
          
            <div class="row  g-4">
                <div class="col-md-10 col-sm-12 mx-0 text-white align-content-center k_tstartauto k_text2 px-0 mx-0">
                    <h2 class="fw-lighter   mb-2 k_marketsmall">Smaller is Better: Q8-Chat LLM is an Efficient Generative AI Experience on Intel® Xeon® Processors
                    </h2>
            </div>
        </div>
    </section>
    <section class="k_space k_spacenone">
        <div class="k_container11">
            <div class="row  g-3">
                <div class="float-end k_bignone" style="padding-left:70%;">
                    <div>
                        <a href="#" class="fs-4"><i class="fa-solid fa-print mx-3 k_icon0"></i></a>
                        <a href="#" class="fs-4"> <i class="fa-regular fa-envelope k_icon0"></i></a>
                    </div>
                </div>
                <div class="col-lg-3 col-md-4 col-sm-12">
                    <div class="VK_sticky_side_bar VK_side_bar_postion_stickey">
                        <div>
                            <div class="VK_sidebar_dropdown">
                                <ul class="k_listnone k_menu ">
                                    <li class="k_text"><a href="#section1">A Primer on Quantization</a></li>
                                    <li class="k_text"><a href="#section2">Quantizing LLMs</a></li>
                                    <li class="k_text"><a href="#section3">Quantizing LLMs with SmoothQuant*</a></li>
                                    <li class="k_text"><a href="#section4">Chat Experience on Intel Xeon Processors</a></li>
                                    <li class="k_text"><a href="#" class="k_submenu-toggle">Next Steps</a>
                                        <ul class="k_listnone k_submenu">
                                            <li class="k_text"><a href="#" class="k_petamenu-toggle"></a>Acknowledgement</a>
                                                <ul class="k_listnone k_petamenu">
                                                    <li class="k_text"><a href="#">Appendix: Detailed Results</a></li>
                                                </ul>
                                            </li>
                                        </ul>
                                    </li>
                                </ul>
                            </div>
                        </div>
                    </div>
                    <div>
                        <div class="p-3" style="background-color: #F7F7F7;">
                            <p><b>
                                    Get the Latest on All Things CODE</b></p>
                            <p class="text-center k_btnget py-2 k_under k_btn100 my-2 kcokbtn1024" style="width: 80px;">
                                <a href="#" class="text-white">Sign Up</a>
                            </p>
                        </div>
                        <div class="">
                            <p id="singleauthorname" class="authorname mt-2">Julien Simon</p>
                            <p id="singleauthorbio" class="authorbio"><p><i>Chief Evangelist<br>
                            </i>Hugging Face</p>
                            </p>
                        </div>
                    </div>
                </div>
                <div class="col-lg-8 col-md-7 col-sm-12  k_16smpx k_width75">
                    <div class="float-end mx-3 k_smnone">
                        <div>
                            <a href="#" class="fs-4"><i class="fa-solid fa-print mx-3 k_icon0"></i></a>
                            <a href="#" class="fs-4"> <i class="fa-regular fa-envelope k_icon0"></i></a>
                        </div>
                    </div>
                    <div class=" k_smpaddnone k_smpaddnone1 pt-5">
                        <p>Large language models (LLMs) are taking the machine learning world by storm. Thanks to their Transformer architecture, LLMs have an uncanny ability to learn from vast amounts of unstructured data like text, images, video, or audio. They perform very well on many task types, either extractive like text classification or generative like text summarization and text-to-image generation.</p>
                        <p>As their name implies, LLMs are large models that often exceed the 10-billion parameter mark. Some have more than 100 billion parameters, like the BLOOM model. LLMs require lots of computing power, which is typically found in high-end GPUs, to predict fast enough for low-latency use cases like search or conversational applications. Unfortunately, for many organizations the associated costs can be prohibitive and make it difficult to use state-of-the-art LLMs in their applications.</p>
                        <p>In this post, I will discuss optimization techniques that help reduce LLM size and inference latency, helping them run efficiently on Intel® CPUs.</p>

                        <h2 class="fw-light mt-5">A Primer on Quantization</h2>
                        <p>LLMs usually train with 16-bit floating point parameters (aka FP16/BF16). Thus, storing the value of a single weight or activation value requires 2 bytes of memory. In addition, floating point arithmetic is more complex and slower than integer arithmetic and requires additional computing power.</p>
                        <p>Quantization is a model-compression technique that aims to solve both problems by reducing the range of unique values model parameters can take. For instance, you can quantize models to lower precision like 8-bit integers (INT8) to shrink them and replace complex floating-point operations with simpler and faster integer operations.</p>
                        <p>In a nutshell, quantization rescales model parameters to smaller value ranges. When successful, it shrinks your model by at least 2x without any impact on model accuracy.</p>
                        <p class="k_plink1 k_intext1blue1">You can apply quantization during training, aka quantization-aware training (<a href="#">QAT</a>), which generally yields the best results. If you’d prefer to quantize an existing model, you can apply post-training quantization (<a href="#">PTQ</a>), a much faster technique that requires very little computing power.</p>
                        <p class="k_plink1 k_intext1blue1">Different quantization tools are available. For example, PyTorch* has built-in support for&nbsp;<a href="#">quantization</a>. You can also use the Hugging Face&nbsp;<a href="#">Optimum Intel</a>&nbsp;library, which includes developer-friendly APIs for QAT and PTQ.</p>

                        <h2 class="fw-light mt-5">Quantizing LLMs</h2>
                        <p class="k_plink1 k_intext1blue1">Recent studies&nbsp;<a href="#"><sup>[1]</sup></a><a href="#"><sup>[2]</sup></a>&nbsp;show that current quantization techniques don’t work well with LLMs. In particular, LLMs exhibit large-magnitude outliers in specific activation channels across all layers and tokens.</p>
                        <p>Here’s an example with the OPT-13B model. You can see that one of the activation channels has much larger values than all others across all tokens. This phenomenon is visible in all the Transformer layers of the model.</p>
                        <div class="my-5 col-sm-12 col-md-6 m-auto">
                            <img src="../img/rushita_img/Q8llm1.png" alt="" width="100%">
                        </div>
                        <p class="utility-text-1" style="text-align:center"><strong>Source: SmoothQuant</strong></p>
                        <p>The best quantization techniques to date quantize activations token-wise, causing either truncated outliers or underflowing low-magnitude activations. Both solutions hurt model quality significantly. Moreover, quantization-aware training requires additional model training; this is not practical in most cases due to lack of compute resources and data.</p>
                        <p class="k_plink1 k_intext1blue1"><strong>SmoothQuant*</strong>&nbsp;<a href="#"><sup>[3]</sup></a><a href="#"><sup>[4]</sup></a>&nbsp;<strong>is a new quantization technique that solves this problem</strong>. It applies a joint mathematical transformation to weights and activations which reduces the ratio between outlier and non-outlier values for activations at the cost of increasing the ratio for weights. This transformation makes the layers of the Transformer "quantization-friendly" and enables 8-bit quantization without hurting model quality. As a consequence, SmoothQuant produces smaller, faster models that run well on Intel CPU platforms.</p>
                        <div class="my-5 col-sm-12 col-md-8 m-auto">
                            <img src="../img/rushita_img/Q8llm2.png" alt="" width="100%">
                        </div>
                        <p>Now, let’s see how SmoothQuant works when applied to popular LLMs.</p>
                        <h2 class="fw-light mt-5">Quantizing LLMs with SmoothQuant*</h2>
                        <p class="k_plink1 k_intext1blue1">Our friends at Intel have quantized several LLMs with SmoothQuant-O3: OPT&nbsp;<a href="#">2.7B</a>&nbsp;and&nbsp;<a href="#">6.7B</a>&nbsp;<a href="#"><sup>[5]</sup></a>, LLaMA&nbsp;7B&nbsp;<a href="#"><sup>[6]</sup></a>, Alpaca&nbsp;<a href="#">7B</a>&nbsp;<a href="#"><sup>[7]</sup></a>, Vicuna&nbsp;<a href="#">7B</a>&nbsp;<a href="#"><sup>[8]</sup></a>, BloomZ&nbsp;<a href="#">7.1B</a>&nbsp;<a href="#"><sup>[9]</sup></a>, and MPT-7B-chat&nbsp;<a href="#"><sup>[10]</sup></a>. They also evaluated the accuracy of the quantized models, using&nbsp;<a href="#">Language Model Evaluation Harness</a>.</p>
                        <p>The table below presents a summary of their findings. The second column shows the ratio of benchmarks that have improved post-quantization. The third column contains the mean average degradation (*<em>a negative value indicates that the benchmark has improved</em>). You can find the detailed results at the end of this post.</p>
                       <div class="my-5 col-sm-12 col-md-8 m-auto">
                            <img src="../img/rushita_img/Q8llm3.png" alt="" width="100%">
                       </div>
                        <p>As you can see, OPT models are great candidates for SmoothQuant quantization. Models are ~2x smaller compared to pretrained 16-bit models. Most of the metrics improve, and those that don’t are only marginally penalized.</p>
                        <p>The picture is a little more contrasted for LLaMA 7B and BloomZ 7.1B. Models are compressed by a factor of ~2x, with about half the task seeing metric improvements. The other half is only marginally impacted, with a single task seeing more than 3% relative degradation.</p>
                        <p class="k_plink1 k_intext1blue1">The obvious benefit of working with smaller models is a significant reduction in inference latency. Here’s a&nbsp;<a href="#">video</a>&nbsp;demonstrating real-time text generation with the MPT-7B-chat model on a single-socket Intel Sapphire Rapids CPU with 32 cores and a batch size of 1.</p>
                        <p>In this example, we ask the model: “What is the role of Hugging Face in democratizing NLP?”. This sends the following prompt to the model: "<em>A chat between a curious user and an artificial intelligence assistant. The assistant gives helpful, detailed, and polite answers to the user's questions. USER: What is the role of Hugging Face in democratizing NLP? ASSISTANT:</em>"</p>
                        <p>The example shows the additional benefits you can get from 8bit quantization coupled with 4th Gen Intel® Xeon® processors, resulting in very low generation time for each token. This level of performance definitely makes it possible to run LLMs on CPU platforms, giving customers more IT flexibility and better cost-performance than ever before.</p>

                        <h2 class="fw-light mt-5">Chat Experience on Intel Xeon Processors</h2>
                        <p>Recently, Clement, the CEO of Hugging Face, recently said, “More companies would be better served focusing on smaller, specific models that are cheaper to train and run.”</p>
                        <p>The emergence of relatively smaller models like Alpaca, BloomZ, and Vicuna open a new opportunity for enterprises to lower the cost of fine-tuning and inference in production. As demonstrated above, high-quality quantization brings high-quality chat experiences to Intel CPU platforms without the need of running mammoth LLMs and complex AI accelerators.</p>
                        <p>Together with Intel, we're hosting a new, exciting demo in Spaces called&nbsp;Q8-Chat&nbsp;(pronounced "Cute chat"). Q8-Chat offers you a ChatGPT-like chat experience while only running on a single socket Intel Sapphire Rapids CPU with 32 cores and a batch size of 1.</p>

                        <h2 class="fw-light mt-5">Next Steps</h2>
                        <p class="k_plink1 k_intext1blue1">We’re currently working on integrating these new quantization techniques into the Hugging Face&nbsp;<a href="#">Optimum Intel</a>&nbsp;library through&nbsp;<a href="#">Intel® Neural Compressor</a>. Once we’re done, you’ll be able to replicate these demos with just a few lines of code.</p>
                        <p>Stay tuned. The future is 8-bit!</p>
                        <p><em>This post is guaranteed 100% ChatGBT-free.</em></p>
                        <h3>Acknowledgement</h3>
                        <p>This blog was made in conjunction with Ofir Zafrir, Igor Margulis, Guy Boudoukh and Moshe Wasserblat from Intel Labs. Special thanks to them for their great comments and collaboration.</p>
                        <h3>Appendix: Detailed Results</h3>
                        <p>A negative value indicates that the benchmark has improved.</p>
                        <div class="my-2 col-sm-12 col-md-8 m-auto">
                            <img src="../img/rushita_img/Q8llm4.png" alt="" width="100%">
                        </div>
                        <div class="my-2 col-sm-12 col-md-8 m-auto">
                            <img src="../img/rushita_img/Q8llm5.png" alt="" width="100%">
                        </div>
                        <div class="my-2 col-sm-12 col-md-8 m-auto">
                            <img src="../img/rushita_img/Q8llm6.png" alt="" width="100%">
                        </div>
                        <div class="my-2 col-sm-12 col-md-8 m-auto">
                            <img src="../img/rushita_img/Q8llm7.png" alt="" width="100%">
                        </div>
                        <p class="mt-4">Learn More:</p>
                        <p class="k_plink1 k_intext1blue1"><a href="../rushita_Solutions/k_solutions_Developer-Resources-from-Intel-Hugging-Face.html">Intel AIML Ecosystem- HuggingFace</a></p>
                        <p class="k_plink1 k_intext1blue1"><a href="#">Hugging Intel website</a></p>
                    </div>
                </div>
    </section>
    <section class="my-4" style="font-size: 13px;">
        <div class="k_container11">
            <div class="row">
                <div>
                    <hr class="mb-5">
                    <p>Product and Performance Information </p>
                    <div class="k_plink1 k_intext1blue1"><sup>1</sup>Performance varies by use, configuration and other
                        factors. Learn more at &nbsp;<a href="#">www.Intel.com/PerformanceIndex.</a>.
                    </div>
                </div>
            </div>
        </div>
    </section>
    <div id="footer"></div>
    <script>
        // navbar include  
        fetch('../y_index/y_navbar.html')
            .then(response => response.text())
            .then(data => {
                document.getElementById('navbar').innerHTML = data;
            });
        // footer include 
        fetch('../y_index/y_footer.html')
            .then(response => response.text())
            .then(data => {
                document.getElementById('footer').innerHTML = data;
            });
    </script>
    <script src="https://cdn.jsdelivr.net/npm/@splidejs/splide@4.1.4/dist/js/splide.min.js"></script>
    <script src="../js/jquery-3.7.1.js"></script>

    <script src="../js/owl.carousel.min.js"></script>
    <script src="../js/rushita.js"></script>
</body>

</html>