<!DOCTYPE html>
<html lang="en">

<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>Scalable I/O Between Accelerators and Host Processors</title>

    <!-- font family -->
    <link href="https://fonts.cdnfonts.com/css/intel-clear" rel="stylesheet">
    <link rel="stylesheet" href="/css/rushita_automotive.css">
    <link rel="stylesheet"
        href="/css/dk_developer_edge_iot_5G_industrial_automation_see_all_Intelligent_connection_management_for_automated_handover.css">
    <!-- header footer -->
    <link rel="stylesheet" href='/css/yatri.css'>

    <link href="https://cdn.jsdelivr.net/npm/bootstrap@5.0.2/dist/css/bootstrap.min.css" rel="stylesheet"
        integrity="sha384-EVSTQN3/azprG1Anm3QDgpJLIm9Nao0Yz1ztcQTwFspd3yD65VohhpuuCOmLASjC" crossorigin="anonymous">
    <script src="https://cdn.jsdelivr.net/npm/bootstrap@5.0.2/dist/js/bootstrap.bundle.min.js"
        integrity="sha384-MrcW6ZMFYlzcLA8Nl+NtUVF0sA7MsXsP1UyJoMp4YLEuNSfAP+JcXn/tWtIaxVXM"
        crossorigin="anonymous"></script>
    <link href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/6.6.0/css/all.min.css" rel="stylesheet">

</head>

<style>
    .dk_things_code{
        padding: 1rem 0rem 0rem 0rem !important;
    }
</style>

<body>
    <!-- header -->
    <div id="navbar"></div>

    <!-------------------------------->
    <section class="m_ai_tdrop">
        <div>
            <button class="btn dropdown-toggle" type="button" data-bs-toggle="dropdown" aria-expanded="false">
                Developers
            </button>
            <ul class="dropdown-menu">
                <li><a class="dropdown-item m_dropActive" href="">Overview</a></li>
                <li><a class="dropdown-item m_dropActive" href="">Topics & Technologies</a></li>
                <li><a class="dropdown-item m_dropActive" href="">Tools</a></li>
                <li><a class="dropdown-item m_dropActive" href="">Hardware Platforms</a></li>
                <li><a class="dropdown-item m_dropActive" href="">Resources & Documentation</a></li>
                <li><a class="dropdown-item m_dropActive" href="">Learn</a></li>
                <li><a class="dropdown-item m_dropActive" href="">Community & Events</a></li>
                <li><a class="dropdown-item m_dropActive" href="">Developer Programs</a></li>
                <li><a class="dropdown-item m_dropActive" href="">Get Help</a></li>
            </ul>
        </div>
    
    
        <div class="m_ai_shlash">/</div>
        <div>
            <button class="btn dropdown-toggle" type="button" data-bs-toggle="dropdown" aria-expanded="false">
                Topics & Technologies
            </button>
            <ul class="dropdown-menu">
                <li><a class="dropdown-item m_dropActive" href="">Artificial Intelligence</a></li>
                <li><a class="dropdown-item m_dropActive" href="">Client Applications</a></li>
                <li><a class="dropdown-item m_dropActive" href="">Cloud</a></li>
                <li><a class="dropdown-item m_dropActive" href="">GPU Research</a></li>
                <li><a class="dropdown-item m_dropActive" href="">Edge Computing</a></li>
                <li><a class="dropdown-item m_dropActive" href="">GameDev</a></li>
                <li><a class="dropdown-item m_dropActive" href="">HPC</a></li>
                <li><a class="dropdown-item m_dropActive" href="">Data Center</a></li>
                <li><a class="dropdown-item m_dropActive" href="">Firmware</a></li>
                <li><a class="dropdown-item m_dropActive" href="">Networking</a></li>
                <li><a class="dropdown-item m_dropActive" href="">Open Ecosystem</a></li>
                <li><a class="dropdown-item m_dropActive" href="">Persistent Memory</a></li>
                <li><a class="dropdown-item m_dropActive" href="">Intel® Platform Analysis Technology</a></li>
                <li><a class="dropdown-item m_dropActive" href="">Runtime Languages</a></li>
                <li><a class="dropdown-item m_dropActive" href="">Software Security Guidance</a></li>
                <li><a class="dropdown-item m_dropActive" href="">Storage</a></li>
            </ul>
        </div>
    
        <div class="m_ai_shlash">/</div>
    
        <div>
            <button class="btn dropdown-toggle" type="button" data-bs-toggle="dropdown" aria-expanded="false">
                Data Center
            </button>
            <ul class="dropdown-menu">
                <li><a class="dropdown-item m_dropActive" href="">Tools & Libraries</a></li>
            </ul>
        </div>
        <div class="m_ai_shlash">/</div>
        <div class="m_ai_httl">Scalable IO with Accelerators and Host Processors</div>
    </section>
    <!-- --------------------------------------------------------------------- -->

    <!-- VMware Horizon -->
    <section>
        <div class="mv_vmware_bg_color">
            <div class="container">
                <div class="mv_vmware_padd">
                    <div class="row">
                        <div class="col-md-12 col-sm-12">
                            <div class="mv_vmware_heading">
                                <h3>Scalable I/O Between Accelerators and Host Processors</h3>
                            </div>
                        </div>
                    </div>
                    <div class="mv_cd_page_marquee_info">
                        <div class="mv_cd_page_marquee_action">
                            <div class="mv_cd_page_marquee_action_padd">
                                <label for="">ID</label>
                                <span>721793</span>
                            </div>
                            <div class="mv_cd_page_marquee_action_padd">
                                <label for="">Updated</label>
                                <span>2/16/2022</span>
                            </div>
                            <div class="mv_cd_page_marquee_action_padd">
                                <label for="">Version</label>
                                <span>Latest</span>
                            </div>
                            <div class="mv_cd_page_marquee_action_padd">
                                <label for=""></label>
                                <span>Public</span>
                            </div>
                        </div>
                    </div>
                </div>
            </div>
        </div>
    </section>
    <section class="container py-5">
        <div class="row">
            <div class="d-flex justify-content-end col-xl-10 py-3 d-md-none">
                <i class="fa-solid fa-print fs-4 px-2 " style="color:#0068B5"></i>
                <i class="fa-regular fa-envelope fs-4 px-2" style="color:#0068B5"></i>
            </div>
            <div class="col-lg-3 col-md-4">
                <!-- nav -->
                <div class="VK_sticky_side_bar VK_side_bar_postion_stickey">
                    <div>
                        <div class="VK_sidebar_dropdown">
                            <p class="m-0">
                                <a href="#dk_introduction" class="text-decoration-none VK_a">
                                    Introduction
                                </a>
                            </p>
                            <details>
                                <summary>
                                    <a href="#dk_Current_Landscape" class="text-decoration-none VK_a">
                                        Current Landscape
                                    </a>
                                </summary>
                                <ul class="list-unstyled ps-3 mb-0">
                                    <li>
                                        <a href="#dk_work_submission" class="text-decoration-none VK_a my-1">
                                            Work Submission Overheads
                                        </a>
                                    </li>
                                </ul>
                                <ul class="list-unstyled ps-3 mb-0">
                                    <li>
                                        <a href="#dk_memory" class="text-decoration-none VK_a my-1">
                                            Memory Management Complexity Overheads
                                        </a>
                                    </li>
                                </ul>
                                <ul class="list-unstyled ps-3 mb-0">
                                    <li>
                                        <a href="#dk_work_completion" class="text-decoration-none VK_a my-1">
                                            Work Completion Synchronization Overheads
                                        </a>
                                    </li>
                                </ul>
                                <ul class="list-unstyled ps-3 mb-0">
                                    <li>
                                        <a href="#dk_accelerator" class="text-decoration-none VK_a my-1">
                                            Accelerator Shareability
                                        </a>
                                    </li>
                                </ul>
                                <!-- <details>
                                    <summary>
                                        <a href="#dk_supported_features" class="text-decoration-none VK_a">
                                            Supported Features
                                        </a>
                                    </summary>
                                    <ul class="list-unstyled ps-3 mb-0">
                                        <li>
                                            <a href="#dk_subscription" class="text-decoration-none VK_a my-1">
                                                Subscription for RSRP/RRC reports with SDRAN RIC v1.4.113
                                            </a>
                                        </li>
                                    </ul>
                                    <ul class="list-unstyled ps-3 mb-0">
                                        <li>
                                            <a href="#dk_connection_deployment" class="text-decoration-none VK_a my-1">
                                                Connection Management Deployment
                                            </a>
                                        </li>
                                    </ul>
                                    <ul class="list-unstyled ps-3 mb-0">
                                        <li>
                                            <a href="#dk_automated" class="text-decoration-none VK_a my-1">
                                                Automated Handover using OpenVINO™ Inferencing
                                            </a>
                                        </li>
                                    </ul>
                                    <ul class="list-unstyled ps-3 mb-0">
                                        <li>
                                            <a href="#dk_node_feature_discovery" class="text-decoration-none VK_a my-1">
                                                Node Feature Discovery (NFD)
                                            </a>
                                        </li>
                                    </ul>
                                    <ul class="list-unstyled ps-3 mb-0">
                                        <li>
                                            <a href="#dk_cpu_manager" class="text-decoration-none VK_a my-1">
                                                CPU Manager
                                            </a>
                                        </li>
                                    </ul>
                                </details> -->
                            </details>
                            <details>
                                <summary>
                                    <a href="#dk_acc_interfaceing" class="text-decoration-none VK_a">
                                        Accelerator Interfacing Technologies
                                    </a>
                                </summary>
                                <ul class="list-unstyled ps-3 mb-0">
                                    <li>
                                        <a href="#dk_enhancements" class="text-decoration-none VK_a my-1">
                                            Enhancements for Offload Efficiency & Scalability
                                        </a>
                                    </li>
                                </ul>
                                <ul class="list-unstyled ps-3 mb-0">
                                    <li>
                                        <a href="#dk_shared_virtual" class="text-decoration-none VK_a my-1">
                                            Shared Virtual Memory (SVM)
                                        </a>
                                    </li>
                                </ul>
                                <ul class="list-unstyled ps-3 mb-0">
                                    <li>
                                        <a href="#dk_intel_scalabel" class="text-decoration-none VK_a my-1">
                                            Intel® Scalable I/O Virtualization (Intel® Scalable IOV)
                                        </a>
                                    </li>
                                </ul>
                            </details>
                            <p class="m-0">
                                <a href="#dk_acc_interfacing_tec" class="text-decoration-none VK_a">
                                    Accelerator Interfacing Technologies with Intel® Data Streaming Accelerator
                                </a>
                            </p>
                        </div>
                    </div>
                </div>
                <!-- thinkcode -->
                <div class="dk_things_code_main">
                    <div class="dk_things_code">
                        <div class="dk_high_quality">
                            <p>By Utkarsh Y Kakaiya, <br>
                                Sanjay Kumar, <br>
                                Rajesh Madukkarumukumana Sankaran, <br>
                                Prashant Seth</p>
                        </div>
                    </div> 
                </div>
            </div>
            <div class="col-lg-9 col-md-8">
                <div class="d-md-flex justify-content-end col-xl-10 py-3 d-none">
                    <i class="fa-solid fa-print fs-4 px-2 " style="color:#0068B5"></i>
                    <i class="fa-regular fa-envelope fs-4 px-2" style="color:#0068B5"></i>
                </div>
                <div class="col-xl-10 VK_all_sections">
                    <div style="padding-bottom: 16px;">
                        <p>&nbsp;</p>
                        <h5 style="font-weight: 550;">A recipe for efficient coordination between user-mode applications and accelerators for optimizing data processing.</h5>
                    </div>
                    <section id="dk_introduction">
                        <h3 style="font-weight: 300;">Introduction</h3>
                        <p>The emerging era of data-centric computing is forcing increased focus on accelerating workloads and reducing COGS (cost of goods sold) in data centers. Hardware methods for such acceleration include specialized instruction set architecture (ISA) extensions in CPU cores, programmable heterogeneous elements (such as GPUs and FPGAs), and offload acceleration engines for data movement and transformation functions. While ISA-based acceleration is well defined within the instruction set architecture of the host CPU, offload-based acceleration organically evolved from traditional I/O controller and device driver models without consistent constructs and capabilities. This paper provides an overview of various accelerator-interfacing technologies that were introduced on upcoming Intel® Xeon® processors. These technologies target reduced offload overheads, minimized end-to-end latencies, a simplified memory model, and scalable virtualization capabilities suitable for workload deployment through virtual machines and/or containers.</p>
                        <p>&nbsp;</p>
                    </section>
                    <section id="dk_Current_Landscape">
                        <h4 style="font-weight: 350;">Current Landscape</h4>
                        <p>Offload acceleration hardware and software that evolved from traditional I/O controller designs suffer from many challenges. These include work submission overheads, memory management complexity, work completion synchronization overheads, and sharing accelerators among applications or tenants.</p>
                        <p class="mb-0">&nbsp;</p>
                        <section id="dk_work_submission">
                            <h4>Work Submission Overheads</h4>
                            <p>Traditionally, when an application submits work to an accelerator, the request is routed to a kernel-mode device driver that abstracts the interface between the software and hardware of the underlying accelerator device. The latencies and overheads associated with kernel I/O stacks can cause bottlenecks for high-performance, streaming accelerators.&nbsp;</p>
                            <p class="mb-0">&nbsp;</p>
                        </section>
                        <section id="dk_memory">
                            <h4>Memory Management Complexity Overheads</h4>
                            <p>Traditional accelerator designs require pinned memory to share data between an application and a hardware accelerator. Also, an accelerator’s view of memory (accessed via direct memory access) is significantly different from an application’s view, often requiring the underlying software stack to bridge the two views through costly memory pinning and unpinning and DMA map and unmap operations.</p>
                            <p class="mb-0">&nbsp;</p>
                        </section>

                        <section id="dk_work_completion">
                            <h4>Work Completion Synchronization Overheads</h4>
                            <p>Existing software stacks for accelerators rely on either interrupt-driven processing, busy-polling of completion status registers, or descriptors in memory. Interrupt processing architecture in operating system kernels imposes overhead with context switching and deferred processing that can reduce system performance. On the other hand, busy polling consumes more power, reduces the number of CPU cycles available to other applications, and can negatively impact scaling.</p>
                        </section>

                        <section id="dk_accelerator">
                            <h4>Accelerator Shareability</h4>
                            <p>Efficient and secure sharing of an accelerator across multiple concurrent applications, containers, and virtual machines is a foundational requirement for deploying data centers. Hardware-assisted I/O virtualization, such as SR-IOV, accelerates I/O virtualization by eliminating the hypervisor from the process of accessing an accelerator on the behest of guest software.</p>
                            <p class="mb-0">However, such architectures tend to be hardware-intensive and less well suited for two kinds of designs:</p>
                            <ul> 
                                <li>Resource-constrained system-on-a-chip (SoC) &nbsp;integrated accelerator designs</li> 
                                <li>Use cases that need more scalability than is currently available in virtual machine-based usages (for example, uses that share an accelerator among thousands of concurrent containers)</li> 
                            </ul>
                            <p class="mb-0">In summary, the system architecture for accelerators must address the following requirements:</p>
                            <ul> 
                                <li>Offload efficiency—low overhead, user-mode, function offload (scalable and low-latency work dispatch, lightweight synchronization, event signaling, and others)</li> 
                                <li>Memory model—a uniform view of memory by the application and the function offloaded to the accelerator</li> 
                                <li>Virtualization—efficient sharing of the accelerator across applications, containers, and virtual machines</li> 
                                <li>Consistency—a consistent hardware and software interface and SoC interfacing architecture across all IPs</li> 
                            </ul>
                            <p>&nbsp;</p>
                        </section>

                        <section id="dk_acc_interfaceing">
                            <h4 style="font-weight: 350;">Accelerator Interfacing Technologies</h4>
                            <p>This section summarizes the capabilities of accelerator-interfacing technologies on upcoming Intel® Xeon® processors.&nbsp;</p>
                            <p class="mb-0">These capabilities address the requirements above and include the following:</p>
                            <ul> 
                                <li>Work-dispatch instructions (MOVDIRI, MOVDIR64B, ENQCMD/S) for optimized offload</li> 
                                <li>User-mode wait instructions (UMONITOR, UMWAIT, TPAUSE) for efficient synchronization</li> 
                                <li>Low-latency user interrupts</li> 
                                <li>Shared virtual memory</li> 
                                <li>Scalable I/O virtualization</li> 
                            </ul>
                            <p class="mb-0">&nbsp;</p>
                        </section>

                        <section id="dk_enhancements">
                            <h4>Enhancements for Offload Efficiency & Scalability</h4>
                            <p>MOVDIRI<br> Enables high-throughput (4B or 8B) doorbell-writes using direct-store semantics to benefit streaming offload models where small units of work are streaming at a high rate to the accelerator.</p>
                            <p>MOVDIR64B<br> Enables 64-byte atomic writes to accelerator work-queues to benefit low-latency offload models where accelerator devices are highly optimized for completing the requested operation at a minimal latency. The 64-byte payload enables accelerators to avoid DMA read latencies for fetching the work-descriptor and in some cases even the actual data (thereby reducing the end-to-end latency).</p>
                            <p>ENQCMD/S<br> Enable simultaneous and direct work submission from multiple, non-cooperating software entities (such as applications, containers, or applications/containers inside VMs) to an accelerator’s work queue (termed shared work queue or SWQ) as shown in the following figure. The instructions to enqueue commands—ENQCMD (enqueue command) and ENQCMDS (enqueue command as supervisor)—have two unique features:&nbsp;</p>
                            <ul> 
                                <li>The work descriptor contains a process address space identifier (PASID) that allows the accelerator to identify the submitting software agent on a per-descriptor basis</li> 
                                <li>The commands use PCIe* deferrable memory write (DMWr) requests to allow the accelerator to carry-out or defer incoming DMWr requests</li> 
                            </ul>
                            <p>ENQCMD/S instructions return a "success" or "retry" (deferred) indication to software. Success indicates that the work was accepted into the SWQ, while retry indicates it was not accepted due to SWQ capacity, QoS, or other reasons. On receiving a retry status, the work submitter may retry later.</p>
                            <p>
                                <img class="w-100" src="/img/darshit_image/scalable-io-whitepaper-fig1.png" alt="">
                            </p>
                            <p>UMONITOR/UMWAIT/TPAUSE<br> Enable low-latency synchronization between user-mode software and offloaded tasks. Also, allow a processor to enter an implementation-dependent, optimized state while waiting for an accelerator to complete the dispatched work. The optimized state may be either a lightweight power or performance-optimized state or an enhanced power/performance-optimized state. The UMWAIT and TPAUSE instructions allow software to choose between the two optimized states; they also provide a mechanism to specify an optional timeout value. The TPAUSE instruction can be used along with the transactional synchronization extensions to wait on multiple events. These instructions allow a hyperthread (HT) to use compute resources when a sibling thread is efficiently waiting for an event.</p>
                            <p>User Interrupts<br> Enable a lightweight mechanism for directly signaling the user-mode software. User interrupts enable event delivery to the user-space applications without any kernel intervention and can be used by the kernel agents to send notifications to user-space application in lieu of using the operating system signaling mechanisms. User interrupts reduce the end-to-end latency, overall jitter, and context-switching overheads for high-performance applications.</p>
                            <p class="mb-0">&nbsp;</p>
                        </section>

                        <section id="dk_shared_virtual">
                            <h4>Shared Virtual Memory (SVM)</h4>
                            <p class="mb-0">SVM architecture enables a unified view of memory from both the CPU and an accelerator by:&nbsp;</p>
                            <ul> 
                                <li>Allowing the accelerator to use same virtual addresses as the CPU</li> 
                                <li>Enabling the accelerator to access unpinned memory and to recover from the I/O page-faults</li> 
                            </ul>
                            <p>Upcoming Intel Xeon processors&nbsp;support SVM capabilities, such as process address space identifier (PASID), address translation services (ATS), and page request services (PRS). System software allocates a PASID to identify the address space of each client submitting the work, and Intel® Virtualization Technology (Intel® VT) for Directed I/O (Intel® VT-d) is extended to share the client’s CPU page-tables with Intel VT-d to perform PASID-granular DMA remapping and to help the accelerator recover from the I/O page-faults.</p>
                            <p>The accelerator uses SVM capabilities to process directly the data from the application address space. On receipt of a work descriptor, the accelerator looks-up the device translation lookaside buffer (DevTLB) for the DMA address translations; if address translations are already cached (a DevTLB hit scenario), the DMA requests are issued with the translated host physical addresses (HPA) acquired from the DevTLB. On a DevTLB miss, the accelerator issues an ATS address translation request to the IOMMU, which consults its address translation table(s) to acquire the translation. On successful translation, the returned address translation information is cached in the DevTLB, and the DMA requests are issued. On an unsuccessful translation (that is, I/O page-fault), the accelerator can issue a PRS page-request to system software to request "page-in" for the faulted page (like CPU page-fault handling). On receipt of successful page response, the accelerator reissues the address translation request to obtain the translations after the fault has been handled successfully on the host.</p>
                            <p>System software can change the application/VM page-tables by trimming the process’s working-set, handling overcommits to VMM memory, tearing down an application or a VM, and so on. If this occurs, system software tells the accelerator to invalidate the DevTLB entries associated with this change and then synchronizes the responses.</p>
                            <p>
                                <img class="w-100" src="/img/darshit_image/scalable-io-whitepaper-fig2.png" alt="">
                            </p>
                            <p class="mb-0">&nbsp;</p>
                        </section>

                        <section id="dk_intel_scalabel">
                            <h4>Intel® Scalable I/O Virtualization (Intel® Scalable IOV)</h4>
                            <p class="mb-0">SVM architecture enables a unified view of memory from both the CPU and an accelerator by:&nbsp;</p>
                            <p>Intel Scalable IOV is a novel approach to hardware-assisted I/O virtualization. It enables fine-grained, flexible, high-performance sharing of I/O devices across isolated domains (applications, VMs, containers, and more), while reducing the complexity of such sharing for endpoint hardware devices. It also enables fine-grained, provisioned, device resources (for example, work queue, queue-pair, or context) to be independently assigned to client domains. Software accesses to the accelerator are categorized as either ‘direct path’ or ‘intercepted path’. Direct-path accesses (for example, work submission or work completion processing) are mapped directly to the accelerator resources for performance. The intercepted-path accesses, like configuration operations, are emulated by a virtual device composition module (VDCM) for greater flexibility. Intel Scalable IOV also extends Intel® VT-d to support PASID-granular, DMA remapping for fine-grained isolation among device resources assigned to different domains.</p>
                            <p>
                                <img class="w-100" src="/img/darshit_image/scalable-io-image0216022.png" alt="">
                            </p>
                            <p>Intel Scalable IOV provides flexible sharing of device resources that have different address domains and use different abstractions, such as system calls for application processes or virtual device interfaces for VMs. It also enables dynamic mapping of VDEVs to device resources, allowing a VMM to over-provision device resources. More broadly, Intel Scalable IOV enables a VMM to maintain generational compatibility in a datacenter by using VDCM to virtualize the VDEV’s capability and present compatible VDEV capabilities irrespective of the different generations of physical I/O devices. This ensures that a given guest operating system image with a VDEV driver can be deployed or migrated to any of the physical machines.</p>
                            <p>
                                <img class="w-100" src="/img/darshit_image/scalable-io-whitepaper-fig4.png" alt="">
                            </p>
                            <p class="mb-0">&nbsp;</p>
                        </section>

                        <section id="dk_acc_interfacing_tec">
                            <h4 style="font-weight: 350;">Accelerator Interfacing Technologies with Intel® Data Streaming Accelerator</h4>
                            <p>Intel® Data Streaming Accelerator (Intel® DSA), a high-performance accelerator for copying and transforming data, is integrated into upcoming Intel Xeon processors.&nbsp;The purpose of Intel DSA is to optimize the movement and transformation of streaming data, which is common in applications designed for high-performance storage, networking, persistent memory, and various data processing applications.&nbsp;</p>
                            <p>Intel DSA makes use of the accelerator-interfacing technologies stated earlier to enable efficient and scalable accelerator offload while reducing the cost and complexity associated with building such a scalable accelerator hardware.</p>
                            <p>Intel DSA supports device-hosted dedicated work queues (DWQ), which allow individual clients to own or control the flow/occupancy of their work queues, and device-hosted shared work queues (SWQ) which enable scalable sharing. As shown in the figure below, software may assign the DWQ to an individual client while map the SWQ to one or more clients. Software uses the MOVDIR64B instruction to submit 64-byte work descriptors to DWQs and ENQCMD/S instructions to submit 64-byte work descriptor to SWQs. The work descriptor can also request a completion interrupt, a completion write, or both thereby, enabling efficient synchronization via UMONITOR/UMWAIT instructions.</p>
                            <p>Intel DSA supports SVM and recoverable I/O page-faults, enabling a simplified programming model and making its adoption seamless in applications, operating systems and hypervisor software. Support for scalable I/O virtualization capabilities enable Intel DSA offload in virtual-machine or container-based deployments and make the live-migration viable while keeping the Intel DSA virtual device assigned to the VM or container.</p>
                            <p>
                                <img class="w-100" src="/img/darshit_image/scalable-io-whitepaper-fig5.png" alt="">
                            </p>
                            <p>&nbsp;</p>
                        </section>
                </div>
            </div>
        </div>
    </section>

    <section style="border-top: 1px solid #d7d7d7;" class="container py-5">
        <h4 class="h6">Product and Performance Information</h4>
        <div class="disclaimer" style="font-size: 12px;"><sup>1</sup> Performance varies by use, configuration and other
            factors. Learn more at <a class="b_special_a1" href="/Product/B1_1_5xeon6_performance_Index.html">www.Intel.com/PerformanceIndex.</a></div>
        </div>
    </section>

    <!-- footer -->
    <div id="footer"></div>

    <!-- nav script -->
    <script>
        // navbar include  
        fetch('/y_index/y_navbar.html')
            .then(response => response.text())
            .then(data => {
                document.getElementById('navbar').innerHTML = data;
            });
        // footer include 
        fetch('/y_index/y_footer.html')
            .then(response => response.text())
            .then(data => {
                document.getElementById('footer').innerHTML = data;
            });
    </script>
    <!-- nav script -->
    <script>
        document.addEventListener('DOMContentLoaded', function () {
            if (document.getElementsByClassName('VK_all_sections section') && document.getElementsByClassName('VK_sidebar_dropdown')) {
                const sections = document.querySelectorAll('.VK_all_sections section');
                const navLinks = document.querySelectorAll('.VK_sidebar_dropdown a');
                const detailsElements = document.querySelectorAll('.VK_sidebar_dropdown details');

                function removeActiveClass() {
                    navLinks.forEach(link => link.classList.remove('VK_sidebar_active_link'));
                    detailsElements.forEach(details => {
                        details.removeAttribute('open');
                        details.setAttribute('close', ''); // Optional: to visually indicate it's closed
                    });
                }

                function activateLinkAndDetails(targetId) {
                    navLinks.forEach(link => {
                        if (link.getAttribute('href') === `#${targetId}`) {
                            link.classList.add('VK_sidebar_active_link');
                            let parentDetails = link.closest('details');

                            // Open all ancestor details elements
                            while (parentDetails) {
                                parentDetails.setAttribute('open', '');
                                parentDetails.removeAttribute('close'); // Optional: remove the closed indicator
                                parentDetails = parentDetails.parentElement.closest('details');
                            }
                        }
                    });
                }

                function onScroll() {
                    let currentSection = '';
                    sections.forEach(section => {
                        const sectionTop = section.getBoundingClientRect().top;
                        const sectionBottom = section.getBoundingClientRect().bottom;

                        // Check if the section is in view
                        if (sectionTop <= 100 && sectionBottom >= 0) {
                            currentSection = section.getAttribute('id');
                        }
                    });

                    if (currentSection) {
                        removeActiveClass();
                        activateLinkAndDetails(currentSection);
                    } else {
                        removeActiveClass();
                    }
                }

                window.addEventListener('scroll', onScroll);
            } else {
                return
            }
        });
    </script>

    <!-- copy script -->
    <script>
        document.addEventListener("DOMContentLoaded", () => {
            document.querySelectorAll(".mv_copy_icon").forEach((icon) => {
                icon.addEventListener("click", async function () {
                    try {
                        const toolbar = this.closest(".mv_code_toolbar");
                        const codeBlock = toolbar.querySelector(".code-content");
                        const codeContent = codeBlock.innerText;

                        // Use Clipboard API to copy text
                        await navigator.clipboard.writeText(codeContent);

                        // Hide the copy icon and show the "Copied!" message
                        const message = toolbar.querySelector(".mv_copy_message");
                        this.classList.add("hidden"); // Hide the copy icon
                        message.classList.remove("hidden"); // Show the "Copied!" message

                        // Hide the message and show the icon again after 2 seconds
                        setTimeout(() => {
                            message.classList.add("hidden");
                            this.classList.remove("hidden");
                        }, 2000); // Adjust delay as needed

                    } catch (err) {
                        console.error('Failed to copy text: ', err);
                    }
                });
            });
        });
    </script>

</body>

</html>