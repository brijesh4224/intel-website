<!DOCTYPE html>
<html lang="en">

<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>Accelerate AI Workloads on Amazon Web Services</title>
    <link href="https://cdn.jsdelivr.net/npm/bootstrap@5.0.2/dist/css/bootstrap.min.css" rel="stylesheet"
        integrity="sha384-EVSTQN3/azprG1Anm3QDgpJLIm9Nao0Yz1ztcQTwFspd3yD65VohhpuuCOmLASjC" crossorigin="anonymous">

    <link href=" https://fonts.cdnfonts.com/css/intel-clear " rel="stylesheet">
    <link rel="stylesheet" href="../css/owl.carousel.min.css">
    <link rel="stylesheet" href="../css/yatri.css">
    <link rel="stylesheet" href="../css/rushita.css">
    <link rel="stylesheet" href="../css/rushita_automotive.css">

    <link rel="stylesheet" href="../css/owl.theme.default.min.css">
    <style>
        * {
            font-family: 'Intel Clear', sans-serif;
        }

        .dk_new_options_table {
            border: none !important;
            justify-content: center !important;
            text-align: center !important;
        }

        .dk_new_options_table thead tr td {
            margin-left: 0;
            max-width: fit-content;
            white-space: normal;
            overflow: auto;
            background: #fff;
            padding: 1rem;
            text-align: left;
            border-left: .125rem solid #e2e2e2;
            font-weight: 700 !important;
        }

        .dk_new_options_table thead tr:nth-child(even) td {
            background-color: #f7f7f7;
        }

        .mv_intel_amx h2 {
            font-weight: 300;
        }

        .mv_intel_amx {
            font-size: 1.25rem;
        }

        .mv_intel_amx_bg_color {
            background-color: #0068B5;
        }

        .mv_intel_amx_content {
            padding-right: 200px;
        }

        .mv_intel_amx_item {
            align-content: center;
        }

        .mv_intel_amx {
            color: #fff;
            padding: 1rem;
        }

        .mv_intel_amx h3 {
            font-weight: 300;
        }

        .mv_intel_amx p {
            margin-top: 1.5rem;
            margin-bottom: 0rem;
        }

        .mv_intel_amx_image {
            padding: 1rem;
        }

        .mv_intel_amx_image img {
            width: 100%;
            /* height: 199px; */
        }

        .mv_intel_amx_heading_text {
            font-size: 1.2rem;
            line-height: 1.15;
        }

        .VK_sidebar_active_link {
            color: #262626;
            font-weight: 700;
        }

        .VK_sidebar_active_link:hover {
            color: #262626;
        }

        .VK_print_email_font span {
            font-size: 1.375rem;
        }

        .VK_side_bar_postion_stickey {
            position: sticky;
            top: 0px;
            z-index: 3;
            background-color: #fff;
        }

        .VK_side_heading {
            font-size: 26px;
            font-weight: 400;
        }

        .VK_sidebar_dropdown P {
            margin-left: .313rem !important;
            margin-bottom: .313rem !important;
        }

        .VK_sidebar_dropdown details {
            margin-left: .313rem !important;
            margin-bottom: .313rem !important;
        }
    </style>
</head>

<body>
    <div id="navbar"></div>

    <section class="m_ai_tdrop">
        <div>
            <button class="btn dropdown-toggle" type="button" data-bs-toggle="dropdown" aria-expanded="false">
                Developers
            </button>
            <ul class="dropdown-menu">
                <li><a class="dropdown-item m_dropActive"
                        href="../dhruvin_developer-tools/ds_Developer-Zone.html">Overview</a></li>
                <li><a class="dropdown-item m_dropActive"
                        href="../rushita_Solutions/k_solutions_in_Viewall_SDF_Industrial-Automation_Control-flow-Enforcement_Technology.html">Topics
                        & Technologies</a></li>
                <li><a class="dropdown-item m_dropActive"
                        href="../dhruvin_developer-tools/ds_Development-Tools.html">Tools</a></li>
                <li><a class="dropdown-item m_dropActive"
                        href="../rushita_Solutions/k_solutions_in_Viewall_SDF_Industrial-Automation_Hardware-Platforms.html">Hardware
                        Platforms</a></li>
                <li><a class="dropdown-item m_dropActive"
                        href="../dhruvin_developer-tools/ds_Resource-Documentation-Center.html">Resources &
                        Documentation</a></li>
                <li><a class="dropdown-item m_dropActive" href="../dhruvin_developer-tools/ds_Learn.html">Learn</a>
                </li>
                <li><a class="dropdown-item m_dropActive"
                        href="../dhruvin_developer-tools/ds_Communities-and-Events.html">Community & Events</a></li>
                <li><a class="dropdown-item m_dropActive"
                        href="../dhruvin_developer-tools/ds_Developer-Programs.html">Developer Programs</a></li>
                <li><a class="dropdown-item m_dropActive" href="../dhruvin_developer-tools/ds_Get-Help.html">Get
                        Help</a></li>
            </ul>
        </div>


        <div class="m_ai_shlash">/</div>
        <div>
            <button class="btn dropdown-toggle" type="button" data-bs-toggle="dropdown" aria-expanded="false">
                Tools
            </button>
            <ul class="dropdown-menu">
                <li><a class="dropdown-item m_dropActive" href="../Product/B20_developer_catelog.html">Software
                        Catalog</a></li>
                <li><a class="dropdown-item m_dropActive" href="../Product/B17_oneapi.html">oneAPI</a></li>
                <li><a class="dropdown-item m_dropActive"
                        href="../rushita_Solutions/k_solutions_Intel-Tiber™Edge-Platform.html">Intel® Tiber™ Edge
                        Platform</a></li>
                <li><a class="dropdown-item m_dropActive" href="../Product/B10_intel_Quarts.html">FPGA</a></li>
                <li><a class="dropdown-item m_dropActive" href="../VK_developers/VK_technology_sdk.html">Intel®
                        Active Management Technology SDK</a></li>
                <li><a class="dropdown-item m_dropActive" href="../VK_developers/VK_intel_adviser.html">Intel®
                        Advisor</a></li>
                <li><a class="dropdown-item m_dropActive" href="#">Intel® AI Reference Models</a></li>
                <li><a class="dropdown-item m_dropActive"
                        href="../rushita_Solutions/k_solutions_Intel-Collaboration-Suite-for-WebRTC.html">Intel®
                        Collaboration Suite for WebRTC SDK</a>
                </li>
                <li><a class="dropdown-item m_dropActive" href="../Product/B1_19_Intel_AICloud.html">Intel® Tiber™
                        AI Cloud</a></li>
                <li><a class="dropdown-item m_dropActive"
                        href="../rushita_Solutions/k_solutions_Intel-Distribution-for-Python.html">Intel® Distribution
                        for Python*</a></li>
                <li><a class="dropdown-item m_dropActive"
                        href="../rushita_Solutions/k_solutions_Intel-Distribution-for-GDB.html">Intel® Distribution for
                        GDB*</a></li>
                <li><a class="dropdown-item m_dropActive" href="#">Intel® DPC++ Compatibility Tool</a></li>
                <li><a class="dropdown-item m_dropActive" href="#">Intel® Dynamic Application Loader</a></li>
                <li><a class="dropdown-item m_dropActive"
                        href="../rushita_Solutions/k_solutions_Topics_viewall_Cloud-Insider-Program_AI-Frameworks-and-Tools.html">Frameworks</a>
                </li>
                <li><a class="dropdown-item m_dropActive" href="#">Intel® Embree</a></li>
                <li><a class="dropdown-item m_dropActive" href="../VK_developers/VK_ai_scikit.html">Intel® Extension
                        for Scikit-learn*</a></li>
                <li><a class="dropdown-item m_dropActive"
                        href="../rushita_Solutions/k_solutions_Intel-Fortran-Compiler.html">Intel® Fortran Compiler</a>
                </li>
                <li><a class="dropdown-item m_dropActive" href="#">Intel® Graphics Performance Analyzers</a></li>
                <li><a class="dropdown-item m_dropActive"
                        href="../rushita_Solutions/k_solutions_Intel-HE-Toolkit.html">Intel® Homomorphic Encryption
                        Toolkit</a></li>
                <li><a class="dropdown-item m_dropActive"
                        href="../rushita_Solutions/k_solutions_Intel-In-Band-Manageability.html">Intel® In-Band
                        Manageability</a></li>
                <li><a class="dropdown-item m_dropActive"
                        href="../rushita_Solutions/k_solutions_Intel-Cryptography-Primitives-Library.html">Intel®
                        Integrated Performance Primitives</a></li>
                <li><a class="dropdown-item m_dropActive" href="../rushita_Solutions/">Intel® Integrated Simulation
                        Infrastructure with
                        Modeling</a></li>
                <li><a class="dropdown-item m_dropActive"
                        href="../rushita_Solutions/k_solutions_Instruction-Set-Architecture(ISA)Extensions.html">Instruction
                        Set Architecture (ISA) Extensions</a>
                </li>
                <li><a class="dropdown-item m_dropActive"
                        href="../rushita_Solutions/k_solutions_Intel-Intelligent-Storage-Acceleration-Library.html">Intel®
                        Intelligent Storage Acceleration Library
                        (Intel® ISA-L)</a></li>
                <li><a class="dropdown-item m_dropActive" href="#">Modin*</a></li>
                <li><a class="dropdown-item m_dropActive" href="#">Intel® MPI Library</a></li>
                <li><a class="dropdown-item m_dropActive" href="#">Intel® Neural Compressor</a></li>
                <li><a class="dropdown-item m_dropActive" href="#">OpenCL™ Runtime</a></li>
                <li><a class="dropdown-item m_dropActive" href="#">Intel® Open Image Denoise</a></li>
                <li><a class="dropdown-item m_dropActive" href="#">Intel® Open Path Guiding Library (Intel® Open
                        PGL)</a></li>
                <li><a class="dropdown-item m_dropActive" href="#">Pin</a></li>
                <li><a class="dropdown-item m_dropActive" href="#">Intel® Platform Analysis Library</a></li>
                <li><a class="dropdown-item m_dropActive" href="#">Intel Tools for OpenCL™ Software</a></li>
                <li><a class="dropdown-item m_dropActive" href="#">Intel Tools for OpenCL™ Applications</a></li>
                <li><a class="dropdown-item m_dropActive" href="#">Intel® OpenSWR</a></li>
                <li><a class="dropdown-item m_dropActive" href="#">OpenVINO™ Toolkit</a></li>
                <li><a class="dropdown-item m_dropActive" href="#">Intel® Open Volume Kernel Library</a></li>
                <li><a class="dropdown-item m_dropActive" href="#">Intel® Optimization for XGBoost*</a></li>
                <li><a class="dropdown-item m_dropActive" href="#">Intel® OSPRay</a></li>
                <li><a class="dropdown-item m_dropActive" href="#">Intel® OSPRay for Hydra*</a></li>
                <li><a class="dropdown-item m_dropActive" href="#">Intel® OSPRay Studio</a></li>
                <li><a class="dropdown-item m_dropActive" href="#">PyTorch* Optimizations from Intel</a></li>
                <li><a class="dropdown-item m_dropActive" href="#">TensorFlow* Optimizations from Intel</a></li>
                <li><a class="dropdown-item m_dropActive" href="#">Intel® Rendering Toolkit</a></li>
                <li><a class="dropdown-item m_dropActive" href="#">Intel® Smart Edge Open</a></li>
                <li><a class="dropdown-item m_dropActive" href="#">Intel® Software Guard Extensions</a></li>
                <li><a class="dropdown-item m_dropActive" href="#">Intel® Secure Device Onboard</a></li>
                <li><a class="dropdown-item m_dropActive" href="#">Intel® Software Development Emulator</a></li>
                <li><a class="dropdown-item m_dropActive" href="#">Intel® Trust Domain Extensions (Intel® TDX)</a>
                </li>
                <li><a class="dropdown-item m_dropActive" href="#">Intel® Quantum SDK</a></li>
                <li><a class="dropdown-item m_dropActive" href="#">Intel® Query Processing Library (Intel® QPL)</a>
                </li>
                <li><a class="dropdown-item m_dropActive" href="#">Intel® Video Processing Library</a></li>
                <li><a class="dropdown-item m_dropActive" href="#">Intel® VTune™ Profiler</a></li>
                <li><a class="dropdown-item m_dropActive" href="#">Resellers</a></li>
            </ul>
        </div>
        <div class="m_ai_shlash">/</div>
        <div>
            <button class="btn dropdown-toggle" type="button" data-bs-toggle="dropdown" aria-expanded="false">
                oneAPI
            </button>
            <ul class="dropdown-menu">
                <li><a class="dropdown-item m_dropActive" href="#">Overview</a></li>
                <li><a class="dropdown-item m_dropActive" href="#">Data Parallel C++/SYCL*</a></li>
                <li><a class="dropdown-item m_dropActive" href="#">Toolkits</a></li>
                <li><a class="dropdown-item m_dropActive" href="#">Tech Articles & How-Tos</a></li>
                <li><a class="dropdown-item m_dropActive" href="#">Components</a></li>
                <li><a class="dropdown-item m_dropActive" href="#">Code Samples</a></li>
                <li><a class="dropdown-item m_dropActive" href="#">Training</a></li>
                <li><a class="dropdown-item m_dropActive" href="#">Documentation</a></li>
                <li><a class="dropdown-item m_dropActive" href="#">Support</a></li>
            </ul>
        </div>
        <div class="m_ai_shlash">/</div>
        <div>
            <button class="btn dropdown-toggle" type="button" data-bs-toggle="dropdown" aria-expanded="false">
                Tech Articles & How-Tos
            </button>
            <ul class="dropdown-menu">
                <li><a class="dropdown-item m_dropActive" href="#">Library</a></li>
                <li><a class="dropdown-item m_dropActive" href="#">News Updates</a></li>
                <li><a class="dropdown-item m_dropActive" href="#">Webinars</a></li>
            </ul>
        </div>
        <div class="m_ai_shlash">/</div>
        <div class="m_ai_httl">Accelerate AI Workloads on Amazon Web Services
        </div>
    </section>
    <section class="k_bgblue">
        <div class="k_container11">
            <div class="row text-white py-4">
                <h2 class="fw-light">Accelerate Your AI Workloads with Intel® Optimized AI Software on Amazon Web Services (AWS)*</h2>
            </div>
        </div>
    </section>
    <section class="k_space k_spacenone">
        <div class="k_container11">
            <div class="row  g-3">
                <div class="float-end k_bignone" style="padding-left:70%;">
                    <div>
                        <a href="#" class="fs-4"><i class="fa-solid fa-print mx-3 k_icon0"></i></a>
                        <a href="#" class="fs-4"> <i class="fa-regular fa-envelope k_icon0"></i></a>
                    </div>
                </div>
                <div class="col-lg-3 col-md-4 col-sm-12">
                    <div class="VK_sticky_side_bar VK_side_bar_postion_stickey">
                        <div>
                            <div class="VK_sidebar_dropdown">
                                <ul class="k_listnone k_menu ">
                                    <li class="k_text px-2"><a href="#section1">Summary of Intel® AI Analytics Toolkit (AI Kit)</a></li>
                                    <li class="k_text px-2"><a href="#section1">Get Started</a></li>
                                    <li class="k_text px-2"><a href="#section1">Amazon SageMaker*</a></li>
                                    <li class="k_text px-2"><a href="#section1">AWS EC2* Instances Powered by Intel Processors and Accelerators for AI</a></li>
                                    <li class="k_text px-2"><a href="#section1">Intel® Optimization for TensorFlow* on AWS*</a></li>
                                  
                                    <li class="k_text"><a href="#" class="k_submenu-toggle">AWS Marketplace</a>
                                        <ul class="k_listnone k_submenu">
                                            <li class="k_text"><a href="#"></a>Classical Machine Learning:</a></li>
                                            <li class="k_text"><a href="#"></a>Deep Learning:</a></li>
                                        </ul>
                                    </li>
                                    <li class="k_text"><a href="#" class="k_submenu-toggle">What’s Next?</a>
                                        <ul class="k_listnone k_submenu">
                                            <li class="k_text"><a href="#"></a>Expert Tips</a></li>
                                            <li class="k_text"><a href="#"></a>Useful Resources</a></li>
                                        </ul>
                                    </li>
                                </ul>
                            </div>
                        </div>
                    </div>
                    <div>
                        <p><b>Get the Latest on All Things CODE</b></p>
                        <p class="text-center k_btnget py-2 k_under k_btn100 my-2 kcokbtn1024" style="width: 80px;">
                            <a href="#" class="text-white">Sign Up</a>
                        </p>
                        <div class=" mt-4 ">
                          
                            <div>
                                <p class="k_plink1"><b>Stefana Raileanu</b>, <i>AI software solutions engineer</i><br>
                                    <a href="#">LinkedIn</a></p>
                                    <p class="k_plink1"><b>Ramya Ravi</b>, <i>AI software marketing engineer</i><br>
                                        <a href="#">LinkedIn</a></p>
                                        <p>Intel Corporation</p>
                            </div>
                        </div>
                    </div>
                </div>
                <div class="col-lg-8 col-md-7 col-sm-12  k_16smpx k_width75">
                    <div class="float-end mx-3 k_smnone">
                        <div>
                            <a href="#" class="fs-4"><i class="fa-solid fa-print mx-3 k_icon0"></i></a>
                            <a href="#" class="fs-4"> <i class="fa-regular fa-envelope k_icon0"></i></a>
                        </div>
                    </div>
                    <div class=" k_smpaddnone k_smpaddnone1 pt-5">
                        <p class="k_plink1 k_intext1blue1">Amazon Web Services (AWS)* and Intel have been collaborating for more than 16 years to develop, build, and support cloud services. The collaboration also focuses on AI software and hardware integration. This article focuses on how to use Intel-optimized AI software on AWS for <a href="#">classical machine learning</a> and deep learning.</p>
                        <h2 class="fw-light">Summary of Intel® AI Analytics Toolkit (AI Kit)</h2>
                        <p>The Intel AI Analytics Toolkit (<a href="#" style="color:blue; text-decoration:underline">AI Kit</a>) allows data scientists, developers, and researchers to use AI tools and frameworks to accelerate end-to-end data science and analytics pipelines on Intel® architecture. The components are built using oneAPI libraries for low-level compute optimizations. This toolkit maximizes performance from preprocessing through machine learning and provides interoperability for efficient model development.</p>
                        <p>As of February 2023, the AI Kit has optimizations for the following frameworks and libraries:</p>
                        <ul>
                            <li><a href="#" style="color:blue; text-decoration:underline">TensorFlow</a>*<br>
                            Starting with TensorFlow 2.9, the optimizations by Intel are up-streamed automatically to the original distribution. For TensorFlow versions between 2.5 and 2.9, Intel optimizations can be enabled by setting the environment variable: <span class="code-simple">TF_ENABLE_ONEDNN_OPTS=1</span>. <a href="#" style="color:blue; text-decoration:underline">Intel® Extension for TensorFlow*</a>, an extension plug-in based on TensorFlow PluggableDevice interface, enables the use of Intel GPUs with TensorFlow and facilitates the use of additional features such as Advanced Auto Mixed Precision (AMP) and quantization.</li>
                            <li><a href="#" style="color:blue; text-decoration:underline">PyTorch</a>*<br>
                            Most optimizations are already up-streamed to the original distribution of PyTorch. For an extra performance boost on Intel hardware, such as Intel CPUs and GPUs, the <a href="#" style="color:blue; text-decoration:underline">Intel® Extension for PyTorch*</a> is available.</li>
                            <li><a href="#" style="color:blue; text-decoration:underline">scikit-learn</a>*<br>
                            With <a href="#" style="color:blue; text-decoration:underline">Intel® Extension for Scikit-learn*</a>, you can accelerate your scikit-learn applications and still have full conformance with all scikit-learn APIs and algorithms. Intel Extension for Scikit-learn is a free software AI accelerator that brings up to 100X acceleration across a variety of applications.</li>
                            <li ><a href="#" style="color:blue; text-decoration:underline">XGBoost</a><br>
                            In collaboration with the XGBoost community, Intel has been directly upstreaming many <a href="#" style="color:blue; text-decoration:underline">optimizations for XGBoost</a>. These optimizations provide superior performance on Intel CPUs. To achieve better <a href="#" class="k_plink k_intext1blue">inference</a> performance, XGBoost models can be converted using <a href="#" style="color:blue; text-decoration:underline">daal4py</a>, a tool created to give data scientists the easiest way to use the <a href="#" style="color:blue; text-decoration:underline">Intel® oneAPI Data Analytics Library (oneDAL)</a>.</li>
                            <li><a href="#" style="color:blue; text-decoration:underline">Modin</a>*<br>
                            Modin* is a drop-in replacement for pandas. This enables data scientists to scale to distributed DataFrame processing without any API code-related changes. Intel® Distribution of Modin* adds optimizations to further accelerate processing on Intel hardware.</li>
                        </ul>
                        <p>Additionally, Intel also offers:</p>
                        <ul>
                            <li><a href="#" style="color:blue; text-decoration:underline">Intel® Distribution for Python*</a>—a distribution&nbsp;optimized for Intel architecture</li>
                            <li><a href="#" style="color:blue; text-decoration:underline">Intel® Neural Compressor</a>—a deep learning tool for model compression</li>
                            <li><a href="#" style="color:blue; text-decoration:underline">Model Zoo for Intel® Architecture</a> —a collection of pretrained models, sample scripts, best practices, and tutorials for open source machine learning models to run on Intel® Xeon® Scalable processors</li>
                        </ul>
                        <h2 class="fw-light">Get Started</h2>
                        <h2 class="fw-light">Amazon SageMaker*</h2>
                        <p>Amazon SageMaker* is a platform that enables developers to create, train, and deploy machine learning models in the cloud. To take advantage of Intel AI software optimizations in SageMaker, you must set the <a href="#" style="color:blue; text-decoration:underline">instance type</a> behind Amazon SageMaker services (for example, SageMaker Studio notebooks, training jobs, or endpoints) based on Intel hardware. In Table 1<em>,</em> you can see the description of all AWS instances available in SageMaker Studio as of February 2023. To change the instance to a different one from<em> </em>Table 1 in SageMaker Studio, turn off the <strong>Fast launch only</strong> option (usually turned on by default), to see all available instances.</p>
                        <div class="my-5">
                            <img src="../img/rushita_img/LLM3.png" alt="" width="100%">
                        </div>
                        <p>Most tools available in the AI Kit can be installed through conda* or PyPI (you can find more details on installing external libraries and kernels in SageMaker notebook instances in <a href="#" style="text-align: justify; color: blue; text-decoration-line: underline;">this guide</a>). Below is a quick list of installation instructions for the AI Kit components (you must go through the installation guide for each tool to make sure you fulfill the software and hardware requirements).</p>
                        <ul style="list-style-type:square">
                            <li><strong>Intel® Distribution for Python*</strong><br>
                            <span class="code-simple" style="background-color: #E6E6E6;">conda install -c https://software.repos.intel.com/python/conda/ python</span> (This distribution does not contain basic packages such as NumPy.)<br>
                            <em>or</em><br>
                            <span class="code-simple" style="background-color: #E6E6E6;">conda install -c https://software.repos.intel.com/python/conda/ intelpython3_core</span> (This installation option includes NumPy and other basic packages.)<br>
                            <em>or</em><br>
                            <span class="code-simple" style="background-color: #E6E6E6;">conda install -c https://software.repos.intel.com/python/conda/ intelpython3_full</span> (This is the most complete distribution of Python that, in addition to basic packages, includes libraries such as scikit-learn, scikit-learn extension, XGBoost and daal4py.)</li>
                            <li><strong>Intel® Extension for TensorFlow*</strong><sup>1</sup><br>
                            GPU:<br>
                            <span class="code-simple" style="background-color: #E6E6E6;">pip install tensorflow==2.11.0</span><br>
                            <span class="code-simple" style="background-color: #E6E6E6;">pip install --upgrade intel-extension-for-tensorflow[gpu]</span><br>
                            CPU:<br>
                            <span class="code-simple" style="background-color: #E6E6E6;">pip install tensorflow==2.11.0</span><br>
                            <span class="code-simple" style="background-color: #E6E6E6;">pip install --upgrade intel-extension-for-tensorflow[cpu]</span></li>
                            <li><strong>Intel Extension for PyTorch</strong><sup>2</sup><br>
                            GPU<em>:</em><br>
                            <span class="code-simple" style="background-color: #E6E6E6;">python -m pip install torch==1.13.0a0 -f https://developer.intel.com/ipex-whl-stable-xpu</span><br>
                            <span class="code-simple" style="background-color: #E6E6E6;">python -m pip install intel_extension_for_pytorch==1.13.10+xpu -f https://developer.intel.com/ipex-whl-stable-xpu</span><br>
                            CPU<em>:</em><br>
                            <span class="code-simple" style="background-color: #E6E6E6;">pip install intel_extension_for_pytorch</span><br>
                            <em>or</em><br>
                            <span class="code-simple" style="background-color: #E6E6E6;">pip install intel_extension_for_pytorch -f https://developer.intel.com/ipex-whl-stable-cpu</span></li>
                            <li><strong>Intel Extension for Scikit-learn</strong><br>
                            <span class="code-simple" style="background-color: #E6E6E6;">pip install scikit-learn-intelex</span><br>
                            or<br>
                            <span class="code-simple" style="background-color: #E6E6E6;">conda install -c conda-forge scikit-learn-intelex</span></li>
                            <li><strong>Intel Optimization for XGBoost</strong><br>
                            <span class="code-simple">pip install xgboost</span><br>
                            <span class="code-simple">pip install daal4py</span> (daal4py is used to optimize XGBoost models and speed up inference on Intel architecture)</li>
                            <li><strong>Modin</strong><br>
                            <span class="code-simple" style="background-color: #E6E6E6;">pip install modin[all]</span> (open <s>-</s>source Modin package, to which Intel also heavily contributes and maintains)<br>
                            or<br>
                            <span class="code-simple" style="background-color: #E6E6E6;">conda install -c https://software.repos.intel.com/python/conda/ modin-all</span> (Intel® Distribution of Modin*)</li>
                            <li><strong>Intel Neural Compressor</strong><br>
                            <span class="code-simple" style="background-color: #E6E6E6;">pip install neural-compressor</span><br>
                            or<br>
                            <span class="code-simple" style="background-color: #E6E6E6;">conda install -c https://software.repos.intel.com/python/conda/ neural-compressor</span></li>
                        </ul>
                        <p>Also, check out the <a href="#" style="color:blue; text-decoration:underline">quick start guide</a> to take advantage of Intel AI optimizations for popular frameworks.</p>
                        <div class="my-4">
                            <img src="../img/rushita_img/LLM4.png" alt="" width="100%">
                            <strong>Table1.&nbsp;<a href="#" style="color:blue; text-decoration:underline">AWS Available Studio Instance Types</a></strong>
                        </div>
                        <p>Legend:</p>
                        <div class="my-5">
                            <img src="../img/rushita_img/LLM5.png" alt="" width="100%">
                        </div>
                        <p>As most of Intel’s software optimizations use <a href="#" style="color:blue; text-decoration:underline">Intel® Advanced Vector Extensions 512 (Intel® AVX-512)</a>, it is necessary to choose an instance based on Intel Xeon Scalable processors to see the performance boost. To specifically take advantage of the deep learning optimizations available in the AI Kit, <a href="#" style="color:blue; text-decoration:underline">Intel Deep Learning Boost (Intel DL Boost) (VNNI)</a>, <a href="#" style="color:blue; text-decoration:underline">Intel AVX-512 with FP16 instruction set</a> or Intel® Advanced Matrix Extensions (Intel® AMX) with bfloat16 instructions are required as these instructions are leveraged by the software to optimize deep learning training and inference workloads. The 4th generation Intel Xeon Scalable processor is the first generation that supports Intel® AMX with bfloat16 along with Intel® AVX-512 with FP16. Therefore, we recommend using instances based on 4th generation Intel Xeon Scalable processors for deep Learning when they become available in SageMaker. To ensure software compatibility, make sure to check the software requirements of the optimization tool and check that it is compatible with the chosen image in SageMaker. <a href="#" style="color:blue; text-decoration:underline">Here is a description</a> of current available images in SageMaker. This <a href="#" style="color:blue; text-decoration:underline">link</a> describes how to create and import your custom image in SageMaker.</p>

                        <h2 class="fw-light">AWS EC2* Instances Powered by Intel Processors and Accelerators for AI</h2>
                        <p>In November 2022, Amazon announced <a href="#" style="color:blue; text-decoration:underline">the first EC2 instances powered by 4th generation Intel Xeon Scalable processors</a>. These are the first AWS instances powered by Intel to support Intel AMX with bfloat16 along with Intel® AVX-512 with FP16. Check out <a href="#" style="color:blue; text-decoration:underline">this guide</a> to use AI software optimizations directly on AWS instances.</p>
                        <p><a href="#" style="color:blue; text-decoration:underline">AWS is also the only cloud service provider</a>, as of February 2023, that offers an <a href="#" style="color:blue; text-decoration:underline">instance type (DL1)</a> based on <a href="#" style="color:blue; text-decoration:underline">Habana Gaudi</a>*, a type of integrated circuit chip customized for deep learning (currently the instance is only available in selected regions).</p>

                        <h2 class="fw-light">Intel® Optimization for TensorFlow* on AWS*</h2>
                        <p>Additionally, if you are particularly interested in TensorFlow, on the Intel® Developer Zone platform you can find several performance analyses on AWS. <a href="#" style="color:blue; text-decoration:underline">This article</a> compares the performance benefits of TensorFlow 2.8 with oneDNN optimizations on AWS C6i instance types and TensorFlow 2.8 without oneDNN, while <a href="#" style="color:blue; text-decoration:underline">this one</a> compares the inference performance using TensorFlow 2.9 for 3rd gen Intel Xeon processor instance type and 3rd gen AMD EPYC instance type.</p>

                        <h2 class="fw-light">AWS Marketplace</h2>
                        <p>AWS Marketplace provides a channel for independent software vendors (ISVs) and AWS consulting partners to provide their solutions to AWS customers for free or for a cost. Since Intel AI Analytics Toolkit is free, there are no software fees associated with its components offered on AWS Marketplace.</p>
                        <p>There are several delivery methods for the products available in the marketplace. More details on this can be found <a href="#" style="color:blue; text-decoration:underline">here</a>.</p>
                        <h3>Classical Machine Learning:<a class="inpage-nav-anchor" id="inpage-nav-5-undefined"></a></h3>
                        <ol>
                            <li>Scikit-learn<br>
                            <a href="#" style="color:blue; text-decoration:underline">Scikit-learn* with Intel® oneAPI Data Analytics Library (oneDAL)</a><br>
                            Scikit-learn* with Intel® oneAPI Data Analytics Library (oneDAL) is a daal4py optimized version of scikit-learn with a set of Python* modules for machine learning and data mining. To optimize workloads based on the latest version of scikit-learn, use <a href="#" style="color:blue; text-decoration:underline">Intel® Extension for Scikit-learn*</a>.<br>
                            <a href="#" style="color:blue; text-decoration:underline">Delivery Method: Container</a>&nbsp;</li>
                            <li>XGBoost<br>
                            <a href="#" style="color:blue; text-decoration:underline">Intel® Optimization for XGBoost</a>*<br>
                            XGBoost is an optimized distributed gradient boosting library designed to be highly efficient, flexible, and portable. It implements machine learning algorithms under the Gradient Boosting framework. XGBoost provides a parallel tree boosting (also known as GBDT, GBM) that solves many data science problems in a fast and accurate way.<br>
                            <a href="#" style="color:blue; text-decoration:underline">Delivery Method: Container</a></li>
                        </ol>
                        <h3>Deep Learning:<a class="inpage-nav-anchor" id="inpage-nav-5-1"></a></h3>
                        <ol>
                            <li>TensorFlow<br>
                            <a href="#" style="color:blue; text-decoration:underline">Intel Optimization for TensorFlow with Jupyter Notebook</a><br>
                            This is a binary distribution of TensorFlow with Intel® oneAPI Deep Neural Network Library (oneDNN) primitives.<br>
                            <a href="#" style="color:blue; text-decoration:underline">Delivery Method: Container</a><br>
                            <br>
                            <a href="#" style="color:blue; text-decoration:underline">Intel Optimization for TensorFlow Training</a><br>
                            This includes the Python* 3 interpreter and the following preinstalled wheels and libraries: Intel® Optimization for TensorFlow, Open MPI, Horovod*.<br>
                            <a href="#" style="color:blue; text-decoration:underline">Delivery Method: Container</a><br>
                            <br>
                            <a href="#" style="color:blue; text-decoration:underline">Intel Optimization for TensorFlow Serving</a><br>
                            This is a flexible, high-performance serving system for machine learning models, designed for production environments.<br>
                            <a href="#" style="color:blue; text-decoration:underline">Delivery Method: Container</a><br>
                            <br>
                            <a href="#" style="color:blue; text-decoration:underline">TensorFlow Perf Comparison with Jupyter Notebooks</a><br>
                            This is a container with Jupyter* Notebooks and preinstalled environments for analyzing the performance benefit from using Intel Optimization for TensorFlow with oneAPI Deep Neural Network Library (oneDNN).<br>
                            <a href="#" style="color:blue; text-decoration:underline">Delivery Method: Container</a><br>
                            <br>
                            <a href="#" style="color:blue; text-decoration:underline">Intel Optimization for TensorFlow on Ubuntu</a><br>
                            Intel Optimization for TensorFlow on Ubuntu Container 2.9.1-ubuntu-22.04 contains support for Intel Optimization for TensorFlow version 2.9.1 with Ubuntu 22.04 and Python 3.10.<br>
                            <a href="#" style="color:blue; text-decoration:underline">Delivery Method: Container</a><br>
                            <br>
                            <a href="#" style="color:blue; text-decoration:underline">BERT FP32 Training and oneDNN with TensorFlow</a><br>
                            A container based on Ubuntu 20.04 that has all components necessary to train or re-train BERT Large with FP32 precision using Intel Optimizations for TensorFlow 2.3. Includes MPI 2.1.1 and Horovod* 20.3.<br>
                            <a href="#" style="color:blue; text-decoration:underline">Delivery Method: Container</a></li>
                        </ol>
                        <p>&nbsp;</p>
                        <ol start="2">
                            <li>PyTorch<br>
                            <a href="#" style="color:blue; text-decoration:underline">Intel Extension for PyTorch</a><br>
                            This extends the original PyTorch framework by creating extensions that optimize performance of deep learning models. This container contains PyTorch v1.12.100 and Intel Extension for PyTorch v1.12.100.<br>
                            <a href="#" style="color:blue; text-decoration:underline">Delivery Method: Container</a></li>
                        </ol>
                        <p>&nbsp;</p>
                        <ol start="3">
                            <li>OpenVINO™<br>
                            <a href="#" style="color:blue; text-decoration:underline">Intel® Distribution of OpenVINO™ Toolkit</a><br>
                            This is a comprehensive toolkit for quickly developing applications and solutions that solve a variety of tasks including emulation of human vision, automatic speech recognition, natural language processing, recommendation systems, and many others.<br>
                            <a href="#" style="color:blue; text-decoration:underline">Delivery Method: Amazon Machine Image</a></li>
                        </ol>
                        <p>&nbsp;</p>
                        <ol start="4">
                            <li>BigDL<br>
                            <a href="#" style="color:blue; text-decoration:underline">BigDL with Apache Spark</a>*<br>
                            This AMI (Linux/Unix) includes an Apache Spark instance, the Analytics Zoo and BigDL library, Jupyter Notebook, and Python, which you can use to train deep learning models.<br>
                            <a href="#" style="color:blue; text-decoration:underline">Delivery Methods: Amazon Machine Image</a><br>
                            <br>
                            <a href="#" style="color:blue; text-decoration:underline">BigDL Text Classifier on Analytics Zoo</a><br>
                            Build a text classification model with BigDL and Analytics Zoo. BigDL is a distributed deep learning library created specifically to train and use deep learning models in Apache Spark.<br>
                            <a href="#" style="color:blue; text-decoration:underline">Delivery Methods: Amazon SageMaker</a></li>
                        </ol>
                        <p>&nbsp;</p>
                        <ol start="5">
                            <li>Other<br>
                            <a href="#" style="color:blue; text-decoration:underline">Deep Learning Reference Stack</a><br>
                            The Deep Learning Reference Stack is an integrated, highly performant open source stack optimized for Intel Xeon Scalable platforms.<br>
                            <a href="#" style="color:blue; text-decoration:underline">Delivery Method: Amazon Machine Image</a></li>
                        </ol>
                        <p>The new additions in the Marketplace can be found by filtering the results by Publisher: Intel and Intel AI. Also, you can filter by delivery methods.</p>

                        <h2 class="fw-light">What’s Next?</h2>
                        <p>To stay up to date with new marketplace entries, new instances and any relevant collaboration with AWS, you can follow <a href="#" style="color:blue; text-decoration:underline">this partner showcase page</a>. We encourage you to learn more about and incorporate Intel’s other <a href="#" style="color:blue; text-decoration:underline">AI and machine learning framework optimizations</a> and <a href="#" style="color:blue; text-decoration:underline">end-to-end portfolio of tools</a> into your AI workflow. Also, visit Intel’s <a href="#" style="color:blue; text-decoration:underline">AI and machine learning page</a> to learn about Intel’s AI software development resources to prepare, build, deploy, and scale AI solutions.</p>
                        <p>For more details about the new 4th gen Intel Xeon Scalable Processors, visit <a href="#" style="color:blue; text-decoration:underline">AI Platform</a> where you can learn about how Intel is empowering developers to run end-to-end AI pipelines with Intel Xeon Scalable Processors.</p>
                        <h3>Useful Resources<a class="inpage-nav-anchor" id="inpage-nav-6-undefined"></a></h3>
                        <ul>
                            <li><a href="#" style="color:blue; text-decoration:underline">Intel AI Developer Tools and Resources</a></li>
                            <li><a href="#" style="color:blue; text-decoration:underline">oneAPI Unified Programming Model</a></li>
                            <li><a href="#" style="color:blue; text-decoration:underline">Official Documentation - Intel® Optimization for TensorFlow*</a></li>
                            <li><a href="#" style="color:blue; text-decoration:underline">Official Documentation - Intel® Optimization for PyTorch*</a></li>
                            <li><a href="#" style="color:blue; text-decoration:underline">Official Documentation - Intel® Extension for Scikit-learn*</a></li>
                            <li><a href="#" style="color:blue; text-decoration:underline">Official Documentation – Intel® Optimization for XGBoost*</a></li>
                            <li><a href="#" style="color:blue; text-decoration:underline">Official Documentation - Intel® Distribution of Modin</a></li>
                            <li><a href="#" style="color:blue; text-decoration:underline">Speed up your Machine Learning Workloads with Intel® Extension for Scikit-Learn in AutoGluon</a></li>
                            <li><a href="#" style="color:blue; text-decoration:underline">Model Zoo for Intel® Architecture</a></li>
                            <li><a href="#" style="color:blue; text-decoration:underline">Intel® Advanced Matrix Extensions Overview</a></li>
                            <li><a href="#" style="color:blue; text-decoration:underline">Accelerate AI Workloads with Intel® AMX</a></li>
                        </ul>
                    </div>
                </div>
            </div>
    </section>
    <section class="my-4" style="font-size: 13px;">
        <div class="k_container11">
            <div class="row">
                <div>
                    <hr class="mb-5">
                    <p>Product and Performance Information </p>
                    <div class="k_plink1 k_intext1blue1"><sup>1</sup>Refer to <a href="#">this link</a> for the latest version of Intel Extension for TensorFlow.</div>
                    <div class="k_plink1 k_intext1blue1"><sup>2</sup>Refer to <a href="#">this link</a> for the latest version of Intel® Extension for PyTorch*.</div>
                    <div class="k_plink1 k_intext1blue1"><sup>3</sup>Performance varies by use, configuration and other
                        factors. Learn more at &nbsp;<a href="#">www.Intel.com/PerformanceIndex.</a>.
                    </div>
                </div>
            </div>
        </div>
    </section>
    <div id="footer"></div>
    <script>
        // navbar include  
        fetch('../y_index/y_navbar.html')
            .then(response => response.text())
            .then(data => {
                document.getElementById('navbar').innerHTML = data;
            });
        // footer include 
        fetch('../y_index/y_footer.html')
            .then(response => response.text())
            .then(data => {
                document.getElementById('footer').innerHTML = data;
            });
    </script>
    <script src="https://cdn.jsdelivr.net/npm/@splidejs/splide@4.1.4/dist/js/splide.min.js"></script>
    <script src="../js/jquery-3.7.1.js"></script>

    <script src="../js/owl.carousel.min.js"></script>
    <script src="../js/rushita.js"></script>
</body>

</html>