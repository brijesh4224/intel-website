<!DOCTYPE html>
<html lang="en">

<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>RAG</title>
    <link href="https://cdn.jsdelivr.net/npm/bootstrap@5.0.2/dist/css/bootstrap.min.css" rel="stylesheet"
        integrity="sha384-EVSTQN3/azprG1Anm3QDgpJLIm9Nao0Yz1ztcQTwFspd3yD65VohhpuuCOmLASjC" crossorigin="anonymous">

    <link href=" https://fonts.cdnfonts.com/css/intel-clear " rel="stylesheet">
    <link rel="stylesheet" href="../css/owl.carousel.min.css">

    <link rel="stylesheet" href="../css/rushita.css">
    <link rel="stylesheet" href="../css/rushita_automotive.css">
    <link rel="stylesheet" href="../css/yatri.css">
    <link rel="stylesheet" href="../css/owl.theme.default.min.css">
    <style>
        * {
            font-family: 'Intel Clear', sans-serif;
        }

        * {
            margin: 0;
            padding: 0;
            box-sizing: border-box;
        }

        /* Sticky sidebar styles - now enforced for all screens including mobile */
        .sticky-sidebar {
            position: -webkit-sticky;
            /* For Safari */
            position: sticky;
            top: 0;
            overflow-y: auto;
            background-color: white;
            max-height: 100vh;
            z-index: 100;
            width: 100%;
        }

        .K_sticky_side_bar {
            padding: 10px;
        }

        /* Tab container styles */
        .tab-container {
            display: flex;
            flex-direction: column;
            gap: 8px;
        }



        .k_btn a {
            text-decoration: none;
            color: inherit;
            display: block;
            width: 100%;
            font-size: 14px;
        }


        /* Small screen specific styles */
        @media screen and (max-width: 425px) {
            .sticky-sidebar {
                position: sticky !important;
                /* Force sticky on mobile */
                top: 0 !important;
                left: 0;
                right: 0;
                width: 100%;
                background: white;
            }

            .K_sticky_side_bar {
                padding: 0px;
            }

            .k_btn {
                padding: 15px 10px;
                /* Larger touch target for mobile */
                margin-bottom: 5px;
            }

            .k_btn a {
                font-size: 16px;
                /* Larger font for better readability on mobile */
            }

            /* Ensure content below doesn't overlap */
            .sticky-sidebar+* {
                margin-top: 10px;
            }
        }
    </style>
</head>

<body>
    <div id="navbar"></div>

    <section class="m_ai_tdrop">
        <div class="m_ai_httl">
            What Is Retrieval-Augmented Generation (RAG)?</div>
        </div>
    </section>
    <section class="k_bgpista">
        <div class="k_container11">
            <div class="row  py-3">
                <div
                    class="col-lg-8 col-md-12 col-sm-12   mx-0 text-white align-content-center  k_tstartauto k_text2  px-0 mx-0 k_mdorder2 ">
                    <h3 class="fs3 mb-2 fw-lighter k_marketsmall">Harness the Full Potential of LLMs with RAG</h3>
                    <p class=" fs-5 k_md-small">RAG allows organizations to customize LLMs on their own data without retraining or fine-tuning, enabling organizations to deploy customized LLM applications quickly and cost-effectively.
                    </p>

                </div>
                <div class="col-lg-3 col-md-12 col-sm-12 k_mdimg  k_mdorder1">
                    <img src="../img/rushita_img/ragbg.avif" alt="" width="100%">
                </div>
            </div>
        </div>
    </section>
    <section class="my-3 k_spacenone">
        <div class="k_container11">
            <div class="row g-3">
                <div class="float-end k_bignone" style="padding-left:70%;">
                    <div>
                        <a href="#" class="fs-4"><i class="fa-solid fa-print mx-3 k_icon0"></i></a>
                        <a href="#" class="fs-4"> <i class="fa-regular fa-envelope k_icon0"></i></a>
                    </div>
                </div>
                <div class="col-lg-3 col-md-4 col-sm-12">

                    <div class="sticky-sidebar">
                        <div class="K_sticky_side_bar">
                            <div class="tab-container">
                                <div class="k_btn k_incorbtn1 k_text active" data-tab="key1">
                                    <a href="#key1">What is RAG?</a>
                                </div>
                                <div class="k_btn k_incorbtn1 k_text" data-tab="key2">
                                    <a href="#key2">What are the Benefits of RAG?</a>
                                </div>
                                <div class="k_btn k_incorbtn1 k_text" data-tab="key3">
                                    <a href="#key3">How Does RAG Work?</a>
                                </div>
                                <div class="k_btn k_incorbtn1 k_text " data-tab="key4">
                                    <a href="#key4">How Are People Using RAG?</a>
                                </div>
                                <div class="k_btn k_incorbtn1 k_text" data-tab="key5">
                                    <a href="#key5">Begin Your RAG Journey</a>
                                </div>
                            </div>
                        </div>
                    </div>
                    <div class="k_bggrey p-3">
                        <p><b>Key Takeaways
                            </b></p>
                            <ul>
                                <li><p>RAG is an AI framework that helps LLMs deliver more- accurate and -relevant responses by allowing models to access data not included in their training.</p>
                                </li>
                                <li><p>In enterprise settings, RAG enables organizations to customize LLMs on their proprietary data without retraining or fine-tuning.</p>
                                </li>
                                <li><p>RAG connects LLMs to a proprietary data knowledge base stored locally or in a private data center. This provides a practical way for businesses to continuously inject fresh data while keeping their data secure.</p>
                                </li>
                                <li><p>Without the need for fine-tuning, RAG enables organizations to customize and launch generative AI applications more quickly and cost-effectively.</p>
                                </li>
                              
                    </ul>
                    </div>
                </div>
                <div class="col-lg-8 col-md-7 col-sm-12 k_20px k_16smpx k_width75">
                    <div class="float-end mx-3 k_smnone">
                        <div>
                            <a href="#" class="fs-4 k_iconauto"><i class="fa-solid fa-print mx-3 k_icon0"></i></a>
                            <a href="#" class="fs-4"> <i class="fa-regular fa-envelope k_icon0"></i></a>
                        </div>
                    </div>
                    <div>
                        <div class="my-5 k_smpaddnone">
                            <h4 class="fw-lighter k_plink1 k_intext1blue1">Retrieval-augmented generation (RAG) allows organizations to ground LLMs on their own data without retraining or fine-tuning. This helps businesses deploy customized artificial intelligence (AI) capabilities at a fraction of the time and cost. Learn how using RAG can benefit your generative AI initiatives.</h4>
                        </div>
                        <h2 class="k_26px mt-5 fw-lighter pt-4">What Is RAG?</h2>
                        <p>Large language models (LLMs) like chatbots can quickly translate languages, answer customer questions with humanlike responses, and even generate code. However, LLMs are only familiar with information they’ve encountered during training. To effectively address ever-evolving and specialized knowledge areas—such as deep knowledge about your business and customers—LLMs need exposure to the latest data. While retraining or fine-tuning is an option, the process can require additional time and cost. Even then, LLMs may generate incorrect responses.</p>
                        <p>RAG, an increasingly popular AI framework, helps LLMs deliver more-accurate and -relevant AI responses. RAG supplements an LLM with data from an external knowledge base, ensuring LLMs can access the most-reliable and -current information. This additional data helps LLMs deliver up-to-date and contextually meaningful responses.</p>
                        <p>In enterprise settings, RAG offers organizations a cost-effective approach to generative AI. Off-the-shelf LLMs, known as foundational LLMs, are trained to respond to a broad range of topics. However, they often need to be customized to an organization’s data before they can produce business-specific results. RAG allows organizations to inject their own data into LLMs without retraining or fine-tuning, lowering the barrier of entry to domain-specific, tangible use cases.</p>
                        <p>For example, your organization could give employees access to a RAG-based chatbot to help boost productivity. To help plan your vacation, you could ask the chatbot how many vacation days you have available for the remainder of the year. The chatbot would search internal databases for relevant information, pulling your company’s vacation policy and how many vacation days you’ve already used to output how many days you can ask off work.</p>
                        <p>A foundational LLM that hasn’t been trained on your organization’s records could not provide an answer—or, worse, may confidently provide the wrong answer. In order to equip the foundational model to effectively answer the question, you’d need to fine-tune it to your company’s data every time someone takes a vacation day.</p>
                        <h2 class="k_26px mt-5 fw-lighter pt-4">What are the Benefits of RAG?</h2>
                        <p>Integrating RAG into generative AI applications has a range of benefits.<br>
                            &nbsp;</p>
                            <ul>
                                <li><strong>Cost-effective alternative to fine-tuning:</strong> In many cases, RAG can enable organizations to customize LLMs to their own domain and data at a fraction of the time and cost it takes to retrain or fine-tune models. This creates a shorter pathway to generative AI models that can deliver relevant and meaningful AI results to employees and customers.</li>
                                <li><strong>More reliable outcomes:</strong> Experts estimate that the world’s most popular LLMs generate incorrect outputs, or “hallucinate,” between 2 and 22 percent of the time.<sup>1</sup>&nbsp;By providing LLMs with additional context from reliable knowledge sources, RAG helps improve LLM accuracy and reduce hallucinations. RAG can also provide source citations so users can fact-check answers and research topics further.</li>
                                <li><strong>Up-to-the-minute insights:</strong> Using RAG, businesses can continuously inject new data into models, ensuring LLMs stay up to date with rapidly changing topics. RAG-based models can even connect directly to sources such as websites and social media feeds to generate answers with near-real-time information.&nbsp;</li>
                                <li><strong>Enhanced data privacy:</strong> Because external knowledge bases can be stored locally or in private data centers, RAG doesn’t require organizations to share confidential data with third-party LLMs. Organizations can customize and deploy models while keeping their data secure.</li>
                            </ul>

                        <h2 class="k_26px mt-5 fw-lighter pt-4">How Does RAG Work?</h2>
                        <p>A traditional LLM is trained on massive amounts of data from the internet, including articles, video transcripts, and chat forums. A RAG system adds a retrieval mechanism that cross-references information from a custom-built knowledge base before answering a prompt. The additional information strengthens the LLM’s training, resulting in an answer that better aligns with the user’s or the organization’s needs.</p>
                        <p class="k_plink1 k_intext1blue1">The first step to enabling a RAG-based LLM solution is to build a knowledge base. This private collection of data can include a variety of text-based sources, such as the company handbook and product briefs. You will need to do some work to prepare your data for efficient processing, including cleaning up the data, such as removing duplicate information, and breaking the data into manageable chunks. Then, a specialized AI model called an embedding model converts the text into vectors—mathematical representations of the text—that capture context and relationships between words. Vectors are stored in a <a href="#">vector database</a>&nbsp;for fast retrieval.</p>
                        <p>When a user or subsystem submits a query, it is passed through the core component of the workflow, the retrieval mechanism. This mechanism searches the vector database for relevant matches and shares the most relevant data with the LLM as additional context.</p>
                        <p>The LLM then combines its training with the external data to generate a final response, ensuring the user receives a contextually accurate and meaningful answer.</p>
                        <p class="k_plink1 k_intext1blue1">Dive deeper into these steps by reading our&nbsp;<a href="#">article on how to implement RAG.</a></p>

                        <h2 class="k_26px mt-5 fw-lighter pt-4">How Are People Using RAG?</h2>
                        <p>Organizations across industries are using RAG to drive employee productivity, deliver personalized experiences, and reduce operational costs.</p>
                        <p>Here are a few examples of how RAG is transforming industries.&nbsp;</p>
                        <ul>
                            <li class="k_plink1 k_intext1blue1"><strong>Personalized shopping experiences:</strong> RAG-based retail recommendation systems can collect real-time customer preferences and market trends from sources such as search engines and X (formerly Twitter). This enables retailers to provide up-to-the-minute, personalized product recommendations to each shopper. <a href="#">Read more.</a></li>
                            <li class="k_plink1 k_intext1blue1"><strong>Predictive manufacturing maintenance:</strong> By tapping into historical performance data, equipment-specific data, and live sensor data, RAG-based anomaly detection systems can catch equipment irregularities at the earliest signs of trouble, allowing manufacturers to address potential issues before they lead to downtime. In-depth knowledge of complex machinery enables RAG systems to detect subtle changes in equipment speed and precision that are often missed by traditional systems. <a href="#">Read more.</a></li>
                            <li class="k_plink1 k_intext1blue1"><strong>Financial services AI assistants:</strong> RAG-based chatbots can synthesize a complex web of real-time market trends and regulations and provide users with timely, customized, and actionable financial advice. These powerful AI assistants help financial institutions deliver customized advice across a large customer base while complying with ever-evolving regulations. <a href="#">Read more.</a>&nbsp;</li>
                        </ul>


                        <h2 class="k_26px mt-5 fw-lighter pt-4">Take the Next Step in Your RAG Journey</h2>
                        <p>As you seek to capture the value and opportunity of generative AI and LLMs, RAG can offer a shorter pathway to customized LLM applications than fine-tuning. Learn more about the RAG pipeline, and explore tools that can streamline implementation.</p>
                        <p class="k_plink1 k_intext1blue1"><a href="#"><strong>Building Blocks of RAG with Intel</strong><strong>:</strong></a> Read more about key components of the RAG pipeline.</p>
                        <p class="k_plink1 k_intext1blue1"><a href="#"><strong>How to Implement RAG</strong><strong>:</strong></a> Get Intel® hardware and software recommendations across the RAG pipeline.</p>
                        <p class="k_plink1 k_intext1blue1"><a href="#"><strong>Intel Tiber™ Developer Cloud</strong><strong>:</strong></a> Test important aspects of the RAG pipeline on Intel® hardware and software.</p>
                    </div>
                </div>
            </div>
        </div>
    </section>

   
    <section class="k_space">
        <div class="k_container11">
            <div class="row">
                <h3 class="mb-4">Frequently Asked Questions</h3>
                <div class="accordion accordion-flush" id="accordionFlushExample">
                    <div class="accordion-item">
                        <h2 class="accordion-header k_topborder" id="flush-headingOne">
                            <button class="accordion-button ruchi2 collapsed k_vlink2" type="button"
                                data-bs-toggle="collapse" data-bs-target="#flush-collapseOne" aria-expanded="false"
                                aria-controls="flush-collapseOne">
                                What is RAG (retrieval-augmented generation)?
                            </button>
                        </h2>
                        <div id="flush-collapseOne" class="accordion-collapse collapse"
                            aria-labelledby="flush-headingOne" data-bs-parent="#accordionFlushExample">
                            <div class="accordion-body">
                                <p class="k_plink1 k_bluehover1">RAG is a technique for optimizing large language models (LLMs) used in applications such as chatbots. RAG-based models use a retrieval mechanism to draw data from an external knowledge base, giving LLMs access to the most-up-to-date and -accurate information. LLMs then use this additional information to provide more-relevant and -meaningful responses.</p>
                            </div>
                        </div>
                    </div>
                </div>
                <div class="accordion accordion-flush" id="accordionFlushExample">
                    <div class="accordion-item">
                        <h2 class="accordion-header k_topborder k_borderbottom" id="flush-headingOne1">
                            <button class="accordion-button ruchi2 collapsed k_vlink2" type="button"
                                data-bs-toggle="collapse" data-bs-target="#flush-collapseOne1" aria-expanded="false"
                                aria-controls="flush-collapseOne">
                                Why is retrieval-augmented generation important (RAG)?
                            </button>
                        </h2>
                        <div id="flush-collapseOne1" class="accordion-collapse collapse"
                            aria-labelledby="flush-headingOne1" data-bs-parent="#accordionFlushExample1">
                            <div class="accordion-body">
                                <p>Generative AI technology, such as LLM-driven chatbots, is helping to revolutionize industries. However, many off-the-shelf LLMs are suited for general-purpose use cases and must be customized to an organization’s data to produce contextually accurate results. RAG allows organizations to ground LLMs on their own data without retraining or fine-tuning models, offering a shorter pathway to generative AI.

                                </p>

                            </div>
                        </div>
                    </div>
                </div>
                <div class="accordion accordion-flush" id="accordionFlushExample">
                    <div class="accordion-item">
                        <h2 class="accordion-header k_topborder k_borderbottom" id="flush-headingOne2">
                            <button class="accordion-button ruchi2 collapsed k_vlink2" type="button"
                                data-bs-toggle="collapse" data-bs-target="#flush-collapseOne2" aria-expanded="false"
                                aria-controls="flush-collapseOne">
                                What are the benefits of retrieval-augmented generation (RAG)?
                            </button>
                        </h2>
                        <div id="flush-collapseOne2" class="accordion-collapse collapse"
                            aria-labelledby="flush-headingOne2" data-bs-parent="#accordionFlushExample2">
                            <div class="accordion-body">
                                <p>LLMs run the risk of creating incorrect outputs, often referred to as hallucinations. RAG injects external data into LLMs to enhance their reliability and accuracy. In enterprise settings, RAG allows organizations to ground LLMs on their own data, creating a more cost-effective approach to customized AI than retraining or fine-tuning.</p>

                            </div>
                        </div>
                    </div>
                </div>
                <hr class="">
            </div>
        </div>
    </section>
   
    <section class="k_space">
        <div class="k_container11">
            <div class="row">
                <h4 class="h6">Product and Performance Information</h4>
                <div style="font-size: 12px;">
                    <div class="k_plink1 k_intext1blue1"><sup>1</sup>“Hallucination Leaderboard,” Vectara. Accessed May 16, 2024 <a href="#">https://github.com/vectara/hallucination-leaderboard.</a>.
                    </div>
                </div>
            </div>
    </section>
    <div id="footer"></div>
    <script>
        // navbar include  
        fetch('../y_index/y_navbar.html')
            .then(response => response.text())
            .then(data => {
                document.getElementById('navbar').innerHTML = data;
            });
        // footer include 
        fetch('../y_index/y_footer.html')
            .then(response => response.text())
            .then(data => {
                document.getElementById('footer').innerHTML = data;
            });
    </script>
    <script>
        const playButton = document.querySelector('.play-button');
        const video = document.getElementById('myVideo');
        const thumbnail = document.querySelector('.thumbnail');

        playButton.addEventListener('click', function () {
            thumbnail.style.display = 'none';
            playButton.style.display = 'none';
            video.style.display = 'block';
            video.play();
        });

        video.addEventListener('pause', function () {
            if (video.currentTime === 0 || video.ended) {
                video.style.display = 'none';
                thumbnail.style.display = 'block';
                playButton.style.display = 'block';
            }
        });
    </script>
    <script src="https://cdn.jsdelivr.net/npm/@splidejs/splide@4.1.4/dist/js/splide.min.js"></script>
    <script src="../js/jquery-3.7.1.js"></script>
    <!-- <script src="js/jquery-3.6.4.min.js"></script> -->
    <script src="../js/owl.carousel.min.js"></script>
    <script src="../js/rushita.js"></script>
    <script src="../js/monika.js"></script>
    <script src="https://cdn.jsdelivr.net/npm/bootstrap@5.0.2/dist/js/bootstrap.bundle.min.js"
        integrity="sha384-MrcW6ZMFYlzcLA8Nl+NtUVF0sA7MsXsP1UyJoMp4YLEuNSfAP+JcXn/tWtIaxVXM"
        crossorigin="anonymous"></script>



</body>

</html>