<!DOCTYPE html>
<html lang="en">

<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>Performance Debugging</title>

    <!-- slider -->
    <link rel="stylesheet" href="/css/all.min.css">
    <link rel="stylesheet" href="/css/animate.min.css">
    <link rel="stylesheet" href="/css/owl.carousel.min.css">
    <link rel="stylesheet" href="/css/owl.theme.default.min.css">

    <!-- Style Css -->
    <link rel="stylesheet" href="/css/mv_PyTorch_Optimizations_from_Intel.css">

    <!-- header footer -->
    <link rel="stylesheet" href='/css/yatri.css'>

    <link href="https://cdn.jsdelivr.net/npm/bootstrap@5.0.2/dist/css/bootstrap.min.css" rel="stylesheet"
        integrity="sha384-EVSTQN3/azprG1Anm3QDgpJLIm9Nao0Yz1ztcQTwFspd3yD65VohhpuuCOmLASjC" crossorigin="anonymous">
    <script src="https://cdn.jsdelivr.net/npm/bootstrap@5.0.2/dist/js/bootstrap.bundle.min.js"
        integrity="sha384-MrcW6ZMFYlzcLA8Nl+NtUVF0sA7MsXsP1UyJoMp4YLEuNSfAP+JcXn/tWtIaxVXM"
        crossorigin="anonymous"></script>
    <link href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/6.6.0/css/all.min.css" rel="stylesheet">


</head>

<body>
    <div id="navbar"></div>
    <section>
        <div class="">
            <div class="mv_featured_bg_color">
                <div class="mv_download_product">
                    <div class="mv_breadcrumb row">
                        <div class="col-md-12">
                        </div>
                    </div>
                    <div class="row mv_enhance_content">
                        <div class="col-md-12">
                            <div class="mv_date_row">
                            </div>

                            <div class="mv_enhance_heading mb-4 mx-auto">
                                <h1 class="mt-5 text-center" style="font-weight: 200;">PyTorch* Optimizations from Intel
                                </h1>
                                <p class="text-center">Speed Up AI from Research to Production Deployment</p>
                            </div>
                        </div>
                    </div>
                </div>
            </div>
            <div class="mv_featured_bg_color">
                <div class="mv_download_product2">
                    <div class="mv_breadcrumb row">
                        <div class="col-md-12">
                        </div>
                    </div>
                    <div class="row mv_enhance_content">
                        <div class="col-md-12">
                            <div class="mv_date_row">
                            </div>

                            <div class="mv_enhance_heading mb-4 mx-auto">
                                <h1 class="mt-5 text-center" style="font-weight: 200;">Discontinuation Notice
                                </h1>
                                <p class="text-center">Intel® Developer Cloud for oneAPI will be discontinued effective
                                    October 31, 2024. This includes all features and services associated with the
                                    platform.</p>
                                <div class="justify-content-center d-flex">
                                    <button class="">Details</button>
                                </div>
                            </div>
                        </div>
                    </div>
                </div>
            </div>

            <div class="row mv_enhance_heading mx-auto">
                <div class="col-6">
                    <h2 style="font-weight: 200;">Maximize PyTorch Performance on Intel® Hardware</h2>
                    <p>
                        PyTorch* is an AI and machine learning framework popular for both research and production usage.
                        This open source library is often used for deep learning applications whose compute-intensive
                        training and inference test the limits of available hardware resources.
                    </p>
                    <p>
                        Intel releases its newest optimizations and features in Intel® Extension for PyTorch* before
                        upstreaming them into open source PyTorch.
                    </p>
                    <p>With a few lines of code, you can use Intel Extension for PyTorch to:</p>
                    <ul>
                        <li>Take advantage of the most up-to-date Intel software and hardware optimizations for PyTorch.
                        </li>
                        <li>Automatically mix different precision data types to reduce the model size and computational
                            workload for inference.</li>
                        <li>Add your own performance customizations using APIs.</li>
                    </ul>

                    <p>
                        Intel also works closely with the open source PyTorch project to optimize the PyTorch framework
                        for Intel hardware. These optimizations for PyTorch, along with the extension, are part of the
                        end-to-end suite of Intel® AI and machine learning <a href="">development tools and
                            resources</a>.
                    </p>
                </div>
                <div class="col-6">
                    <div class="row">
                        <div class="col-6">
                            <h6><b>Download the Stand-Alone Versions</b></h6>
                            <p>Stand-alone versions of PyTorch and Intel Extension for PyTorch are available. You can
                                install them using a package manager or build from the source.
                            </p>
                            <p><a href="">PyTorch | Intel Extension for PyTorch</a></p>
                        </div>
                        <div class="col-6">
                            <h6><b>Help Intel® Extension for PyTorch* Evolve</b></h6>
                            <p>This open source component has an active developer community. We welcome you to
                                participate.</p>
                            <p><a href="">Open Source Version (GitHub*)</a></p>
                        </div>

                        <h5><b>Download the AI Tools</b></h5>
                        <p>PyTorch and Intel Extension for PyTorch are available in the AI Tools Selector, which
                            provides accelerated machine learning and data analytics pipelines with optimized deep
                            learning frameworks and high-performing Python* libraries.
                        </p>

                        <div class="mv_the_tools_btn">
                            <button>Get The Tools Now</button>
                        </div>
                    </div>
                </div>

                <div>
                    <div class="mv_mv_gpu_solution_vidoe mx-auto">
                        <video controls loop class="mx-auto">
                            <source src="/img/mv_video/video.mp4" type="video/mp4">
                        </video>
                    </div>
                </div>

                <h1 style="font-weight: 200;">Features</h1>

                <div class="mv_pytorch_123 mx-auto">
                    <img src="../img/mv_image/pytorch.jpg" />
                </div>

                <div class="row">
                    <div class="col-4">
                        <p><b>Open Source PyTorch Powered by Optimizations from Intel</b></p>
                        <ul>
                            <li>Accelerate PyTorch training and inference with Intel® oneAPI Deep Neural Network Library
                                (oneDNN) features such as graph and node optimizations.
                            </li>
                            <li>
                                Take advantage of Intel® Deep Learning Boost, Intel® Advanced Vector Extensions (Intel®
                                AVX-512), and Intel® Advanced Matrix Extensions (Intel® AMX) instruction set features to
                                parallelize and accelerate PyTorch workloads.
                            </li>
                            <li>
                                Perform distributed training with oneAPI Collective Communications Library (oneCCL)
                                bindings for PyTorch.
                            </li>
                        </ul>
                    </div>
                    <div class="col-4">
                        <p><b>Intel Extension for PyTorch Optimizations and Features</b></p>
                        <ul>
                            <li>Apply the newest performance optimizations not yet in PyTorch with minimal code changes.
                            </li>
                            <li>Parallelize operations without having to analyze task dependencies.</li>
                            <li>Automatically mix operator data type precision between float32 and bfloat16 to reduce
                                computational workload and model size.</li>
                            <li>Convert to a channels-last memory format for faster image-based deep learning
                                performance.</li>
                            <li>Control aspects of the thread runtime such as multistream inference and asynchronous
                                task spawning.</li>
                            <li>Run PyTorch on Intel GPU hardware.</li>
                        </ul>
                    </div>
                    <div class="col-4">
                        <p><b>Optimized Deployment with OpenVINO™ Toolkit</b></p>
                        <ul>
                            <li>Import your PyTorch model into <a href="">OpenVINO Runtime</a> to compress model size
                                and increase inference speed.</li>
                            <li>Instantly target Intel CPUs, GPUs (integrated or discrete), NPUs, or FPGAs.</li>
                            <li>Deploy with OpenVINO model server for optimized inference in microservice applications,
                                container-based, or cloud environments. Scale using the same architecture API as KServe
                                for inference execution and inference service provided in gRPC* or REST.</li>
                        </ul>
                    </div>
                </div>

                <p>Access the latest AI benchmark performance data for PyTorch and OpenVINO toolkit when running on data
                    center products from Intel. <a href="">Performance Data</a>.
                </p>

                <h1 style="font-weight: 200;">Documentation & Code Samples</h1>
                <div class="row">
                    <div class="col-6">
                        <p>Documentation</p>
                        <ul>
                            <li><a href="">PyTorch Documentation</a></li>
                            <li><a href="">PyTorch Performance Tuning Guide</a></li>
                            <li>Intel Extension for PyTorch</li>
                            <ul>
                                <li><a href="">Documentation & Tutorials</a></li>
                                <li><a href="">Installation Guide (All Operating Systems)</a></li>
                                <li><a href="">Get Started: Cheat Sheet</a></li>
                                <li><a href="">Performance Tuning Guide</a></li>
                                <li><a href="">Release Notes</a></li>
                                <li><a href="">System Requirements</a></li>
                                <li><a href="">GPU Release Documentation and Installation</a></li>
                            </ul>
                            <li><a href="">TorchServe with Intel Extension for PyTorch</a></li>
                            <li><a href="">oneCCL Bindings for PyTorch</a></li>
                            <a href="">View All Documentation</a>
                        </ul>
                    </div>
                    <div class="col-6">
                        <p><b>Intel Extension for PyTorch Code Samples</b></p>
                        <ul>
                            <li><a href="">Single-Instance Training</a></li>
                            <li><a href="">bfloat16 Inference—Imperative Mode</a></li>
                            <li><a href="">bfloat16 Inference—TorchScript Mode</a></li>
                            <li><a href="">int8 Deployment—Graph Mode</a></li>
                            <li><a href="">C++ Dynamic Library</a></li>
                            <li><a href="">GPU Single-Instance Training</a></li>
                            <li><a href="">GPU Inference</a></li>
                            <a href="">More Samples</a>
                        </ul>
                    </div>
                </div>

                <h2 style="font-weight: 200;">Training & Tutorials</h2>
                <div class="row">
                    <div class="col-6">
                        <ul>
                            <li><a href="">Accelerate PyTorch Training and Inference Performance Using Intel AMX</a>
                            </li>
                            <li><a href="">Llama 2 Inference with PyTorch on Intel® Arc™ A-series GPUs</a></li>
                            <li><a href="">Build an Interactive Chat-Generation Model Using DialoGPT and PyTorch</a>
                            </li>
                            <li><a href="">Stable Diffusion* with Intel Arc GPUs</a></li>
                            <li><a href="">Accelerated Image Segmentation Using PyTorch</a></li>
                            <li><a href="">Visual Quality Inspection for the Pharmaceutical Industry</a></li>
                            <li><a href="">Get Faster PyTorch Programs with TorchDynamo</a></li>
                            <li><a href="">How to Improve TorchServe Inference Performance with Intel Extension for
                                    PyTorch</a></li>
                        </ul>
                    </div>
                </div>

                <h2 style="font-weight: 200;">Demonstrations</h2>
                <div class="row mb-5">
                    <div class="col-6">
                        <div class="mb-5">
                            <p><b>Optimize Text and Image Generation Using PyTorch</b></p>
                            <p>Learn how to speed up generative AI that runs on CPUs by setting key environment
                                variables,
                                by using <b>ipex.llm.optimize()</b> for a Llama 2 model and <b>ipex.optimize()</b> for a
                                Stable Diffusion
                                model.
                            </p>
                            <p><a href="">Read</a></p>
                        </div>
                        <div>
                            <p><b>Build an End-to-End Language Identification with PyTorch</b></p>
                            <p>Follow along with a code sample that performs language identification from audio samples
                                using the Hugging Face SpeechBrain* toolkit. Learn how to optimize the model for
                                inference on CPU or GPU using Intel Extension for PyTorch.
                            </p>
                            <p><a href="">Read</a></p>
                        </div>
                    </div>

                    <div class="col-6">
                        <div class="mb-5">
                            <p><b>Predict Forest Fires Using Transfer Learning on a CPU</b></p>
                            <p>This application classifies aerial photos according to the fire danger they convey. It
                                uses the MODIS fire dataset to adapt a pretrained ResNet-18 model.
                            </p>
                            <p><a href="">Read</a></p>
                        </div>
                        <div>
                            <p><b>Optimize PyTorch* Performance on the Latest Intel® CPUs and GPUs</b></p>
                            <p>Get deep insight into Intel Extension for PyTorch, learning the optimizations that
                                deliver speedups on CPU and GPU. See these optimizations applied to computer vision and
                                NLP models.
                            </p>
                            <p><a href="">watch</a></p>
                        </div>
                    </div>
                </div>


                <h2 style="font-weight: 200;">Case Studies</h2>
                <div class="row mb-5">
                    <div class="col-6">
                        <div class="mb-5">
                            <p><b>Intel and Microsoft Azure* Accelerate PadChest and fMRI Models</b></p>
                            <p>Using Intel Extension for PyTorch with the OpenVINO toolkit, this project optimized for
                                deployment to Intel CPUs a chest X-ray image classification dataset and a brain
                                functional magnetic resonance imaging (fMRI) resting-state classification model.
                            </p>
                            <p><a href="">Learn More</a></p>
                        </div>
                        <div>
                            <p><b>L&T Technology Services Enhances Chest Radiology Outcomes</b></p>
                            <p>Chest-rAI* is a deep learning algorithm developed by L&T Technology Services (LTTS) to
                                detect and isolate abnormalities in chest X-ray imagery. LTTS adopted the AI Tools and
                                OpenVINO toolkit, reducing inference time by 46% and reducing their product development
                                time from eight weeks to two weeks.
                            </p>
                            <p><a href="">Learn More</a></p>
                        </div>
                    </div>

                    <div class="col-6">
                        <div class="mb-5">
                            <p><b>Hugging Face* Accelerates Stable Diffusion* on CPUs</b></p>
                            <p>Automatic mixed precision in Intel Extension for PyTorch helped this application take
                                advantage of Intel AMX to speed up inference latency by 2x.
                            </p>
                            <p><a href="">Learn More</a></p>
                        </div>
                        <div>
                            <p><b>HippoScreen Improves AI Performance by 2.4x</b></p>
                            <p>The Taiwan-based neurotechnology startup used tools and frameworks in the Intel® oneAPI
                                Base Toolkit and AI Tools to the improve the efficiency and training times of deep
                                learning models used in its Brain Waves AI system.
                            </p>
                            <p><a href="">Learn More</a></p>
                        </div>
                    </div>
                </div>

                <h2 style="font-weight: 200;">News</h2>
                <div class="row mb-5">
                    <div class="col-4">
                        <p><b>PyTorch v2.1 Contains New Performance Features for AI Developers</b></p>
                        <p>Intel made significant contributions to five new features that include TorchInductor-CPU
                            optimizations, a CPU dynamic shape inference path for torch.compile, and a C++ wrapper.
                        </p>
                        <p><a href="">Learn More</a></p>
                    </div>
                    <div class="col-4">
                        <p><b>Intel Joins the PyTorch Foundation</b></p>
                        <p>
                            Intel is now a Premier member of the PyTorch Foundation, with four full-time PyTorch
                            maintainers for CPU performance, and a seat on the PyTorch Foundation Governing Board.
                        </p>
                        <p><a href="">Learn More</a></p>
                    </div>
                    <div class="col-4">
                        <p><b>Introducing Intel Extension for PyTorch for GPUs</b></p>
                        <p>
                            This extension now supports Intel GPUs. Learn which features are supported in this release,
                            how to install it, and how to get started running PyTorch on Intel GPUs.
                        </p>
                        <p><a href="">Learn More</a></p>
                    </div>
                </div>

                <h2 style="font-weight: 200;">Specifications</h2>
                <div class="row mb-5">
                    <div class="col-4">
                        <b>Processors:</b>
                        <ul>
                            <li>Intel Xeon processor</li>
                            <li>Intel® Core™ processor</li>
                            <li><a href="">Intel GPU</a></li>
                        </ul>
                    </div>
                    <div class="col-4">
                        <b>Operating systems:</b>
                        <ul>
                            <li>Linux* (Intel Extension for PyTorch is for Linux only)</li>
                            <li>Windows*</li>
                        </ul>
                    </div>
                    <div class="col-4">
                        <b>Languages:</b>
                        <ul>
                            <li>Python</li>
                            <li>PythonC++</li>
                        </ul>
                    </div>
                </div>

                <h2 style="font-weight: 200;">Get Help</h2>
                <div class="row">
                    <div class="col-6">
                        <p>Your success is our success. Access these support resources when you need assistance.</p>
                        <ul>
                            <li>AI Tools Support Forum</li>
                            <li>Intel® Optimized AI Frameworks Support Forum</li>
                            <li>Intel Extension for PyTorch: GitHub Issue Tickets</li>
                        </ul>
                    </div>
                </div>
            </div>

                <div class=" justify-content-end">
                    <div class=" row form-container ">
                        <div class="col-6 mv_main_triangle">
                            <h1 class="mv_triangel_text">Stay Up to Date on AI Workload Optimizations</h1>
                            <p>
                                Sign up to receive hand-curated technical articles, tutorials, developer tools, training
                                opportunities, and more to help you accelerate and optimize your end-to-end AI and data
                                science workflows. Take a chance and subscribe. You can change your mind at any time.
                            </p>
                        </div>
                        <div class="col-6">
                            <form class="">
                                <div class="mb-3">
                                    <label class="form-label">All fields are required unless marked optional.</label>
                                    <input type="email" class="form-control" placeholder="Business Email Address"
                                        required>
                                </div>

                                <div class="mb-3">
                                    <select class="form-select" required>
                                        <option value="">Please select a country/region</option>
                                        <option value="us">United States</option>
                                        <option value="uk">United Kingdom</option>
                                        <option value="ca">Canada</option>
                                    </select>
                                </div>

                                <div class="mb-3">
                                    <input type="text" class="form-control" placeholder="Company" required>
                                </div>

                                <div class="mb-3">
                                    <select class="form-select" required>
                                        <option value="">Please Select a Profession</option>
                                        <option value="developer">Developer</option>
                                        <option value="data-scientist">Data Scientist</option>
                                        <option value="engineer">Engineer</option>
                                    </select>
                                </div>

                                <div class="mb-3">
                                    <select class="form-select" required>
                                        <option value="">Select an option</option>
                                        <option value="frontend">Frontend Developer</option>
                                        <option value="backend">Backend Developer</option>
                                        <option value="fullstack">Full Stack Developer</option>
                                    </select>
                                </div>

                                <p class="mt-3 small-text">
                                    This site is protected by reCAPTCHA and the Google
                                    <a href="#">Privacy Policy</a> and
                                    <a href="#">Terms of Service</a> apply.
                                </p>

                                <button type="submit" class="btn mv_sign_up_btn">Sign Up</button>

                                <p class="small-text">
                                    By submitting this form, you are confirming you are age 18 years or older. Intel may
                                    contact you for marketing-related communications. You can opt out at any time. To
                                    learn
                                    more about Intel's practices, including how to manage your preferences and settings,
                                    visit Intel's
                                    <a href="#">Privacy Notice</a>.
                                </p>
                            </form>
                        </div>
                    </div>
                </div>

            <!-- <div class="mv_main_product1 mx-auto">

            </div> -->

            <div class="row">
                <!-- Sidebar -->
                <!-- Main Content -->
            </div>

    </section>
    <div id="footer"></div>

    <script>
        fetch('/y_index/y_navbar.html')
            .then(response => response.text())
            .then(data => {
                document.getElementById('navbar').innerHTML = data;
            });
        fetch('/y_index/y_footer.html')
            .then(response => response.text())
            .then(data => {
                document.getElementById('footer').innerHTML = data;
            });
    </script>
</body>

</html>