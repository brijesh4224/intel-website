<!DOCTYPE html>
<html lang="en">
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>LTIMindtree Optimizes AI-Enabled Chatbot Abilities</title>
    <link rel="stylesheet" href="/css/B_style.css">
    <!-- BOSSTRAP CSS FILE -->
    <link href="https://cdn.jsdelivr.net/npm/bootstrap@5.0.2/dist/css/bootstrap.min.css" rel="stylesheet"
        integrity="sha384-EVSTQN3/azprG1Anm3QDgpJLIm9Nao0Yz1ztcQTwFspd3yD65VohhpuuCOmLASjC" crossorigin="anonymous">
    <!-- INTEL ONLINE FONT CONECTIVITY  -->
    <link href="https://fonts.cdnfonts.com/css/intel-clear" rel="stylesheet">
    <!-- FONT AWASOME LINK -->
    <link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/6.6.0/css/all.min.css"
        integrity="sha512-Kc323vGBEqzTmouAECnVceyQqyqdsSiqLQISBL29aUW4U/M7pSPA/gEUZQqv1cwx4OnYxTxve5UMg5GT6L4JJg=="
        crossorigin="anonymous" referrerpolicy="no-referrer" />
</head>
<body>
    <div id="navbar"></div>
    <section class="" style="background-color: #0068B5;">
        <div class="b_container text-white py-4">
            <h1 class="h3">LTIMindtree Optimizes AI-Enabled Chatbot Capabilities</h1>
            <p class="h5">LTIMindtree uses SigOpt Intelligent Experimentation Platform to automate AI model production for better end customer results.</p>
        </div>
    </section>
    <section class="b_container py-5">
        <div class="row">
            <div class="d-flex justify-content-end col-xl-10 py-3 d-md-none">
                <i class="fa-solid fa-file fs-4 px-2" style="color:#0068B5"></i>    
                <i class="fa-solid fa-print fs-4 px-2 " style="color:#0068B5"></i>
                <i class="fa-regular fa-envelope fs-4 px-2" style="color:#0068B5"></i>
            </div>
            <div class="col-lg-3 col-md-4">
                <div class="bg-light p-3">
                    <h5 class="font-weight-bolder">At a glance:</h5>
                    <ul class="ps-3">    
                        <li><p class="mb-0">As of November 14, 2023, Mindtree merged with L&amp;T Infotech to form LTIMindtree. LTIMindtree is a global technology consulting and digital solutions company with deep engineering experience, specializing in the delivery of agile and comprehensive enterprise solutions that use artificial intelligence (AI).</p>
                        </li>
                        <li><p class="mb-0">Using SigOpt Intelligent Experimentation Platform, LTIMindtree was able to optimize their call center automated call response and summarization system while also experiencing significant CPU performance benefits. </p>
                        </li>
                    </ul>
                    <div class="col-xxl-10 text-center py-2" style="background-color: #0068B5;">
                        <a href="" class=" text-white text-decoration-none">
                            Download the one-page summary</a>
                    </div>
                </div>
            </div>
            <div class="col-lg-9 col-md-8" >
                <div class="d-md-flex justify-content-end col-xl-10 py-3 d-none">
                    <i class="fa-solid fa-file fs-4 px-2" style="color:#0068B5"></i>    
                    <i class="fa-solid fa-print fs-4 px-2 " style="color:#0068B5"></i>
                    <i class="fa-regular fa-envelope fs-4 px-2" style="color:#0068B5"></i>
                </div>
                <div class="col-xl-10 py-5 fs-5">
                    <div>
                        <p>Using <a href="#" class="b_special_a1">SigOpt</a> yielded up to 63 percent improvement in inference time beyond baseline performance for pretrained AI transformers.<sup>1</sup></p>
                        <p><a href="#" class="b_special_a1">LTIMindtree</a> is an Indian multinational service provider with decades of deep engineering experience, specializing in the delivery of agile and comprehensive enterprise solutions that use novel artificial intelligence (AI) technology. One of the cornerstones in the LTIMindtree AI suite of products is its AI-powered call summarizer, which helps call center agents summarize completed customer calls, a complex task that requires AI models to be both current and consistently improved at a granular level. LTIMindtree is committed to continuous improvement of AI model performance and response times to ensure superior products for their customers. In this case, the goal was to enable faster and more accurate call summaries using AI tools.</p>
                        <p>For LTIMindtree, improving call summarization meant meticulously fine-tuning AI models for use with individual customers. However, manually fine-tuning AI models for every individual customer was time consuming and introduced operational bottlenecks to the process. The LTIMindtree team sought a tool to overcome these challenges and settled on using SigOpt to automate the entire fine-tuning workflow.</p>
                    </div>
                    <div class="d-flex  px-md-5 py-5">
                                <i class="fa-solid fa-quote-left " style="font-size: 74px; color: #E5E6E6;"></i>
                                <i class="font-italic px-4">“The investment with the SigOpt Intelligent Experimentation Platform was definitely worth the results LTIMindtree has achieved.”—Bhanu Prakash Aladahallinanjappa, program architect, LTIMindtree<sup>2</sup></i>
                    </div>
                    <div>
                        <p>By using SigOpt, a world-class solution for operationalizing the production of AI models, Mindtree saw not just a reduction in the operational cost but also a significant performance gain in both accuracy and inference time. This SigOpt-enabled workflow ultimately translated to an up to 63 percent reduction in inference time when compared with the performance of the pre-trained HuggingFace transformer BART.<sup>1</sup> More importantly, this model performance gain translated to a better, more productive customer experience.</p>
                            <p>LTIMindtree is focused on delivering operational efficiency by using avant-garde AI models tailored to customer needs and data. In this case, LTIMindtree’s expertise was intended for application in the telecommunications industry, where AI-enabled chatbots can help reduce voluntary customer churn, increase average revenue per user, and deliver cost-effective customer convenience. When customers interact with a chatbot, it needs to be a positive, efficient, and accurate experience for long-term customer retention and minimal need for human assistance.<sup>3</sup></p>
                            <p>Chatbots help provide better customer experiences through quick resolutions while increasing employee efficiency and productivity. Speed, responsiveness, and accuracy are key to improving customer service. In a telecom, as well as in most other customer service environments, call accuracy is measured by the Recall-Oriented Understudy for Gisting Evaluation (ROUGE) score.</p>
                            <h4 class="mt-5">Comparing SigOpt to Other Methods</h4>
                            <p>Conventional hyperparameter tuning methods like grid search and random search are tedious and time consuming. LTIMindtree was confronted with this challenge when fine-tuning hyperparameters to improve chatbot performance in call responses and summaries. Specifically, they wanted to select the right deep learning architecture to give chatbot exchanges a measurable improvement in performance. Through the following experiments, LTIMindtree sought to determine whether the SigOpt Intelligent Experimentation Platform was the right tool to facilitate the fine-tuning of hyperparameters.</p>
                            <p>Rather than manually interpreting and optimizing its AI models or combining multiple tools within LTIMindtree’s existing infrastructure, the SigOpt Intelligent Experimentation Platform gave LTIMindtree step-by-step clarity with a model-agnostic cloud-based solution.</p>
                    </div>
                    <div>
                        <img src="../img/brijesh/image287.png" class="w-100">
                    </div>
                    <em>Figure 1. LTIMindtree’s workflow for fine-tuning AI models using the SAMSum data set.</em>
                    <div class="pt-4">
                        <p>SigOpt optimizes AI models through a combination of Bayesian and other global optimization algorithms to boost model performance while reducing costs and saving time. With SigOpt, LTIMindtree experts implemented their model optimization experiments with a few lines of code using LTIMindtree’s existing environments and tools. SigOpt brings together data management, optimization, analytics, transparency, and scalability so modelers can track runs, visualize training curves, and optimize hyperparameters via an integrated dashboard designed exclusively for intelligent experimentation. LTIMindtree could easily see what did and didn’t work within their experiments, as well as a history of what had been done and how the different models were performing.</p>
                    </div>
                    <div class="d-flex  px-md-5 py-5">
                        <i class="fa-solid fa-quote-left " style="font-size: 74px; color: #E5E6E6;"></i>
                        <i class="font-italic px-4">“Model customization and accuracy improvements are what our customers are insisting on instead of using available cloud solutions in the contact center space. We will definitely recommend or offer our service around customization using the SigOpt Intelligent Experimentation Platform.”—Bhanu Prakash Aladahallinanjappa, program architect, LTIMindtree</i>
                     </div>
                     <div>
                        <p>Before tackling the project, LTIMindtree chose to become familiar with SigOpt by comparing the SigOpt optimization algorithms to other standard approaches for hyperparameter optimization.</p>
                     </div>
                     <div class="d-flex  px-md-5 py-5">
                        <i class="fa-solid fa-quote-left " style="font-size: 74px; color: #E5E6E6;"></i>
                        <i class="font-italic px-4">“LTIMindtree’s cognitive contact center solution now offers unprecedented accuracy and performance of the summarization model to customers, courtesy of the features in the SigOpt Intelligent Experimentation Platform”—Lakshmi Ranganathan, technical consulting engineering lead, Intel India</i>
                     </div>
                     <div>
                        <p>For the comparison, LTIMindtree used grid search, random search, and the <a href="#" class="b_special_a1">SciPy optimization library</a> and compared performance on the eggholder function. The <a href="#" class="b_special_a1">eggholder function</a> is considered a classic function within the optimization literature. The resulting comparison gave quick insight into how SigOpt was able to find the best value in fewer iterations compared to the other approaches.</p>
                     </div>
                     <div class="responsive-table-component editorial-table-component selectable  theme-light-default link-default">

                <!--this contains the description and buttons-->
            <!--end of description-->
                </div>
                
                </div>
                <div class="col-12">
                    <div class="b_table_responsive overflow-auto">
                       <table class="b_table image-rendition-feature" disprows="5">
                            <thead>
                            <tr class="text-center" style="background-color: #E9E9E9;">
                                <th class="border-1 border-white">Method</th>
                                <th class="border-1 border-white">Number of evaluations</th>
                                <th class="border-1 border-white">Max value achieved</th>
                            </tr>   
                            </thead>

                            <tbody>
                            <tr class="data" data-category-id="">
                                <td style="text-align: left;">Bayesian optimization by SigOpt tool</td>
                                <td style="text-align: center;">40</td>
                                <td style="text-align: center;">158.55</td>
                            </tr>
                            <tr class="data bg-light" data-category-id="">
                                <td style="text-align: left;">Grid search</td>
                                <td style="text-align: center;">80</td>
                                <td style="text-align: center;">138.22</td>
                            </tr>
                            <tr class="data" data-category-id="">
                                <td style="text-align: left;">Random search</td>
                                <td style="text-align: center;">70</td>
                                <td style="text-align: center;">145.95</td>
                            </tr>
                            </tbody>
                        </table>
                    </div>
                </div>
                <div class="col-xl-10 py-5 fs-5">
                    <div class="py-5">
                        <img src="../img/brijesh/image288.png" class="w-100">
                    </div>
                    <em>Figure 2. The LTIMindtree team tried conventional tuning methods like grid search and random search. This image displays the results comparison with SigOpt.<sup>1</sup></em>
                    <div class="py-5">
                        <p>For additional validation, LTIMindtree tried image classification on the <a href="#" class="b_special_a1">MNIST data set</a> using a <a href="#" class="b_special_a1">multilayer perceptron model</a>.</p>
                        <p>Overall, running these two test cases gave LTIMindtree the confidence to continue with SigOpt for this project.</p>
                        <h4 class="mt-5">Choosing the Right Deep Learning Architecture That Aligns with Modeling and Business Objectives</h4>
                        <p>One of the challenges when building deep learning models is to choose the right architecture. Choosing the right architecture means finding the architecture that is not just ensuring the best model performance but is also satisfying the requirements for going into production. Once LTIMindtree verified the effectiveness of SigOpt, LTIMindtree used the platform to help build a case for determining which AI transformer model architecture to use for their customers.</p>
                        <p>To select the right transformer model architecture, LTIMindtree experimented using a GPU-enabled machine. To identify a model candidate, LTIMindtree tested a <a href="#" class="b_special_a1">Pegasus model</a> and a <a href="#" class="b_special_a1">BART model</a>, both from <a href="#" class="b_special_a1">Hugging Face</a>. They also chose the <a href="#" class="b_special_a1">SAMSum Corpus</a> data set for abstractive summarization.</p>
                        <p>LTIMindtree’s goal was to fine-tune a pretrained model—optimizing batch size and learning rate—to understand if the SigOpt Intelligent Experimentation Platform could select new and better hyperparameter values and improve transformer models.</p>
                        <p>Initially, LTIMindtree tried to optimize the Pegasus model by minimizing evaluation loss. Seeing the early results gave the LTIMindtree team the confidence to rule out the Pegasus model as a potential model candidate.</p>
                    </div>
                    <div class="py-2 d-flex align-items-center" style="position: relative;">
                        <div style="position: absolute; height: 100%; width: 5px; background-color: lightgray;"></div>
                        <p class="px-4">An AI transformer model is a deep learning model commonly used in natural language processing tasks that adopts the mechanism of self-attention to weigh individual parts of the input data.</p>
                    </div>
                    <div class="py-5">
                        <p>After ruling out the Pegasus model, LTIMindtree switched their attention to the BART model. They also switched from looking at evaluation loss to looking at the ROUGE score metrics to better compare the pretrained baseline models. The ROUGE score comes in three different forms:</p>
                        <ul>
                            <li>ROUGE 1 – Number of matching unigrams in sentence/total unigrams in sentence</li>
                            <li>ROUGE 2 – Number of matching bigrams in sentence/total bigrams in sentence</li>
                            <li>ROUGE L – Length of longest common subsequence/total words in sentence</li>
                        </ul>
                        <p>The metrics measure the difference between the true sentence and the generated sentence—in this case, for summarization. As a baseline, LTIMindtree used the pretrained BART model and got a ROUGE 1 score of 54.39. This is also the model the team decided to use for weight initialization for the fine-tuning.</p>
                    </div>
                    <div class="py-5">
                        <img src="../img/brijesh/image289.png" class="w-100">
                    </div>
                    <em>Figure 3. LTIMindtree’s solution block diagram.</em>
                    <div class="py-5">
                        <h4>Operationalizing the Production of AI Models to Optimize the End Customer Experience</h4>
                        <p>For summarization of the call conversation, a pretrained Facebook/BART-large-XSum model was used as the base model. The model was fine-tuned on the SAMSum Corpus data set, a human-annotated dialogue data set for abstractive summarization. Hyperparameter optimization was carried out using SigOpt with the ROUGE score as the performance metric.</p>
                        <p>With dual goals of maximizing the ROUGE score and minimizing inference time, LTIMindtree used <a href="#" class="b_special_a1">SigOpt’s multimeric optimization</a> advanced feature to visualize possible design solutions. Using SigOpt’s web application, LTIMindTree was able to visualize how these two competing metrics performed after running multiple experiments and created a Pareto Frontier visualizing the best outcomes for each metric combination. From here, LTIMindtree was able to select the best configuration for their models to bring into production.</p>
                    </div>
                    <div class="py-5">
                        <img src="../img/brijesh/image290.png" class="w-100">
                    </div>
                    <em>Figure 4. The Pareto Frontier provided by SigOpt’s visualization tools.</em>
                    <div class="py-5">
                        <p>As a result of using SigOpt, LTIMindtree optimized its AI models to achieve 63 percent faster responsiveness and better call summarization through contact center bots. The models not only automate the task of post-call summarization but also provide text summaries that are consistent and accurate, thereby improving productivity and performance. Below is a summary from the baseline model and a summary from the model fine-tuned using SigOpt.</p>
                    </div>
                    <div class="py-5">
                        <img src="../img/brijesh/image291.png" class="w-100">
                    </div>
                    <em>Figure 5. The summary from the fine-tuned model is more concise and efficient.<sup>1</sup></em>
                    <div class="py-5">
                        <p>Improving Model Accuracy and Realizing Significant CPU Performance Benefits to Boost Inference by Up to 63 Percent</p>
                        <p>Getting a more concise reference report of customer engagements is a key success criterion for any abstractive summary model. On average, LTIMindtree found that manual summary extraction takes five to ten minutes, depending upon call length, and is subject to the potential for human error. Additionally, the increased speed through efficiency helps agents switch from one call to the next. Both the chatbot responsiveness and engagement summaries have now been vastly improved due to working with SigOpt.</p>
                        <p>SigOpt was able to find models that performed well and have lower inference times despite the industry trend for the opposite to occur. Keep in mind, also, the inference improvements shown here are multiplicative with hardware performance improvements. Meaning a more efficient processor will accelerate these gains even further. For reference, the Intel hardware configuration LTIMindtree used was <a href="#" class="b_special_a1">3rd Gen Intel® Xeon®</a> processors.<sup>4</sup> The following results show this reduced inference time.<sup>5</sup></p>
                        <p>As a result of using SigOpt, LTIMindtree now has a framework that enables them to transfer knowledge from one project to the next.</p>
                    </div>
                </div>
                <div class="col-12">
                    <div class="b_table_responsive overflow-auto">
                       <table class="b_table image-rendition-feature" disprows="5">
                            <thead>
                            <tr class="text-center" style="background-color: #E9E9E9;">
                                <th class="border-1 border-white" style="width:500px !important">Transcript files with summary</th>
                                <th class="border-1 border-white">	Inference time in seconds</th>
                                <th class="border-1 border-white">Model name</th>
                            </tr>   
                            </thead>

                            <tbody>
                            <tr class="data" data-category-id="">
                                <td style="text-align: left">Customer is angry because he can’t access his email for almost a week. Rocket Speed Internet will call him back at the same number, but he needs to check which lights are lit on his modem. There is a problem with the DSL line behind customer’s desk. It’s the gray phone cord at the back part of the modem. The agent tells customer to plug it in and it fixes the problem.</td>
                                <td style="text-align: center;">16.75044</td>
                                <td style="text-align: center;">Hugging Face latest model; model created without SigOpt help</td>
                            </tr>
                            <tr class="data bg-light" data-category-id="">
                                <td style="text-align: left;">Customer can’t access his email for almost a week. Agent will call him back at the same number as before. Customer has a problem with his DSL modem. The problem is with the gray phone cord at the back part of the modem, which is behind his desk. Agent helps him to fix it over the phone.</td>
                                <td style="text-align: center;">6.86279</td>
                                <td style="text-align: center;">Model created with help from SigOpt</td>
                            </tr>
                            </tbody>
                        </table>
                    </div>
                </div>
                <div class="col-xl-10 py-5 fs-5">
                    <em>Figure 6. Transcript files with summary example.</em>
                    <div class="d-flex  px-md-5 py-5">
                        <i class="fa-solid fa-quote-left " style="font-size: 74px; color: #E5E6E6;"></i>
                        <i class="font-italic px-4">““We intended to use the SigOpt Intelligent Experimentation Platform to improve model accuracy (ROUGE score), but we also got significant CPU performance benefits.”—Bhanu Prakash Aladahallinanjappa, program architect, LTIMindtree</i>
                    </div>
                    <h4 class="pt-5">Summary: SigOpt’s Intelligent Experimentation Value for LTIMindtree’s Future Use Cases</h4>
                    <ol class="py-5">
                        <li><strong>Sample efficiency:</strong> A key component of building out deep learning models is optimizing for performance. When using approaches such as grid search and other less-sample-efficient optimization methods, one of the challenges often becomes narrowing down the search space to avoid applying infinite computational resources. SigOpt, on the other hand, provides a set of Bayesian and other global optimization algorithms that are specifically designed to be as sample-efficient as possible and to reduce the computational resources needed to optimize a model.</li>
                        <li><strong>Advanced experimentation features:</strong> SigOpt offers a wide variety of advanced experimentation features that help modelers to better align their modeling objectives with business objectives. One of these features is multimetric optimization, which allows the modeler to optimize multiple competing metrics at the same time.</li>
                        <li><strong>Ease of use:</strong> SigOpt offers an easy-to-use client library that allows modelers to easily integrate SigOpt into what they are doing today. In addition, an intuitive web dashboard experience allows the user to store artifacts, visualize results, and work closely with other members of the modeling team and other key stakeholders.</li>
                        <li><strong>Standardized modeling workflow:</strong> Just as importantly, SigOpt standardizes the modeling workflow, which leads to better overall model performance because it allows modelers to focus on applying domain knowledge to the problem instead of investing in developing a modeling experimentation process.</li>
                    </ol>
                    <div class="py-2 d-flex align-items-center" style="position: relative;">
                        <div style="position: absolute; height: 100%; width: 5px; background-color: lightgray;"></div>
                        <p class="px-4">By using the SigOpt Intelligent Experimentation Platform, the chatbot response inference time decreased from 16.75 seconds to 6.86 seconds.</p>
                    </div>
                    <div class="pt-5">
                        <p>LTIMindtree’s telecommunications project objective was to reduce call agent time by optimizing their call center automated call response and summarization system. The goal was to improve the chatbot capabilities to deliver a faster, smoother, and more natural response as well as to summarize each engagement more concisely.</p>
                        <p>The SigOpt Intelligent Experimentation Platform helped LTIMindtree achieve chatbot performance improvement through an organized viewpoint with automatic optimizations to easily find the experiments that yielded the best customized results. LTIMindtree was able to easily track their chosen metrics and visualize which optimizations best achieved those metrics. This experiment helped LTIMindtree choose the most appropriate deep learning model architecture for improved chatbot performance for both responses and engagement summaries, using customized models and metrics.</p>
                        <p>The inference time it took for the chatbot to summarize a customer call before working with SigOpt was 16.75 seconds; by using SigOpt, the inference time was reduced to 6.86 seconds.5 This improvement reduced the chatbot response time, meaning a faster response to telecommunications customers and a more than 50 percent decrease in human agent time on routine tasks, yielding more human agent time to support customers on calls. The engagement summaries were also improved significantly by reducing the word count and smoothing the phrasing to effectively document the customer engagement.</p>
                        <p>Additionally, LTIMindtree not only delivered on improving chatbot performance but also experienced an unexpected benefit of significant CPU performance benefits, enabled by SigOpt.</p>
                        <p>Lastly, due to the measured impact of the improvements to accuracy and inference time, LTIMindtree will now offer an AI model optimization service for call centers as a product in its marketing catalog for current and future customers.</p>
                        <p><a href="#" class="b_special_a1">Download the PDF ›</a></p>
                    </div>
                </div>
               
            </div>
        </div>
    </section>
    <section class="py-5 bg-light">
        <div  class="b_container">
            <div class="row"> 
                <h2 class="col-md-9">Explore Related Stories</h2>
                <div class="col-md-2 text-center py-2 d-flex align-items-center justify-content-center" style="background-color: #0068B5;">
                    <a href="" class=" text-white text-decoration-none">
                        Intel Customer Spotlight <i class="fa-solid fa-arrow-right"></i></a>
                </div>
            </div>
            <div class="row py-4">
                <div class="col-xl-3 col-md-6 col-12 gx-4" >
                    <img src="../img/brijesh/image292.png" class="w-100">
                    <h4 class="py-3"><a href="#" class="b_special_a2">Storm Reply Taps EC2 C7i Instances on CPUs for LLM</a></h4>
                </div>
                <div class="col-xl-3 col-md-6 col-12 gx-4" >
                    <img src="../img/brijesh/image293.png" class="w-100">
                    <h4 class="py-3"><a href="#" class="b_special_a2">Meituan Accelerates Vision AI Inference Services</a></h4>
                </div>
                <div class="col-xl-3 col-md-6 col-12 gx-4" >
                    <img src="../img/brijesh/image294.png" class="w-100">
                    <h4 class="py-3"><a href="#" class="b_special_a2">Tokopedia Supports Growing Userbase</a></h4>
                </div>
                <div class="col-xl-3 col-md-6 col-12 gx-4" >
                    <img src="../img/brijesh/image295.png" class="w-100">
                    <h4 class="py-3"><a href="#" class="b_special_a2">Alibaba Builds End-to-End PPML Solution</a></h4>
                </div>
            </div>
        </div>
    </section>
    <section style="background-color:#0068B5">
        <div class="b_container py-5 text-white">
            <h2>Explore Related Products and Solutions</h2>
            <div class="row py-4">
                <div class="col-md-6 row">
                    <div class="col-lg-5">
                        <img src="../img/brijesh/image296.jpg" class="w-100">
                    </div>
                    <div class="col-lg-7">
                        <h5 id="promo-main-heading-1" class="blade-item-heading">
                            <a href="#" class="b_special_a">Intel® Xeon® Scalable Processors</a>
                        </h5>
                        <p>Drive actionable insight, count on hardware-based security, and deploy dynamic service delivery with Intel® Xeon® Scalable processors.</p>
                        <a href="#" class="b_special_a">Learn more</a>
                    </div>
                </div>
                <div class="col-md-6 row">
                    <div class="col-lg-5">
                        <img src="../img/brijesh/image297.png" class="w-100">
                    </div>
                    <div class="col-lg-7">
                        <h5 id="promo-main-heading-1" class="blade-item-heading">
                            <a href="#" class="b_special_a">SigOpt</a>
                        </h5>
                        <p>A leading platform for the optimization of artificial intelligence (AI) software models at scale.</p>
                        <a href="#" class="b_special_a">Learn more</a>
                    </div>
                </div>
            </div>
        </div>
    </section>
    <section style="background-color: #8F5DA2;">
        <div class="b_container py-5 text-white">
            <div class="row">
                <div class="col-md-4">
                    <h5>Customer Stories and Case Studies</h5>
                    <p class="mb-0">Explore the latest customer stories, case studies, and news releases highlighting data-centric innovations.</p>
                    <ul>
                        <li><a href="#" class="b_special_a">Intel Customer Spotlight</a></li>
                        <li><a href="#" class="b_special_a">Intel Newsroom</a></li>
                    </ul>
                </div>
                <div class="col-md-4">
                    <h5>Data Center Workloads
                    </h5>
                    <p class="mb-0">Learn how Intel® technologies can help provide the scalability needed for high-demand workloads and applications.</p>
                    <ul>
                        <li><a href="#" class="b_special_a">Advanced Analytics</a></li>
                        <li><a href="#" class="b_special_a">Artificial Intelligence (AI)</a></li>
                        <li><a href="#" class="b_special_a">Cloud Computing</a></li>
                        <li><a href="#" class="b_special_a">High Performance Computing (HPC)</a></li>
                    </ul>
                </div>
                <div class="col-md-4">
                    <h5>CData Center Insights</h5>
                    <p class="mb-0">Get the latest information about Intel data center performance, flexibility, and scalability.</p>
                    <ul>
                        <li><a href="#" class="b_special_a">Cloud Service Provider Resources</a></li>
                        <li><a href="#" class="b_special_a">Network Transformation & Communications Technology</a></li>
                    </ul>
                </div>
            </div>
        </div>
    </section>
    <section class="b_container py-5">
        <h4 class="h6">Product and Performance Information</h4>
        <div class="disclaimer" style="font-size: 12px;"><sup>1</sup>All values were part of experiments/evaluation.</div>
        <div class="disclaimer" style="font-size: 12px;"><sup>2</sup>Bhanu Prakash Aladahallinanjappa is an accomplished program architect with over 20 years of experience in the consumer electronics, semiconductor, and automotive industries. He has extensive experience with short-range wireless networks, Linux, firmware, machine learning and deep learning. Currently, Bhanu draws on this expertise to address a variety of problems in ML/DL at LTIMindtree partnering semiconductor companies. Within LTIMindtree, he is the go-to person for the most difficult and pressing technical challenges that require data science and optimization solutions. He is passionate about fostering the next generation of technical architects, serving as a mentor and advisor to emerging engineers across these domains.</div>
        <div class="disclaimer" style="font-size: 12px;"><sup>3</sup>“Powering Contact Center Transformation by Using Intel AI,” LTIMindtree. https://builders.intel.com/docs/aibuilders/mindtree-powering-contact-center-transformation-by-using-intel-ai.pdf</div>
        <div class="disclaimer" style="font-size: 12px;"><sup>4</sup>See www.intel.com/3gen-xeon-config. Results may vary.</div>
        <div class="disclaimer" style="font-size: 12px;"><sup>5</sup>Results reported by LTIMindtree during their experimentation.</div>
    </section>
    <div id="footer"></div>
    <script>
        // navbar include  
        fetch('/y_index/y_navbar.html')
            .then(response => response.text())
            .then(data => {
                document.getElementById('navbar').innerHTML = data;
            });
        // footer include 
        fetch('/y_index/y_footer.html')
            .then(response => response.text())
            .then(data => {
                document.getElementById('footer').innerHTML = data;
            });
    </script>
    <script src="https://cdn.jsdelivr.net/npm/bootstrap@5.0.2/dist/js/bootstrap.bundle.min.js"
    integrity="sha384-MrcW6ZMFYlzcLA8Nl+NtUVF0sA7MsXsP1UyJoMp4YLEuNSfAP+JcXn/tWtIaxVXM" crossorigin="anonymous">
    </script>
</body>
</html>