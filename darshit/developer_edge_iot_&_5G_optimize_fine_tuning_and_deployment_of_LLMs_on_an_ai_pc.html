<!DOCTYPE html>
<html lang="en">

<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>Optimize Fine-Tuning and Deployment of LLMs on an AI PC</title>

    <link rel="stylesheet"
        href="/css/dk_developer_edge_iot_&_5G_optimize_fine_tuning_and_deployment_of_LLMs_on_an_ai_pc.css">

    <!-- header footer -->
    <link rel="stylesheet" href='/css/yatri.css'>

    <link href="https://cdn.jsdelivr.net/npm/bootstrap@5.0.2/dist/css/bootstrap.min.css" rel="stylesheet"
        integrity="sha384-EVSTQN3/azprG1Anm3QDgpJLIm9Nao0Yz1ztcQTwFspd3yD65VohhpuuCOmLASjC" crossorigin="anonymous">
    <script src="https://cdn.jsdelivr.net/npm/bootstrap@5.0.2/dist/js/bootstrap.bundle.min.js"
        integrity="sha384-MrcW6ZMFYlzcLA8Nl+NtUVF0sA7MsXsP1UyJoMp4YLEuNSfAP+JcXn/tWtIaxVXM"
        crossorigin="anonymous"></script>
    <link href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/6.6.0/css/all.min.css" rel="stylesheet">
</head>

<body>

    <!-- header -->
    <div id="navbar"></div>

    <!-- Optimize Fine-Tuning and Deployment of LLMs on an AI PC -->
    <section>
        <div class="mv_intel_amx_bg_color">
            <div class="container">
                <div class="row mv_intel_amx_content">
                    <div class="col-md-12 col-sm-12 mv_intel_amx_item">
                        <div class="mv_intel_amx">
                            <h3>Optimize Fine-Tuning and Deployment of LLMs on an AI PC</h3>
                            <p></p>
                        </div>
                    </div>
                </div>
            </div>
        </div>
    </section>

    <section class="container py-5">
        <div class="row">
            <div class="d-flex justify-content-end col-xl-10 py-3 d-md-none">
                <i class="fa-solid fa-print fs-4 px-2 " style="color:#0068B5"></i>
                <i class="fa-regular fa-envelope fs-4 px-2" style="color:#0068B5"></i>
            </div>
            <div class="col-lg-3 col-md-4">
                <!-- nav -->
                <div class="VK_client_app_navigation VK_ai_navigation">
                    <div class="justify-content-center align-items-center overflow-hidden flex-nowrap mb-4">
                        <ul class="VK_ai_nav_bar list-unstyled m-0">
                            <li>
                                <a href="#dk_prerequisites" class="text-dark text-decoration-none d-block">
                                    Prerequisites
                                </a>
                            </li>
                            <li>
                                <a href="#dk_next_steps" class="text-dark text-decoration-none d-block VK_ai_nav_link">
                                    Next Steps
                                </a>
                            </li>
                            <li>
                                <a href="#dk_sdditional"
                                    class="text-dark text-decoration-none d-block VK_ai_nav_link">
                                    Additional Resources
                                </a>
                            </li>
                            <li>
                                <a href="#dk_notices" class="text-dark text-decoration-none d-block VK_ai_nav_link">
                                    Notices and Disclaimers
                                </a>
                            </li>
                        </ul>
                    </div>
                </div>
                <div class="dk_things_code_main">
                    <div class="dk_things_code">
                        <h6>Author:</h6>
                    </div>
                    <p class="mb-0" style="padding-top: .25rem; padding-bottom: .625rem; font-weight: 700;">Kelli
                        Belcher</p>
                    <p>AI software solutions engineer</p>
                </div>
            </div>
            <div class="col-lg-9 col-md-8">
                <div class="d-md-flex justify-content-end col-xl-10 py-3 d-none">
                    <i class="fa-solid fa-print fs-4 px-2 " style="color:#0068B5"></i>
                    <i class="fa-regular fa-envelope fs-4 px-2" style="color:#0068B5"></i>
                </div>
                <div class="col-xl-10">
                    <p>&nbsp;</p>
                    <div style="padding-bottom: 16px;">
                        <p>Fine-tuning and deploying large language models (LLMs) with billions of parameters requires
                            significant memory and computational resources. To reduce these demands, we created a
                            two-part solution. The first part of this solution was performed using the <a
                                class="b_special_a1" href="">Llama 2 7B LLM developed by Meta* on an Intel<sup>®</sup>
                                Gaudi<sup>®</sup> 2 AI accelerator</a>.</p>
                        <p class="mb-0">&nbsp;</p>
                        <p>This article shows how to further optimize the inference component of the Llama 2 7B model
                            using the OpenVINO<sup>™</sup> toolkit to accelerate text generation on high-throughput
                            Intel<sup>®</sup> Arc<sup>™</sup> GPUs, which are built into Intel<sup>®</sup>
                            Core<sup>™</sup> Ultra processors. The GPU enables high-performance and low-power processing
                            by using the included feature set and capabilities and integrating them directly into the
                            system-on-a-chip (SoC) to deliver a new design optimization point for graphics. The AI PC
                            integrated GPU features eight X<sup>e</sup>-cores and 128 vector engines with an advanced
                            feature set, including support for Microsoft DirectX* 12 and Intel<sup>®</sup> X<sup>e</sup>
                            Super Sampling (X<sup>e</sup>SS) AI-based upscaling.<br>
                            &nbsp;</p>
                        <p class="mb-0">&nbsp;</p>
                        <p>To streamline and enhance the deployment of the Llama 2 7B LLM on the AI PC, we use the
                            OpenVINO<sup>™</sup> toolkit optimizations that are available as part of the Hugging Face*
                            Optimum ecosystem.</p>
                        <p class="mb-0">&nbsp;</p>
                    </div>
                    <section id="dk_prerequisites">
                        <h3 style="font-weight: 350; margin: 1rem 0 11px;">Prerequisites</h3>
                        <p class="mb-0">Before running this application, do the following:</p>
                        <ol>
                            <li>Ensure your AI PC meets the OpenVINO toolkit <a class="b_special_a1" href="">system
                                    requirements</a>.&nbsp;</li>
                            <li>Install the dependencies in the requirements.txt file in the <a class="b_special_a1"
                                    href="">source repository</a>.&nbsp;</li>
                        </ol>
                        <p>Once you have successfully installed the required packages, you are ready to optimize the 7
                            billion Llama 2 LLM for deployment on your AI PC.</p>
                        <p>This solution uses the model that was fine-tuned and uploaded to Hugging Face on the <a
                                class="b_special_a1" href="">FunDialogues community page</a>.&nbsp;</p>
                        <p>The model, with approximately 7 billion parameters, is just under 27 GB. To reduce its memory
                            footprint, we apply a compression technique using the OpenVINO toolkit to quantize the model
                            weights to int8 precision.</p>
                        <p>The optimized libraries from the OpenVINO toolkit can be imported from the Optimum for Intel
                            library as shown in the following code snippet. This library serves as the interface between
                            the Hugging Face Transformers and Diffusers libraries with OpenVINO toolkit optimizations.
                        </p>
                        <!-- code toolbar 3 -->
                        <div class="mv_code_toolbar">
                            <div class="mv_toolbar_item mv_copy_icon">
                                <i class="fa-regular fa-copy"></i>
                            </div>
                            <div class="mv_copy_message text-end hidden">Copied</div>
                            <div class="code-content">
                                <div style="padding-bottom: 0rem !important" class="d-flex mv_pre">
                                    <div style="border-right: 1px solid #ccc" class="pe-3">
                                        1
                                    </div>
                                    <div class="">
                                        <div class="mv_code text-break">
                                            <p class="mb-0">from optimum.intel import OVModelForCausalLM</p>
                                        </div>
                                    </div>
                                </div>
                                <div style="
                                  padding-top: 0rem !important;
                                " class="d-flex mv_pre">
                                    <div style="border-right: 1px solid #ccc" class="pe-3">
                                        2
                                    </div>
                                    <div class="">
                                        <div class="mv_code text-break">
                                            <p class="mb-0">from transformers import AutoTokenizer, pipeline</p>
                                        </div>
                                    </div>
                                </div>
                            </div>
                        </div>
                        <p>Next, the model is loaded from Hugging Face and exported to the OpenVINO toolkit intermediate
                            representation (IR) format with optimizations for performing inference on Intel Arc GPUs.
                            When exporting the model, the model weights are quantized to int8 precision, which is an
                            8-bit weight-only quantization provided by the Neural Network Compression Framework (NNCF).
                            This method compresses weights to an 8-bit integer datatype, which balances model size
                            reduction and accuracy, making it a versatile option for a broad range of applications.</p>
                        <!-- code toolbar 3 -->
                        <div class="mv_code_toolbar">
                            <div class="mv_toolbar_item mv_copy_icon">
                                <i class="fa-regular fa-copy"></i>
                            </div>
                            <div class="mv_copy_message text-end hidden">Copied</div>
                            <div class="code-content">
                                <div style="padding-bottom: 0rem !important" class="d-flex mv_pre">
                                    <div style="border-right: 1px solid #ccc" class="pe-3">
                                        1
                                    </div>
                                    <div class="">
                                        <div class="mv_code text-break">
                                            <p class="mb-0">model_id <span class="mv_sign_color">=</span> <span
                                                    class="mv_span_color">"FunDialogues/llamav2-LoRaco-7b-merged"</span>
                                            </p>
                                        </div>
                                    </div>
                                </div>
                                <div style="
                              padding-top: 0rem !important;
                            " class="d-flex mv_pre">
                                    <div style="border-right: 1px solid #ccc" class="pe-3">
                                        2
                                    </div>
                                    <div class="">
                                        <div class="mv_code text-break">
                                            <p class="mb-0">model <span class="mv_sign_color">=</span>
                                                OVModelForCausalLM.from_pretrained(model_id, export=True,
                                                load_in_8bit=True)</p>
                                        </div>
                                    </div>
                                </div>
                            </div>
                        </div>
                        <p>Once the model has been exported and quantized, the following output appears:</p>
                        <img class="w-100" src="/img/darshit_image/output1.png" alt="">
                        <p>After the model is exported to the OpenVINO toolkit IR format, the tokenizer is created and
                            the device is set to compile the model to the GPU.</p>
                        <!-- code toolbar 3 -->
                        <div class="mv_code_toolbar">
                            <div class="mv_toolbar_item mv_copy_icon">
                                <i class="fa-regular fa-copy"></i>
                            </div>
                            <div class="mv_copy_message text-end hidden">Copied</div>
                            <div class="code-content">
                                <div style="padding-bottom: 0rem !important" class="d-flex mv_pre">
                                    <div style="border-right: 1px solid #ccc" class="pe-3">
                                        1
                                    </div>
                                    <div class="">
                                        <div class="mv_code text-break">
                                            <p class="mb-0">tokenizer = AutoTokenizer.from_pretrained(model_id)</p>
                                        </div>
                                    </div>
                                </div>
                                <div style="
                              padding-top: 0rem !important;
                            " class="d-flex mv_pre">
                                    <div style="border-right: 1px solid #ccc" class="pe-3">
                                        2
                                    </div>
                                    <div class="">
                                        <div class="mv_code text-break">
                                            <p class="mb-0">model.to( <span class="mv_span_color">"gpu"</span>)</p>
                                        </div>
                                    </div>
                                </div>
                            </div>
                        </div>
                        <p>Next, we use the Hugging Face text generation pipeline to run inference.</p>
                        <!-- code toolbar 3 -->
                        <div class="mv_code_toolbar">
                            <div class="mv_toolbar_item mv_copy_icon">
                                <i class="fa-regular fa-copy"></i>
                            </div>
                            <div class="mv_copy_message text-end hidden">Copied</div>
                            <div class="code-content">
                                <div style="padding-bottom: 0rem !important" class="d-flex mv_pre">
                                    <div style="border-right: 1px solid #ccc" class="pe-3">
                                        1
                                    </div>
                                    <div class="">
                                        <div class="mv_code text-break">
                                            <p class="mb-0">query <span class="mv_sign_color">=</span> <span class="mv_span_color">"How far away is the moon"</span></p>
                                        </div>
                                    </div>
                                </div>
                                <div style="
                              padding-top: 0rem !important;
                              padding-bottom: 0rem !important;
                            " class="d-flex mv_pre">
                                    <div style="border-right: 1px solid #ccc" class="pe-3">
                                        2
                                    </div>
                                    <div class="">
                                        <div class="mv_code text-break">
                                            <p class="mb-0">pipe = pipeline( <span class="mv_span_color">"text-generation"</span>, model <span class="mv_sign_color">=</span> model, tokenizer <span class="mv_sign_color">=</span> tokenizer, max_new_tokens = 50)</p>
                                        </div>
                                    </div>
                                </div>
                                <div style="
                              padding-top: 0rem !important;
                              padding-bottom: 0rem !important;
                            " class="d-flex mv_pre">
                                    <div style="border-right: 1px solid #ccc" class="pe-3">
                                        3
                                    </div>
                                    <div class="">
                                        <div class="mv_code text-break">
                                            <p class="mb-0">response <span class="mv_sign_color">=</span> pipe(query)</p>
                                        </div>
                                    </div>
                                </div>
                                <div style="
                              padding-top: 0rem !important;
                            " class="d-flex mv_pre">
                                    <div style="border-right: 1px solid #ccc" class="pe-3">
                                        4
                                    </div>
                                    <div class="">
                                        <div class="mv_code text-break">
                                            <p class="mb-0">print(response[0][<span class="mv_span_color">'generated_text'</span>])</p>
                                        </div>
                                    </div>
                                </div>
                            </div>
                        </div>
                        <p>Your output will be similar to:</p>
                          <!-- code toolbar 3 -->
                          <div class="mv_code_toolbar">
                            <div class="mv_toolbar_item mv_copy_icon">
                                <i class="fa-regular fa-copy"></i>
                            </div>
                            <div class="mv_copy_message text-end hidden">Copied</div>
                            <div class="code-content">
                                <div style="padding-bottom: 0rem !important" class="d-flex mv_pre">
                                    <div style="border-right: 1px solid #ccc" class="pe-3">
                                        1
                                    </div>
                                    <div class="">
                                        <div class="mv_code text-break">
                                            <p class="mb-0">Compiling the model to GPU ... </p>
                                        </div>
                                    </div>
                                </div>
                                <div style="
                              padding-top: 0rem !important;
                              padding-bottom: 0rem !important;
                            " class="d-flex mv_pre">
                                    <div style="border-right: 1px solid #ccc" class="pe-3">
                                        2
                                    </div>
                                    <div class="">
                                        <div class="mv_code text-break">
                                            <p class="mb-0">How far away is the moon from the earth?</p>
                                        </div>
                                    </div>
                                </div>
                                <div style="
                              padding-top: 0rem !important;
                              padding-bottom: 0rem !important;
                            " class="d-flex mv_pre">
                                    <div style="border-right: 1px solid #ccc" class="pe-3">
                                        3
                                    </div>
                                    <div class="">
                                        <div class="mv_code text-break">
                                            <p class="mb-0">The moon is about 238,900 miles away from the Earth.</p>
                                        </div>
                                    </div>
                                </div>
                            </div>
                        </div>
                        <p>The first time the pipeline is run, it compiles the model to the GPU, which takes between one to two minutes. After the model has been compiled, we can ask new questions, and it will take just a few seconds to generate new responses.</p>
                        <p class="mb-0">&nbsp;</p>
                    </section>
                    <section id="dk_next_steps">
                        <h3 style="font-weight: 350; margin: 2.5rem 0 11px;">Next Steps</h3>
                        <ul>
                            <li>On GitHub*, <a class="b_special_a1" href="">access the full source code</a>.</li>
                            <li>For help or to talk to OpenVINO toolkit developers, visit the <a class="b_special_a1" href="">Intel® DevHub channel on Discord*</a>.</li>
                        </ul>
                        <p class="mb-0">&nbsp;</p>
                    </section>
                    <section id="dk_sdditional">
                        <h3 style="font-weight: 350; margin: 2.5rem 0 11px;">Additional Resources</h3>
                        <p><a class="b_special_a1" href="">Intel Gaudi 2 AI Accelerator</a><br>
                            <a class="b_special_a1" href="">OpenVINO™ Toolkit on GitHub</a><br>
                            <a class="b_special_a1" href="">AI PCs from Intel</a><br>
                            <a class="b_special_a1" href="">Intel Arc Graphics</a><br>
                            <a class="b_special_a1" href="">Optimum for Intel Library</a><br>
                            <a class="b_special_a1" href="">Neural Network Compression Framework (NNCF)</a><br>
                            <a class="b_special_a1" href="">Hugging Face Transformers</a><br>
                            <a class="b_special_a1" href="">Hugging Face Diffusers</a></p>
                    </section>
                    <section id="dk_notices">
                        <h3 style="font-weight: 350; margin: 2.5rem 0 11px;">Notices and Disclaimers </h3>
                        <p>Use of the pretrained Llama 2 model is subject to compliance with third-party licenses, including the <em>Llama 2 Community License Agreement</em> (LLAMAV2). For guidance on the intended use of the Llama 2 model, what will be considered misuse and out-of-scope uses, who are the intended users, and additional terms, review and read the <a href="https://ai.meta.com/llama/license/">license instructions</a>.&nbsp;</p>
                        <p>&nbsp;</p>
                        <p>&nbsp;</p>
                    </section>
                </div>
            </div>
            <p class="mb-0">&nbsp;</p>
        </div>
    </section>

    <section style="border-top: 1px solid #d7d7d7;" class="container py-5">
        <h4 class="h6">Product and Performance Information</h4>
        <div class="disclaimer" style="font-size: 12px;"><sup>1</sup> Performance varies by use, configuration and other
            factors. Learn more at <a class="b_special_a1" href="">www.Intel.com/PerformanceIndex</a>.</div>
        </div>
    </section>

    <!-- footer -->
    <div id="footer"></div>

    <!-- script header and footer -->
    <script>
        // navbar include  
        fetch('/y_index/y_navbar.html')
            .then(response => response.text())
            .then(data => {
                document.getElementById('navbar').innerHTML = data;
            });
        // footer include 
        fetch('/y_index/y_footer.html')
            .then(response => response.text())
            .then(data => {
                document.getElementById('footer').innerHTML = data;
            });
    </script>

    <!-- nav script -->
    <script>
        document.addEventListener('DOMContentLoaded', function () {
            const nav = document.querySelector('.VK_client_app_navigation');
            const navLinks = document.querySelectorAll('.VK_ai_nav_bar a');
            const sections = document.querySelectorAll('section[id]');
            let navOffset = nav.offsetTop;

            // Add smooth scrolling to all links
            navLinks.forEach(link => {
                link.addEventListener('click', function (e) {
                    e.preventDefault();
                    document.querySelector(this.getAttribute('href')).scrollIntoView({
                        behavior: 'smooth'
                    });
                });
            });

            // Sticky Navigation
            window.addEventListener('scroll', () => {
                if (window.pageYOffset >= navOffset) {
                    nav.classList.add('VK_sticky_nav_bar');
                } else {
                    nav.classList.remove('VK_sticky_nav_bar');
                }
                // Section highlighting
                sections.forEach(section => {
                    const sectionTop = section.offsetTop - nav.clientHeight;
                    const sectionHeight = section.clientHeight;
                    console.log(sectionTop);
                    console.log(sectionHeight);
                    if (window.pageYOffset >= sectionTop && window.pageYOffset <= sectionTop + sectionHeight) {
                        navLinks.forEach(link => {
                            link.classList.remove('active');
                            if (link.getAttribute('href') === `#${section.id}`) {
                                link.classList.add('active');

                                // Ensure the active link is visible in the nav bar
                                const navBar = document.querySelector('.VK_ai_nav_bar');
                                const activeLink = document.querySelector('.VK_ai_nav_bar a.active');
                                const linkRect = activeLink.getBoundingClientRect();
                                const navBarRect = navBar.getBoundingClientRect();

                                if (linkRect.left < navBarRect.left || linkRect.right > navBarRect.right) {
                                    activeLink.scrollIntoView({ inline: 'center', behavior: 'smooth' });
                                }
                            }
                        });
                    }
                });
            });
        });
    </script>

    <!-- copy script -->
    <script>
        document.addEventListener("DOMContentLoaded", () => {
            document.querySelectorAll(".mv_copy_icon").forEach((icon) => {
                icon.addEventListener("click", async function () {
                    try {
                        const toolbar = this.closest(".mv_code_toolbar");
                        const codeBlock = toolbar.querySelector(".code-content");
                        const codeContent = codeBlock.innerText;

                        // Use Clipboard API to copy text
                        await navigator.clipboard.writeText(codeContent);

                        // Hide the copy icon and show the "Copied!" message
                        const message = toolbar.querySelector(".mv_copy_message");
                        this.classList.add("hidden"); // Hide the copy icon
                        message.classList.remove("hidden"); // Show the "Copied!" message

                        // Hide the message and show the icon again after 2 seconds
                        setTimeout(() => {
                            message.classList.add("hidden");
                            this.classList.remove("hidden");
                        }, 2000); // Adjust delay as needed

                    } catch (err) {
                        console.error('Failed to copy text: ', err);
                    }
                });
            });
        });
    </script>

</body>

</html>