<!DOCTYPE html>
<html lang="en">

<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>Optimize Fine-Tuning and Deployment of LLMs on an AI PC</title>

    <link rel="stylesheet" href="/css/dk_ipus_improve_network_latency_in_microservices_based_applications.css">
    <link rel="stylesheet" href="/css/dk_nav_header.css">

    <!-- header footer -->
    <link rel="stylesheet" href='/css/yatri.css'>

    <link href="https://cdn.jsdelivr.net/npm/bootstrap@5.0.2/dist/css/bootstrap.min.css" rel="stylesheet"
        integrity="sha384-EVSTQN3/azprG1Anm3QDgpJLIm9Nao0Yz1ztcQTwFspd3yD65VohhpuuCOmLASjC" crossorigin="anonymous">
    <script src="https://cdn.jsdelivr.net/npm/bootstrap@5.0.2/dist/js/bootstrap.bundle.min.js"
        integrity="sha384-MrcW6ZMFYlzcLA8Nl+NtUVF0sA7MsXsP1UyJoMp4YLEuNSfAP+JcXn/tWtIaxVXM"
        crossorigin="anonymous"></script>
    <link href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/6.6.0/css/all.min.css" rel="stylesheet">
</head>
<style>
    nav{
        position: relative !important;
    }
</style>

<body>

    <!-- header -->
    <div id="navbar"></div>

        <!-- --------------------------------------------------------------------- -->
        <section>
            <nav class="mb_sub_nv">
                <div class="mv_breadcrumb">
                    <ol class="mv_spark_breadcrumb_items">
                        <li><p class="mb-0">Intel® IPUs Solve Microservices Network Challenges</p></li>
                    </ol>
                </div>
            </nav>
        </section>
        <!-- --------------------------------------------------------------------- -->

    <!-- Optimize Fine-Tuning and Deployment of LLMs on an AI PC -->
    <section>
        <div class="mv_intel_amx_bg_color">
            <div class="container">
                <div class="row mv_intel_amx_content">
                    <div class="col-md-9 mv_intel_amx_item">
                        <div class="mv_intel_amx">
                            <h4>IPUs Improve Network Latency in Microservices-Based Applications</h3>
                            <p>Intel Infrastructure Processing Units (IPUs) leverage Napatech’s virtualized data plane software to enable breakthrough latency and throughput for microservices-based cloud applications</p>
                        </div>
                    </div>
                    <div class="col-md-3 dk_napa_img">
                        <img class="w-100 mb-3" src="/img/darshit_image/napatech-customer-testimonial-video-thumbnail.png.rendition.intel.web.480.270.png" alt="">
                    </div>
                </div>
            </div>
        </div>
    </section>

    <section class="container py-5">
        <div class="row">
            <div class="d-flex justify-content-end col-xl-10 py-3 d-md-none">
                <i class="fa-solid fa-print fs-4 px-2 " style="color:#0068B5"></i>
                <i class="fa-regular fa-envelope fs-4 px-2" style="color:#0068B5"></i>
            </div>
            <div class="col-lg-3 col-md-4">
                <!-- nav -->
                <div class="VK_client_app_navigation VK_ai_navigation">
                    <div class="justify-content-center align-items-center overflow-hidden flex-nowrap mb-4">
                        <ul class="VK_ai_nav_bar list-unstyled m-0">
                            <li>
                                <a href="#what_are_micro" class="text-dark text-decoration-none d-block">
                                    What are Microservices?
                                </a>
                            </li>
                            <li>
                                <a href="#networking_challenge" class="text-dark text-decoration-none d-block VK_ai_nav_link">
                                    Networking Challenges for Microservices
                                </a>
                            </li>
                            <li>
                                <a href="#leveraging_intel"
                                    class="text-dark text-decoration-none d-block VK_ai_nav_link">
                                    Leveraging Intel® FPGA IPU-Based Architecture
                                </a>
                            </li>
                            <li>
                                <a href="#quantifying_the_benefits" class="text-dark text-decoration-none d-block VK_ai_nav_link">
                                    Quantifying the Benefits in the Real-World
                                </a>
                            </li>
                            <li>
                                <a href="#use_case1" class="text-dark text-decoration-none d-block VK_ai_nav_link">
                                    Use Case 1 - Pub-Sub Application Performance Analysis by MIT
                                </a>
                            </li>
                            <li>
                                <a href="#use_case2"
                                    class="text-dark text-decoration-none d-block VK_ai_nav_link">
                                    Use Case 2 - Three-Tier TCP Application Performance Analysis by MIT
                                </a>
                            </li>
                            <li>
                                <a href="#additional_info" class="text-dark text-decoration-none d-block VK_ai_nav_link">
                                    Additional Information
                                </a>
                            </li>
                        </ul>
                    </div>
                </div>
                <div class="dk_things_code_main">
                    <div class="dk_things_code">
                        <p><b>Summary</b></p>
                        <ul>    
                            <li>
                                    Microservices-based software architectures deployed by
                                    cloud service providers deliver important benefits such as
                                    accelerated deployment, simplified debugging, and improved
                                    scalability. However, they introduce significant networking
                                    overheads, so that parameters such as network latency have
                                    a major influence on overall application performance and
                                    data center cost.                 
                            </li>
                            <li>
                                    By leveraging Intel FPGA IPUs running virtualized data plane
                                    software from Napatech, service providers can maximize the
                                    performance of their networking infrastructure, enabling
                                    a level of performance otherwise unachievable while
                                    minimizing their overall data center CAPEX and OPEX.
                            </li>
                            <li>
                                    An analysis performed by MIT demonstrated that in two typical
                                    microservices-based use cases, this IPU solution enables a
                                    50% increase in system throughput compared to a system
                                    configuration based on a standard Network Interface Card
                                    (NIC). This enables service providers to decrease the number
                                    of servers required to support their total workload for these
                                    use cases by approximately one-third, driving a significant
                                    reduction in server CAPEX, OPEX, and energy efficiency. 
                            </li>
                        </ul>
                    </div>
                    <p class="mb-0" style="padding-top: .25rem; padding-bottom: .625rem; font-weight: 700;">Kelli
                        Charlie Ashton</p>
                    <p>Senior Director of Business Development, Napatech</p>
                    <p class="mb-0" style="padding-top: .25rem; padding-bottom: .625rem; font-weight: 700;">Rich Howell
                    </p>
                    <p>Product Marketing Manager, Intel</p>
                </div>
            </div>
            <div class="col-lg-9 col-md-8">
                <div class="d-md-flex justify-content-end col-xl-10 py-3 d-none">
                    <i class="fa-regular fa-file-lines fs-4 px-2" style="color:#0068B5"></i>
                    <i class="fa-solid fa-print fs-4 px-2 " style="color:#0068B5"></i>
                    <i class="fa-regular fa-envelope fs-4 px-2" style="color:#0068B5"></i>
                </div>
                <div class="col-xl-10">
                    <h4 style="font-weight: 300;">This solution brief analyzes the benefits delivered by an Infrastructure Processing Unit (IPU) solution for two microservices-based use cases, a Publish-Subscribe (Pub-Sub) application and a three-tier client-server application. In these use cases, the IPU solution enables a 50% increase in system throughput compared to a system configuration based on a standard Network Interface Card (NIC).</h4>
                    <p>&nbsp;</p>
                    <p>&nbsp;</p>

                    <section id="what_are_micro">
                    <h4 style="font-weight: 300;">What are Microservices?</h4>
                    <p>Microservices refer to a modern software development approach that involves breaking down a large application into smaller, independent, loosely coupled services. Rather than implementing applications as traditional monolithic software systems, cloud service providers, including well-known companies such as Amazon, eBay, Netflix and Twitter, are increasingly implementing their applications as microservices rather than traditional monolithic designs.</p>
                    <p>Some benefits of microservices include:</p>
                    <ul role="list">
                        <li aria-setsize="-1" role="listitem">
                        <p><strong>Scalability</strong>: Microservices allow for better scalability, as individual services can be scaled independently of each other. This means that developers can scale up or down only the services that need it, without affecting the rest of the application.</p>
                        </li>
                        <li aria-setsize="-1" role="listitem">
                        <p><strong>Flexibility: </strong>Microservices make it easier to make changes to a system because individual services can be updated without affecting the entire application. This makes it easier to adopt new technologies, experiment with different programming languages and test new features.</p>
                        </li>
                        <li aria-setsize="-1" role="listitem">
                        <p><strong>Fault isolation: </strong>Since each microservice is an independent component, if one service fails it doesn’t affect the rest of the application. This means that developers can quickly identify and fix problems without affecting the entire system.</p>
                        </li>
                        <li aria-setsize="-1" role="listitem">
                        <p><strong>Improved development speed:</strong> Microservices enable smaller, more focused development teams to work independently on specific services. This speeds up the development process and makes it easier to manage large, complex systems.</p>
                        </li>
                        <li aria-setsize="-1" role="listitem">
                        <p><strong>Better fault tolerance: </strong>With microservices, it’s easier to build fault-tolerant systems because each service can be designed to handle errors independently. This means that the entire system is more resilient and less likely to fail.</p>
                        </li>
                        <li aria-setsize="-1" role="listitem">
                        <p><strong>Improved testing: </strong>Since each microservice is independent, it’s easier to test individual services. This means that developers can test services in isolation, which makes it easier to find and fix bugs.</p>
                        </li>
                    </ul>
                    <p>While microservices-based software architectures deliver important benefits, they introduce significant networking overheads, so that parameters such as network latency have a major influence on overall application performance and data center cost. By leveraging Intel FPGA Infrastructure Processing Units (IPUs) running virtualized data plane software from Napatech, service providers can maximize the performance of their networking infrastructure, enabling a level of performance otherwise unachievable while minimizing their overall data center CAPEX and OPEX.</p>
                    <p>&nbsp;</p>
                    </section>

                    <section id="networking_challenge">
                        <h4 style="font-weight: 300;">Networking Challenges for Microservices</h4>
                        <p>In a microservices architecture, network latency presents a significant challenge as virtualized services implemented in containers or Virtual Machines (VMs) communicate with each other over a virtualized network. For example, microservices communicate with each other frequently, which can result in a large amount of network traffic. This increased network traffic can lead to network congestion and increased latency, which can negatively impact the performance of the system. Similarly, in a microservices architecture, services often need to call other services to complete a task and each network call adds additional latency to the system. As the number of services and the complexity of the system increases, the number of network calls also increases, which can lead to significant latency challenges. Finally, different microservices may use different network protocols for communication. For example, one service may use REST (REpresentational State Transfer) while another service may use gRPC (Google Remote Procedure Call). Translating between different network protocols can add additional latency to the system.</p>
                        <p>Traditionally, a virtualized data plane is implemented completely in software and many of its compute cycles are consumed by running a virtual switch (vSwitch) which routes network traffic between VMs. Since each vSwitch operation requires a significant number of CPU cycles, this architecture can introduce unacceptable latency into the system and may also prevent the system from achieving the overall performance or throughput required. At the same time, a CPU that is heavily utilized running the virtual data plane will have fewer cores available for running applications and services, increasing the number of servers required to support the data center workload, and increasing both CAPEX and OPEX. <strong>See Figure 1.</strong></p>
                        <img class="w-100" src="/img/darshit_image/multiple-vms-interconnected-diagram.png" alt="">
                        <h5 style="text-align: center; padding-top: 10px;">Figure 1. Multiple VMs interconnected with a software virtual switch running on a server configured with a standard Ethernet adapter</h5>
                        <p>&nbsp;</p>
                    </section>

                    <section id="leveraging_intel">
                        <h4 style="font-weight: 300;">Leveraging Intel® FPGA IPU-Based Architecture</h4>
                        <p>A more efficient and cost-effective system-level architecture leverages an Intel FPGA IPU to offload the vSwitch from the server CPU, freeing up the server CPU for running applications and services.</p>
                        <p>The IPU, which replaces the standard Network Interface Card (NIC) in the data center server, implements the vSwitch in hardware, using a programmable FPGA (Field Programmable Gate Array) to run the data plane in conjunction with a general-purpose CPU that runs the control plane. The vSwitch presents an industry-standard API (Application Programming Interface) to the VMs, ensuring that no changes need to made to the VMs themselves when taking advantage of this architecture. <strong>See Figure 2.</strong></p>
                        <p class="mb-4">The IPU-based architecture delivers three key benefits for a data center running microservices-based applications:</p>

                        <ul role="list">
                            <li aria-setsize="-1" role="listitem">
                            <p>Ultra-low latency, which minimizes the delay traffic between the microservices;</p>
                            </li>
                            <li aria-setsize="-1" role="listitem">
                            <p>High performance, which maximizes the overall throughput of the system and application;</p>
                            </li>
                            <li aria-setsize="-1" role="listitem">
                            <p>Optimum server CPU utilization with no server CPU cores consumed by the vSwitch data plane, which minimizes the total number of servers required for the overall workload, also minimizing data center CAPEX and OPEX.</p>
                            </li>
                        </ul>
                        <img class="w-100" src="/img/darshit_image/high-performance-system-architecture-diagram.png" alt="">
                        <h5 style="font-weight: 300; text-align: center; padding-top: 10px;">Figure 2. High-performance system architecture in which multiple VMs are interconnected with an offloaded virtualswitch running on an IPU</h5>
                        <p>&nbsp;</p>
                    </section>

                    <section id="quantifying_the_benefits">
                        <h4 style="font-weight: 300;">MIT Analysis</h4>
                        <p>To quantify the benefits of vSwitch offload in real-world scenarios, Massachusetts Institute of Technology (MIT) analyzed the performance of two microservices-based use cases, comparing the results from using a traditional software-based vSwitch with those obtained using an Intel IPU running virtualized data plane software from Napatech, a leading provider of SmartNIC and IPU solutions. These two use cases were a publish-subscribe “pub-sub” application that uses message passing for data transfers across multiple tiers and a three-tier TCP application comprising a web server, in-memory cache, and back-end database. The results of this benchmarking initiative are documented in the paper <a class="b_special_a1" href="">“Microservice Benchmarking on Intel IPUs running Napatech Software”</a> published by MIT.</p>
                        <p>&nbsp;</p>
                    </section>

                    <section id="use_case1">
                        <h4 style="font-weight: 300;">Pub-Sub Application Performance Analysis</h4>
                        <p class="mb-4">A pub-sub application, short for "publish-subscribe application," is a messaging pattern commonly used in distributed systems to facilitate the communication and coordination between different components or services. The pub-sub pattern allows for asynchronous and decoupled communication, where senders of messages, known as publishers, do not need to know the specific recipients, known as subscribers. Pub-sub applications are applicable to use cases such as:</p>

                        <ul role="list">
                            <li aria-setsize="-1" role="listitem">
                            <p><strong>Seating reservation systems</strong> that create a floor plan, assign seats to it and then manage the live seat-booking events. As clients buy tickets, the pub-sub system updates the floor plan everywhere in real time and keeps the distributed cache system in sync. Clients never end up requesting a seat only to find out someone had bought it while they were still in the browsing/shopping phase.</p>
                            </li>
                            <li aria-setsize="-1" role="listitem">
                            <p><strong>Educational tools </strong>that allow students to participate in a classroom via a web-based app, where clients often encounter issues such as unreliable WiFi or unpredictable cellular networks. The pub-sub system recovers their connection when they rejoin the network and is able to handle rapid changes in the number of online participants.</p>
                            </li>
                            <li aria-setsize="-1" role="listitem">
                            <p><strong>Financial applications </strong>such as the distribution of market data including stock prices, market indices, trade data and order book updates to subscribers within an organization.</p>
                            </li>
                            <li aria-setsize="-1" role="listitem">
                            <p><strong>Internet of Things (IoT) systems</strong>, where pub-sub facilitates communication between numerous IoT devices and enables efficient data dissemination. Sensors publish data, then subscribers can receive and process that data in real-time.</p>
                            </li>
                        </ul>
                        <p>For this analysis, MIT evaluated a five-tier chain topology developed with a pub-sub communication model from <a class="b_special_a1" href="" rel="noreferrer noopener">Dapr</a>, which is a portable, event-driven runtime that enables developers to build resilient, stateless and stateful applications that run both on the cloud and edge, while supporting a diversity of languages and developer frameworks. Each tier performs CPU-intensive computation for a user-specified amount of time, before broadcasting its output to the downstream tier. <strong>See Figure 3</strong>.</p>
                        <p>Within the five-tier pub-sub application, the placement of services across the two OVS-enabled servers ensures that dependent services are running on different physical machines, so that all traffic between tiers passes across the IPUs, when enabled.</p>

                        <img class="w-100" src="/img/darshit_image/ipu-offloaded-5-tier-diagram.png" alt="">

                        <h5 style="text-align: center;">Figure 3. Traffic flow in the IPU-offloaded 5-tier pub-sub application</h5>
                        <p>&nbsp;</p>
                        <p>MIT analyzed the performance of the pub-sub system both with and without the IPU-based offload, measuring the messaging latency across varying loads which are expressed as thousands of queries per second (kQPS). <strong>See Figure 4</strong>.</p>

                        <img class="w-100" src="/img/darshit_image/5-tier-pub-sub-application-diagram.png" alt="">

                        <h5 style="text-align: center;">Figure 4. Latency and throughput improvements with IPU offload for 5-tier Pub-sub application</h5>
                        <p>&nbsp;</p>
                        <p>When offload is disabled and considering tail (i.e. worstcase) latency, the application starts to saturate at 90kQPS, as indicated by the inflection point in the graph. Beyond that load level, the system can no longer efficiently keep up with requests, most likely due to packet drops that result in TCP retransmissions. When offload is enabled, however, the system is still keeping up with requests at a load of 140kQPS, the maximum rate used in this test, indicating that <strong>the IPU enables a 50% increase in throughput while maintaining acceptable tail latency.</strong> This represents a significant improvement in system capacity, resulting in savings of 30-40% in both total server cost and energy consumption.</p>
                        <p>&nbsp;</p>
                    </section>

                    <section id="use_case2">
                        <h4 style="font-weight: 300;">Three-Tier TCP Application Performance Analysis</h4>
                        <p>A three-tier TCP (Transmission Control Protocol) application refers to a software architecture design that divides an application into three logical layers or tiers, each responsible for specific functions. These tiers are typically referred to as the presentation tier, application tier, and data tier. The TCP protocol is used for communication between these tiers:</p>
                        <p class="mb-0">&nbsp;</p>
                        <ul role="list">
                            <li aria-setsize="-1" role="listitem">
                            <p><strong>Presentation Tier: </strong>Also known as the user interface (UI) tier, this layer is responsible for presenting the application’s information to users and receiving their inputs. It deals with graphical user interface (GUI) components, such as web pages, forms, or desktop interfaces. The presentation tier communicates with the application tier to retrieve or update data as necessary.</p>
                            </li>
                        </ul>
                        <ul role="list">
                            <li aria-setsize="-1" role="listitem">
                            <p><strong>Application Tier: </strong>The application tier contains the business logic and processing logic of the application. It handles the core functionality and performs tasks such as data validation, business rules enforcement, and application-specific operations. This tier processes the requests from the presentation tier and communicates with the data tier to retrieve or store data.</p>
                            </li>
                            <li aria-setsize="-1" role="listitem">
                            <p><strong>Data Tier: </strong>The data tier, also known as the data access layer or database tier, is responsible for managing the storage and retrieval of data. It handles interactions with the database systems, such as querying and updating data. The data tier receives requests from the application tier and returns the requested data or performs the necessary data modifications.</p>
                            </li>
                        </ul>
                        <p>In a three-tier TCP application, the communication between these tiers is facilitated using the TCP protocol. TCP ensures reliable and ordered delivery of data between the tiers, providing a connection-oriented and stream-based communication mechanism. By separating the application into these three tiers, the three-tier TCP architecture allows for modularity, scalability, and easier maintenance of the application. Each tier can be developed and scaled independently, facilitating flexibility and reusability of components.</p>
                        <p>For this analysis, MIT evaluated a three-tier application with <a class="b_special_a1" href="" rel="noreferrer noopener">NGINX</a> as the front-end web server, <a class="b_special_a1" href="" rel="noreferrer noopener">Memcached</a> as the in-memory caching tier, and <a class="b_special_a1" href="" rel="noreferrer noopener">MongoDB</a> as the back-end database with persistent storage. Clients interact with NGINX, which checks if a key-value pair is cached in Memcached and, if so, returns the value to the client. If not, NGINX interfaces with MongoDB to fetch the output and additionally cache it in Memcached. <strong>See Figure 5</strong>.</p>

                        <img class="w-100" src="/img/darshit_image/ipu-offloaded-3-tier-diagram.png" alt="">
                        <h5 style="text-align: center;">Figure 5. Traffic flow in the IPU-offloaded 3-tier TCP application</h5>
                        <p class="mb-0">&nbsp;</p>
                        <p>MIT analyzed the performance of the three-tier TCP application both with and without the IPU-based offload, measuring the messaging latency across varying loads which, as in the previous example, are expressed as thousands of queries per second (kQPS).&nbsp;<strong>See Figure 6</strong>.</p>

                        <img class="w-100" src="/img/darshit_image/3-tier-tcp-application-diagram.png" alt="">
                        <h5 style="text-align: center; font-weight: 300;" >Figure 6. Latency and throughput improvements with IPU offload for 3-tier TCP application</h5>
                        <p>&nbsp;</p>
                        <p>When offload is disabled and considering tail (i.e. worst-case) latency, the application starts to saturate at approximately 17kQPS, as indicated by the inflection point in the graph. Beyond that load level, the system can no longer efficiently keep up with requests, most likely due to packet drops that result in TCP retransmissions. When offload is enabled, however, saturation does not start until a load of 26kQPS, indicating that <strong>the IPU enables a 53% increase in throughput while maintaining acceptable tail latency.</strong>&nbsp;Like the previous example, this represents a significant improvement in system capacity, resulting in savings of 30-40% in both total server cost and energy consumption.</p>

                        <p>&nbsp;</p>

                        <h4 style="font-weight: 300;">System Configuration</h4>
                        <p>The system configuration used by MIT for microservices benchmarking was as follows:</p>
                        <p class="mb-0">&nbsp;</p>
                        <ul>
                            <li>Two Inspur dual-socket servers, each featuring an Intel® Xeon® Gold 6338 Processor with 48MB cache, running at 2.0 GHz with 3.2 GHz turbo speed. Each server was configured with 512GB memory, a 480GB boot drive, dual 1.6TB P6410 NVMe storage modules and one 10G Intel® Ethernet Controller XL710 NIC.</li>
                        </ul>
                        <ul>
                            <li>In addition to the standard NIC, each server was configured with one Intel IPU C5000X adapter&nbsp;with dual 10/25G SFP28 ports and a PCIe 3.0 host interface, based on an Intel® Stratix® FPGA and Intel® Xeon® D System-on-Chip (SoC).<strong> See Figure 7</strong>.</li>
                        </ul>
                        <ul>
                            <li>Each IPU was running the Link-Virtualization 4.3.3 software from Napatech, providing an offloaded and accelerated virtualized data plane including functions such as Open vSwitch (OVS), VirtIO support, live migration, VM-to-VM mirroring, VLAN/VxLAN encapsulation/decapsulation, Q-in-Q, RSS load balancing, link aggregation and Quality of Service (QoS).</li>
                        </ul>

                        <img class="w-100" src="/img/darshit_image/fpga-ipu-c5000x-pl-board-graphic.png" alt="">
                        <h5 style="text-align: center;">Figure 7. Intel IPU C5000X adapter with dual 10/25G SFP28 ports and a PCIe 3.0 host interface, based on an Intel® Stratix® FPGA and Intel® Xeon® D System-on-Chip (SoC)</h5>
                    </section>
                </div>
            </div>
            <p class="mb-0">&nbsp;</p>
        </div>
    </section>

     <!-------------------------------- Related Links ---------------------------------->
     <section>
        <div class="mv_discover_more_padd">
            <div class="container">
                <h4 class="mb-3" style="font-weight: 350; color: #fff;">Additional Information</h4>
                <div class="row mv_intel_tiber_content">
                    <div class="mv_intel_tiber col-xxl-4 col-md-6">
                        <div class="mv_intel_card">
                            <div class="mv_intel_tiber_img">
                                <i class="fa-regular fa-file"></i>
                            </div>
                            <div style="align-content: center;">
                                <a href="" class="dk_issue">
                                Intel® IPU Platform C5000X-PL</a>
                            </div>
                        </div>
                    </div>
                    <div class="mv_intel_tiber col-xxl-4 col-md-6">
                        <div class="mv_intel_card">
                            <div class="mv_intel_tiber_img">
                                <i class="fa-regular fa-file"></i>
                            </div>
                            <div style="align-content: center;">
                                <a href="" class="dk_issue">
                                    Intel-based IPU with Napatech Link-Virtualization Software</a>
                            </div>
                        </div>
                    </div>
                    <div class="mv_intel_tiber col-xxl-4 col-md-6">
                        <div class="mv_intel_card">
                            <div class="mv_intel_tiber_img">
                                <i class="fa-solid fa-share-nodes"></i>
                            </div>
                            <div style="align-content: center;">
                                <a href="" class="dk_issue">MIT Paper - Microservice Benchmarking on Intel IPUs running Napatech Software</a>
                            </div>
                        </div>
                    </div>
                </div>
            </div>
        </div>
    </section>
    <!-- ------------------------------------------------------------------------- -->

    <!-- footer -->
    <div id="footer"></div>

    <!-- script header and footer -->
    <script>
        // navbar include  
        fetch('/y_index/y_navbar.html')
            .then(response => response.text())
            .then(data => {
                document.getElementById('navbar').innerHTML = data;
            });
        // footer include 
        fetch('/y_index/y_footer.html')
            .then(response => response.text())
            .then(data => {
                document.getElementById('footer').innerHTML = data;
            });
    </script>

    <!-- nav script -->
    <script>
        document.addEventListener('DOMContentLoaded', function () {
            const nav = document.querySelector('.VK_client_app_navigation');
            const navLinks = document.querySelectorAll('.VK_ai_nav_bar a');
            const sections = document.querySelectorAll('section[id]');
            let navOffset = nav.offsetTop;

            // Add smooth scrolling to all links
            navLinks.forEach(link => {
                link.addEventListener('click', function (e) {
                    e.preventDefault();
                    document.querySelector(this.getAttribute('href')).scrollIntoView({
                        behavior: 'smooth'
                    });
                });
            });

            // Sticky Navigation
            window.addEventListener('scroll', () => {
                if (window.pageYOffset >= navOffset) {
                    nav.classList.add('VK_sticky_nav_bar');
                } else {
                    nav.classList.remove('VK_sticky_nav_bar');
                }
                // Section highlighting
                sections.forEach(section => {
                    const sectionTop = section.offsetTop - nav.clientHeight;
                    const sectionHeight = section.clientHeight;
                    console.log(sectionTop);
                    console.log(sectionHeight);
                    if (window.pageYOffset >= sectionTop && window.pageYOffset <= sectionTop + sectionHeight) {
                        navLinks.forEach(link => {
                            link.classList.remove('active');
                            if (link.getAttribute('href') === `#${section.id}`) {
                                link.classList.add('active');

                                // Ensure the active link is visible in the nav bar
                                const navBar = document.querySelector('.VK_ai_nav_bar');
                                const activeLink = document.querySelector('.VK_ai_nav_bar a.active');
                                const linkRect = activeLink.getBoundingClientRect();
                                const navBarRect = navBar.getBoundingClientRect();

                                if (linkRect.left < navBarRect.left || linkRect.right > navBarRect.right) {
                                    activeLink.scrollIntoView({ inline: 'center', behavior: 'smooth' });
                                }
                            }
                        });
                    }
                });
            });
        });
    </script>

    <!-- copy script -->
    <script>
        document.addEventListener("DOMContentLoaded", () => {
            document.querySelectorAll(".mv_copy_icon").forEach((icon) => {
                icon.addEventListener("click", async function () {
                    try {
                        const toolbar = this.closest(".mv_code_toolbar");
                        const codeBlock = toolbar.querySelector(".code-content");
                        const codeContent = codeBlock.innerText;

                        // Use Clipboard API to copy text
                        await navigator.clipboard.writeText(codeContent);

                        // Hide the copy icon and show the "Copied!" message
                        const message = toolbar.querySelector(".mv_copy_message");
                        this.classList.add("hidden"); // Hide the copy icon
                        message.classList.remove("hidden"); // Show the "Copied!" message

                        // Hide the message and show the icon again after 2 seconds
                        setTimeout(() => {
                            message.classList.add("hidden");
                            this.classList.remove("hidden");
                        }, 2000); // Adjust delay as needed

                    } catch (err) {
                        console.error('Failed to copy text: ', err);
                    }
                });
            });
        });
    </script>

</body>

</html>