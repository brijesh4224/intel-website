<!DOCTYPE html>
<html lang="en">

<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>What's New</title>

    <!-- slider -->
    <link rel="stylesheet" href="/css/all.min.css">
    <link rel="stylesheet" href="/css/animate.min.css">
    <link rel="stylesheet" href="/css/owl.carousel.min.css">
    <link rel="stylesheet" href="/css/owl.theme.default.min.css">

    <!-- Style Css -->
    <link rel="stylesheet" href="/css/mv_Intel_Distribution_of_OpenVINO_Toolkit.css">

    <!-- header footer -->
    <link rel="stylesheet" href='/css/yatri.css'>

    <link href="https://cdn.jsdelivr.net/npm/bootstrap@5.0.2/dist/css/bootstrap.min.css" rel="stylesheet"
        integrity="sha384-EVSTQN3/azprG1Anm3QDgpJLIm9Nao0Yz1ztcQTwFspd3yD65VohhpuuCOmLASjC" crossorigin="anonymous">
    <script src="https://cdn.jsdelivr.net/npm/bootstrap@5.0.2/dist/js/bootstrap.bundle.min.js"
        integrity="sha384-MrcW6ZMFYlzcLA8Nl+NtUVF0sA7MsXsP1UyJoMp4YLEuNSfAP+JcXn/tWtIaxVXM"
        crossorigin="anonymous"></script>
    <link href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/6.6.0/css/all.min.css" rel="stylesheet">
</head>

<body>
    <div id="navbar"></div>
    <section>
        <div class="">
            <div class="mv_featured_bg_color">
                <div class="mv_download_product">
                    <div class="mv_breadcrumb row">
                        <div class="col-md-12">
                        </div>
                    </div>
                    <div class="row mv_enhance_content">
                        <div class="col-md-10">

                            <div class="mv_enhance_heading11 mx-auto">
                                <img src="../img/mv_image/openvinotm.png" />
                            </div>

                            <div class="mv_enhance_heading mb-4 mx-auto">
                                <h3 class="mt-2" style="font-weight: 200; color: white;">OpenVINO™ toolkit: An open
                                    source AI toolkit that makes it easier to write once, deploy anywhere.
                                </h3>
                            </div>
                            <!-- <div class="mv_enhance_heading mx-auto d-flex ">
                                <div class="me-2">
                                    <button>Overview</button>
                                </div>
                                <div class="me-2">
                                    <button>What'sNew</button>
                                </div>
                                <div class="me-2">
                                    <button>GetStarted</button>
                                </div>
                                <div class="me-2">
                                    <button>EdgeAIReferenceKits</button>
                                </div>
                                <div class="me-2">
                                    <button>AIPC</button>
                                </div>
                                <div class="me-2">
                                    <button>Download</button>
                                </div>
                            </div> -->
                        </div>

                        <div class="col-6">
                            <!-- <div class="mv_enhance_heading mx-auto justify-content-center d-flex">
                                <img src="../img/mv_image/man-woman.png" />
                            </div> -->
                        </div>
                    </div>
                </div>
            </div>

            <div class="row mv_enhance_heading mx-auto">
                <div class="col-6">
                    <h2 style="font-weight: 200;" class="mb-4">What's New in Version 2024.4</h2>
                    <p>
                        This release takes your AI deployments to the next level with new features and performance
                        enhancements. It introduces broader support for large language models (LLMs), optimized runtimes
                        for Intel® hardware, and expanded capabilities for efficient AI deployment across edge, cloud,
                        and local environments. Explore the latest updates and unlock new possibilities for your AI
                        projects.
                    </p>

                    <p><a href="">Release Notes</a></p>
                    <p><a href="">View System Requirements</a></p>
                </div>
                <div class="col-6">
                    <img src="../img/mv_image/seven-cart.png" class="object-fit-cover w-100" />
                </div>
            </div>

            <div class="mv_enhance_heading mx-auto">
                <h2 style="font-weight: 200;">Latest Features</h2>
                <b>Easier Model Access and Conversion</b>
            </div>

            <div class="mv_enhance_heading mx-auto mt-4">
                <div class="table-responsive product-table ">
                    <table class="table table-bordered">
                        <thead>
                            <tr>
                                <th style="width: 40%; background-color: #e9e9e9" class="text-center">
                                    Product</th>
                                <th style="width: 20%; background-color: #e9e9e9" class="text-center">
                                    Details</th>
                            </tr>
                        </thead>
                        <tbody>
                            <tr>
                                <td>New Model Support </td>
                                <td>Support for GLM-4-9B Chat, MiniCPM-1B, Llama 3 and 3.1, Phi-3-Mini, Phi-3-Medium,
                                    and YOLOX-s models.

                                    NPUs on Intel® Core™ Ultra processor (Series 2) enabled for transformer models like
                                    Stable Diffusion*. </td>
                            </tr>
                        </tbody>
                    </table>
                </div>
            </div>

            <div class="mv_enhance_heading mx-auto">
                <b>Generative AI and LLM Enhancements </b>
                <p>Expanded model support and accelerated inference.</p>
            </div>

            <div class="mv_enhance_heading mx-auto mt-4">
                <div class="table-responsive product-table ">
                    <table class="table table-bordered">
                        <thead>
                            <tr>
                                <th style="width: 40%; background-color: #e9e9e9" class="text-center">
                                    Product</th>
                                <th style="width: 20%; background-color: #e9e9e9" class="text-center">
                                    Details</th>
                            </tr>
                        </thead>
                        <tbody>
                            <tr>
                                <td>New Jupyter* Notebooks</td>
                                <td>
                                    Noteworthy notebooks added: Florence-2, NuExtract-tiny Structure Extraction, Flux.1
                                    Image Generation, PixArt-α: Photorealistic Text-to-Image Synthesis, and Phi-3-Vision
                                    Visual Language Assistant.
                                </td>
                            </tr>
                        </tbody>
                    </table>
                </div>
            </div>

            <div class="mv_enhance_heading mx-lg-auto">
                <b>More Portability and Performance</b>
                <p>Develop once, deploy anywhere. OpenVINO toolkit enables developers to run AI at the edge, in the
                    cloud, or locally. </p>
            </div>

            <div class="mv_enhance_heading mx-auto mt-4">
                <div class="table-responsive product-table ">
                    <table class="table table-bordered">
                        <thead>
                            <tr>
                                <th style="width: 40%; background-color: #e9e9e9" class="text-center">
                                    Product</th>
                                <th style="width: 20%; background-color: #e9e9e9" class="text-center">
                                    Details</th>
                            </tr>
                        </thead>
                        <tbody>
                            <tr>
                                <td>Model Serving Enhancements</td>
                                <td>
                                    OpenVINO Model Server now comes with production-quality support for
                                    OpenAI*-compatible API, which enables significantly higher throughput for parallel
                                    inferencing on Intel® Xeon® processors when serving LLMs to many concurrent
                                    users.<br><br>
                                    Improved performance and memory consumption with prefix caching, KV cache
                                    compression, and other optimizations for serving LLMs using OVMS.
                                </td>
                            </tr>

                            <tr>
                                <td>Intel Hardware Support</td>
                                <td>
                                    OpenVINO runtime optimized for Intel® Xe Matrix Extensions (Intel® XMX) systolic
                                    arrays on built-in GPUs for efficient matrix multiplication resulting in significant
                                    LLM performance boost with improved first and second token latency, as well as a
                                    smaller memory footprint on Intel Core Ultra processors (Series 2). <br><br>
                                    Improved performance and memory consumption with prefix caching, KV cache
                                    compression, and other optimizations for serving LLMs using OVMS.<br><br>
                                    Memory sharing is enabled for NPUs on Intel Core Ultra processors (Series 2) for
                                    efficient pipeline integration without memory copy overhead.<br><br>
                                    Support for Intel Core Ultra processors (Series 2) on Windows*.<br><br>
                                    Addition of the PagedAttention feature for discrete GPUs enables a significant boost
                                    in throughput for parallel inferencing when serving LLMs on Intel® Arc™ Graphics or
                                    Intel® Data Center GPU Flex Series.<br><br>
                                </td>
                            </tr>

                            <tr>
                                <td>Additional Platform Support</td>
                                <td>
                                    Support for Python* 3.12<br><br>
                                    Support for Red Hat* Enterprise Linux* v9.3 to v9.4 <br><br>
                                </td>
                            </tr>
                        </tbody>
                    </table>
                </div>
            </div>

            <div class="mv_enhance_heading mx-auto">
                <h2 style="font-weight: 200;">Stay Up-To-Date</h2>
                <div class="row">
                    <div class="col-6">
                        <p><a href="">OpenVINO on Medium*</a></p>
                    </div>
                    <div class="col-6">
                        <p><a href="">OpenVINO Toolkit Get Started Guide</a></p>
                    </div>
                </div>
            </div>
        </div>

        <!-- <div class="mv_main_product1 mx-auto">

            </div> -->

        <div class="row">
            <!-- Sidebar -->
            <!-- Main Content -->
        </div>

    </section>
    <div id="footer"></div>

    <script>
        fetch('/y_index/y_navbar.html')
            .then(response => response.text())
            .then(data => {
                document.getElementById('navbar').innerHTML = data;
            });
        fetch('/y_index/y_footer.html')
            .then(response => response.text())
            .then(data => {
                document.getElementById('footer').innerHTML = data;
            });
    </script>
</body>

</html>