<!DOCTYPE html>
<html lang="en">
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>Efficient, custom object detection training template made easy</title>

    <!-- slider -->
    <link rel="stylesheet" href="/css/all.min.css">
    <link rel="stylesheet" href="/css/animate.min.css">
    <link rel="stylesheet" href="/css/owl.carousel.min.css">
    <link rel="stylesheet" href="/css/owl.theme.default.min.css">

    <!-- Style Css -->
    <link rel="stylesheet" href="/css/mv_card.css">

    <!-- header footer -->
    <link rel="stylesheet" href='/css/yatri.css'>

    <link href="https://cdn.jsdelivr.net/npm/bootstrap@5.0.2/dist/css/bootstrap.min.css" rel="stylesheet"
        integrity="sha384-EVSTQN3/azprG1Anm3QDgpJLIm9Nao0Yz1ztcQTwFspd3yD65VohhpuuCOmLASjC" crossorigin="anonymous">
    <script src="https://cdn.jsdelivr.net/npm/bootstrap@5.0.2/dist/js/bootstrap.bundle.min.js"
        integrity="sha384-MrcW6ZMFYlzcLA8Nl+NtUVF0sA7MsXsP1UyJoMp4YLEuNSfAP+JcXn/tWtIaxVXM"
        crossorigin="anonymous"></script>
    <link href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/6.6.0/css/all.min.css" rel="stylesheet">
</head>
<body>
    
    <!-- Intel Geti Header -->
    <div id="mv_navbar"></div>

    <!-- Bgimg -->
    <section>
        <div class="intel_geti_bg_img">
            <div class="container">
                <div class="col-lg-12 col-md-12 col-sm-12 dflex">
                    <div class="mv_bannertxb pr-5 mpr-5">
                        <p class="mv_banner_subtitle">Community</p>
                        <h2>Blog</h2>
                        <p class="mv_banner_text">Get the latest on computer vision AI from Intel.</p>
                    </div>
                </div>
            </div>
        </div>
        <div class="mv_mobile_img">
            <div class="mv_mobile_heading">Community</div>
            <img src="/img/mv_image/mob_-community.webp" alt="">
        </div>
        <div class="intel_product_mobile_img">
            <div class="mv_mobile_bannertxb pr-5 mpr-5">
                <h2>Blog</h2>
                <p class="mv_banner_text">Get the latest on computer vision AI from Intel.</p>
            </div>
        </div>
    </section>

    <!-- Enhance -->
    <section>
        <div class="mv_featured_bg_color">
            <div class="container">
                <div class="mv_breadcrumb row">
                    <div class="col-md-12">
                        <ol class="mv_spark_breadcrumb_items">
                            <li><a class="mv_spark_hyperlink" href="">Home</a></li>
                            <li class="mv_spark_breadcrumb_item">Community</li>
                            <li class="mv_spark_breadcrumb_item"><a class="mv_spark_hyperlink" href="">Blogs</a></li>
                            <li class="mv_spark_breadcrumb_item">Efficient, custom object detection training template made easy</li>
                        </ol>
                    </div>
                </div>
                <div class="row mv_enhance_content">
                    <div class="col-md-8">
                        <div class="mv_date_row">
                            <div class="mv_date_box">
                                <p class="">Feb. 1, 2023</p>
                            </div>
                            <!-- Enhance Model -->
                            <span class="mv_socialIcon mv_spark_card_vertical_buttons">
                                <div data-bs-toggle="modal" data-bs-target="#mv_enhance_share_model">
                                    <i class="fa-solid fa-share-nodes"></i>
                                </div>
                            </span>
                        </div>

                        <div class="mv_enhance_heading">
                            <h1>Efficient, custom object detection training template made easy</h1>
                        </div>

                        <div class="mv_request_trail">
                            <button><a href="">Request Trail</a></button>
                        </div>

                        <ul class="mv_enhance_ul">
                            <li>This blog is a summary of the scientific research published here.</li>
                            <li>The blog highlights the workflow developed in the research to enable efficient object detection model development across many different use cases, with varying dataset sizes, without worrying about heavily customizing a workflow for every use case.</li>
                        </ul>

                        <p class="mv_enhance_p">Deep Learning algorithms are widely used in the industry today – from detecting defects in parts on the factory production line to recommending products to shoppers on e-commerce websites. These algorithms proved their high accuracy and efficiency and have driven significant innovations in businesses utilizing them. These successes and promises have inspired everyone to utilize them in their projects: from a student in a lab project and an enthusiast, who wants to detect his cat in the home camera footage, to a developer from the corporation, looking to ensure that <a class="mv_enhance_a" href="">workers wear safety gear</a>.</p>

                        <p class="mv_enhance_p">However, in the field of deep learning for computer vision, most of the academic research studies tend to provide the highest accuracy on the well-known industry standard – COCO benchmark, tuning features directly to this dataset. But, when applied on a more realistic dataset, that is neither perfect nor balanced, such solutions built on standard COCO benchmarks in general, <a class="mv_enhance_a" href="">perform unsatisfactorily</a>.</p>

                        <p class="mv_enhance_p">Additionally, a model and training pipeline carefully optimized for a specific dataset rarely generalizes well to training on a different dataset. This problem in the AI field is called a “domain shift”. Moreover, fine-tuning and optimizing models and training pipelines for each use case is simply unrealistic, that requires extensive data science, developer, and compute resources – making AI initiatives unrealistic and cost-prohibitive <a class="mv_enhance_a" href="">in many cases</a>.</p>

                        <p class="mv_enhance_p">In this article, our focus is to highlight the challenges in building such a pipeline for object detection computer vision models and discuss our approach to solving these challenges.</p>

                        <h3 class="mv_enhance_h3">Essential elements and associated challenges for creating an object detection model</h3>

                        <p class="mv_enhance_p">There are 3 key elements that impact the overall deep learning model accuracy on a specific dataset and should be carefully tuned for each use cases:</p>

                        <ol class="mv_enhance_ol">
                            <li><strong>Architecture.</strong> Architectures define the structure of the neural network, enabling these networks to learn how to identify the influence of specific input components to achieve a specific output. These setups ultimately affect how accurate or efficient a deep learning model will be in final application at runtime. Additionally, new architectures are being developed frequently which adds the need to continuously evaluate them to develop the best model for specific use cases.</li>
                            <li><strong>Image preprocessing pipeline.</strong> Augmenting the dataset during pre-processing stages, such as by adjusting contrasts, perspectives, input sizes, etc. during preprocessing stages become important to make a model robust. However, it also makes finding a balance for efficient model training challenging.</li>
                            <li><strong>Training pipeline.</strong> Optimizing various learning parameters, such as learning rate, number of epochs, etc. – such technical details require expertise and make model training slow and computationally expensive.</li>
                        </ol>

                        <p class="mv_enhance_p">Expert resources are needed if we are to build these model training pipelines for every use case. The resources and expertise needed to balance these aspects, while building an object detection model, make it challenging for broader adoption. It becomes further challenging if one intends to develop a broadly applicable and efficient model training template that can be applied across various use cases, with varying dataset sizes and complexities.</p>

                        <h3 class="mv_enhance_h3">How does Intel Geti software help solve these challenges?</h3>

                        <p class="mv_enhance_p">To address these challenges, we have developed an alternative approach: a dataset-agnostic template solution for object detection training. It consists of carefully chosen and pre-trained models together with a robust training pipeline for further training. Such a solution works out-of-the-box and provides a strong baseline across a wide range of use-cases.[1] It can be used on its own or as a starting point for further fine-tuning for specific use cases when needed. This solution forms the backbone of Intel® Geti™ software, Intel’s computer vision platform for model development, and enables users of Intel Geti software to efficiently build object detection models.</p>

                        <p class="mv_enhance_p">For users who want to get a ready-to-use solution without diving into technical details, architectures, and various combinations of training parameter experiments, we have carefully chosen 3 templates, based on our research, to train on any dataset, each in different performance-accuracy trade-off regime at inference runtime<sup>[1]</sup>:</p>

                        <ol class="mv_enhance_ol">
                            <li>The fastest model (<a class="mv_enhance_a" href="">SSD</a>)</li>
                            <li>The most accurate model (<a class="mv_enhance_a" href="">VFNet</a>)</li>
                            <li>The balance between speed and accuracy one (<a class="mv_enhance_a" href="">ATSS</a>)</li>
                        </ol>

                        <p class="mv_enhance_p">These final candidates can be deployed on supported hardware with the <a class="mv_enhance_a" href="">OpenVINO toolkit</a> and even further optimized with OpenVINO’s Neural Network Compression Framework (<a class="mv_enhance_a" href="">NNCF</a>) for optimal performance.</p>

                        <h3 class="mv_enhance_h3">Intel Geti software’s template solutions – how did we achieve this?</h3>

                        <p class="mv_enhance_p">These templates are the result of parallel training experiments on a corpus of 11 datasets, as described in the paper.[1] We optimized the choice of architectures and training tricks with respect to the average results on the whole corpora of datasets, as mentioned above, and performance-accuracy trade-offs.</p>

                        <p class="mv_enhance_p">
                            <img class="w-100" src="/img/mv_image/Figure-1-1.png" alt="">
                        </p>
                        <div class="mv_video_caption">Workflow of the research methodology.</div>
                        
                        <p class="mv_enhance_p">Here are the most important elements considered when developing these solutions:</p>

                        <ol class="mv_enhance_ol">
                            <li>
                                <strong>Variability of datasets.</strong> To make sure that this solution achieves expected performance-accuracy trade-offs, we collected a set of 11 public datasets. They vary in terms of the domains, number of images, classes, object sizes, difficulty, and horizontal/vertical alignment. During experiments, we focused on the overall accuracy and behavior on each subset and each dataset particularly to make sure, that tricks work well in any use case.
                                <p class="mv_enhance_p">
                                    <img style="margin-top: 30px;" class="w-100" src="/img/mv_image/Figure-2.png" alt="">
                                </p>
                                <div class="mv_video_caption">Datasets used in the research. <sup>[1]</sup></div>
                            </li>
                            <li>
                                <strong>Architecture choice.</strong> We conducted experiments on several different architectures for each of the 3 different regimes of accuracy-efficiency trade off. Some of the results, including the “finalists” architectures, are shown in the table below:
                                <p class="mv_enhance_p">
                                    <img style="margin-top: 30px;" class="w-100" src="/img/mv_image/Figure-3.png" alt="">
                                </p>
                                <div class="mv_video_caption">Detailed performance of chosen models across all datasets. The relative performance relies on specific model architecture recommendations for various performance-accuracy trade-off regime <sup>[1]</sup></div>
                                <p class="mv_enhance_p">These architectures were further optimized during the experiments.</p>
                            </li>
                            <li>
                                Data preprocessing. For data augmentation, we used classic methods that have gained the trust of researchers: random crop, horizontal flip, multiscale training, and brightness and color distortions. We also carefully tuned the resolution characteristics for each model to achieve the best quality results.
                            </li>
                            <li>
                                <strong>Training pipeline:</strong> We introduced an “Early Stopping” mechanism to dynamically determine the number of epochs to train the model, based on the desired accuracy while reducing the training time. This allowed our training pipeline to balance itself based on the varying complexity of different datasets. We also introduced “ReduceOnPlateau” parameter to dynamically adjust the learning rate in our training pipeline, and iteration patience dynamically adjusts the amount of training based on the dataset sizes. <sup>[1]</sup>
                            </li>
                        </ol>

                        <h3 class="mv_enhance_h3">Conclusion</h3>

                        <p class="mv_enhance_p">The object detection training templates developed with this approach provide an efficient and broadly applicable model training pipeline, across use cases, dataset sizes, and accuracy-performance tradeoff needs. This template solution powers Intel Geti software, Intel’s computer vision platform for model development, and enables users of Intel Geti software to efficiently build object detection models. We have chosen model architectures for Intel Geti software by evaluating the trade-off on various accuracy-performance regimes as described in this research. This enables users of the platform to easily select model architectures and efficiently train them for their use case taking advantage of the training template described in this research, without spending time evaluating themselves.</p>

                        <p class="mv_enhance_p">For more technical details on our experiments, readers are advised to check out the published research <a class="mv_enhance_a" href="">here<sup>[1]</sup></a>.</p>

                        <h3 class="mv_enhance_h3">Reference:</h3>

                        <p class="mv_enhance_p">Galina Zalesskaya, Bogna Bylicka, Eugene Liu, <em><i>“How to train an accurate and efficient object detection model on any dataset”,</i></em> <a class="mv_enhance_a" href="">arXiv:2211.17170</a></p>

                        <h3 class="mv_enhance_h3">Technical Details</h3>

                        <p style="font-size: 12px;" class="mv_enhance_p">System configuration for running parallel experiments described in the blog: 1 node, Intel® Core™ i9-10980XE CPU, 18 cores, HT On, Turbo On, Total Memory 128GB, Ubuntu 20.04.5 LTS, Kernel 5.15.0-56-generic, gcc (Ubuntu 9.4.0-1ubuntu1~20.04.1) 9.4.0, GPU NVIDIA Corporation GA102 [GeForce RTX 3090], driver version: 470.161.03, CUDA version: 11.4, 2TB NVMe SSD</p>

                        <h3 class="mv_enhance_h3">Disclaimers</h3>

                        <p style="font-size: 12px;" class="mv_enhance_p">Performance varies by use, configuration, and other factors. Learn more at www.Intel.com/PerformanceIndex.<br>Performance results are based on testing as of dates shown in configurations and may not reflect all publicly available updates.<br>See backup for configuration details.<br>No product or component can be absolutely secure.<br>Your costs and results may vary.<br>
                        Intel technologies may require enabled hardware, software or service activation.<br>© Intel Corporation. Intel, the Intel logo, and other Intel marks are trademarks of Intel Corporation or its subsidiaries. Other names and brands may be claimed as the property of others.</p>
                    </div>
                    <div class="col-md-4">
                        <div class="mv_related_blog_margin">
                            <div class="mv_related_blog">
                                <h4>Related Blog</h4>
                                <ul class="mv_related_ul">
                                    <div class="d-flex">
                                        <i class="fa-solid fa-chevron-right"></i>
                                        <li><a href="">Intel<sup>®</sup> Geti<sup>™</sup> 2.0.0 Release: Advancing AI Model Development</a></li>
                                    </div>
                                    <div class="d-flex">
                                        <i class="fa-solid fa-chevron-right"></i>
                                        <li><a href="">Data and AI Metrics with Intel<sup>®</sup> Geti<sup>™</sup></a></li>
                                    </div>
                                    <div class="d-flex">
                                        <i class="fa-solid fa-chevron-right"></i>
                                        <li><a href="">Intel<sup>®</sup> Geti<sup>™</sup> AI Software Overview: Learn What Is Under the Hood</a></li>
                                    </div>
                                    <div class="d-flex">
                                        <i class="fa-solid fa-chevron-right"></i>
                                        <li><a href="">Intel<sup>®</sup> Geti<sup>™</sup> Software Recognized by SIA as Winner of the Best New Products & Solutions Award for Video Analytics  at ISC West, 2024</a></li>
                                    </div>
                                    <div class="d-flex">
                                        <i class="fa-solid fa-chevron-right"></i>
                                        <li><a href="">Mastering the Intel<sup>®</sup> Geti<sup>™</sup> SDK in 9 Steps: A Beginner’s Guide</a></li>
                                    </div>
                                    <div class="d-flex">
                                        <i class="fa-solid fa-chevron-right"></i>
                                        <li><a href="">The Next Evolution: Intel<sup>®</sup> Geti<sup>™</sup> 1.8.0 is here</a></li>
                                    </div>
                                    <div class="d-flex">
                                        <i class="fa-solid fa-chevron-right"></i>
                                        <li><a href="">Interactive Annotation with SAM – speeding up the time to model</a></li>
                                    </div>
                                    <div class="d-flex">
                                        <i class="fa-solid fa-chevron-right"></i>
                                        <li><a href="">Computer Vision Task Overview and Applications</a></li>
                                    </div>
                                    <div class="d-flex">
                                        <i class="fa-solid fa-chevron-right"></i>
                                        <li><a href="">The Intel<sup>®</sup> Geti<sup>™</sup> SDK: A Game-Changer for Rapid AI Model Development and Deployment in your production system</a></li>
                                    </div>
                                </ul>
                            </div>
                        </div>
                    </div>
                </div>
            </div>
        </div>
    </section>

    <!-- Learn More About -->
    <section>
        <div class="mv_more_about_bg_color">
            <div class="container">
                <div class="mv_more_about">
                    <h2>Learn More About the Intel<sup>®</sup> Geti<sup>™</sup> Software</h2>
                    <p>Learn how you can build AI models at scale with Intel<sup>®</sup> Geti<sup>™</sup> software.</p>
                </div>
                <div class="mv_more_about_button">
                    <div style="text-align: center;" class="mv_learn_more">
                        <button><a href="">Contact Us<i class="fa-solid fa-arrow-right-long"></i></a></button>
                    </div>
                </div>
            </div>
        </div>
    </section>

    <!-- Footer -->
    <div id="footer"></div>

    <!---------------------------------------- Model ---------------------------------------->
    <!-- Enhance Model -->
    <div class="modal" id="mv_enhance_share_model" tabindex="-1">
        <div class="modal-dialog modal-dialog-centered mv_platform_dialog">
          <div class="modal-content">
            <div class="modal-header mv_plaform_header">
              <h4 class="modal-title mv_platform_title">Efficient, custom object detection training template made easy</h4>
              <button type="button" class="btn-close" data-bs-dismiss="modal" aria-label="Close"></button>
            </div>
            <div class="modal-body mv_platform_body">
              <p>https://geti.intel.com/blog/efficient-custom-object-detection-training-template-made-easy</p>
            </div>
            <div class="text-center mv_padshar">
                <div class="mv_custom_button">
                    <a href="https://www.facebook.com/share_channel/?link=https%3A%2F%2Fgeti.intel.com%2Fvideo%2Fintroduction-to-intels-next-generation-computer-vision-ai-platform&app_id=966242223397117&source_surface=external_reshare&display&hashtag">
                        <img src="/img/mv_image/icon_fb.svg" alt="">
                    </a>
                </div>
                <div class="mv_custom_button">
                    <a href="https://x.com/intent/tweet?text=Platform&url=https%3A%2F%2Fgeti.intel.com%2Fvideo%2Fintroduction-to-intels-next-generation-computer-vision-ai-platform">
                        <img src="/img/mv_image/icon_tw.svg" alt="">
                    </a>
                </div>
                <div class="mv_custom_button">
                    <a href="https://www.linkedin.com/uas/login?session_redirect=https%3A%2F%2Fwww.linkedin.com%2FshareArticle%3Ftitle%3DPlatform%26url%3Dhttps%253A%252F%252Fgeti.intel.com%252Fvideo%252Fintroduction-to-intels-next-generation-computer-vision-ai-platform">
                        <img src="/img/mv_image/icon_in.svg" alt="">
                    </a>
                </div>
                <div class="mv_custom_button">
                    <a href="">
                        <img src="/img/mv_image/icon_copy_link.svg" alt="">
                    </a>
                </div>
            </div>
          </div>
        </div>
    </div>
    <!-- --------------------------------------------------------------------------------- -->

    <!-- script intel geti header -->
    <script>
        // header include
        fetch("/vaidikhtml/intel_geti_platform_header.html")
            .then((response) => response.text())
            .then((data) => {
            document.getElementById("mv_navbar").innerHTML = data;
            setupDropdown();
            });

        function setupDropdown() {
            const dropdownToggle = document.getElementById("dropdownToggle");
            const dropdownMenu = document.getElementById("dropdownMenu");
            const dropdownIcon = document.getElementById("dropdownIcon");

            // console.log(dropdownToggle, dropdownMenu, dropdownIcon); // Check if any are null

            if (dropdownToggle && dropdownMenu && dropdownIcon) {
            dropdownToggle.addEventListener("click", function (event) {
                event.preventDefault(); // Prevent the default anchor behavior
                const isOpen = dropdownMenu.style.display === "block";

                // Toggle dropdown visibility
                dropdownMenu.style.display = isOpen ? "none" : "block";

                // Change the icon based on dropdown state
                dropdownIcon.classList.toggle("fa-chevron-down", isOpen);
                dropdownIcon.classList.toggle("fa-chevron-up", !isOpen);
            });
            } else {
            console.error("One or more dropdown elements are null:", {
                dropdownToggle,
                dropdownMenu,
                dropdownIcon,
            });
            }
        }
    </script>

    <!-- script footer -->
    <script>
        // footer include 
        fetch('/y_index/y_footer.html')
            .then(response => response.text())
            .then(data => {
                document.getElementById('footer').innerHTML = data;
            });
    </script>

</body>
</html>