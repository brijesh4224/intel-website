<!DOCTYPE html>
<html lang="en">

<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>Llama 3 with Intel® AI Solutions</title>
    <link href="https://cdn.jsdelivr.net/npm/bootstrap@5.0.2/dist/css/bootstrap.min.css" rel="stylesheet"
        integrity="sha384-EVSTQN3/azprG1Anm3QDgpJLIm9Nao0Yz1ztcQTwFspd3yD65VohhpuuCOmLASjC" crossorigin="anonymous">

    <link href=" https://fonts.cdnfonts.com/css/intel-clear " rel="stylesheet">
    <link rel="stylesheet" href="../css/owl.carousel.min.css">
    <link rel="stylesheet" href="../css/yatri.css">
    <link rel="stylesheet" href="../css/rushita.css">
    <link rel="stylesheet" href="../css/rushita_automotive.css">

    <link rel="stylesheet" href="../css/owl.theme.default.min.css">
    <style>
        * {
            font-family: 'Intel Clear', sans-serif;
        }

        .dk_new_options_table {
            border: none !important;
            justify-content: center !important;
            text-align: center !important;
        }

        .dk_new_options_table thead tr td {
            margin-left: 0;
            max-width: fit-content;
            white-space: normal;
            overflow: auto;
            background: #fff;
            padding: 1rem;
            text-align: left;
            border-left: .125rem solid #e2e2e2;
            font-weight: 700 !important;
        }

        .dk_new_options_table thead tr:nth-child(even) td {
            background-color: #f7f7f7;
        }

        .mv_intel_amx h2 {
            font-weight: 300;
        }

        .mv_intel_amx {
            font-size: 1.25rem;
        }

        .mv_intel_amx_bg_color {
            background-color: #0068B5;
        }

        .mv_intel_amx_content {
            padding-right: 200px;
        }

        .mv_intel_amx_item {
            align-content: center;
        }

        .mv_intel_amx {
            color: #fff;
            padding: 1rem;
        }

        .mv_intel_amx h3 {
            font-weight: 300;
        }

        .mv_intel_amx p {
            margin-top: 1.5rem;
            margin-bottom: 0rem;
        }

        .mv_intel_amx_image {
            padding: 1rem;
        }

        .mv_intel_amx_image img {
            width: 100%;
            /* height: 199px; */
        }

        .mv_intel_amx_heading_text {
            font-size: 1.2rem;
            line-height: 1.15;
        }

        .VK_sidebar_active_link {
            color: #262626;
            font-weight: 700;
        }

        .VK_sidebar_active_link:hover {
            color: #262626;
        }

        .VK_print_email_font span {
            font-size: 1.375rem;
        }

        .VK_side_bar_postion_stickey {
            position: sticky;
            top: 0px;
            z-index: 3;
            background-color: #fff;
        }

        .VK_side_heading {
            font-size: 26px;
            font-weight: 400;
        }

        .VK_sidebar_dropdown P {
            margin-left: .313rem !important;
            margin-bottom: .313rem !important;
        }

        .VK_sidebar_dropdown details {
            margin-left: .313rem !important;
            margin-bottom: .313rem !important;
        }
    </style>
</head>

<body>
    <div id="navbar"></div>

    <section class="m_ai_tdrop">
        <div>
            <button class="btn dropdown-toggle" type="button" data-bs-toggle="dropdown" aria-expanded="false">
                Developers
            </button>
            <ul class="dropdown-menu">
                <li><a class="dropdown-item m_dropActive"
                        href="../dhruvin_developer-tools/ds_Developer-Zone.html">Overview</a></li>
                <li><a class="dropdown-item m_dropActive"
                        href="../rushita_Solutions/k_solutions_in_Viewall_SDF_Industrial-Automation_Control-flow-Enforcement_Technology.html">Topics
                        & Technologies</a></li>
                <li><a class="dropdown-item m_dropActive"
                        href="../dhruvin_developer-tools/ds_Development-Tools.html">Tools</a></li>
                <li><a class="dropdown-item m_dropActive"
                        href="../rushita_Solutions/k_solutions_in_Viewall_SDF_Industrial-Automation_Hardware-Platforms.html">Hardware
                        Platforms</a></li>
                <li><a class="dropdown-item m_dropActive"
                        href="../dhruvin_developer-tools/ds_Resource-Documentation-Center.html">Resources &
                        Documentation</a></li>
                <li><a class="dropdown-item m_dropActive" href="../dhruvin_developer-tools/ds_Learn.html">Learn</a>
                </li>
                <li><a class="dropdown-item m_dropActive"
                        href="../dhruvin_developer-tools/ds_Communities-and-Events.html">Community & Events</a></li>
                <li><a class="dropdown-item m_dropActive"
                        href="../dhruvin_developer-tools/ds_Developer-Programs.html">Developer Programs</a></li>
                <li><a class="dropdown-item m_dropActive" href="../dhruvin_developer-tools/ds_Get-Help.html">Get
                        Help</a></li>
            </ul>
        </div>


        <div class="m_ai_shlash">/</div>
        <div>
            <button class="btn dropdown-toggle" type="button" data-bs-toggle="dropdown" aria-expanded="false">
                Tools
            </button>
            <ul class="dropdown-menu">
                <li><a class="dropdown-item m_dropActive" href="../Product/B20_developer_catelog.html">Software
                        Catalog</a></li>
                <li><a class="dropdown-item m_dropActive" href="../Product/B17_oneapi.html">oneAPI</a></li>
                <li><a class="dropdown-item m_dropActive"
                        href="../rushita_Solutions/k_solutions_Intel-Tiber™Edge-Platform.html">Intel® Tiber™ Edge
                        Platform</a></li>
                <li><a class="dropdown-item m_dropActive" href="../Product/B10_intel_Quarts.html">FPGA</a></li>
                <li><a class="dropdown-item m_dropActive" href="../VK_developers/VK_technology_sdk.html">Intel®
                        Active Management Technology SDK</a></li>
                <li><a class="dropdown-item m_dropActive" href="../VK_developers/VK_intel_adviser.html">Intel®
                        Advisor</a></li>
                <li><a class="dropdown-item m_dropActive" href="#">Intel® AI Reference Models</a></li>
                <li><a class="dropdown-item m_dropActive"
                        href="../rushita_Solutions/k_solutions_Intel-Collaboration-Suite-for-WebRTC.html">Intel®
                        Collaboration Suite for WebRTC SDK</a>
                </li>
                <li><a class="dropdown-item m_dropActive" href="../Product/B1_19_Intel_AICloud.html">Intel® Tiber™
                        AI Cloud</a></li>
                <li><a class="dropdown-item m_dropActive"
                        href="../rushita_Solutions/k_solutions_Intel-Distribution-for-Python.html">Intel® Distribution
                        for Python*</a></li>
                <li><a class="dropdown-item m_dropActive"
                        href="../rushita_Solutions/k_solutions_Intel-Distribution-for-GDB.html">Intel® Distribution for
                        GDB*</a></li>
                <li><a class="dropdown-item m_dropActive" href="#">Intel® DPC++ Compatibility Tool</a></li>
                <li><a class="dropdown-item m_dropActive" href="#">Intel® Dynamic Application Loader</a></li>
                <li><a class="dropdown-item m_dropActive"
                        href="../rushita_Solutions/k_solutions_Topics_viewall_Cloud-Insider-Program_AI-Frameworks-and-Tools.html">Frameworks</a>
                </li>
                <li><a class="dropdown-item m_dropActive" href="#">Intel® Embree</a></li>
                <li><a class="dropdown-item m_dropActive" href="../VK_developers/VK_ai_scikit.html">Intel® Extension
                        for Scikit-learn*</a></li>
                <li><a class="dropdown-item m_dropActive"
                        href="../rushita_Solutions/k_solutions_Intel-Fortran-Compiler.html">Intel® Fortran Compiler</a>
                </li>
                <li><a class="dropdown-item m_dropActive" href="#">Intel® Graphics Performance Analyzers</a></li>
                <li><a class="dropdown-item m_dropActive"
                        href="../rushita_Solutions/k_solutions_Intel-HE-Toolkit.html">Intel® Homomorphic Encryption
                        Toolkit</a></li>
                <li><a class="dropdown-item m_dropActive"
                        href="../rushita_Solutions/k_solutions_Intel-In-Band-Manageability.html">Intel® In-Band
                        Manageability</a></li>
                <li><a class="dropdown-item m_dropActive"
                        href="../rushita_Solutions/k_solutions_Intel-Cryptography-Primitives-Library.html">Intel®
                        Integrated Performance Primitives</a></li>
                <li><a class="dropdown-item m_dropActive" href="../rushita_Solutions/">Intel® Integrated Simulation
                        Infrastructure with
                        Modeling</a></li>
                <li><a class="dropdown-item m_dropActive"
                        href="../rushita_Solutions/k_solutions_Instruction-Set-Architecture(ISA)Extensions.html">Instruction
                        Set Architecture (ISA) Extensions</a>
                </li>
                <li><a class="dropdown-item m_dropActive"
                        href="../rushita_Solutions/k_solutions_Intel-Intelligent-Storage-Acceleration-Library.html">Intel®
                        Intelligent Storage Acceleration Library
                        (Intel® ISA-L)</a></li>
                <li><a class="dropdown-item m_dropActive" href="#">Modin*</a></li>
                <li><a class="dropdown-item m_dropActive" href="#">Intel® MPI Library</a></li>
                <li><a class="dropdown-item m_dropActive" href="#">Intel® Neural Compressor</a></li>
                <li><a class="dropdown-item m_dropActive" href="#">OpenCL™ Runtime</a></li>
                <li><a class="dropdown-item m_dropActive" href="#">Intel® Open Image Denoise</a></li>
                <li><a class="dropdown-item m_dropActive" href="#">Intel® Open Path Guiding Library (Intel® Open
                        PGL)</a></li>
                <li><a class="dropdown-item m_dropActive" href="#">Pin</a></li>
                <li><a class="dropdown-item m_dropActive" href="#">Intel® Platform Analysis Library</a></li>
                <li><a class="dropdown-item m_dropActive" href="#">Intel Tools for OpenCL™ Software</a></li>
                <li><a class="dropdown-item m_dropActive" href="#">Intel Tools for OpenCL™ Applications</a></li>
                <li><a class="dropdown-item m_dropActive" href="#">Intel® OpenSWR</a></li>
                <li><a class="dropdown-item m_dropActive" href="#">OpenVINO™ Toolkit</a></li>
                <li><a class="dropdown-item m_dropActive" href="#">Intel® Open Volume Kernel Library</a></li>
                <li><a class="dropdown-item m_dropActive" href="#">Intel® Optimization for XGBoost*</a></li>
                <li><a class="dropdown-item m_dropActive" href="#">Intel® OSPRay</a></li>
                <li><a class="dropdown-item m_dropActive" href="#">Intel® OSPRay for Hydra*</a></li>
                <li><a class="dropdown-item m_dropActive" href="#">Intel® OSPRay Studio</a></li>
                <li><a class="dropdown-item m_dropActive" href="#">PyTorch* Optimizations from Intel</a></li>
                <li><a class="dropdown-item m_dropActive" href="#">TensorFlow* Optimizations from Intel</a></li>
                <li><a class="dropdown-item m_dropActive" href="#">Intel® Rendering Toolkit</a></li>
                <li><a class="dropdown-item m_dropActive" href="#">Intel® Smart Edge Open</a></li>
                <li><a class="dropdown-item m_dropActive" href="#">Intel® Software Guard Extensions</a></li>
                <li><a class="dropdown-item m_dropActive" href="#">Intel® Secure Device Onboard</a></li>
                <li><a class="dropdown-item m_dropActive" href="#">Intel® Software Development Emulator</a></li>
                <li><a class="dropdown-item m_dropActive" href="#">Intel® Trust Domain Extensions (Intel® TDX)</a>
                </li>
                <li><a class="dropdown-item m_dropActive" href="#">Intel® Quantum SDK</a></li>
                <li><a class="dropdown-item m_dropActive" href="#">Intel® Query Processing Library (Intel® QPL)</a>
                </li>
                <li><a class="dropdown-item m_dropActive" href="#">Intel® Video Processing Library</a></li>
                <li><a class="dropdown-item m_dropActive" href="#">Intel® VTune™ Profiler</a></li>
                <li><a class="dropdown-item m_dropActive" href="#">Resellers</a></li>
            </ul>
        </div>
        <div class="m_ai_shlash">/</div>
        <div>
            <button class="btn dropdown-toggle" type="button" data-bs-toggle="dropdown" aria-expanded="false">
                oneAPI
            </button>
            <ul class="dropdown-menu">
                <li><a class="dropdown-item m_dropActive" href="#">Overview</a></li>
                <li><a class="dropdown-item m_dropActive" href="#">Data Parallel C++/SYCL*</a></li>
                <li><a class="dropdown-item m_dropActive" href="#">Toolkits</a></li>
                <li><a class="dropdown-item m_dropActive" href="#">Tech Articles & How-Tos</a></li>
                <li><a class="dropdown-item m_dropActive" href="#">Components</a></li>
                <li><a class="dropdown-item m_dropActive" href="#">Code Samples</a></li>
                <li><a class="dropdown-item m_dropActive" href="#">Training</a></li>
                <li><a class="dropdown-item m_dropActive" href="#">Documentation</a></li>
                <li><a class="dropdown-item m_dropActive" href="#">Support</a></li>
            </ul>
        </div>
        <div class="m_ai_shlash">/</div>
        <div>
            <button class="btn dropdown-toggle" type="button" data-bs-toggle="dropdown" aria-expanded="false">
                Tech Articles & How-Tos
            </button>
            <ul class="dropdown-menu">
                <li><a class="dropdown-item m_dropActive" href="#">Library</a></li>
                <li><a class="dropdown-item m_dropActive" href="#">News Updates</a></li>
                <li><a class="dropdown-item m_dropActive" href="#">Webinars</a></li>
            </ul>
        </div>
        <div class="m_ai_shlash">/</div>
        <div class="m_ai_httl">Llama 3 with Intel® AI Solutions
        </div>
    </section>
    <section class="k_bgblue">
        <div class="k_container11">
            <div class="row text-white py-4">
                <h3 class="fw-light">Accelerate Meta* Llama 3 with Intel® AI Solutions</h3>
            </div>
        </div>
    </section>
    <section class="k_space k_spacenone">
        <div class="k_container11">
            <div class="row  g-3">
                <div class="float-end k_bignone" style="padding-left:70%;">
                    <div>
                        <a href="#" class="fs-4"><i class="fa-solid fa-print mx-3 k_icon0"></i></a>
                        <a href="#" class="fs-4"> <i class="fa-regular fa-envelope k_icon0"></i></a>
                    </div>
                </div>
                <div class="col-lg-3 col-md-4 col-sm-12">
                    <div class="VK_sticky_side_bar VK_side_bar_postion_stickey">
                        <div>
                            <div class="VK_sidebar_dropdown">
                                <ul class="k_listnone k_menu ">
                                    <li class="k_text px-2"><a href="#section1">Intel® Gaudi® AI Accelerators</a></li>
                                    <li class="k_text px-2"><a href="#section1">Intel® Xeon® Scalable Processors</a></li>
                                    <li class="k_text px-2"><a href="#section1">Intel® Client Platforms</a></li>
                                    <li class="k_text"><a href="#" class="k_submenu-toggle">Summary</a>
                                        <ul class="k_listnone k_submenu">
                                            <li class="k_text"><a href="#"></a>References</a></li>
                                            <li class="k_text"><a href="#"></a>Product and Performance Information</a></li>
                                        </ul>
                                    </li>
                                </ul>
                            </div>
                        </div>
                    </div>
                    <div>
                        <p><b>Stay in the Know on All Things CODE</b></p>
                        <p class="text-center k_btnget py-2 k_under k_btn100 my-2 kcokbtn1024" style="width: 80px;">
                            <a href="#" class="text-white">Sign Up</a>
                        </p>
                        <div class=" mt-4 ">
                            <div>
                                <p class="k_plink1">
                                    Fan Zhao, Stefanka Von Brzeski, Antony Vance, Patricia M Mwove, Chen Levkovich, Susan Lansing, Todd Matsler, Gurman Singh, Agnes So, Andres Rodriguez</p>
                                    <p>Intel Corporation</p>
                            </div>
                        </div>
                    </div>
                </div>
                <div class="col-lg-8 col-md-7 col-sm-12  k_16smpx k_width75">
                    <div class="float-end mx-3 k_smnone">
                        <div>
                            <a href="#" class="fs-4"><i class="fa-solid fa-print mx-3 k_icon0"></i></a>
                            <a href="#" class="fs-4"> <i class="fa-regular fa-envelope k_icon0"></i></a>
                        </div>
                    </div>
                    <div class=" k_smpaddnone k_smpaddnone1 pt-5">
                        <p class="articleDate">4/18/2024</p>
                        <p>As a close partner of Meta* on <a aria-label="Link Llama 2" href="https://llama.meta.com/" rel="noreferrer noopener" title="https://llama.meta.com/">Llama 2</a>, we are excited to support the launch of Meta <a href="https://llama.meta.com/">Llama 3</a>, the next generation of Llama models. Effective today, we have validated our AI product portfolio on the first Llama 3 8B and 70B models. In addition to running on Intel data center platforms, Intel is enabling&nbsp;developers to now run Llama 3 locally and optimize for applications and models on Intel client CPUs and GPUs.</p>
                        <p>Innovations, derivative models, and applications based on Llama 2 have enabled a vibrant ecosystem, including Purple Llama, which advances the development of open software to build <a href="/content/www/us/en/developer/topic-technology/artificial-intelligence/training/generative-ai.html">generative AI</a> trust and safety. Llama 3 introduces new capabilities, additional sizes, and enhanced model performance. This release features pretrained and fine-tuned language models with 8B and 70B parameter counts, demonstrating improved performance on a wide range of industry benchmarks, and enabling new capabilities such as improved reasoning. Llama 3 uses a new tokenizer that&nbsp;encodes language much more efficiently, leading to improved model performance.</p>
                        <p>Intel is bringing AI everywhere through a robust AI product portfolio that includes&nbsp;ubiquitous hardware and open software. In the data center, Intel® Gaudi® AI accelerators and Intel® Xeon® processors with Intel® Advanced Matrix Extensions (AMX) provide users with options to meet dynamic and wide-ranging AI requirements. On the client side, Intel enables LLMs to be run locally with either AI PCs powered by &nbsp;Intel® Core™ Ultra with an NPU and a built-in Arc™ GPU, or Arc discrete GPUs with&nbsp;Intel® Xᵉ Matrix Extensions (Intel® XMX) acceleration.</p>
                        <p>We are sharing our initial performance results of Llama 3 models on the Intel AI product portfolio using open-source software such as PyTorch*, DeepSpeed*, Hugging Face Optimum library and <a href="/content/www/us/en/developer/tools/oneapi/optimization-for-pytorch.html">Intel® Extension for PyTorch*</a>, which provide the latest software optimizations for LLMs.&nbsp;</p>
                        <h2 class="fw-light mt-5">Intel® Gaudi® AI Accelerators</h2>
                        <p>Purpose architected for high-performance, high-efficiency training and deployment of generative AI—multi-modal and large language models – Intel® Gaudi® 2 accelerators have optimized performance on Llama 2 models – 7B, 13B and 70B parameter – and provide first-time performance measurements for the new Llama 3 model for <a href="/content/www/us/en/developer/topic-technology/artificial-intelligence/training/inference-and-large-language-models.html">inference</a> and fine-tuning. With the maturity of Intel® Gaudi® software, we were able to easily run the new Llama 3 model and quickly generate results for both inference and fine-tuning, which you can see in the tables below. In addition, Meta Llama 3 is supported on the newly announced Intel®&nbsp;Gaudi® 3 accelerator.</p>
                        <!-- <div class="k_table-container">
                            <table class="k_tebal col-lg-12  col-md-8 col-sm-3  k_tspace">
                                <thead class="k_tebal text-center">
                                    <tr class="k_e2bg  k_tpadding1 k_tsmall">
                                        <th class=" k_cell-padding1 k_rightborder1 col-lg-4 col-md-3 col-1">
                                        </th>
                                        <th class="col-lg-8 col-md-2 col-1"><p><b>Intel® Technologies and Resources for AI in Retail</b></p>
                                       </th>
                                   
                                    </tr>
                                </thead>
                                <tbody class="k_tebal k_14px">
                                    <tr class="  k_rightborder1 k_tpadding1 k_tsmall">
                                        <td>
                                            <p class="k_plink1 k_intext1blue1"></p>
                                           </td>
                                           <td>
                                           <p class="text-center"><b>Intel® AI Hardware</b></p>
                                           </td>
                                    </tr>
                                    <tr class="k_tgrey k_rightborder1 k_tpadding1 k_tsmall">
                                        <td>
                                         <p class="k_plink1 k_intext1blue1"><a href="#">Intel® Core™ processors </a>and <a href="#"> Intel Atom® processors</a></p>
                                        </td>
                                        <td>
                                        <p>Intel® processors come in a range of options to give you the right level of performance where you need it. These CPU offerings are ideal for retail solutions at the edge, including digital signage, robotics, POS systems, and interactive kiosks.</p>
                                        </td>
                                       
                                    
                                    </tr>
                                    <tr class="  k_rightborder1 k_tpadding1 k_tsmall">
                                        <td>
                                            <p class="k_plink1 k_intext1blue1"><a href="#">Intel® Xeon® Scalable processors</a></p>
                                           </td>
                                           <td>
                                           <p>Intel® Xeon® Scalable processors deliver high performance for machine learning and deep learning in the cloud, data center, or at the edge, with built-in features to accelerate AI. This gives you a strong foundation for demand forecasting, predictive analytics, product recommendations, and more—without the need to purchase additional GPUs</p>
                                           </td>
                                    </tr>
                                    <tr class="k_tgrey  k_rightborder1 k_tpadding1 k_tsmall">
                                        <td>
                                            <p class="k_plink1 k_intext1blue1">Intel® discrete GPUs:<a href="#">Intel® Data Center GPU Flex Series </a>and <a href="#"> Intel® Arc™ graphics solutions</a></p>
                                           </td>
                                           <td>
                                           <p>Intel® discrete GPUs are designed to complement your Intel® processors so you can more efficiently handle increasingly diverse and complex AI workloads such as multiple object detection or multiple classification models.</p>
                                           </td>
                                    </tr>
                                    <tr class="  k_rightborder1 k_tpadding1 k_tsmall">
                                        <td>
                                            <p class="k_plink1 k_intext1blue1"><a href="#">Intel® RealSense™ cameras</p>
                                           </td>
                                           <td>
                                           <p>Intel® RealSense™ technology enables vision‑based solutions designed to help you understand the retail environment in 3D.</p>
                                           </td>
                                    </tr>
                                  
                                </tbody>
                            </table>
                           
                        </div> -->
                        <p>Table 1. Llama 3 inference on Intel® Gaudi® 2 Accelerator&nbsp;(* Average next token latency)</p>
                        <!--  -->
                        <p>Table 2. Llama 3 fine-tuning on Intel® Gaudi® 2&nbsp;Accelerator</p>
                        <p>Use this&nbsp;<a aria-label="Link first example" href="https://github.com/huggingface/optimum-habana/tree/main/examples/text-generation" rel="noreferrer noopener" title="https://github.com/huggingface/optimum-habana/tree/main/examples/text-generation">first example</a> to run the inference performance benchmark and this&nbsp;<a aria-label="Link second example" href="https://github.com/huggingface/optimum-habana/tree/main/examples/language-modeling#peft" rel="noreferrer noopener" title="https://github.com/huggingface/optimum-habana/tree/main/examples/language-modeling#peft">second example</a> to run the fine-tuning benchmark.</p>

                        <h2 class="fw-light mt-5">Intel® Xeon® Scalable Processors</h2>
                        <p>Intel Xeon processors address demanding end-to-end AI workloads. Available across major cloud service providers, Intel Xeon processors have an AI engine in every core AMX that unlocks new levels of performance for inference and training. Furthermore, generic computing in Xeons can provide lower latency and work alongside other workloads.&nbsp;</p>
                        <p>Intel has been continuously optimizing LLM inference for Xeon platforms. &nbsp;As an example, compared to Llama 2 launch software improvements in PyTorch and Intel<strong>®</strong> Extension for PyTorch have evolved in delivering 5x latency reduction. The optimization makes use of paged attention and tensor parallel to maximize the available compute utilization and memory bandwidth.&nbsp;Figure 1 shows the performance of Meta Llama 3 8B inference on AWS m7i.metal-48x instance, which is based on 4th Gen Intel Xeon Scalable processor.&nbsp;</p>
                        <div class="my-5">
                            <img src="../img/rushita_img/llam.png" alt="" width="100%">
                            <figcaption>Figure 1. Llama 3 next token latency on AWS instance</figcaption>
                        </div>
                        <p>We benchmarked Meta Llama 3 on an Intel® Xeon® 6 processor with Performance cores (formerly code-named Granite Rapids) to share a preview of the performance. These preview numbers demonstrate that Intel Xeon 6 offers a 2x improvement on Llama 3 8B inference latency compared to widely available 4th Gen Intel Xeon processors, and the ability to run larger language models, like Llama 3 70B, under 100ms per generated token on a single two socket server.</p>
                        <div class="my-5">
                            <img src="../img/rushita_img/llam1.png" alt="" width="100%">
                            <figcaption>Figure 2.&nbsp;Llama 3 next token latency Intel Xeon 6 with P-cores (formerly code-named Granite Rapids)</figcaption>
                        </div>
                        <p class="k_plink1 k_intext1blue1">Given that Llama 3 is featured with a tokenizer that&nbsp;encodes language more efficiently, a quick comparison between Llama 3 and Llama 2 was done using a randomly picked input prompt. The number of tokens tokenized by Llama 3 is 18% less than Llama 2&nbsp;with the same input <a aria-label="Link prompt" href="#">prompt</a>. Therefore, even though Llama 3 8B is larger than Llama 2 7B, the inference latency by running BF16 inference on AWS m7i.metal-48xl for the whole prompt is almost the same (Llama 3 is 1.04x faster than Llama 2 in the case that we evaluated.).</p>
                        <p class="k_plink1 k_intext1blue1">Developers can find <a aria-label="Link instructions" href="#">instructions</a> to run Llama 3 and other LLMs on Intel® Xeon® platforms.&nbsp;</p>

                        <h2 class="fw-light mt-5">Intel® Client Platforms</h2>
                        <p>AI PCs powered by Intel® Core™ Ultra processors deliver exceptional local AI performance in the client space through specialized silicon in three engines: CPU, GPU, and NPU. For Llama 3 evaluation, we targeted the built-in Arc™ GPU available in the Core™ Ultra H series products.</p>
                        <p>In an initial round of evaluation, the Intel® Core™ Ultra processor already generates faster than typical human reading speeds. These results are driven by the built-in Arc™ GPU with 8 Xe-cores, inclusive DP4a AI acceleration, and up to 120 GB/s of system memory bandwidth. We are excited to invest continued performance and power efficiency optimizations on Llama 3, especially as we move to our next-generation processors.</p>
                        <p class="k_plink1 k_intext1blue1">With launch day support across Intel® Core™ Ultra processors and Intel® Arc™ graphics products, the collaboration between Intel and Meta provides both a local development vehicle and deployment across millions of devices. Intel client hardware is accelerated through comprehensive software <a href="#">tools</a>, including PyTorch and Intel® Extension for PyTorch used for local research and development and <a href="#">OpenVINO™ Toolkit</a> for model deployment and inference.</p>
                        <p>&nbsp;</p>

                        <h2 class="fw-light mt-5">Intel® Gaudi® AI Accelerators</h2>
                        <h2 class="fw-light mt-5">Intel® Gaudi® AI Accelerators</h2>
                        <h2 class="fw-light mt-5">Intel® Gaudi® AI Accelerators</h2>
                        <h2 class="fw-light mt-5">Intel® Gaudi® AI Accelerators</h2>
                        <h2 class="fw-light mt-5">Intel® Gaudi® AI Accelerators</h2>
                        <h2 class="fw-light mt-5">Intel® Gaudi® AI Accelerators</h2>
                        <h2 class="fw-light mt-5">Intel® Gaudi® AI Accelerators</h2>
                        <h2 class="fw-light mt-5">Intel® Gaudi® AI Accelerators</h2>
                        <h2 class="fw-light mt-5">Intel® Gaudi® AI Accelerators</h2>
                        <h2 class="fw-light mt-5">Intel® Gaudi® AI Accelerators</h2>
                        <h2 class="fw-light mt-5">Intel® Gaudi® AI Accelerators</h2>

                        <p>Use this&nbsp;<a aria-label="Link first example" href="https://github.com/huggingface/optimum-habana/tree/main/examples/text-generation" rel="noreferrer noopener" title="https://github.com/huggingface/optimum-habana/tree/main/examples/text-generation">first example</a> to run the inference performance benchmark and this&nbsp;<a aria-label="Link second example" href="https://github.com/huggingface/optimum-habana/tree/main/examples/language-modeling#peft" rel="noreferrer noopener" title="https://github.com/huggingface/optimum-habana/tree/main/examples/language-modeling#peft">second example</a> to run the fine-tuning benchmark.</p>

                        <p class="k_plink1 k_intext1blue1">Intel Gaudi 2 AI Accelerator: Measurement on&nbsp;System HLS-Gaudi2 with eight Habana Gaudi2 HL-225H Mezzanine cards and two Intel® Xeon® Platinum 8380 CPU @ 2.30GHz, and 1TB of System Memory. Common Software Ubuntu22.04, Gaudi Software version 1.15.0-479, PyTorch: Models run with PyTorch v2.2.0 use&nbsp;<a href="#" title="#">this</a> Docker image Environment: These workloads are run using the Docker images running directly on the Host OS. Performance was measured on April 17th 2024.</p>
                        <p>Intel Xeon Processor: Measurement on Intel Xeon®&nbsp;6 Processor (formerly code-named: Granite Rapids) using: 2x Intel® Xeon® 6 processors with P-cores, HT On, Turbo On, NUMA 6, Integrated Accelerators Available [used]: DLB [8], DSA [8], IAA[8], QAT[8], Total Memory 1536GB (24x64GB DDR5 8800 MT/s [8800 MT/s]), BIOS BHSDCRB1.IPC.0031.D44.2403292312, microcode 0x810001d0, 1x Ethernet Controller I210 Gigabit Network Connection 1x SSK Storage 953.9G, Red Hat Enterprise Linux 9.2 (Plow), 6.2.0-gnr.bkc.6.2.4.15.28.x86_64, Test by Intel on April 17th 2024.</p>
                        <p>Measurement on&nbsp;4th Gen&nbsp;Intel® Xeon®&nbsp;Scalable processor (formerly code-named: Sapphire Rapids) using: AWS m7i.metal-48xl instance, 2x&nbsp;Intel® Xeon® Platinum 8488C, 48cores, HT On, Turbo On, NUMA 2, Integrated Accelerators Available [used]: DLB [8], DSA [8], IAA[8], QAT[8], Total Memory 768GB (16x32GB DDR5 4800 MT/s [4400 MT/s]); (16x16GB DDR5 4800 MT/s [4400 MT/s]), BIOS Amazon EC2, microcode 0x2b000590, 1x Ethernet Controller Elastic Network Adapter (ENA) Amazon Elastic Block Store 256G, Ubuntu 22.04.4 LTS, 6.5.0-1016-aws, Test by Intel on April 17th 2024.</p>
                        <p>Intel® Core™ Ultra: Measurement on an Intel Core Ultra 7 155H platform (MSI Prestige 16 AI Evo B1MG-005US) using 32GB LP5x 6400Mhz total memory, Intel graphics driver 101.5382 WHQL, Windows 11 Pro version 22631.3447, Balanced OS power plan, Best Performance OS power mode, Extreme Performance MSI Center mode, and core isolation enabled. Test by Intel on April 17th 2024.</p>
                        <p>Intel® Arc™ A-Series Graphics: Measurement on Intel Arc A770 16GB Limited Edition graphics using&nbsp;Intel Core i9-14900K,&nbsp;ASUS ROG MAXIMUS Z790 HERO motherboard,&nbsp;32GB (2x 16GB) DDR5 5600Mhz and&nbsp;Corsair MP600 Pro XT 4TB NVMe. Software configurations include Intel graphics driver&nbsp;101.5382 WHQL,&nbsp;Windows 11 Pro version&nbsp;22631.3447,&nbsp;Performance power policy, and core isolation disabled. Test by Intel on April 17th 2024.</p>
                    </div>
                </div>
            </div>
    </section>
    <section class="my-4" style="font-size: 13px;">
        <div class="k_container11">
            <div class="row">
                <div>
                    <hr class="mb-5">
                    <p>Product and Performance Information </p>
                
                    <div class="k_plink1 k_intext1blue1"><sup>1</sup>Performance varies by use, configuration and other
                        factors. Learn more at &nbsp;<a href="#">www.Intel.com/PerformanceIndex.</a>.
                    </div>
                </div>
            </div>
        </div>
    </section>
    <div id="footer"></div>
    <script>
        // navbar include  
        fetch('../y_index/y_navbar.html')
            .then(response => response.text())
            .then(data => {
                document.getElementById('navbar').innerHTML = data;
            });
        // footer include 
        fetch('../y_index/y_footer.html')
            .then(response => response.text())
            .then(data => {
                document.getElementById('footer').innerHTML = data;
            });
    </script>
    <script src="https://cdn.jsdelivr.net/npm/@splidejs/splide@4.1.4/dist/js/splide.min.js"></script>
    <script src="../js/jquery-3.7.1.js"></script>

    <script src="../js/owl.carousel.min.js"></script>
    <script src="../js/rushita.js"></script>
</body>

</html>