<!DOCTYPE html>
<html lang="en">

<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>Document</title>

    <!-- font family -->
    <link href="https://fonts.cdnfonts.com/css/intel-clear" rel="stylesheet">
    <!-- boootstap file -->
    <link href="https://cdn.jsdelivr.net/npm/bootstrap@5.0.2/dist/css/bootstrap.min.css" rel="stylesheet"
        integrity="sha384-EVSTQN3/azprG1Anm3QDgpJLIm9Nao0Yz1ztcQTwFspd3yD65VohhpuuCOmLASjC" crossorigin="anonymous">
    <!-- costom css file -->
    <link rel="stylesheet" href="/css/vivek.css">
    <link rel="stylesheet" href="/css/yatri.css">

    <!-- all.min file -->
    <link rel="stylesheet" href="/css/all.min.css">

</head>

<body>

    <main>

        <!-- header -->
        <header>
            <div id="navbar"></div>
        </header>


        <!-- poster -->
        <section class=" VK_light_blue">
            <div class="VK_cont">
                <div class="row m-0">
                    <div class="col text-white">
                        <h1 class="VK_py_pre_heading fw-light m-0 py-4 mt-2">
                            Effective Deployment of AI Workloads in a Windows* Environment powered by Intel® Xe Graphics
                        </h1>
                        <div
                            class="d-flex pb-4 col-md-4 col-sm-6 col-12 flex-md-row flex-column justify-content-between">
                            <div class="d-flex flex-md-column flex-row">
                                <p class="mb-2 me-3 w-100">
                                    ID
                                </p>
                                <p class="mb-2 me-3 w-100">
                                    672474
                                </p>
                            </div>
                            <div class="d-flex flex-md-column flex-row">
                                <p class="mb-2 me-3 w-100">
                                    Updated
                                </p>
                                <p class="mb-2 me-3 w-100">
                                    3/31/2021
                                </p>
                            </div>
                            <div class="d-flex flex-md-column flex-row">
                                <p class="mb-2 me-3 w-100">
                                    Version
                                </p>
                                <p class="mb-2 me-3 w-100">
                                    Latest
                                </p>
                            </div>
                            <div class="d-flex flex-md-column flex-row">
                                <p class="mb-2 me-3 d-none d-md-block">
                                    &nbsp;
                                </p>
                                <p class="mb-2 me-3 w-100">
                                    Public
                                </p>
                            </div>
                        </div>
                    </div>
                </div>
            </div>
        </section>


        <!--  -->
        <section class="">
            <div class="VK_cont py-5 VK_border_bottom">
                <div class="row m-0">
                    <div class="col-md-4 col-lg-3 p-0">

                    </div>
                    <div class="col-md-8 ps-sm-5">
                        <div class="">
                            <div class="VK_section_descriptions">
                                <div class="text-end">
                                    <p class="m-0 VK_print_email_font">
                                        <span class="VK_a mx-2 d-inline-block">
                                            <i class="fa-solid fa-print"></i>
                                        </span>
                                        <span class="VK_a mx-2 d-inline-block">
                                            <i class="fa-regular fa-envelope"></i>
                                        </span>
                                    </p>
                                </div>
                            </div>
                            <section class="mt-5" id="VK_Abstract">
                                <p>
                                    Note: This article represents work completed by
                                    <a href="" class="Vk_text_underline_dots VK_a">
                                        Intel Software Innovator, Silviu-Tudor Serban
                                    </a>
                                </p>
                            </section>
                            <div class="mt-5">
                                <h3 class="VK_side_heading fw-bolder mb-3">
                                    Introduction to Intel® Xe Graphics Architecture
                                </h3>
                                <p>
                                    Intel® Xe graphics is a novel GPU architecture consisting of four different
                                    microarchitectures: Intel® Processor Graphics Xᵉ-LP for integrated and entry-level
                                    discrete graphics, Intel® Processor Graphics Xᵉ-HP and Intel® Processor Graphics
                                    Xᵉ-HPG for enthusiast and datacenter parts, and Intel® Processor Graphics Xᵉ-HPC for
                                    high performance computing clusters.
                                </p>
                                <p>
                                    In this article we focus on the Intel® Processor Graphics Xᵉ-LP microarchitecture
                                    and its compute performance along with potential for powering AI workloads. The Xᵉ
                                    architecture is uniquely positioned to leverage
                                    <a href="" class="Vk_text_undrline_dots VK_a">
                                        Intel® Deep Link
                                    </a>
                                    technology, where users can simultaneously unleash the compute performance of all
                                    system silicon on complex AI workloads.
                                </p>
                                <p>
                                    Our Xᵉ-LP system is a Dell XPS* 13 laptop, powered by an Intel® Core™ i7-1165G7 CPU
                                    and Intel® Iris® Xe integrated graphics.
                                </p>
                                <div class="d-flex justify-content-center mt-4">
                                    <div class="col-md-8">
                                        <img src="/img/vivek/VK_199.jpg" class="w-100" alt="">
                                    </div>
                                </div>
                                <p class="text-center">
                                    Xᵉ-LP system (Dell XPS* 13 laptop)
                                </p>
                                <p>
                                    The Intel Xᵉ-LP iGPU lives on the same chip with the processor and utilizes a
                                    portion of the system’s memory, rather than using a dedicated DDR chip.
                                </p>
                                <p>
                                    In terms of performance, the Xᵉ-LP iGPU is very capable for compute scenarios and
                                    its 96 Execution Units and 1.30Ghz max running frequency translate to outstanding AI
                                    inference capabilities for its size and wattage.
                                </p>
                            </div>
                            <div class="mt-5">
                                <h3 class="VK_side_heading fw-bolder">
                                    Intel® Xe Powered AI Workloads in Windows* Environments
                                </h3>
                                <p>
                                    Microsoft DirectML* and
                                    <a href="" class="Vk_text_underline_dots VK_a">
                                        Intel® Distribution of OpenVINO™ toolkit
                                    </a>
                                    are powerful platforms which are turbocharging AI development by lowering the
                                    barrier of entry to Machine Learning. We will explore Intel Xᵉ architecture’s
                                    potential for multi-platform AI deployment and its performance running Microsoft
                                    DirectML and OpenVINO™ workloads.
                                </p>
                                <p class="m-0">
                                    To make things more interesting, we will run our assessment on three very different
                                    systems:
                                </p>
                                <ul>
                                    <li>
                                        The Dell XPS* 13 laptop powered by a 4-core Intel i7-1165G7 and Intel® Iris® Xe
                                        integrated graphics
                                    </li>
                                    <li>
                                        An HP workstation powered by a 10-core Intel® Xeon®-4114 and Quadro* P1000
                                        discrete GPU
                                    </li>
                                    <li>
                                        A custom high-end PC powered by an 8-core Intel i7-10700K and an RTX* 3070
                                        discrete GPU
                                    </li>
                                </ul>
                            </div>
                            <div class="mt-5">
                                <h3 class="VK_n22 fw-bolder">
                                    Microsoft DirectML
                                </h3>
                                <p>
                                    <a href="" class="Vk_text_underline_dots VK_a">
                                        DirectML
                                    </a>
                                    is a high-performance, hardware-accelerated DirectX 12 library for machine learning.
                                    DirectML provides GPU acceleration for common machine learning tasks across a broad
                                    range of supported hardware and drivers, including all DirectX 12-capable GPUs from
                                    vendors such as AMD, Intel, NVIDIA, and Qualcomm.
                                </p>
                                <p>
                                    When used standalone, the DirectML API is a low-level DirectX 12 library and is
                                    suitable for high-performance, low-latency applications such as frameworks, games,
                                    and other real-time applications. The seamless interoperability of DirectML with
                                    Direct3D 12 as well as its low overhead and conformance across hardware makes
                                    DirectML ideal for accelerating machine learning when both high performance is
                                    desired, and the reliability and predictability of results across hardware is
                                    critical.
                                </p>
                                <p>
                                    DirectML efficiently executes the individual layers of your inference model on the
                                    GPU (or on AI-acceleration cores, if present). Each layer is an operator, and
                                    DirectML provides a library of low-level, hardware-accelerated machine learning
                                    primitive operators. While DirectML is in its early stages compared to the more
                                    mature CUDA, it provides several advantages that make it an attractive option for
                                    many AI workloads.
                                </p>
                            </div>
                            <div class="mt-5">
                                <h3 class="VK_n22 fw-bolder">
                                    DirectML Environment Setup
                                </h3>
                                <p>
                                    A really nice feature of DirectML is that it provides support for TensorFlow*, one
                                    of the most popular end-to-end open source platforms for machine learning, via the
                                    <a href="" class="Vk_text_underline_dots VK_a">
                                        TensorFlow-DirectML project.
                                    </a>
                                </p>
                                <p>
                                    TensorFlow requires Python, which leads us to installing
                                    <a href="" class="Vk_text_underline_dots VK_a">
                                        Anaconda
                                    </a>
                                    as a first step. Anaconda is one of the best tools for setting up and managing
                                    Python environments on Windows. It’s also free and open source.
                                </p>
                                <p>
                                    Assuming Anaconda is successfully installed, we can fire up the Anaconda Command
                                    Prompt and create a development environment with 3 commands:
                                </p>
                                <div class="my-5">
                                    <div class="VK_theme_bg border pb-4 pe-3 pt-2 rounded-3">
                                        <div class="text-end">
                                            <button class="m-0 text-primary border-0 bg-transparent VK_copy_btn">
                                                <i class="fa-regular fa-copy"></i>
                                            </button>
                                        </div>
                                        <div class="VK_code-container">
                                            <div class="VK_line-number"></div>
                                            <code class="VK_theme_color">
<pre class="VK_code-block"><p class="m-0">conda create --name directml python=<span class="VK_code_blue">3.7</span> 
conda activate directml 
pip install tensorflow-directml</p></pre>
                                            </code>
                                        </div>
                                    </div>
                                </div>
                                <p>
                                    In order to verify everything is working well, we can fire up a Python session and
                                    see if TensorFlow DirectML is running correctly:
                                </p>
                                <div class="my-5">
                                    <div class="VK_theme_bg border pb-4 pe-3 pt-2 rounded-3">
                                        <div class="text-end">
                                            <button class="m-0 text-primary border-0 bg-transparent VK_copy_btn">
                                                <i class="fa-regular fa-copy"></i>
                                            </button>
                                        </div>
                                        <div class="VK_code-container">
                                            <div class="VK_line-number"></div>
                                            <code class="VK_theme_color">
<pre class="VK_code-block"><p class="m-0"><span class="VK_code_blue">import</span> tensorflow.compat.v1 <span class="VK_code_blue">as</span> tf 
tf.enable_eager_execution(tf.ConfigProto(log_device_placement=<span class="VK_code_blue">True</span>)) 
<span class="VK_code_blue">print</span>(tf.add([<span class="VK_code_blue">1.0</span>, <span class="VK_code_blue">2.0</span>], [<span class="VK_code_blue">3.0</span>, <span class="VK_code_blue">4.0</span>])) </p></pre>
                                            </code>
                                        </div>
                                    </div>
                                </div>
                                <p>
                                    We should see a message similar to the following if there were no errors:
                                </p>
                                <div class="my-5">
                                    <div class="VK_theme_bg border pb-4 pe-3 pt-2 rounded-3">
                                        <div class="text-end">
                                            <button class="m-0 text-primary border-0 bg-transparent VK_copy_btn">
                                                <i class="fa-regular fa-copy"></i>
                                            </button>
                                        </div>
                                        <div class="VK_code-container">
                                            <div class="VK_line-number"></div>
                                            <code class="VK_theme_color">
<pre class="VK_code-block"><p class="m-0"><span class="VK_code_blue">2021-03-25 11:27:18.235973</span>: I tensorflow/core/common_runtime/dml/dml_device_factory.cc:<span class="VK_code_blue">45</span>] DirectML device enumeration: found <span class="VK_code_blue">1</span> compatible adapters. </p></pre>
                                            </code>
                                        </div>
                                    </div>
                                </div>
                                <p>
                                    This means DirectML and Tensorflow are up and running on our system and all we need
                                    to do to run our detection scripts in the future is to launch an Anaconda Prompt and
                                    activate the DirectML environment.
                                </p>
                                <div class="d-flex justify-content-center">
                                    <img src="/img/vivek/VK_200.png" class="w-100" alt="">
                                </div>
                            </div>
                            <div class="mt-5">
                                <h3 class="VK_n22 fw-bolder">
                                    DirectML Xe Graphics Performance
                                </h3>
                                <p>
                                    We’ve selected a custom trained Resnet101 model from our production pipeline for
                                    comparing inference performance using DirectML. The model is trained on large images
                                    and running inference on it is sufficiently resource intensive to challenge the
                                    three test systems.
                                </p>
                                <p>
                                    Our primary goal regarding the Xᵉ-LP graphics system is to see how well suited it is
                                    for running inference in a production setup and to see how well Xᵉ-LP stacks up
                                    against the discrete GPUs from our test systems.
                                </p>
                                <p>
                                    As we can see in Table 1 below, the Xᵉ-LP system packs quite a punch. Remarkably the
                                    total TDP of the i7-1165G7, which includes the iGPU, is only 28W.
                                </p>
                                <div class="overflow-auto">
                                    <p class="text-center m-0">
                                        Table 1: DirectML Custom Resnet101 performance results
                                    </p>
                                    <table class="VK_side_nav_table">
                                        <thead class="">
                                            <tr>
                                                <th class="pe-5 py-1 VK_bg_e6 ps-3">
                                                    Hardware configuration
                                                </th>
                                                <th class="pe-5 py-1 VK_bg_e6 ps-3">
                                                    Inference Platform
                                                </th>
                                                <th class="pe-5 py-1 VK_bg_e6 ps-3">
                                                    Inference Device
                                                </th>
                                                <th class="pe-5 py-1 VK_bg_e6 ps-3">
                                                    Average FPS (Higher is Better)
                                                </th>
                                                <th class="pe-5 py-1 VK_bg_e6 ps-3">
                                                    Average CPU Load (Lower is better)
                                                </th>
                                                <th class="pe-5 py-1 VK_bg_e6 ps-3">
                                                    System Type
                                                </th>
                                            </tr>
                                        </thead>
                                        <tbody>
                                            <tr class="VK_theme_tbody">
                                                <td class="p-3">
                                                    i7-10700K
                                                </td>
                                                <td class="p-3">
                                                    DirectML
                                                </td>
                                                <td class="p-3">
                                                    CPU
                                                </td>
                                                <td class="p-3">
                                                    0.7
                                                </td>
                                                <td class="p-3">
                                                    max-content
                                                </td>
                                                <td class="p-3">
                                                    Desktop
                                                </td>
                                            </tr>
                                            <tr class="VK_theme_tbody">
                                                <td class="p-3">
                                                    i7-1165G7
                                                </td>
                                                <td class="p-3">
                                                    DirectML
                                                </td>
                                                <td class="p-3">
                                                    CPU
                                                </td>
                                                <td class="p-3">
                                                    0.4
                                                </td>
                                                <td class="p-3">
                                                    max-content
                                                </td>
                                                <td class="p-3">
                                                    Ultrabook(AC power)
                                                </td>
                                            </tr>
                                            <tr class="VK_theme_tbody">
                                                <td class="p-3">
                                                    i7-1165G7 w/ Xe-LP iGPU
                                                </td>
                                                <td class="p-3">
                                                    DirectML
                                                </td>
                                                <td class="p-3">
                                                    GPU
                                                </td>
                                                <td class="p-3">
                                                    0.6
                                                </td>
                                                <td class="p-3">
                                                    20%
                                                </td>
                                                <td class="p-3">
                                                    Ultrabook(AC power)
                                                </td>
                                            </tr>
                                            <tr class="VK_theme_tbody">
                                                <td class="p-3">
                                                    Xeon-4114 w/ Quadro P1000
                                                </td>
                                                <td class="p-3">
                                                    DirectML
                                                </td>
                                                <td class="p-3">
                                                    GPU
                                                </td>
                                                <td class="p-3">
                                                    0.6
                                                </td>
                                                <td class="p-3">
                                                    10%
                                                </td>
                                                <td class="p-3">
                                                    Desktop
                                                </td>
                                            </tr>
                                            <tr class="VK_theme_tbody">
                                                <td class="p-3">
                                                    i7-10700K w/ RTX 3070
                                                </td>
                                                <td class="p-3">
                                                    DirectML
                                                </td>
                                                <td class="p-3">
                                                    GPU
                                                </td>
                                                <td class="p-3">
                                                    2.2
                                                </td>
                                                <td class="p-3">
                                                    10%
                                                </td>
                                                <td class="p-3">
                                                    Desktop
                                                </td>
                                            </tr>
                                        </tbody>
                                    </table>
                                </div>
                                <p class="mt-4 m-0">
                                    By further analyzing the results table, we can extract a set of interesting
                                    conclusions:
                                </p>
                                <ul>
                                    <li>
                                        Running inference explicitly on CPU produces good results in terms of FPS, but
                                        it comes at a great cost regarding CPU load, which makes it a less than ideal
                                        option when critical software needs to run on the same machine.
                                    </li>
                                    <li>
                                        While the CPU load looks to be a bit higher on the Xe-LP system compared to the
                                        others, this is most likely a consequence of a less powerful mobile CPU compared
                                        to desktop CPUs (4 core i7-1165G7 vs 8 core i7-10700K vs 10 core Xeon-4114)
                                    </li>
                                    <li>
                                        The DirectML inference performance of Xᵉ-LP is on par with the dedicated Quadro
                                        P1000 workstation dedicated graphics card
                                    </li>
                                    <li>
                                        While DirectML inference FPS on the RTX 3070 is roughly 3.5x faster than Xᵉ-LP,
                                        the RTX 3070 can draw up to 300W in intensive loads and comes at a considerably
                                        higher price tag.
                                    </li>
                                </ul>
                            </div>
                            <div class="mt-5">
                                <h3 class="VK_n22 fw-bolder">
                                    Intel® Distribution of OpenVINO™ toolkit
                                </h3>
                                <p class="m-0">
                                    <a href="" class="Vk_text_underline_dots VK_a">
                                        Intel OpenVINO
                                    </a>
                                    is a platform for computer vision inference and deep neural network optimization
                                    which focuses on high-performance AI deployment from Edge to Cloud and it works on
                                    Linux, Windows and MacOS.
                                    <br>
                                    It provides optimized calls for OpenCV and OpenVX and a common API for heterogeneous
                                    inference execution across a wide range of computer vision accelerators- CPU, GPU,
                                    VPU and FPGA.
                                </p>
                                <p>
                                    A complete set of guides for getting up and running with OpenVINO is available
                                    <a href="" class="Vk_text_underline_dots VK_a">
                                        online.
                                    </a>
                                </p>
                                <div class="d-flex justify-content-center my-5">
                                    <div class="col-lg-8 col-xl-7 col-xxl-6">
                                        <img src="/img/vivek/VK_201.png" class="w-100" alt="">
                                    </div>
                                </div>
                                <p>
                                    Furthermore, an open model zoo containing pre-trained models, demos and a downloader
                                    tool for public models is provided with the distro as well as a separate
                                    <a href="" class="Vk_text_underline_dots VK_a">
                                        repository.
                                    </a>
                                </p>
                            </div>
                            <div class="mt-5">
                                <h3 class="VK_n22 fw-bolder">
                                    OpenVINO Environment Setup
                                </h3>
                                <p>
                                    Previously, we performed tests using our custom trained Resnet101 model on DirectML,
                                    so it makes sense to go through the OpenVINO Model Optimizer conversion process by
                                    using a very similar TensorFlow Resnet101 model, which is publicly available and
                                    pre-trained on the COCO dataset.
                                </p>
                                <p>
                                    Model Optimizer is a python command-line tool built to facilitate the transition
                                    between the training and deployment environment, by taking an existing trained model
                                    and converting it to the OpenVINO intermediate representation (ir).
                                    <br>
                                    Here are the steps for completing the ir conversion process:
                                </p>
                                <p>
                                    <b>
                                        Step 1.
                                    </b>
                                    Retrieve the TensorFlow model from the modelzoo
                                    <a href="" class="Vk_text_underline_dots VK_a">
                                        repository.
                                    </a>
                                    There are plenty of available models ready for out-of-the-box inference, however for
                                    the scope of this article we choose "faster_rcnn_resnet101_coco"
                                </p>
                                <p>
                                    <b>
                                        Step 2.
                                    </b>
                                    Extract the "faster_rcnn_resnet101_coco" archive to a location of your choice. For
                                    simplicity we chose the D: partition.
                                    The files of primary interest are "interested frozen_inference_graph.pb" and
                                    "pipeline.config", which will be used with the model python script
                                </p>
                                <p>
                                    <b>
                                        Step 3.
                                    </b>
                                    We need to run 2 OpenVINO setup scripts to make sure all prerequisites are
                                    installed.
                                    <br>
                                    We open a Command Prompt and run the following commands:
                                </p>
                                <div class="my-5">
                                    <div class="VK_theme_bg border pb-4 pe-3 pt-2 rounded-3">
                                        <div class="text-end">
                                            <button class="m-0 text-primary border-0 bg-transparent VK_copy_btn">
                                                <i class="fa-regular fa-copy"></i>
                                            </button>
                                        </div>
                                        <div class="VK_code-container">
                                            <div class="VK_line-number"></div>
                                            <code class="VK_theme_color">
<pre class="VK_code-block"><p class="m-0">> cd C:\Program Files (x86)\Intel\openvino_2021\<span class="VK_code_blue">bin</span>
> setupvars.bat
> cd C:\Program Files (x86)\Intel\openvino_2021\deployment_tools\model_optimizer\install_prerequisites
> install_prerequisites.bat</p></pre>
                                            </code>
                                        </div>
                                    </div>
                                </div>
                                <p>
                                    <b>
                                        Step 4.
                                    </b>
                                    Now we are ready to run the Model Optimizer script.
                                    <br>
                                    In the same Command Prompt we run:
                                </p>
                                <div class="my-5">
                                    <div class="VK_theme_bg border pb-4 pe-3 pt-2 rounded-3">
                                        <div class="text-end">
                                            <button class="m-0 text-primary border-0 bg-transparent VK_copy_btn">
                                                <i class="fa-regular fa-copy"></i>
                                            </button>
                                        </div>
                                        <div class="VK_code-container">
                                            <div class="VK_line-number"></div>
                                            <code class="VK_theme_color">
<pre class="VK_code-block"><p class="m-0">> cd C:\Program Files (x86)\Intel\openvino_2021\deployment_tools\model_optimizer
> python mo_tf.py --input_model D:/frozen_inference_graph.pb --output_dir D: --tensorflow_object_detection_api_pipeline_config D:/pipeline.config --tensorflow_use_custom_operations_config extensions/front/tf/faster_rcnn_support.json</p></pre>
                                            </code>
                                        </div>
                                    </div>
                                </div>
                                <p>
                                    If the script runs successfully, the output will resemble this:
                                </p>
                                <div class="d-flex justify-content-center mb-4">
                                    <img src="/img/vivek/VK_202.png" class="w-100" alt="">
                                </div>
                                <p>
                                    The result of this script conversion process is a set of 3 files that can be
                                    consumed by the OpenVINO inference engine: "frozen_inference_graph.xml",
                                    "frozen_inference_graph.bin", and "frozen_inference_graph.mapping".
                                </p>
                                <p>
                                    <b>
                                        Step 5.
                                    </b>
                                    Download and install
                                    <a href="" class="Vk_text_underline_dots VK_a">
                                        Visual Studio 2019
                                    </a>
                                </p>
                                <p>
                                    <b>
                                        Step 6.
                                    </b>
                                    Next, open a command prompt and run the following commands:
                                </p>
                                <div>
                                    <div class="VK_theme_bg border p-3 rounded-3">
                                        <div class="text-end">
                                            <button class="m-0 text-primary border-0 bg-transparent VK_copy_btn">
                                                <i class="fa-regular fa-copy"></i>
                                            </button>
                                        </div>
                                        <code class="VK_theme_color">
<pre><p class="m-0">> cd C:\Program Files (x86)\Intel\openvino_2021\inference_engine\samples\cpp
> build_samples_msvc.bat</p></pre>
                                        </code>
                                    </div>
                                </div>
                                <p class="mt-4 text-break">
                                    A Visual Studio solution named
                                    <b>
                                        Demos.sln
                                    </b>
                                    should now be available in the user home folder under
                                    \Documents\Intel\OpenVINO\omz_demos_build
                                </p>
                                <p>
                                    <b>
                                        Step 7.
                                    </b>
                                    Launch the generated Visual Studio solution, and then select the
                                    "object_detection_demo" project and set it as Startup Project:
                                </p>
                                <div class="d-flex justify-content-center">
                                    <img src="/img/vivek/VK_203.png" class="w-100" alt="">
                                </div>
                                <p class="mt-4">
                                    <b>
                                        Step 8.
                                    </b>
                                    Prepare a video file to run inference on and save it in D: directory as video.mp4.
                                </p>
                                <p>
                                    <b>
                                        Step 9.
                                    </b>
                                    Go back to Visual Studio and set the Command Arguments similar to this:
                                </p>
                                <div class="d-flex justify-content-center">
                                    <div class="col-md-8">
                                        <img src="/img/vivek/VK_204.png" class="w-100" alt="">
                                    </div>
                                </div>
                                <p class="mt-4">
                                    Note: A complete list of command line arguments for running the object detection
                                    demo is available
                                    <a href="" class="Vk_text_underline_dots VK_a">
                                        online.
                                    </a>
                                </p>
                                <p>
                                    <b>
                                        Step 10.
                                    </b>
                                    Run the Local Windows Debugger in order to observe the models as they are running
                                    inference. The OpenVINO environment is now ready for running inference.
                                </p>
                                <div class="d-flex justify-content-center">
                                    <div class="col-md-10">
                                        <img src="/img/vivek/VK_205.png" class="w-100" alt="">
                                    </div>
                                </div>
                            </div>
                            <div class="mt-5">
                                <h3 class="VK_side_heading fw-bolder">
                                    OpenVINO Xe performance
                                </h3>
                                <p>
                                    For consistency, we evaluate the OpenVINO optimized version of the custom Resnet101
                                    model which was used previously. This also facilitates a clear comparison between
                                    OpenVINO’s inference engine performance vs. that of DirectML.
                                </p>
                                <p>
                                    The results in Table 2 reveal that running on OpenVINO provides significant
                                    detection speed benefits, with the single caveat of not being able to run OpenVINO
                                    on the Quadro P1000 and RTX 3070.
                                </p>
                                <p class="m-0">
                                    That being said, we gain a very interesting set of insights:
                                </p>
                                <ul>
                                    <li>
                                        Running the Intel OpenVINO converted model, on the same hardware, provides up to
                                        3x FPS performance compared to the same hardware running DirectML, which is a
                                        significant boost.
                                    </li>
                                    <li>
                                        The inference FPS performance of Xe on OpenVINO is comparable to a RTX 3070 with
                                        DirectML and more than 3x faster than a P1000 Quadro dedicated GPU with
                                        DirectML.
                                    </li>
                                </ul>
                                <div class="overflow-auto mt-5">
                                    <p class="m-0 text-center mb-2">
                                        Table 2: DirectML & OpenVINO Custom Resnet101 performance results
                                    </p>
                                    <table class="">
                                        <thead>
                                            <tr>
                                                <th class="VK_bg_e6 ps-2 py-2 pe-3 border-white border-2">
                                                    Hardware configuration
                                                </th>
                                                <th class="VK_bg_e6 ps-2 py-2 pe-3 border-white border-2">
                                                    Inference Platform
                                                </th>
                                                <th class="VK_bg_e6 ps-2 py-2 pe-3 border-white border-2">
                                                    Inference Device
                                                </th>
                                                <th class="VK_bg_e6 ps-2 py-2 pe-3 border-white border-2">
                                                    Average FPS (Higher is Better)
                                                </th>
                                                <th class="VK_bg_e6 ps-2 py-2 pe-3 border-white border-2">
                                                    Average CPU Load (Lower is Better)
                                                </th>
                                                <th class="VK_bg_e6 ps-2 py-2 pe-3 border-white border-2">
                                                    System Type
                                                </th>
                                            </tr>
                                        </thead>
                                        <tbody class="VK_theme_tbody">
                                            <tr>
                                                <td>
                                                    i7-10700K
                                                </td>
                                                <td>
                                                    DirectML
                                                </td>
                                                <td>
                                                    CPU
                                                </td>
                                                <td>
                                                    0.7
                                                </td>
                                                <td>
                                                    max-content
                                                </td>
                                                <td>
                                                    Desktop
                                                </td>
                                            </tr>
                                            <tr>
                                                <td>
                                                    i7-10700K
                                                </td>
                                                <td>
                                                    OpenVINO
                                                </td>
                                                <td>
                                                    CPU
                                                </td>
                                                <td>
                                                    1.9
                                                </td>
                                                <td>
                                                    60%
                                                </td>
                                                <td>
                                                    Desktop
                                                </td>
                                            </tr>
                                            <tr>
                                                <td>
                                                    i7-1165G7
                                                </td>
                                                <td>
                                                    DirectML
                                                </td>
                                                <td>
                                                    CPU
                                                </td>
                                                <td>
                                                    0.4
                                                </td>
                                                <td>
                                                    max-content
                                                </td>
                                                <td>
                                                    Ultrabook
                                                    (AC Power)
                                                </td>
                                            </tr>
                                            <tr>
                                                <td>
                                                    i7-1165G7
                                                </td>
                                                <td>
                                                    OpenVINO
                                                </td>
                                                <td>
                                                    CPU
                                                </td>
                                                <td>
                                                    1.0
                                                </td>
                                                <td>
                                                    65%
                                                </td>
                                                <td>
                                                    Ultrabook
                                                    (AC Power)
                                                </td>
                                            </tr>
                                            <tr>
                                                <td>
                                                    i7-1165G7 + Xe-LP
                                                </td>
                                                <td>
                                                    DirectML
                                                </td>
                                                <td>
                                                    GPU
                                                </td>
                                                <td>
                                                    0.6
                                                </td>
                                                <td>
                                                    20%
                                                </td>
                                                <td>
                                                    Ultrabook
                                                    (AC Power)
                                                </td>
                                            </tr>
                                            <tr>
                                                <td>
                                                    i7-1165G7 + Xe-LP
                                                </td>
                                                <td>
                                                    OpenVINO
                                                </td>
                                                <td>
                                                    GPU
                                                </td>
                                                <td>
                                                    2.0
                                                </td>
                                                <td>
                                                    30%
                                                </td>
                                                <td>
                                                    Ultrabook
                                                    (AC Power)
                                                </td>
                                            </tr>
                                            <tr>
                                                <td>
                                                    Xeon-4114 + Quadro P1000
                                                </td>
                                                <td>
                                                    DirectML
                                                </td>
                                                <td>
                                                    GPU
                                                </td>
                                                <td>
                                                    0.6
                                                </td>
                                                <td>
                                                    10%
                                                </td>
                                                <td>
                                                    Desktop
                                                </td>
                                            </tr>
                                            <tr>
                                                <td>
                                                    i7-10700K + RTX 3070
                                                </td>
                                                <td>
                                                    DirectML
                                                </td>
                                                <td>
                                                    GPU
                                                </td>
                                                <td>
                                                    2.2
                                                </td>
                                                <td>
                                                    10%
                                                </td>
                                                <td>
                                                    Desktop
                                                </td>
                                            </tr>
                                        </tbody>
                                    </table>
                                </div>
                            </div>
                            <div class="mt-5">
                                <h3 class="VK_side_heading fw-light mb-4">
                                    Conclusion
                                </h3>
                                <p>
                                    In this article, we’ve taken a close look at the outstanding capabilities of the
                                    Xᵉ-LP microarchitecture for AI workloads.
                                </p>
                                <p>
                                    Given that Xᵉ-LP has a significantly smaller form factor compared to its sibling
                                    microarchitectures, we can only expect proportionally higher performance scaling up
                                    with upcoming Xᵉ-HP, Xᵉ-HPG and Xᵉ-HPC GPUs.
                                </p>
                                <p>
                                    Furthermore, when Intel® Xe graphics technology is combined with the power of the
                                    OpenVINO inferencing engine, we achieve performance levels that to date, have only
                                    been witnessed on significantly more costly AI computing platforms.
                                </p>
                                <p>
                                    We believe Intel® Xe graphics is a game changing technology that has the power to
                                    remove the traditional barriers of entry for AI and empower software developers and
                                    ML professionals to create new solutions that improve the lives of millions of
                                    people.
                                </p>
                            </div>
                            <div class="mt-5">
                                <h3 class="VK_side_heading fw-bolder mb-3">
                                    Elevate Your Graphics Skills
                                </h3>
                                <p>
                                    Ignite inspiration, share achievements, network with peers and get access to experts
                                    by becoming an
                                    <a href="" class="Vk_text_underline_dots VK_a">
                                        Intel® Software Innovator
                                    </a>.
                                    Game devs, media developers, and other creators can apply to be Intel® Software
                                    Innovators under the new Xᵉ Community track – opening a world of opportunity to
                                    craft amazing applications, games and experiences running on Xᵉ architecture.
                                </p>
                                <p>
                                    To start connecting and sharing your projects, join the global developer community
                                    on
                                    <a href="" class="Vk_text_underline_dots VK_a">
                                        Intel® DevMesh.
                                    </a>
                                </p>
                            </div>
                        </div>
                    </div>
                </div>
            </div>
        </section>

        <!--  -->
        <section class="py-5">
            <div class="VK_cont">
                <div class="row m-0">
                    <div class="col">
                        <p>
                            Product and Performance Information
                        </p>
                        <p class="VK_font14">
                            Performance varies by use, configuration and other factors. Learn more at 
                            <a href="" class="Vk_text_underline_dots VK_a">
                                www.Intel.com/PerformanceIndex.
                            </a>
                        </p>
                    </div>
                </div>
            </div>
        </section>


        <!-- footer -->
        <footer>
            <div id="footer"></div>
        </footer>

    </main>


    <!---------------- Javascript Files ---------------->

    <script>
        // navbar include
        fetch('/y_index/y_navbar.html')
            .then(response => response.text())
            .then(data => {
                document.getElementById('navbar').innerHTML = data;
            });
        // footer include 
        fetch('/y_index/y_footer.html')
            .then(response => response.text())
            .then(data => {
                document.getElementById('footer').innerHTML = data;
            });
    </script>

    <!-- jquery -->
    <script src="/js/jquery-3.7.1.js"></script>


    <!-- bootstrap js file -->
    <script src="https://cdn.jsdelivr.net/npm/bootstrap@5.0.2/dist/js/bootstrap.bundle.min.js"
        integrity="sha384-MrcW6ZMFYlzcLA8Nl+NtUVF0sA7MsXsP1UyJoMp4YLEuNSfAP+JcXn/tWtIaxVXM"
        crossorigin="anonymous"></script>

    <!-- costom js file -->
    <script src="/js/vivek.js"></script>

    <!-- all min -->
    <!-- <script src="/js/all.min.js"></script> -->


</body>

</html>